{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "experienced-income",
   "metadata": {},
   "source": [
    "# Resource Allocation Code Demo\n",
    "\n",
    "The Food Bank of the Southern Tier (FBST) is a member of Feeding America, focused on providing food security for people with limited financial resources, and serves six counties and nearly 4,000 square miles in the New York.  Under normal operations (non COVID times), the Mobile Food Pantry program is among the main activities of the FBST.  The goal of the service is to make nutritious and healthy food more accessible to people in underserved communities.  Even in areas where other agencies provide assistance, clients may not always have access to food due to limited public transportation options, or because those agencies are only open hours or days per work.\n",
    "\n",
    "Here we do a sample experiment testing out some of the existing and developed algorithms against a randomized heuristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54262089",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import or_suite\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exclusive-roots",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting out configuration parameter for the environment\n",
    "CONFIG = or_suite.envs.env_configs.resource_allocation_foodbank_config(3)\n",
    "# CONFIG = or_suite.envs.env_configs.resource_allocation_default_config\n",
    "\n",
    "\n",
    "# Specifying training iteration, epLen, number of episodes, and number of iterations\n",
    "epLen = CONFIG['num_rounds']\n",
    "nEps = 1\n",
    "numIters = 200\n",
    "\n",
    "# Configuration parameters for running the experiment\n",
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/resource/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, # save trajectory for calculating additional metrics\n",
    "                    'epLen' : epLen,\n",
    "                    'render': False,\n",
    "                    'pickle': False # indicator for pickling final information\n",
    "                    }\n",
    "\n",
    "resource_env = gym.make('Resource-v0', config=CONFIG)\n",
    "mon_env = Monitor(resource_env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "comprehensive-amplifier",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and variance endomwnets:\n",
      "[[39.20587486 50.08853996 35.37559313]\n",
      " [46.55235012 59.84495274 42.59752066]\n",
      " [72.245288   90.96648334 62.16188918]] [[  92.94859855  162.47584338  589.93066379]\n",
      " [ 199.32553707  339.36510156  926.26811452]\n",
      " [ 988.84055289 1587.19440903 2584.57344204]]\n",
      "Mean and variance endomwnets:\n",
      "[[ 7.47731355 31.62648643 34.84660757]\n",
      " [ 8.92689891 37.88511292 42.68660077]\n",
      " [13.61348708 57.09146433 63.15584145]] [[   3.49659948   66.09740516  580.48954987]\n",
      " [   7.61656482  130.85082927  963.74654124]\n",
      " [  34.18610677  659.01948972 2581.91028622]]\n",
      "Mean and variance endomwnets:\n",
      "[[ 4.25584282 52.99767184 34.39917429]\n",
      " [ 5.15490496 65.31671668 40.29901029]\n",
      " [ 7.57768503 97.97768305 62.76702875]] [[1.12200259e+00 1.74004003e+02 6.08319619e+02]\n",
      " [2.40380921e+00 3.78433348e+02 8.86329133e+02]\n",
      " [1.14630121e+01 1.86728929e+03 2.75482193e+03]]\n"
     ]
    }
   ],
   "source": [
    "agents = { # 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "#  'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "#  'Equal': or_suite.agents.resource_allocation.equal_allocation.equalAllocationAgent(epLen, CONFIG),\n",
    "#  'FixedThreshold': or_suite.agents.resource_allocation.fixed_threshold.fixedThresholdAgent(epLen, CONFIG),\n",
    " 'Guardrail-0.5': or_suite.agents.resource_allocation.hope_guardrail.hopeguardrailAgent(epLen, CONFIG, 0.5),\n",
    " 'Guardrail-0.3': or_suite.agents.resource_allocation.hope_guardrail.hopeguardrailAgent(epLen, CONFIG, 0.3),\n",
    " 'Guardrail-0.25': or_suite.agents.resource_allocation.hope_guardrail.hopeguardrailAgent(epLen, CONFIG, 0.25)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-dublin",
   "metadata": {},
   "source": [
    "# Step 5: Run Simulations\n",
    "\n",
    "Run the different heuristics in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e2e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1a07ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardrail-0.5\n",
      "\n",
      "env reset!\n",
      "starting_state [392.3      392.3      392.3      392.3      392.3       10.932322\n",
      "   7.617694  10.668706]\n",
      "Lower and Upper Solutions:\n",
      "[[0.13917 0.14981 0.25356 0.15351 0.     ]\n",
      " [0.23113 0.21565 0.      0.21047 0.     ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "[[0.3285  0.35372 0.60246 0.3625  0.     ]\n",
      " [0.54705 0.51015 0.      0.49778 0.     ]\n",
      " [0.23072 0.24067 0.43707 0.24381 0.79162]]\n",
      "timestep:  0\n",
      "new state [382.08      381.97922   381.04694   381.94394   383.84515     7.2902865\n",
      "  13.422441    1.0207489]\n",
      "reward:  -0.9003692079730182\n",
      "timestep:  1\n",
      "new state [372.10687  372.30737  376.20197  372.3709   383.02676   18.746086\n",
      "  22.220646  32.167324]\n",
      "reward:  -0.7707156249571203\n",
      "timestep:  2\n",
      "new state [263.3      263.3      263.3      263.3      263.3       34.28867\n",
      "  41.664326  77.80902 ]\n",
      "reward:  -0.8999260161235547\n",
      "\n",
      "env reset!\n",
      "starting_state [263.3       263.3       263.3       263.3       263.3         8.275917\n",
      "   6.1462727  23.933739 ]\n",
      "timestep:  0\n",
      "new state [251.69704  251.47697  256.76212  251.4052   255.28503    6.277636\n",
      "   7.163428  17.836748]\n",
      "reward:  -1.2417541461107364\n",
      "timestep:  1\n",
      "new state [241.60078   241.30925   245.1806    241.21497   241.15839     3.2439456\n",
      "   4.6910872   5.753231 ]\n",
      "reward:  -0.9356782413748699\n",
      "timestep:  2\n",
      "new state [314.2     314.2     314.2     314.2     314.2      91.38705 116.69336\n",
      "  95.547  ]\n",
      "reward:  -0.8878373456148962\n",
      "\n",
      "env reset!\n",
      "starting_state [314.2      314.2      314.2      314.2      314.2       77.67342\n",
      "  63.238663 144.01955 ]\n",
      "timestep:  0\n",
      "new state [274.74924 274.30692 267.77805 274.15988 265.94348  76.98636  90.14613\n",
      " 123.91545]\n",
      "reward:  -1.7898808322881936\n",
      "timestep:  1\n",
      "new state [231.13269  230.75491  225.24335  230.6289   224.40028   13.722579\n",
      "  16.198635  23.977694]\n",
      "reward:  -1.7577921940782366\n",
      "timestep:  2\n",
      "new state [491.9      491.9      491.9      491.9      491.9       46.427876\n",
      "  87.64983   11.633492]\n",
      "reward:  -0.901404191643661\n",
      "\n",
      "env reset!\n",
      "starting_state [491.9       491.9       491.9       491.9       491.9         3.8670585\n",
      "   6.420634   14.785695 ]\n",
      "timestep:  0\n",
      "new state [483.7059   483.69818  483.10464  483.69724  480.1902     9.356492\n",
      "   9.539852  20.92689 ]\n",
      "reward:  -0.9317098013995301\n",
      "timestep:  1\n",
      "new state [470.58527   470.48538   468.31644   470.4546    463.6146      7.4263606\n",
      "  11.283441   20.330017 ]\n",
      "reward:  -0.9270922781004894\n",
      "timestep:  2\n",
      "new state [88.7       88.7       88.7       88.7       88.7        7.0896263\n",
      "  7.5003157 10.886014 ]\n",
      "reward:  -0.9144155133428208\n",
      "\n",
      "env reset!\n",
      "starting_state [88.7      88.7      88.7      88.7      88.7      17.161901 18.034266\n",
      " 41.1559  ]\n",
      "timestep:  0\n",
      "new state [78.13555  78.06215  76.710754 78.03856  74.91246  17.53796  23.187601\n",
      " 35.562305]\n",
      "reward:  -1.7909297262278212\n",
      "timestep:  1\n",
      "new state [66.87238  66.82445  65.66041  66.80985  62.99366   6.835262  8.435641\n",
      " 10.474026]\n",
      "reward:  -1.764635884128887\n",
      "timestep:  2\n",
      "new state [226.5      226.5      226.5      226.5      226.5       27.394936\n",
      "  46.995453  17.307558]\n",
      "reward:  -1.7508823092055157\n",
      "\n",
      "env reset!\n",
      "starting_state [226.5      226.5      226.5      226.5      226.5        5.490476\n",
      "   5.421324   4.744817]\n",
      "timestep:  0\n",
      "new state [224.02081   224.02672   224.22563   224.02832   224.90703     4.982329\n",
      "   7.5733066   7.7726264]\n",
      "reward:  -1.7323892647243422\n",
      "timestep:  1\n",
      "new state [216.44785  216.53021  217.82301  216.55734  222.30019   60.740826\n",
      "  70.336586  74.74761 ]\n",
      "reward:  -0.9482827038720988\n",
      "timestep:  2\n",
      "new state [332.1     332.1     332.1     332.1     332.1      21.95292  37.47287\n",
      "  53.31124]\n",
      "reward:  -0.8803878563055683\n",
      "\n",
      "env reset!\n",
      "starting_state [332.1      332.1      332.1      332.1      332.1       10.202902\n",
      "   9.098642   6.83522 ]\n",
      "timestep:  0\n",
      "new state [322.1939    322.20435   322.96115   322.20584   326.67944     7.4036946\n",
      "   7.3668222  24.090857 ]\n",
      "reward:  -0.8651589819060344\n",
      "timestep:  1\n",
      "new state [310.17352 310.0294  307.96765 309.98135 307.60126  65.77657 108.52525\n",
      " 134.97325]\n",
      "reward:  -0.9519604788300866\n",
      "timestep:  2\n",
      "new state [294.4       294.4       294.4       294.4       294.4         7.3839045\n",
      "   8.078552   23.081436 ]\n",
      "reward:  -0.8880113425168532\n",
      "\n",
      "env reset!\n",
      "starting_state [294.4      294.4      294.4      294.4      294.4       20.236734\n",
      "  26.302414  66.29913 ]\n",
      "timestep:  0\n",
      "new state [258.06696  257.86746  276.9664   257.80698  272.19437   19.795473\n",
      "  24.024158  47.187183]\n",
      "reward:  -1.197481680716297\n",
      "timestep:  1\n",
      "new state [227.5347   227.25294  244.4043   227.16766  234.81813   42.84446\n",
      "  44.006886  87.89553 ]\n",
      "reward:  -0.9202069776725016\n",
      "timestep:  2\n",
      "new state [271.4      271.4      271.4      271.4      271.4        8.709915\n",
      "  10.102669  18.147213]\n",
      "reward:  -0.9210765485098565\n",
      "\n",
      "env reset!\n",
      "starting_state [271.4      271.4      271.4      271.4      271.4       11.835402\n",
      "  22.375742  25.979523]\n",
      "timestep:  0\n",
      "new state [249.27742  249.5461   263.57227  249.63739  262.69067   17.524372\n",
      "  20.638361  48.990944]\n",
      "reward:  -1.0877134171866942\n",
      "timestep:  1\n",
      "new state [220.92726  221.02806  231.59174  221.06696  246.2802    13.752008\n",
      "  36.53962   57.451855]\n",
      "reward:  -1.0397354709956006\n",
      "timestep:  2\n",
      "new state [431.9      431.9      431.9      431.9      431.9       59.223713\n",
      "  45.17748   72.74192 ]\n",
      "reward:  -0.9038991639977927\n",
      "\n",
      "env reset!\n",
      "starting_state [431.9      431.9      431.9      431.9      431.9       15.673986\n",
      "  11.784581  10.755428]\n",
      "timestep:  0\n",
      "new state [417.82285  417.75537  417.75027  417.72977  423.37204   19.455704\n",
      "  21.211712  14.576744]\n",
      "reward:  -0.8775101762473392\n",
      "timestep:  1\n",
      "new state [396.46463  396.54416  399.64734  396.56436  411.81247   43.571934\n",
      "  73.98386   28.818937]\n",
      "reward:  -0.8567507498900703\n",
      "timestep:  2\n",
      "new state [251.        251.        251.        251.        251.          6.8050537\n",
      "   9.470165   20.936565 ]\n",
      "reward:  -0.8181775844307972\n",
      "\n",
      "env reset!\n",
      "starting_state [251.        251.        251.        251.        251.          5.7822447\n",
      "   5.622657   14.668379 ]\n",
      "timestep:  0\n",
      "new state [247.46732  247.43225  246.81212  247.42091  246.08655    4.964589\n",
      "   7.979662  22.917156]\n",
      "reward:  -1.7991007270435377\n",
      "timestep:  1\n",
      "new state [236.18373  236.08987  233.80077  236.0617   238.41246   27.182522\n",
      "  32.845627  68.26477 ]\n",
      "reward:  -1.0682117148931949\n",
      "timestep:  2\n",
      "new state [424.1      424.1      424.1      424.1      424.1       52.364475\n",
      " 116.56082   95.4568  ]\n",
      "reward:  -0.9239740325249155\n",
      "\n",
      "env reset!\n",
      "starting_state [424.1      424.1      424.1      424.1      424.1       23.085138\n",
      "  29.845253  54.713528]\n",
      "timestep:  0\n",
      "new state [387.5662   387.54086  386.26355  387.53558  380.76123   17.51794\n",
      "  23.701492  69.26325 ]\n",
      "reward:  -0.9156011261211648\n",
      "timestep:  1\n",
      "new state [352.86523 352.58353 345.42496 352.50012 325.91043  46.031    76.6831\n",
      "  83.76971]\n",
      "reward:  -0.9468276901850825\n",
      "timestep:  2\n",
      "new state [486.9      486.9      486.9      486.9      486.9       49.756626\n",
      "  67.749756 139.36096 ]\n",
      "reward:  -0.8788957958517524\n",
      "\n",
      "env reset!\n",
      "starting_state [486.9      486.9      486.9      486.9      486.9       63.406208\n",
      " 148.30202   60.378918]\n",
      "timestep:  0\n",
      "new state [371.0118  374.28427 422.23633 375.3725  438.99698  79.4938  106.23367\n",
      " 201.20831]\n",
      "reward:  -0.8119045961865505\n",
      "timestep:  1\n",
      "new state [240.36018  243.5458   286.34924  244.61841  279.6236    38.576565\n",
      "  55.349182  65.8818  ]\n",
      "reward:  -0.9178371039810845\n",
      "timestep:  2\n",
      "new state [612.3      612.3      612.3      612.3      612.3       25.025757\n",
      "  45.414127  33.943142]\n",
      "reward:  -0.8858688193741905\n",
      "\n",
      "env reset!\n",
      "starting_state [612.3      612.3      612.3      612.3      612.3       27.968258\n",
      "  66.738335  84.74562 ]\n",
      "timestep:  0\n",
      "new state [547.0507   547.9648   558.3771   548.2787   545.1663    43.928947\n",
      "  21.158365  45.88839 ]\n",
      "reward:  -0.8877214229974669\n",
      "timestep:  1\n",
      "new state [510.458     510.58832   511.8446    510.6342    508.80762     4.5594273\n",
      "   8.518999   21.96597  ]\n",
      "reward:  -0.9239245855471359\n",
      "timestep:  2\n",
      "new state [450.7     450.7     450.7     450.7     450.7      77.63267  69.99103\n",
      "  94.91813]\n",
      "reward:  -0.9398612760725984\n",
      "\n",
      "env reset!\n",
      "starting_state [450.7      450.7      450.7      450.7      450.7       47.703785\n",
      "  49.525536  75.24773 ]\n",
      "timestep:  0\n",
      "new state [390.57523  390.4509   389.04712  390.40842  391.0838    67.479576\n",
      "  54.46545  111.912834]\n",
      "reward:  -0.9035085777889277\n",
      "timestep:  1\n",
      "new state [312.79233  311.86243  299.4524   311.5498   302.4304    47.493595\n",
      "  87.26797   78.64809 ]\n",
      "reward:  -0.9223963438748287\n",
      "timestep:  2\n",
      "new state [626.4      626.4      626.4      626.4      626.4       38.041695\n",
      "  35.91565  125.50194 ]\n",
      "reward:  -0.864758552313635\n",
      "\n",
      "env reset!\n",
      "starting_state [626.4      626.4      626.4      626.4      626.4       68.84266\n",
      "  94.208176 110.56915 ]\n",
      "timestep:  0\n",
      "new state [526.7381  527.378   536.5515  527.59174 538.78973  37.79522  87.63676\n",
      "  87.71248]\n",
      "reward:  -0.885269018689979\n",
      "timestep:  1\n",
      "new state [446.14368  448.1914   475.4011   448.88196  469.29205   31.472702\n",
      "  24.848057  79.67594 ]\n",
      "reward:  -0.8699967322668389\n",
      "timestep:  2\n",
      "new state [629.1      629.1      629.1      629.1      629.1       47.327087\n",
      "  26.310238  90.41862 ]\n",
      "reward:  -0.9490478603311706\n",
      "\n",
      "env reset!\n",
      "starting_state [629.1      629.1      629.1      629.1      629.1       24.897203\n",
      "  74.22195   78.3461  ]\n",
      "timestep:  0\n",
      "new state [562.2421   563.5735   579.82056  564.027    567.0301    33.74213\n",
      "  32.012737  87.403915]\n",
      "reward:  -0.8723058356371355\n",
      "timestep:  1\n",
      "new state [513.47943  514.2714   521.27466  514.55023  497.80652    9.608265\n",
      "  11.71757   42.46312 ]\n",
      "reward:  -0.940602369544975\n",
      "timestep:  2\n",
      "new state [252.3       252.3       252.3       252.3       252.3         7.0822525\n",
      "   7.7232594  10.552965 ]\n",
      "reward:  -0.9595467266729447\n",
      "\n",
      "env reset!\n",
      "starting_state [252.3      252.3      252.3      252.3      252.3       22.690355\n",
      "  21.37716   41.088287]\n",
      "timestep:  0\n",
      "new state [240.2001   240.1199   238.91983  240.09326  238.53065   18.794472\n",
      "  18.828686  42.83466 ]\n",
      "reward:  -1.7797130559736978\n",
      "timestep:  1\n",
      "new state [213.84308  213.55745  208.86575  213.4642   224.18022   11.573236\n",
      "  24.75364   18.072481]\n",
      "reward:  -1.0307503767760844\n",
      "timestep:  2\n",
      "new state [180.       180.       180.       180.       180.         9.396008\n",
      "  20.15765   22.25668 ]\n",
      "reward:  -0.8486513853785529\n",
      "\n",
      "env reset!\n",
      "starting_state [180.       180.       180.       180.       180.        45.09914\n",
      "  55.950485  83.77051 ]\n",
      "timestep:  0\n",
      "new state [152.63414  152.67444  153.00899  152.68849  151.92154   31.85227\n",
      "  47.323803  93.19615 ]\n",
      "reward:  -1.7631961764821718\n",
      "timestep:  1\n",
      "new state [128.18787   128.23694   127.634026  128.25711   120.70038     6.087017\n",
      "   7.7241664  10.803691 ]\n",
      "reward:  -1.7818185340212085\n",
      "timestep:  2\n",
      "new state [340.2     340.2     340.2     340.2     340.2      56.34593  75.02445\n",
      "  82.67766]\n",
      "reward:  -1.1165369904688565\n",
      "\n",
      "env reset!\n",
      "starting_state [340.2      340.2      340.2      340.2      340.2       95.16671\n",
      "  59.903145  76.07263 ]\n",
      "timestep:  0\n",
      "new state [258.61627 257.66968 301.93878 257.33624 314.6701  106.97602  70.30888\n",
      " 270.05283]\n",
      "reward:  -1.1093456313729666\n",
      "timestep:  1\n",
      "new state [201.18018  199.06842  224.7218   198.35231  224.22717   78.9236\n",
      "  52.114098  42.04996 ]\n",
      "reward:  -1.8188633403888161\n",
      "timestep:  2\n",
      "new state [862.9      862.9      862.9      862.9      862.9       45.03868\n",
      "  46.135635  39.258255]\n",
      "reward:  -0.874105248053091\n",
      "\n",
      "env reset!\n",
      "starting_state [862.9      862.9      862.9      862.9      862.9       86.95109\n",
      "  84.90955   44.371353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  0\n",
      "new state [777.6495  778.1482  791.07965 778.2958  827.68884  75.25718  84.63726\n",
      " 166.01964]\n",
      "reward:  -0.846738367822145\n",
      "timestep:  1\n",
      "new state [668.32263  668.3946   673.1357   668.40704  696.18445   28.833546\n",
      "  56.928272 183.26923 ]\n",
      "reward:  -0.9200261888742641\n",
      "timestep:  2\n",
      "new state [632.4      632.4      632.4      632.4      632.4       50.193836\n",
      "  74.47444   70.67178 ]\n",
      "reward:  -0.9548446090371185\n",
      "\n",
      "env reset!\n",
      "starting_state [632.4     632.4     632.4     632.4     632.4      68.8054   84.22174\n",
      " 127.70535]\n",
      "timestep:  0\n",
      "new state [534.25977  534.36163  535.08923  534.3983   531.2294    67.63453\n",
      "  54.094967 143.87057 ]\n",
      "reward:  -0.902883538754635\n",
      "timestep:  1\n",
      "new state [449.25537  448.21606  431.43356  447.87634  417.27768   63.066257\n",
      "  71.81964   87.96967 ]\n",
      "reward:  -0.938002654433394\n",
      "timestep:  2\n",
      "new state [605.1      605.1      605.1      605.1      605.1        8.978854\n",
      "   6.497436   7.013225]\n",
      "reward:  -0.8893718790254584\n",
      "\n",
      "env reset!\n",
      "starting_state [605.1      605.1      605.1      605.1      605.1       45.38345\n",
      "  62.868977  64.14087 ]\n",
      "timestep:  0\n",
      "new state [541.0005   541.53754  549.69275  541.7154   554.2706    38.236603\n",
      "  60.039486  39.17372 ]\n",
      "reward:  -0.8759993387271586\n",
      "timestep:  1\n",
      "new state [486.557    487.95538  509.50504  488.41724  523.2108    30.421913\n",
      "  48.387154  82.814674]\n",
      "reward:  -0.8467345105536046\n",
      "timestep:  2\n",
      "new state [486.8      486.8      486.8      486.8      486.8       43.303104\n",
      "  26.81554  104.655334]\n",
      "reward:  -0.910770291922945\n",
      "\n",
      "env reset!\n",
      "starting_state [486.8       486.8       486.8       486.8       486.8         4.246041\n",
      "   8.46335    12.1051445]\n",
      "timestep:  0\n",
      "new state [477.9824    478.06717   478.9469    478.09656   477.21097     6.9337163\n",
      "   6.9050226   3.1503477]\n",
      "reward:  -0.897321453519963\n",
      "timestep:  1\n",
      "new state [471.20044  471.33377  473.38925  471.3778   474.71017   28.496254\n",
      "  73.75888  101.782585]\n",
      "reward:  -0.8407300275353763\n",
      "timestep:  2\n",
      "new state [218.7       218.7       218.7       218.7       218.7        10.630719\n",
      "   6.9710045  19.985203 ]\n",
      "reward:  -0.8938313549047445\n",
      "\n",
      "env reset!\n",
      "starting_state [218.7      218.7      218.7      218.7      218.7       22.827225\n",
      "  29.537369  80.270775]\n",
      "timestep:  0\n",
      "new state [200.8794   200.76224  198.01816  200.72643  191.81682   29.131529\n",
      "  24.086033  35.90745 ]\n",
      "reward:  -1.8031202142203526\n",
      "timestep:  1\n",
      "new state [187.76149  187.55893  183.96371  187.49341  179.77629   43.378193\n",
      "  44.497005  85.76919 ]\n",
      "reward:  -1.764322812745801\n",
      "timestep:  2\n",
      "new state [359.8       359.8       359.8       359.8       359.8        15.8702135\n",
      "  26.540382   56.178318 ]\n",
      "reward:  -1.1592404488779324\n",
      "\n",
      "env reset!\n",
      "starting_state [359.8      359.8      359.8      359.8      359.8       70.43213\n",
      "  40.849953  44.25658 ]\n",
      "timestep:  0\n",
      "new state [304.1052   303.3959   298.00378  303.14386  324.70996   46.474483\n",
      "  35.458675 173.63602 ]\n",
      "reward:  -0.889058421051478\n",
      "timestep:  1\n",
      "new state [229.37936   227.07874   194.09595   226.31204   266.57385     6.7724886\n",
      "   8.5429325  10.706835 ]\n",
      "reward:  -1.1017137699919186\n",
      "timestep:  2\n",
      "new state [415.       415.       415.       415.       415.        20.721453\n",
      "  57.89818   73.81426 ]\n",
      "reward:  -0.890154187887482\n",
      "\n",
      "env reset!\n",
      "starting_state [415.       415.       415.       415.       415.        68.53038\n",
      "  69.694214 136.3754  ]\n",
      "timestep:  0\n",
      "new state [322.89703  322.38348  314.07275  322.21567  306.9734    38.588337\n",
      "  45.5311    41.92854 ]\n",
      "reward:  -0.9197421845229932\n",
      "timestep:  1\n",
      "new state [275.63922  275.41537  272.47635  275.34033  273.73987   16.848251\n",
      "  18.003662  54.69818 ]\n",
      "reward:  -0.8715385203744318\n",
      "timestep:  2\n",
      "new state [488.7     488.7     488.7     488.7     488.7      52.49309  80.51353\n",
      "  86.61034]\n",
      "reward:  -0.947941814095319\n",
      "\n",
      "env reset!\n",
      "starting_state [488.7      488.7      488.7      488.7      488.7       24.715092\n",
      "  26.12814   66.91871 ]\n",
      "timestep:  0\n",
      "new state [450.8482   450.5232   444.54892  450.41928  435.7004    28.025057\n",
      "  29.4309    61.69561 ]\n",
      "reward:  -0.937148091423154\n",
      "timestep:  1\n",
      "new state [411.30737 410.7477  400.68494 410.56808 386.8322   38.65242  71.97519\n",
      " 146.82419]\n",
      "reward:  -0.92424317681603\n",
      "timestep:  2\n",
      "new state [418.2      418.2      418.2      418.2      418.2       14.621867\n",
      "  28.503355  34.427475]\n",
      "reward:  -0.923382591329428\n",
      "\n",
      "env reset!\n",
      "starting_state [418.2      418.2      418.2      418.2      418.2       41.140926\n",
      "  24.08108   90.9433  ]\n",
      "timestep:  0\n",
      "new state [370.52924  369.47534  353.65363  369.12646  346.17487   32.88811\n",
      "  51.908463  46.94099 ]\n",
      "reward:  -0.9555127545688616\n",
      "timestep:  1\n",
      "new state [320.49875  320.06378  313.2974   319.92084  308.97305   32.324745\n",
      "  69.80584   79.33678 ]\n",
      "reward:  -0.8667403338946311\n",
      "timestep:  2\n",
      "new state [653.5      653.5      653.5      653.5      653.5       42.000443\n",
      "  48.14922   59.736176]\n",
      "reward:  -0.8798972700730561\n",
      "\n",
      "env reset!\n",
      "starting_state [653.5     653.5     653.5     653.5     653.5      62.09389  69.46917\n",
      "   1.     ]\n",
      "timestep:  0\n",
      "new state [594.86835  595.8558   615.61914  596.1668   652.6426    41.883297\n",
      "  62.627632  87.61056 ]\n",
      "reward:  -0.7881770128930966\n",
      "timestep:  1\n",
      "new state [526.63574  528.0061   552.06287  528.449    583.2361   110.85075\n",
      " 101.86062   51.575523]\n",
      "reward:  -0.8967131114716983\n",
      "timestep:  2\n",
      "new state [610.5      610.5      610.5      610.5      610.5       29.145187\n",
      "  35.68855   97.507614]\n",
      "reward:  -0.8471529818275081\n",
      "\n",
      "env reset!\n",
      "starting_state [610.5      610.5      610.5      610.5      610.5       55.846092\n",
      "  97.55498   58.32828 ]\n",
      "timestep:  0\n",
      "new state [525.3296   526.94055  551.3126   527.4739   564.24945   45.255993\n",
      "  48.724453  50.271637]\n",
      "reward:  -0.8396272991556087\n",
      "timestep:  1\n",
      "new state [472.20963  473.97693  502.05112  474.5578   524.40643   35.702198\n",
      "  55.011387  43.152588]\n",
      "reward:  -0.8793782206761427\n",
      "timestep:  2\n",
      "new state [403.        403.        403.        403.        403.          5.858639\n",
      "   4.8854113  20.20858  ]\n",
      "reward:  -0.8580546083904961\n",
      "\n",
      "env reset!\n",
      "starting_state [403.       403.       403.       403.       403.        13.502382\n",
      "  13.701265  43.796974]\n",
      "timestep:  0\n",
      "new state [380.96436  380.6936   375.71616  380.60703  368.31583    8.910551\n",
      "   8.320324  21.651993]\n",
      "reward:  -0.9507190112737954\n",
      "timestep:  1\n",
      "new state [368.49005  368.08615  360.8803   367.9563   351.16705   22.710562\n",
      "  33.801067  43.468422]\n",
      "reward:  -0.9375337709269572\n",
      "timestep:  2\n",
      "new state [335.5      335.5      335.5      335.5      335.5       33.21482\n",
      "  56.64547   61.598717]\n",
      "reward:  -0.8909105659518229\n",
      "\n",
      "env reset!\n",
      "starting_state [335.5      335.5      335.5      335.5      335.5       43.707058\n",
      "  60.920345  61.202732]\n",
      "timestep:  0\n",
      "new state [273.69507  274.23175  282.3879   274.40942  314.9705    20.881828\n",
      "  46.271496  48.42366 ]\n",
      "reward:  -0.9452266337295956\n",
      "timestep:  1\n",
      "new state [230.35025  231.5859   248.61978  232.00056  276.60376   21.958979\n",
      "  24.4882    37.25161 ]\n",
      "reward:  -0.8736304193012967\n",
      "timestep:  2\n",
      "new state [292.4      292.4      292.4      292.4      292.4       19.154333\n",
      "  27.784224  22.170706]\n",
      "reward:  -0.9033691671447311\n",
      "\n",
      "env reset!\n",
      "starting_state [292.4      292.4      292.4      292.4      292.4       54.086212\n",
      "  44.356434 129.68245 ]\n",
      "timestep:  0\n",
      "new state [261.99225  261.5678   254.62578  261.42886  248.96161   45.74425\n",
      "  23.512518  25.19479 ]\n",
      "reward:  -1.8050546409894894\n",
      "timestep:  1\n",
      "new state [228.2898   227.32861  216.04306  226.99977  240.49731   29.514809\n",
      "  29.299732  81.67291 ]\n",
      "reward:  -0.9407962985730742\n",
      "timestep:  2\n",
      "new state [482.5       482.5       482.5       482.5       482.5         7.5077925\n",
      "  33.178036   43.72549  ]\n",
      "reward:  -0.9421506921700764\n",
      "\n",
      "env reset!\n",
      "starting_state [482.5       482.5       482.5       482.5       482.5         8.6625185\n",
      "  12.69736     1.       ]\n",
      "timestep:  0\n",
      "new state [472.47754  472.71765  476.83777  472.79553  481.6977    13.120738\n",
      "   9.845924  12.610104]\n",
      "reward:  -0.7825157041816789\n",
      "timestep:  1\n",
      "new state [459.87177  460.0188   463.41663  460.0637   471.7038    48.132317\n",
      "  71.776855  94.96901 ]\n",
      "reward:  -0.8950285058348366\n",
      "timestep:  2\n",
      "new state [429.8      429.8      429.8      429.8      429.8       50.115356\n",
      "  84.95765   95.598305]\n",
      "reward:  -0.8928625589025297\n",
      "\n",
      "env reset!\n",
      "starting_state [429.8      429.8      429.8      429.8      429.8       87.4185\n",
      "  80.061104 160.28911 ]\n",
      "timestep:  0\n",
      "new state [320.30368 319.45837 307.03625 319.1779  376.08673  64.32462  72.24431\n",
      " 152.33092]\n",
      "reward:  -1.0141688486890545\n",
      "timestep:  1\n",
      "new state [224.50601 223.18855 201.66785 222.75864 255.43024  66.48869  51.24108\n",
      "  90.80584]\n",
      "reward:  -0.9247742741858764\n",
      "timestep:  2\n",
      "new state [591.7      591.7      591.7      591.7      591.7       36.281258\n",
      "  42.12271   60.868942]\n",
      "reward:  -0.9134775791924854\n",
      "\n",
      "env reset!\n",
      "starting_state [591.7      591.7      591.7      591.7      591.7       32.55566\n",
      "  46.56073   91.459564]\n",
      "timestep:  0\n",
      "new state [534.43286  534.4199   532.089    534.42285  519.2592    37.598133\n",
      "  47.071373  76.60106 ]\n",
      "reward:  -0.9204001673424881\n",
      "timestep:  1\n",
      "new state [478.65808  478.67166  475.93405  478.68622  458.57794   18.218185\n",
      "  14.086759  17.411419]\n",
      "reward:  -0.9075637275603561\n",
      "timestep:  2\n",
      "new state [333.8      333.8      333.8      333.8      333.8       28.786629\n",
      "  46.826946  29.502718]\n",
      "reward:  -0.8928551488785788\n",
      "\n",
      "env reset!\n",
      "starting_state [333.8      333.8      333.8      333.8      333.8       39.51248\n",
      "  50.263527 141.13283 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  0\n",
      "new state [260.7613   260.21527  297.5957   260.04694  286.53488   35.394726\n",
      "  60.797546  69.90704 ]\n",
      "reward:  -1.2115474344111565\n",
      "timestep:  1\n",
      "new state [199.74588  199.85506  245.68713  199.90851  231.14697   30.988016\n",
      "  41.87631   13.387293]\n",
      "reward:  -0.8822384412401337\n",
      "timestep:  2\n",
      "new state [477.8     477.8     477.8     477.8     477.8      29.97029  79.58301\n",
      "  71.92901]\n",
      "reward:  -0.8174208175723034\n",
      "\n",
      "env reset!\n",
      "starting_state [477.8      477.8      477.8      477.8      477.8       29.97012\n",
      "  47.961544  19.105997]\n",
      "timestep:  0\n",
      "new state [437.3093    438.13312   451.36954   438.4033    462.63632    44.03313\n",
      "  61.8908      7.9277773]\n",
      "reward:  -0.8209004714661026\n",
      "timestep:  1\n",
      "new state [387.15796 389.07614 421.3454  389.7004  456.3076   71.95437  68.23424\n",
      " 121.90351]\n",
      "reward:  -0.7917693910691611\n",
      "timestep:  2\n",
      "new state [714.6      714.6      714.6      714.6      714.6       71.721085\n",
      "  91.92644  256.4721  ]\n",
      "reward:  -0.9139102138775407\n",
      "\n",
      "env reset!\n",
      "starting_state [714.6      714.6      714.6      714.6      714.6       83.69408\n",
      "  66.76063   30.913458]\n",
      "timestep:  0\n",
      "new state [643.4527   643.4978   650.63293  643.49176  690.05304   87.388596\n",
      "  86.80331  148.7227  ]\n",
      "reward:  -0.8480449471153941\n",
      "timestep:  1\n",
      "new state [532.9465   532.5109   532.93915  532.34436  572.2341    41.848778\n",
      "  51.709995  63.689907]\n",
      "reward:  -0.9112369217618426\n",
      "timestep:  2\n",
      "new state [473.3      473.3      473.3      473.3      473.3       11.666571\n",
      "   8.46677   26.66461 ]\n",
      "reward:  -0.8891564992583139\n",
      "\n",
      "env reset!\n",
      "starting_state [473.3      473.3      473.3      473.3      473.3       31.897774\n",
      "  30.293598  37.71321 ]\n",
      "timestep:  0\n",
      "new state [437.54828  437.4864   437.58438  437.46265  443.41437   30.410604\n",
      "  61.84637   54.497173]\n",
      "reward:  -0.8916862166322888\n",
      "timestep:  1\n",
      "new state [381.15173  382.0628   395.4132   382.36597  400.22717   29.187922\n",
      "  46.02662   71.41302 ]\n",
      "reward:  -0.8620943695139035\n",
      "timestep:  2\n",
      "new state [275.8      275.8      275.8      275.8      275.8        7.706619\n",
      "  10.654398  12.997147]\n",
      "reward:  -0.9038256151835553\n",
      "\n",
      "env reset!\n",
      "starting_state [275.8      275.8      275.8      275.8      275.8        9.147536\n",
      "   7.465553  25.64343 ]\n",
      "timestep:  0\n",
      "new state [262.79453  262.58417  268.72354  262.5157   267.2119    11.42402\n",
      "  11.975187  20.14769 ]\n",
      "reward:  -1.2291415834577621\n",
      "timestep:  1\n",
      "new state [247.84224  247.58517  253.02908  247.50127  251.2509    58.717133\n",
      "  62.244896 162.72615 ]\n",
      "reward:  -0.9100151064514815\n",
      "timestep:  2\n",
      "new state [479.1      479.1      479.1      479.1      479.1       61.003307\n",
      "  43.146927  54.689846]\n",
      "reward:  -1.0477009537810793\n",
      "\n",
      "env reset!\n",
      "starting_state [479.1       479.1       479.1       479.1       479.1         7.744819\n",
      "   3.7875311   7.7758455]\n",
      "timestep:  0\n",
      "new state [472.68982   472.5569    471.03357   472.51132   472.93872     7.655129\n",
      "   7.8068266  21.566545 ]\n",
      "reward:  -0.9211351620505973\n",
      "timestep:  1\n",
      "new state [460.92856   460.67603   456.99167   460.5921    455.8585     12.829673\n",
      "  14.9739895   1.       ]\n",
      "reward:  -0.9417418736078451\n",
      "timestep:  2\n",
      "new state [94.1      94.1      94.1      94.1      94.1       5.184535  6.589685\n",
      "  8.542588]\n",
      "reward:  -0.7928506878365486\n",
      "\n",
      "env reset!\n",
      "starting_state [94.1       94.1       94.1       94.1       94.1        6.7454433\n",
      "  8.724924  24.011929 ]\n",
      "timestep:  0\n",
      "new state [88.80636  88.770485 87.93441  88.75951  86.05835   9.141403 12.27315\n",
      " 11.689247]\n",
      "reward:  -1.8039369112431276\n",
      "timestep:  1\n",
      "new state [83.55916  83.56773  83.44366  83.571304 82.13666  37.538708 51.112934\n",
      " 36.43125 ]\n",
      "reward:  -1.7331665431513035\n",
      "timestep:  2\n",
      "new state [319.4      319.4      319.4      319.4      319.4       40.22966\n",
      "  46.932587  55.57324 ]\n",
      "reward:  -1.7156234147461362\n",
      "\n",
      "env reset!\n",
      "starting_state [319.4      319.4      319.4      319.4      319.4       26.7644\n",
      "  23.814106  28.514479]\n",
      "timestep:  0\n",
      "new state [291.00153  290.92154  290.80078  290.8916   309.83432   32.317825\n",
      "  40.683517  88.29138 ]\n",
      "reward:  -0.9585767427703974\n",
      "timestep:  1\n",
      "new state [237.7586   237.4863   232.72073  237.39862  239.9046    13.293848\n",
      "  11.490452  14.483939]\n",
      "reward:  -0.9269535903783603\n",
      "timestep:  2\n",
      "new state [204.5       204.5       204.5       204.5       204.5         6.953627\n",
      "   4.6202626  11.862257 ]\n",
      "reward:  -0.8931053058836429\n",
      "\n",
      "env reset!\n",
      "starting_state [204.5      204.5      204.5      204.5      204.5       30.500729\n",
      "  49.106117  36.047768]\n",
      "timestep:  0\n",
      "new state [185.39499  185.68175  190.05988  185.7764   192.39934   44.25565\n",
      "  55.641575  82.57135 ]\n",
      "reward:  -1.7144882314526981\n",
      "timestep:  1\n",
      "new state [158.33469  158.67088  163.50516  158.78267  164.72267   39.81807\n",
      "  55.147755  89.94631 ]\n",
      "reward:  -1.7625604425021626\n",
      "timestep:  2\n",
      "new state [594.3      594.3      594.3      594.3      594.3       39.69959\n",
      "  48.491627  27.505339]\n",
      "reward:  -1.7687532810048745\n",
      "\n",
      "env reset!\n",
      "starting_state [594.3      594.3      594.3      594.3      594.3        9.560337\n",
      "  18.160345  16.280468]\n",
      "timestep:  0\n",
      "new state [577.46857  577.7356   581.41547  577.8252   581.3982    12.147562\n",
      "  12.095174  11.091602]\n",
      "reward:  -0.8640310358927383\n",
      "timestep:  1\n",
      "new state [564.30237   564.599     569.24316   564.6967    572.6057     10.6206045\n",
      "  17.326115   40.010418 ]\n",
      "reward:  -0.8736207645881805\n",
      "timestep:  2\n",
      "new state [151.8       151.8       151.8       151.8       151.8         7.2141314\n",
      "   7.1654654  17.336367 ]\n",
      "reward:  -0.9318555650571965\n",
      "\n",
      "env reset!\n",
      "starting_state [151.8      151.8      151.8      151.8      151.8       25.72831\n",
      "  15.967594  60.49054 ]\n",
      "timestep:  0\n",
      "new state [138.63823 138.36183 134.05582 138.27072 131.54024  35.91849  36.95268\n",
      "  83.62861]\n",
      "reward:  -1.8175073428711568\n",
      "timestep:  1\n",
      "new state [116.95483  116.522896 109.42845  116.381584 103.52334   67.79835\n",
      "  27.307924 127.137474]\n",
      "reward:  -1.7903219219141158\n",
      "timestep:  2\n",
      "new state [530.6      530.6      530.6      530.6      530.6       47.492477\n",
      "  61.085274  29.563437]\n",
      "reward:  -1.8229544945771397\n",
      "\n",
      "env reset!\n",
      "starting_state [530.6      530.6      530.6      530.6      530.6       13.346056\n",
      "  25.30514   28.181671]\n",
      "timestep:  0\n",
      "new state [505.87054  506.18732  510.2295   506.29468  508.27148   22.105148\n",
      "  25.031742  45.86107 ]\n",
      "reward:  -0.879279135404279\n",
      "timestep:  1\n",
      "new state [474.33432 474.56097 476.855   474.63986 471.9434   78.61618  69.34076\n",
      "   7.90992]\n",
      "reward:  -0.9155339461885259\n",
      "timestep:  2\n",
      "new state [567.2      567.2      567.2      567.2      567.2       48.755356\n",
      "  71.0898   147.91473 ]\n",
      "reward:  -0.8132571328535337\n",
      "\n",
      "env reset!\n",
      "starting_state [567.2     567.2     567.2     567.2     567.2      47.41181  67.01342\n",
      "  21.97061]\n",
      "timestep:  0\n",
      "new state [509.89648  510.95496  529.0001   511.29865  549.7504    39.510483\n",
      "  69.15841   52.063046]\n",
      "reward:  -0.8167981593767041\n",
      "timestep:  1\n",
      "new state [447.0722   449.16812  482.40686  449.85693  508.48193   66.06673\n",
      "  58.279484  79.13802 ]\n",
      "reward:  -0.8535602828657106\n",
      "timestep:  2\n",
      "new state [573.4      573.4      573.4      573.4      573.4       55.864265\n",
      "  61.33183   25.775007]\n",
      "reward:  -0.8973156604614242\n",
      "\n",
      "env reset!\n",
      "starting_state [573.4      573.4      573.4      573.4      573.4       52.335735\n",
      "  46.926376 107.326164]\n",
      "timestep:  0\n",
      "new state [505.77435  505.11816  494.93732  504.9021   488.38885   35.69795\n",
      "  90.65388  117.951805]\n",
      "reward:  -0.929307101159776\n",
      "timestep:  1\n",
      "new state [417.24152  417.85654  421.8322   418.07806  394.95267   65.96802\n",
      "  45.721138 153.445   ]\n",
      "reward:  -0.8893443444187586\n",
      "timestep:  2\n",
      "new state [504.1      504.1      504.1      504.1      504.1        4.81735\n",
      "   7.943556   8.392993]\n",
      "reward:  -0.9505879278776587\n",
      "\n",
      "env reset!\n",
      "starting_state [504.1      504.1      504.1      504.1      504.1        8.592334\n",
      "  14.370525   8.916034]\n",
      "timestep:  0\n",
      "new state [491.35892   491.58377   495.01935   491.6581    497.03043     7.1535673\n",
      "   6.5900536  12.893903 ]\n",
      "reward:  -0.8426180164041714\n",
      "timestep:  1\n",
      "new state [482.42902  482.58832  485.07077  482.64087  486.81647   15.133276\n",
      "  19.83358   46.44049 ]\n",
      "reward:  -0.9196081146830385\n",
      "timestep:  2\n",
      "new state [301.       301.       301.       301.       301.        58.405956\n",
      "  79.06392  141.05545 ]\n",
      "reward:  -0.9321504998169425\n",
      "\n",
      "env reset!\n",
      "starting_state [301.       301.       301.       301.       301.        42.817184\n",
      "  60.221004  84.10041 ]\n",
      "timestep:  0\n",
      "new state [272.93256  273.06186  274.52432  273.10605  272.81018   61.794315\n",
      "  60.08196  114.665794]\n",
      "reward:  -1.7580367588324253\n",
      "timestep:  1\n",
      "new state [193.3096   192.95654  237.57126  192.84134  234.38435   19.934015\n",
      "  47.369335 108.25264 ]\n",
      "reward:  -1.1575737048611672\n",
      "timestep:  2\n",
      "new state [360.5       360.5       360.5       360.5       360.5         7.5678234\n",
      "  10.192354    9.068209 ]\n",
      "reward:  -0.9319864513998734\n",
      "\n",
      "env reset!\n",
      "starting_state [360.5      360.5      360.5      360.5      360.5       42.87333\n",
      "  66.921486  82.45471 ]\n",
      "timestep:  0\n",
      "new state [290.78278  291.35046  298.59857  291.54297  332.8574    45.661537\n",
      "  60.69222   67.66721 ]\n",
      "reward:  -0.9693571817860329\n",
      "timestep:  1\n",
      "new state [226.9691   227.95146  241.48367  228.28134  279.2375    48.340683\n",
      "  76.10849  134.067   ]\n",
      "reward:  -0.882131516867014\n",
      "timestep:  2\n",
      "new state [669.9      669.9      669.9      669.9      669.9       79.683304\n",
      "  60.88607  108.98051 ]\n",
      "reward:  -0.9128168497594619\n",
      "\n",
      "env reset!\n",
      "starting_state [669.9      669.9      669.9      669.9      669.9       33.390385\n",
      "  16.668211  62.076927]\n",
      "timestep:  0\n",
      "new state [635.49054   634.6458    622.6434    634.36395   620.73364    34.57143\n",
      "  36.346233   12.9542265]\n",
      "reward:  -0.9529958566963374\n",
      "timestep:  1\n",
      "new state [601.26184  600.7575   596.1354   600.581    610.44336   49.942066\n",
      "  47.464767 126.4234  ]\n",
      "reward:  -0.8300119442581188\n",
      "timestep:  2\n",
      "new state [336.6       336.6       336.6       336.6       336.6        10.6723585\n",
      "  11.126039   20.23257  ]\n",
      "reward:  -0.9390745386283977\n",
      "\n",
      "env reset!\n",
      "starting_state [336.6      336.6      336.6      336.6      336.6       39.741768\n",
      "  41.22235    7.326497]\n",
      "timestep:  0\n",
      "new state [299.30377  299.7497   309.4344   299.8877   330.75974   44.275276\n",
      "  41.285793  75.66797 ]\n",
      "reward:  -0.8122344436515816\n",
      "timestep:  1\n",
      "new state [244.71584  244.81569  249.66745  244.83806  270.81668   52.866043\n",
      " 112.38886  127.82566 ]\n",
      "reward:  -0.9155160057904533\n",
      "timestep:  2\n",
      "new state [558.5      558.5      558.5      558.5      558.5       22.954668\n",
      "  38.80809   79.71137 ]\n",
      "reward:  -0.8800479544159521\n",
      "\n",
      "env reset!\n",
      "starting_state [558.5       558.5       558.5       558.5       558.5         8.8545\n",
      "   1.7924875   8.052737 ]\n",
      "timestep:  0\n",
      "new state [552.7528    552.5155    549.645     552.43463   552.12        5.609539\n",
      "   7.5100718   4.0235605]\n",
      "reward:  -0.9493003203452854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  1\n",
      "new state [545.87335  545.7317   544.5032   545.6818   548.9283    46.625374\n",
      "  40.536503  65.2993  ]\n",
      "reward:  -0.8396585025478865\n",
      "timestep:  2\n",
      "new state [454.4     454.4     454.4     454.4     454.4      75.72425  94.26665\n",
      "  65.86504]\n",
      "reward:  -0.9076098209698429\n",
      "\n",
      "env reset!\n",
      "starting_state [454.4      454.4      454.4      454.4      454.4       16.239038\n",
      "  26.541824  42.66182 ]\n",
      "timestep:  0\n",
      "new state [424.70282  424.84818  425.95715  424.89996  420.60666   18.141928\n",
      "   6.920915  28.72264 ]\n",
      "reward:  -0.9062699301163597\n",
      "timestep:  1\n",
      "new state [408.33023  407.98764  402.4701   407.87555  397.85672   20.395384\n",
      "  17.43484   28.010838]\n",
      "reward:  -0.9552226060752397\n",
      "timestep:  2\n",
      "new state [292.1     292.1     292.1     292.1     292.1      52.04399  50.57515\n",
      "  69.5221 ]\n",
      "reward:  -0.9074862298578679\n",
      "\n",
      "env reset!\n",
      "starting_state [292.1     292.1     292.1     292.1     292.1      44.41743  53.63957\n",
      "  93.22526]\n",
      "timestep:  0\n",
      "new state [264.44244  264.41516  263.53046  264.40747  260.85968   53.171635\n",
      "  53.811844  17.529573]\n",
      "reward:  -1.7732161098133217\n",
      "timestep:  1\n",
      "new state [213.49338  213.93634  223.80812  214.07242  246.92943   47.94509\n",
      "  68.326935 282.14127 ]\n",
      "reward:  -0.8284593460472416\n",
      "timestep:  2\n",
      "new state [488.4      488.4      488.4      488.4      488.4        4.852373\n",
      "   7.818657  14.302141]\n",
      "reward:  -1.829435744085184\n",
      "\n",
      "env reset!\n",
      "starting_state [488.4     488.4     488.4     488.4     488.4      51.2192   74.98765\n",
      " 128.39836]\n",
      "timestep:  0\n",
      "new state [400.9284   401.12616  401.38593  401.20087  386.69418   56.98157\n",
      "  41.377167  90.498856]\n",
      "reward:  -0.910864024660186\n",
      "timestep:  1\n",
      "new state [338.69467  338.08173  327.48178  337.8838   315.0043    55.79515\n",
      "  55.610283  71.368744]\n",
      "reward:  -0.9258427134182321\n",
      "timestep:  2\n",
      "new state [623.4      623.4      623.4      623.4      623.4       65.011894\n",
      "  39.646076 116.480385]\n",
      "reward:  -0.8931818937025467\n",
      "\n",
      "env reset!\n",
      "starting_state [623.4      623.4      623.4      623.4      623.4       32.77385\n",
      "  47.948257  49.64708 ]\n",
      "timestep:  0\n",
      "new state [574.94916  575.3979   581.9319   575.54736  584.05804   31.615828\n",
      "  55.26149   69.23797 ]\n",
      "reward:  -0.8764219874263419\n",
      "timestep:  1\n",
      "new state [518.358     519.35956   532.59515   519.69763   529.20447     7.408211\n",
      "   5.7085104   5.003377 ]\n",
      "reward:  -0.8882160563155166\n",
      "timestep:  2\n",
      "new state [442.8      442.8      442.8      442.8      442.8       40.825855\n",
      "  86.69175  119.6945  ]\n",
      "reward:  -0.8751740167183147\n",
      "\n",
      "env reset!\n",
      "starting_state [442.8      442.8      442.8      442.8      442.8       43.107773\n",
      "  72.889244  96.54523 ]\n",
      "timestep:  0\n",
      "new state [366.4901  367.13193 374.59583 367.35193 366.31485  59.03257  76.00735\n",
      " 186.46773]\n",
      "reward:  -0.892346687451813\n",
      "timestep:  1\n",
      "new state [262.49628 262.59857 257.4936  262.65497 303.85895  46.40552  60.88712\n",
      "  69.12301]\n",
      "reward:  -1.045634887241442\n",
      "timestep:  2\n",
      "new state [552.8      552.8      552.8      552.8      552.8       35.454304\n",
      "  45.711605  91.2795  ]\n",
      "reward:  -0.8834148163442817\n",
      "\n",
      "env reset!\n",
      "starting_state [552.8      552.8      552.8      552.8      552.8       10.137753\n",
      "  15.071907  24.344309]\n",
      "timestep:  0\n",
      "new state [535.6079   535.6662   536.0447   535.6872   533.5159    16.575438\n",
      "  20.421974  11.437711]\n",
      "reward:  -0.9067677159087697\n",
      "timestep:  1\n",
      "new state [516.3521   516.63214  521.0494   516.7243   524.4431    50.849857\n",
      "  33.050377  35.747803]\n",
      "reward:  -0.8438541498631115\n",
      "timestep:  2\n",
      "new state [267.1       267.1       267.1       267.1       267.1         5.3387046\n",
      "   6.8743305  10.026472 ]\n",
      "reward:  -0.8876654622137088\n",
      "\n",
      "env reset!\n",
      "starting_state [267.1      267.1      267.1      267.1      267.1       34.193443\n",
      "  31.744572  41.337948]\n",
      "timestep:  0\n",
      "new state [250.9787   250.93555  250.75165  250.91974  253.23619   40.95963\n",
      "  25.543276  84.976944]\n",
      "reward:  -1.755715568709453\n",
      "timestep:  1\n",
      "new state [203.94412  202.965    224.60182  202.6387   224.77135    7.120119\n",
      "  11.146607  21.087925]\n",
      "reward:  -1.2193319020833677\n",
      "timestep:  2\n",
      "new state [204.        204.        204.        204.        204.          5.396743\n",
      "   6.1037455   5.957112 ]\n",
      "reward:  -0.9178547525267405\n",
      "\n",
      "env reset!\n",
      "starting_state [204.       204.       204.       204.       204.         9.975209\n",
      "  13.237509  11.401019]\n",
      "timestep:  0\n",
      "new state [198.44194   198.49362   199.35077   198.51047   200.17384     7.8532887\n",
      "   8.1733885  12.701206 ]\n",
      "reward:  -1.727128775583157\n",
      "timestep:  1\n",
      "new state [188.46046  188.4893   195.00111  188.49841  195.91626    8.361709\n",
      "   9.827693  14.049187]\n",
      "reward:  -1.1309673787022558\n",
      "timestep:  2\n",
      "new state [237.8      237.8      237.8      237.8      237.8       32.564133\n",
      "  44.00888   19.04667 ]\n",
      "reward:  -0.8991355224461031\n",
      "\n",
      "env reset!\n",
      "starting_state [237.8       237.8       237.8       237.8       237.8         7.13509\n",
      "   7.0053797   8.972207 ]\n",
      "timestep:  0\n",
      "new state [234.31415   234.30962   234.32423   234.30785   234.79102     6.7450175\n",
      "  10.266819    8.89521  ]\n",
      "reward:  -1.7543516965018005\n",
      "timestep:  1\n",
      "new state [224.42964  224.54533  226.36766  224.58342  231.80635   29.480658\n",
      "  62.709015  28.188992]\n",
      "reward:  -0.9298292384727518\n",
      "timestep:  2\n",
      "new state [216.3      216.3      216.3      216.3      216.3        8.49617\n",
      "   9.870622  19.917051]\n",
      "reward:  -0.8194241109330509\n",
      "\n",
      "env reset!\n",
      "starting_state [216.3      216.3      216.3      216.3      216.3       43.553753\n",
      "  51.018826   1.      ]\n",
      "timestep:  0\n",
      "new state [198.34927  198.6715   205.04564  198.77332  215.91814   28.891655\n",
      "  43.605488  66.644516]\n",
      "reward:  -1.6473706619688657\n",
      "timestep:  1\n",
      "new state [177.76004  178.17462  185.34485  178.30879  193.58397    6.440929\n",
      "  11.940363  19.323053]\n",
      "reward:  -1.7640622499569474\n",
      "timestep:  2\n",
      "new state [357.5      357.5      357.5      357.5      357.5       42.459766\n",
      "  47.76331   81.45516 ]\n",
      "reward:  -0.9065726846760415\n",
      "\n",
      "env reset!\n",
      "starting_state [357.5       357.5       357.5       357.5       357.5         6.072765\n",
      "   8.961958    7.5151615]\n",
      "timestep:  0\n",
      "new state [348.86856   348.9713    350.55228   349.00528   351.54333     6.4800186\n",
      "   7.7414865  16.02442  ]\n",
      "reward:  -0.8628116746696252\n",
      "timestep:  1\n",
      "new state [338.80774  338.8733   339.64066  338.8958   338.85098    8.881566\n",
      "  12.235224   1.      ]\n",
      "reward:  -0.9236818965408458\n",
      "timestep:  2\n",
      "new state [323.9      323.9      323.9      323.9      323.9       75.30197\n",
      "  49.787437 157.8408  ]\n",
      "reward:  -0.7861479041350209\n",
      "\n",
      "env reset!\n",
      "starting_state [323.9      323.9      323.9      323.9      323.9       48.901306\n",
      "  35.69111   80.94333 ]\n",
      "timestep:  0\n",
      "new state [269.63586  268.91418  296.47906  268.67215  296.77567   75.08307\n",
      "  35.721703 140.8654  ]\n",
      "reward:  -1.1764906667218826\n",
      "timestep:  1\n",
      "new state [192.92905  190.2303   251.31233  189.3286   249.58951   49.725544\n",
      "  55.137745  53.014866]\n",
      "reward:  -1.2312472257306066\n",
      "timestep:  2\n",
      "new state [457.3       457.3       457.3       457.3       457.3        11.368492\n",
      "   9.109175    3.2090178]\n",
      "reward:  -0.8748780693936893\n",
      "\n",
      "env reset!\n",
      "starting_state [457.3      457.3      457.3      457.3      457.3       35.169315\n",
      "  48.360188 143.0966  ]\n",
      "timestep:  0\n",
      "new state [386.27618  385.74988  373.54446  385.59     343.9801    43.604095\n",
      "  53.093307  87.836815]\n",
      "reward:  -0.9477101373460158\n",
      "timestep:  1\n",
      "new state [322.64185  322.101    308.85736  321.93924  274.39838   12.554457\n",
      "  15.851812  31.110483]\n",
      "reward:  -0.9087123992260143\n",
      "timestep:  2\n",
      "new state [267.4       267.4       267.4       267.4       267.4         5.4419436\n",
      "   8.997729   11.274322 ]\n",
      "reward:  -0.9201999291299048\n",
      "\n",
      "env reset!\n",
      "starting_state [267.4      267.4      267.4      267.4      267.4       72.91635\n",
      "  81.09839   65.628204]\n",
      "timestep:  0\n",
      "new state [232.11708 232.3256  236.70593 232.3906  245.3651   51.48809  77.73339\n",
      " 161.97849]\n",
      "reward:  -1.7262273744170529\n",
      "timestep:  1\n",
      "new state [191.2115   191.40652  193.58742  191.4731   191.10573   25.859259\n",
      "  24.853472 117.73947 ]\n",
      "reward:  -1.785764961955495\n",
      "timestep:  2\n",
      "new state [563.6      563.6      563.6      563.6      563.6       48.089382\n",
      "  51.59186   55.553387]\n",
      "reward:  -1.105922908789607\n",
      "\n",
      "env reset!\n",
      "starting_state [563.6      563.6      563.6      563.6      563.6       15.902522\n",
      "  15.575613  42.808907]\n",
      "timestep:  0\n",
      "new state [539.9785   539.7262   535.3011   539.64484  529.69586   14.022411\n",
      "  28.343363  17.737574]\n",
      "reward:  -0.9411956977380714\n",
      "timestep:  1\n",
      "new state [515.7745   516.0379   519.0864   516.12836  515.63324   44.991974\n",
      "  64.075874 106.55253 ]\n",
      "reward:  -0.8396344767256435\n",
      "timestep:  2\n",
      "new state [285.7      285.7      285.7      285.7      285.7       14.01077\n",
      "  18.93984   42.794197]\n",
      "reward:  -0.9088567188430828\n",
      "\n",
      "env reset!\n",
      "starting_state [285.7      285.7      285.7      285.7      285.7       78.967766\n",
      "  92.62216  157.21219 ]\n",
      "timestep:  0\n",
      "new state [237.99298 237.93727 236.48978 237.9205  233.01416  71.12784 156.0503\n",
      " 254.4975 ]\n",
      "reward:  -1.7716632505909728\n",
      "timestep:  1\n",
      "new state [167.24326  167.79532  171.20291  167.99287  147.7508    29.900322\n",
      "  34.581482  75.42273 ]\n",
      "reward:  -1.7681326775728994\n",
      "timestep:  2\n",
      "new state [594.       594.       594.       594.       594.        22.101727\n",
      "  24.940092  45.279736]\n",
      "reward:  -1.1767237089339257\n",
      "\n",
      "env reset!\n",
      "starting_state [594.       594.       594.       594.       594.        21.276386\n",
      "  29.381393  66.78958 ]\n",
      "timestep:  0\n",
      "new state [555.52795  555.41095  551.9754   555.37787  541.1027    33.637905\n",
      "  35.926395  60.168987]\n",
      "reward:  -0.9303194491420187\n",
      "timestep:  1\n",
      "new state [510.94217  510.70383  505.3939   510.6309   493.43695    9.708793\n",
      "  12.176678  21.292076]\n",
      "reward:  -0.9096965957025107\n",
      "timestep:  2\n",
      "new state [393.1      393.1      393.1      393.1      393.1       58.966087\n",
      "  73.504585  49.87436 ]\n",
      "reward:  -0.9124051926185746\n",
      "\n",
      "env reset!\n",
      "starting_state [393.1      393.1      393.1      393.1      393.1       45.40345\n",
      "  33.925877  82.01129 ]\n",
      "timestep:  0\n",
      "new state [340.70416  339.99496  329.8846   339.75845  328.13855   33.562126\n",
      "  72.61967   71.638824]\n",
      "reward:  -0.9319060758664073\n",
      "timestep:  1\n",
      "new state [273.4239    273.83514   278.3173    273.9773    271.37473     6.9421844\n",
      "  15.354708   18.528416 ]\n",
      "reward:  -0.8695087406071257\n",
      "timestep:  2\n",
      "new state [464.       464.       464.       464.       464.        41.18397\n",
      "  93.436844 197.89563 ]\n",
      "reward:  -0.8842220774765469\n",
      "\n",
      "env reset!\n",
      "starting_state [464.        464.        464.        464.        464.          8.760305\n",
      "   5.5812435   1.5295761]\n",
      "timestep:  0\n",
      "new state [457.71613   457.6859    458.05093   457.67322   462.78198     7.0143614\n",
      "   6.200111   10.581147 ]\n",
      "reward:  -0.8420792044793243\n",
      "timestep:  1\n",
      "new state [449.57886  449.49524  449.19727  449.46442  454.39914   29.950949\n",
      "  68.60144  108.1626  ]\n",
      "reward:  -0.911107344804218\n",
      "timestep:  2\n",
      "new state [472.9      472.9      472.9      472.9      472.9      102.919235\n",
      "  66.252045 135.50792 ]\n",
      "reward:  -0.9043253848886877\n",
      "\n",
      "env reset!\n",
      "starting_state [472.9      472.9      472.9      472.9      472.9       33.60332\n",
      "  57.009018  56.126793]\n",
      "timestep:  0\n",
      "new state [417.72495  418.42264  428.0955   418.65656  428.42358   36.321156\n",
      "  32.097343  22.286491]\n",
      "reward:  -0.8716054769700391\n",
      "timestep:  1\n",
      "new state [383.09265  383.83698  396.45663  384.07904  410.74695   19.484802\n",
      "  21.746786  21.200073]\n",
      "reward:  -0.8616324109152725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  2\n",
      "new state [221.7       221.7       221.7       221.7       221.7         9.273838\n",
      "   7.4962244   6.80624  ]\n",
      "reward:  -0.8756082906627898\n",
      "\n",
      "env reset!\n",
      "starting_state [221.7      221.7      221.7      221.7      221.7       18.730669\n",
      "  12.072046  12.40901 ]\n",
      "timestep:  0\n",
      "new state [215.09465  215.03098  214.64449  215.00807  217.53279   14.357786\n",
      "  11.766319  30.252405]\n",
      "reward:  -1.7465311532838894\n",
      "timestep:  1\n",
      "new state [196.96152  196.6689   192.76619  196.5705   207.39787    5.742756\n",
      "   8.286935   8.829516]\n",
      "reward:  -1.0382833444533834\n",
      "timestep:  2\n",
      "new state [170.       170.       170.       170.       170.        14.507949\n",
      "  18.000618  64.7807  ]\n",
      "reward:  -0.8784354063785779\n",
      "\n",
      "env reset!\n",
      "starting_state [170.        170.        170.        170.        170.          5.2659383\n",
      "   8.845427    8.063645 ]\n",
      "timestep:  0\n",
      "new state [166.43745  166.48505  167.16566  166.5009   167.29501    5.69863\n",
      "   7.238175  16.642036]\n",
      "reward:  -1.727733961079378\n",
      "timestep:  1\n",
      "new state [162.35081  162.38109  162.63234  162.39172  161.72046   26.489044\n",
      "  44.003128  91.44425 ]\n",
      "reward:  -1.792035372105724\n",
      "timestep:  2\n",
      "new state [312.5      312.5      312.5      312.5      312.5       49.409008\n",
      "  50.888496  74.72257 ]\n",
      "reward:  -1.7857360052921074\n",
      "\n",
      "env reset!\n",
      "starting_state [312.5      312.5      312.5      312.5      312.5       42.88406\n",
      "  63.042206 135.53072 ]\n",
      "timestep:  0\n",
      "new state [278.7629   278.72278  276.47284  278.71448  267.10117   46.853836\n",
      "  54.501648  81.48021 ]\n",
      "reward:  -1.7878694803328956\n",
      "timestep:  1\n",
      "new state [214.75719  214.73578  212.60547  214.73444  239.78883   53.78755\n",
      "  52.087612  18.043081]\n",
      "reward:  -0.9869706800208755\n",
      "timestep:  2\n",
      "new state [640.9      640.9      640.9      640.9      640.9       82.173065\n",
      " 134.53383   57.94256 ]\n",
      "reward:  -0.8319889851817535\n",
      "\n",
      "env reset!\n",
      "starting_state [640.9      640.9      640.9      640.9      640.9       59.432037\n",
      "  85.04154   81.5292  ]\n",
      "timestep:  0\n",
      "new state [556.0442   556.87213  569.4181   557.1463   576.28766   33.977608\n",
      "  73.60994   60.90982 ]\n",
      "reward:  -0.8716533861580598\n",
      "timestep:  1\n",
      "new state [490.5611   492.6423   522.2893   493.33743  528.0164    32.893726\n",
      "  32.738102  51.507683]\n",
      "reward:  -0.8570119407542316\n",
      "timestep:  2\n",
      "new state [358.7      358.7      358.7      358.7      358.7       17.141262\n",
      "  32.127758  15.155621]\n",
      "reward:  -0.9058356828178444\n",
      "\n",
      "env reset!\n",
      "starting_state [358.7      358.7      358.7      358.7      358.7       16.917152\n",
      "  15.609214  16.31908 ]\n",
      "timestep:  0\n",
      "new state [340.83856   340.82553   341.3677    340.81885   345.76523    10.1829605\n",
      "  11.311356    8.105378 ]\n",
      "reward:  -0.8818719879098776\n",
      "timestep:  1\n",
      "new state [329.43552  329.5024   331.6846   329.52078  339.3381    37.911407\n",
      "  57.753685 119.89824 ]\n",
      "reward:  -0.8585350436954079\n",
      "timestep:  2\n",
      "new state [443.6      443.6      443.6      443.6      443.6       84.632385\n",
      "  66.2095   149.5492  ]\n",
      "reward:  -0.9243217022111463\n",
      "\n",
      "env reset!\n",
      "starting_state [443.6      443.6      443.6      443.6      443.6        8.648337\n",
      "  10.505556   9.598814]\n",
      "timestep:  0\n",
      "new state [432.79733  432.87137  434.18912  432.89523  435.99182    8.534402\n",
      "   9.458114  12.112463]\n",
      "reward:  -0.8706887250955091\n",
      "timestep:  1\n",
      "new state [422.02515 422.11243 423.74875 422.14032 426.39435  67.76523  98.37852\n",
      " 188.71396]\n",
      "reward:  -0.8923655162200569\n",
      "timestep:  2\n",
      "new state [398.8      398.8      398.8      398.8      398.8       36.08509\n",
      "  39.236446  37.480347]\n",
      "reward:  -0.9187714845698794\n",
      "\n",
      "env reset!\n",
      "starting_state [398.8      398.8      398.8      398.8      398.8       53.609783\n",
      "  69.15142   93.68984 ]\n",
      "timestep:  0\n",
      "new state [321.74377 322.0112  325.51865 322.1017  324.57184  48.09443  85.16225\n",
      " 178.50134]\n",
      "reward:  -0.8951778640567909\n",
      "timestep:  1\n",
      "new state [218.17291 218.5938  218.4835  218.755   264.78223  37.23455  54.19108\n",
      "  84.4289 ]\n",
      "reward:  -1.0342795902411956\n",
      "timestep:  2\n",
      "new state [576.5      576.5      576.5      576.5      576.5       27.206663\n",
      "  41.536083   5.398255]\n",
      "reward:  -0.9042909208869079\n",
      "\n",
      "env reset!\n",
      "starting_state [576.5      576.5      576.5      576.5      576.5       39.51871\n",
      "  62.034103 173.62975 ]\n",
      "timestep:  0\n",
      "new state [489.5225   489.08728  476.7722   488.96246  439.00043   70.727875\n",
      "  63.94251   93.313   ]\n",
      "reward:  -0.9447190244642071\n",
      "timestep:  1\n",
      "new state [409.77945  408.99152  393.34518  408.74365  365.06464   35.703125\n",
      "  48.16002   61.922764]\n",
      "reward:  -0.9015028041344424\n",
      "timestep:  2\n",
      "new state [568.2      568.2      568.2      568.2      568.2       53.196083\n",
      "   9.91678   89.91135 ]\n",
      "reward:  -0.8914438742246426\n",
      "\n",
      "env reset!\n",
      "starting_state [568.2     568.2     568.2     568.2     568.2      36.24253  64.35823\n",
      "  59.30623]\n",
      "timestep:  0\n",
      "new state [507.40405  508.27472  520.4122   508.5664   521.2017    43.5855\n",
      "  49.650078  51.289314]\n",
      "reward:  -0.8666440654812873\n",
      "timestep:  1\n",
      "new state [454.09167  455.18488  471.7118   455.547    480.55347   34.74719\n",
      "  43.892017  81.34888 ]\n",
      "reward:  -0.8788334911360451\n",
      "timestep:  2\n",
      "new state [563.4     563.4     563.4     563.4     563.4      88.398    97.89396\n",
      " 199.51474]\n",
      "reward:  -0.9163351637989795\n",
      "\n",
      "env reset!\n",
      "starting_state [563.4      563.4      563.4      563.4      563.4       19.60891\n",
      "  10.847639  22.760033]\n",
      "timestep:  0\n",
      "new state [545.7731    545.4524    541.6333    545.34296   545.3675      8.09595\n",
      "  18.542501    7.0146136]\n",
      "reward:  -0.9226253528455718\n",
      "timestep:  1\n",
      "new state [531.35144  531.44104  533.68066  531.46783  539.8013     5.648247\n",
      "  11.647231  20.138252]\n",
      "reward:  -0.808647515126313\n",
      "timestep:  2\n",
      "new state [113.3       113.3       113.3       113.3       113.3         9.192139\n",
      "   9.424058    9.3811455]\n",
      "reward:  -0.9113494040957532\n",
      "\n",
      "env reset!\n",
      "starting_state [113.3      113.3      113.3      113.3      113.3        9.077349\n",
      "   5.139045  17.247025]\n",
      "timestep:  0\n",
      "new state [109.1694    109.08115   107.798874  109.05176   107.522385    6.418506\n",
      "   6.6911726   5.971604 ]\n",
      "reward:  -1.8098915126989727\n",
      "timestep:  1\n",
      "new state [106.148094 106.07046  105.06116  106.04422  105.51785   74.924\n",
      "  49.702732  99.698296]\n",
      "reward:  -1.7326503000844442\n",
      "timestep:  2\n",
      "new state [506.3      506.3      506.3      506.3      506.3       67.775085\n",
      "  74.19544   67.98529 ]\n",
      "reward:  -1.7817618371292365\n",
      "\n",
      "env reset!\n",
      "starting_state [506.3      506.3      506.3      506.3      506.3       46.976486\n",
      "  42.63326   92.41359 ]\n",
      "timestep:  0\n",
      "new state [446.22403  445.69293  437.586    445.51767  433.09872   48.35976\n",
      "  57.512817  76.2418  ]\n",
      "reward:  -0.9259972202864303\n",
      "timestep:  1\n",
      "new state [381.28497  380.89783  375.09943  380.77002  372.69125   39.86509\n",
      "  43.393986  62.079388]\n",
      "reward:  -0.8941614832992889\n",
      "timestep:  2\n",
      "new state [346.        346.        346.        346.        346.          3.2040584\n",
      "  11.306632    1.7282629]\n",
      "reward:  -0.8994975256877425\n",
      "\n",
      "env reset!\n",
      "starting_state [346.        346.        346.        346.        346.          4.8178806\n",
      "  13.26999    20.839603 ]\n",
      "timestep:  0\n",
      "new state [332.34985  332.51068  333.98242  332.56708  329.4939    11.012333\n",
      "  14.259009  30.54517 ]\n",
      "reward:  -0.9037568281655672\n",
      "timestep:  1\n",
      "new state [313.88452  313.98987  313.99042  314.03003  305.3011    43.476906\n",
      "  16.230469  74.36156 ]\n",
      "reward:  -0.9261470103193747\n",
      "timestep:  2\n",
      "new state [302.8      302.8      302.8      302.8      302.8        8.208014\n",
      "  10.970992  18.40127 ]\n",
      "reward:  -0.9598512981434271\n",
      "\n",
      "env reset!\n",
      "starting_state [302.8      302.8      302.8      302.8      302.8       17.698023\n",
      "  15.023893  33.569214]\n",
      "timestep:  0\n",
      "new state [281.02228  280.7963   277.45804  280.72134  291.55203   13.728886\n",
      "  19.553621  47.191288]\n",
      "reward:  -1.024099606890963\n",
      "timestep:  1\n",
      "new state [254.92755  254.6073   248.55125  254.50551  254.17783   67.167595\n",
      "  67.565704 131.93954 ]\n",
      "reward:  -0.9344547610438768\n",
      "timestep:  2\n",
      "new state [554.6      554.6      554.6      554.6      554.6       46.962765\n",
      "  73.49508  152.8346  ]\n",
      "reward:  -0.9195967656322597\n",
      "\n",
      "env reset!\n",
      "starting_state [554.6      554.6      554.6      554.6      554.6       42.640495\n",
      "  66.17611   12.99464 ]\n",
      "timestep:  0\n",
      "new state [501.39282  502.63     523.1981   503.03342  544.2587    42.420963\n",
      "  42.42093  149.11977 ]\n",
      "reward:  -0.7968364281292858\n",
      "timestep:  1\n",
      "new state [429.84625   430.09515   432.4442    430.18262   426.1701      3.754453\n",
      "  10.728432    7.5455666]\n",
      "reward:  -0.9563161477492784\n",
      "timestep:  2\n",
      "new state [423.5      423.5      423.5      423.5      423.5       75.334785\n",
      "  48.09658   51.355785]\n",
      "reward:  -0.8422544506629585\n",
      "\n",
      "env reset!\n",
      "starting_state [423.5      423.5      423.5      423.5      423.5       46.966454\n",
      "  42.0583     1.      ]\n",
      "timestep:  0\n",
      "new state [384.8328   385.1903   394.7465   385.29507  422.66388   24.042208\n",
      "  38.755566  82.82533 ]\n",
      "reward:  -0.8024939474242101\n",
      "timestep:  1\n",
      "new state [336.62424 336.98138 344.04218 337.0944  357.06628  37.9716   53.52433\n",
      "  59.40087]\n",
      "reward:  -0.9264449732732591\n",
      "timestep:  2\n",
      "new state [473.3      473.3      473.3      473.3      473.3       43.403957\n",
      "  54.507854 140.09032 ]\n",
      "reward:  -0.8813316885548589\n",
      "\n",
      "env reset!\n",
      "starting_state [473.3      473.3      473.3      473.3      473.3       10.125242\n",
      "  19.976053  45.815742]\n",
      "timestep:  0\n",
      "new state [448.47534  448.50122  447.16525  448.51556  437.0163    12.134896\n",
      "  19.819057  36.660152]\n",
      "reward:  -0.9318492511163774\n",
      "timestep:  1\n",
      "new state [425.18878   425.27518   423.8215    425.31302   407.9794      7.1837807\n",
      "   4.037506   11.16719  ]\n",
      "reward:  -0.9162804071122453\n",
      "timestep:  2\n",
      "new state [230.1      230.1      230.1      230.1      230.1       13.681161\n",
      "  47.303646  74.70519 ]\n",
      "reward:  -0.9379105332475655\n",
      "\n",
      "env reset!\n",
      "starting_state [230.1     230.1     230.1     230.1     230.1      51.68909  39.60568\n",
      " 123.81619]\n",
      "timestep:  0\n",
      "new state [201.69516  201.24692  194.02335  201.09987  188.62793   45.431866\n",
      "  30.204258 101.48318 ]\n",
      "reward:  -1.8085248483388463\n",
      "timestep:  1\n",
      "new state [178.50887   177.62567   163.67761   177.33505   154.63586    12.048583\n",
      "   5.3104997  10.341951 ]\n",
      "reward:  -1.8114779541318635\n",
      "timestep:  2\n",
      "new state [322.1      322.1      322.1      322.1      322.1       35.117516\n",
      "  45.045807  39.47191 ]\n",
      "reward:  -0.9893628370724512\n",
      "\n",
      "env reset!\n",
      "starting_state [322.1     322.1     322.1     322.1     322.1      37.10835  80.3216\n",
      "  50.47956]\n",
      "timestep:  0\n",
      "new state [254.32333  255.84906  277.64044  256.35834  305.15182   31.311005\n",
      "  68.57273   87.74197 ]\n",
      "reward:  -0.8959762987571421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  1\n",
      "new state [186.28113  188.6745   220.39314  189.4816   235.64359   89.50899\n",
      " 101.893684  97.4443  ]\n",
      "reward:  -0.8886655529086533\n",
      "timestep:  2\n",
      "new state [645.7      645.7      645.7      645.7      645.7       40.498337\n",
      "  61.951805  56.39791 ]\n",
      "reward:  -1.4303422330759046\n",
      "\n",
      "env reset!\n",
      "starting_state [645.7      645.7      645.7      645.7      645.7       60.89885\n",
      "  93.65985   60.738705]\n",
      "timestep:  0\n",
      "new state [560.44446  561.7603   582.417    562.1935   597.5408    36.809868\n",
      "  81.66664   84.302216]\n",
      "reward:  -0.8467802631505602\n",
      "timestep:  1\n",
      "new state [484.22647  486.7887   523.3537   487.64417  530.7462    36.449165\n",
      "  73.52696   85.32822 ]\n",
      "reward:  -0.8726142318566452\n",
      "timestep:  2\n",
      "new state [651.5      651.5      651.5      651.5      651.5       56.152573\n",
      "  43.663044 101.74984 ]\n",
      "reward:  -0.8818529287381127\n",
      "\n",
      "env reset!\n",
      "starting_state [651.5      651.5      651.5      651.5      651.5       34.027843\n",
      "  53.530132  50.63875 ]\n",
      "timestep:  0\n",
      "new state [599.3548   599.968    608.84015  600.1724   611.36957   54.052227\n",
      "  38.05183   64.70092 ]\n",
      "reward:  -0.8697257080725642\n",
      "timestep:  1\n",
      "new state [545.8546  545.8649  547.97797 545.8623  560.105    35.20498  65.63593\n",
      " 217.53984]\n",
      "reward:  -0.9111487881612518\n",
      "timestep:  2\n",
      "new state [525.6      525.6      525.6      525.6      525.6       51.899887\n",
      "  42.987217 131.81314 ]\n",
      "reward:  -0.9564465434402604\n",
      "\n",
      "env reset!\n",
      "starting_state [525.6       525.6       525.6       525.6       525.6         3.5835872\n",
      "  11.536039   10.604113 ]\n",
      "timestep:  0\n",
      "new state [515.6654   515.8952   518.8005   515.97314  517.198      2.740631\n",
      "   6.006493  13.085949]\n",
      "reward:  -0.861016162009252\n",
      "timestep:  1\n",
      "new state [508.46005  508.7122   511.42688  508.79926  506.83453   16.922613\n",
      "  61.15739  110.63368 ]\n",
      "reward:  -0.9283777521408685\n",
      "timestep:  2\n",
      "new state [254.9      254.9      254.9      254.9      254.9       20.224886\n",
      "  33.344955  48.69424 ]\n",
      "reward:  -0.91469770036615\n",
      "\n",
      "env reset!\n",
      "starting_state [254.9      254.9      254.9      254.9      254.9        9.672476\n",
      "   9.099977  15.319438]\n",
      "timestep:  0\n",
      "new state [249.95879  249.93347  249.60329  249.92491  249.76503    8.313873\n",
      "   8.112054  17.591297]\n",
      "reward:  -1.7713851453495515\n",
      "timestep:  1\n",
      "new state [238.73132  238.62062  236.90182  238.58418  235.83119   22.84295\n",
      "  36.160473  29.250187]\n",
      "reward:  -0.9262311613737902\n",
      "timestep:  2\n",
      "new state [178.4      178.4      178.4      178.4      178.4       19.509071\n",
      "  20.405401  34.33713 ]\n",
      "reward:  -0.8595701352253544\n",
      "\n",
      "env reset!\n",
      "starting_state [178.4     178.4     178.4     178.4     178.4      68.18494 106.23563\n",
      " 141.49883]\n",
      "timestep:  0\n",
      "new state [130.5773   130.91196  134.82968  131.02602  130.97011   60.389053\n",
      " 108.39385  105.72108 ]\n",
      "reward:  -1.754311415156608\n",
      "timestep:  1\n",
      "new state [86.82477   87.758194  99.866776  88.07285   95.51356   38.870117\n",
      " 60.651524   4.2691054]\n",
      "reward:  -1.7316054043221834\n",
      "timestep:  2\n",
      "new state [629.8      629.8      629.8      629.8      629.8       39.511646\n",
      "  72.20736   86.31831 ]\n",
      "reward:  -1.639197977259475\n",
      "\n",
      "env reset!\n",
      "starting_state [629.8      629.8      629.8      629.8      629.8       23.630016\n",
      "  53.624878 165.23486 ]\n",
      "timestep:  0\n",
      "new state [554.57904  554.31775  543.3178   554.2548   498.95813   57.01018\n",
      "  60.347954 107.4253  ]\n",
      "reward:  -0.9525489932000739\n",
      "timestep:  1\n",
      "new state [478.05267 477.51154 461.9889  477.35727 413.85944  58.90677  73.86163\n",
      " 113.98376]\n",
      "reward:  -0.9136528689380348\n",
      "timestep:  2\n",
      "new state [451.5      451.5      451.5      451.5      451.5        5.199422\n",
      "   8.999567  11.531258]\n",
      "reward:  -0.9039935178992105\n",
      "\n",
      "env reset!\n",
      "starting_state [451.5      451.5      451.5      451.5      451.5       35.979908\n",
      "  42.256226  71.03247 ]\n",
      "timestep:  0\n",
      "new state [400.17572  400.1208   398.75626  400.10455  395.23016   39.213387\n",
      "  42.958088  71.78563 ]\n",
      "reward:  -0.9098219363446061\n",
      "timestep:  1\n",
      "new state [347.2315    347.0585    343.73492   347.00397   338.36212     7.3372307\n",
      "   7.7558074  12.387713 ]\n",
      "reward:  -0.9095189371356003\n",
      "timestep:  2\n",
      "new state [299.8      299.8      299.8      299.8      299.8       22.23724\n",
      "  38.209564  38.80978 ]\n",
      "reward:  -0.9066558184816755\n",
      "\n",
      "env reset!\n",
      "starting_state [299.8     299.8     299.8     299.8     299.8      67.93089  80.40699\n",
      " 217.3624 ]\n",
      "timestep:  0\n",
      "new state [250.59482  250.21904  242.24493  250.10162  227.0007    75.81123\n",
      "  60.455784  25.882843]\n",
      "reward:  -1.802350911024998\n",
      "timestep:  1\n",
      "new state [186.6468   186.33234  218.19437  186.21588  218.27269   46.51531\n",
      "  46.771637  80.83141 ]\n",
      "reward:  -1.0070801586495186\n",
      "timestep:  2\n",
      "new state [467.4       467.4       467.4       467.4       467.4         7.8861012\n",
      "   4.584201   12.7137   ]\n",
      "reward:  -0.9117773765689712\n",
      "\n",
      "env reset!\n",
      "starting_state [467.4      467.4      467.4      467.4      467.4       52.81623\n",
      "  35.049046  93.748856]\n",
      "timestep:  0\n",
      "new state [409.24655  408.27502  394.58798  407.9505   393.14258   38.648792\n",
      "  47.95612  114.60722 ]\n",
      "reward:  -0.9371743709145983\n",
      "timestep:  1\n",
      "new state [343.87384  342.55682  321.18826  342.12634  302.3739    62.887608\n",
      "  68.63606   48.027397]\n",
      "reward:  -0.9333205206260511\n",
      "timestep:  2\n",
      "new state [394.6       394.6       394.6       394.6       394.6         4.983289\n",
      "   9.993295    1.9410572]\n",
      "reward:  -0.8576518278273149\n",
      "\n",
      "env reset!\n",
      "starting_state [394.6      394.6      394.6      394.6      394.6       15.260735\n",
      "  11.482609  66.36949 ]\n",
      "timestep:  0\n",
      "new state [367.99252  367.37097  356.39218  367.17062  342.0472    23.294195\n",
      "  24.174845  30.15373 ]\n",
      "reward:  -0.9805761581498549\n",
      "timestep:  1\n",
      "new state [340.15845   339.54144   329.167     339.34094   318.15317     7.01128\n",
      "   7.566665    7.6300273]\n",
      "reward:  -0.8911633095804856\n",
      "timestep:  2\n",
      "new state [308.7      308.7      308.7      308.7      308.7       49.596004\n",
      "  27.82501   10.060733]\n",
      "reward:  -0.8779984905524812\n",
      "\n",
      "env reset!\n",
      "starting_state [308.7      308.7      308.7      308.7      308.7       41.31072\n",
      "  52.407177  95.68648 ]\n",
      "timestep:  0\n",
      "new state [281.52     281.49652  280.46262  281.49072  276.63837   31.152412\n",
      "  69.70468  113.64171 ]\n",
      "reward:  -1.7765218780571874\n",
      "timestep:  1\n",
      "new state [206.93506  207.56729  211.9903   207.7934   238.56569   11.565746\n",
      "  19.625528  35.917618]\n",
      "reward:  -1.0077778316809731\n",
      "timestep:  2\n",
      "new state [288.7      288.7      288.7      288.7      288.7       20.998123\n",
      "  27.793528  59.579525]\n",
      "reward:  -0.9155292048983489\n",
      "\n",
      "env reset!\n",
      "starting_state [288.7      288.7      288.7      288.7      288.7       52.72184\n",
      "  55.522614  90.40519 ]\n",
      "timestep:  0\n",
      "new state [259.7261   259.65128  258.5466   259.62628  258.39813   45.581596\n",
      "  79.116684  74.49585 ]\n",
      "reward:  -1.7690974973939713\n",
      "timestep:  1\n",
      "new state [184.28409  185.23785  198.48605  185.55742  233.41096   20.003832\n",
      "  27.409702  59.636425]\n",
      "reward:  -0.9395682895532309\n",
      "timestep:  2\n",
      "new state [297.4      297.4      297.4      297.4      297.4       11.660681\n",
      "  12.539161  13.080906]\n",
      "reward:  -0.9273297779218599\n",
      "\n",
      "env reset!\n",
      "starting_state [297.4      297.4      297.4      297.4      297.4       61.309956\n",
      "  71.836784 122.0361  ]\n",
      "timestep:  0\n",
      "new state [260.37997  260.33566  259.19772  260.32227  256.50256   51.056732\n",
      "  85.04916  143.0995  ]\n",
      "reward:  -1.771720853115346\n",
      "timestep:  1\n",
      "new state [219.68198  219.81998  219.68433  219.8722   208.55627   23.894533\n",
      "  40.218304  76.06905 ]\n",
      "reward:  -1.77071401025103\n",
      "timestep:  2\n",
      "new state [718.4      718.4      718.4      718.4      718.4       54.537197\n",
      "  93.56043  141.97952 ]\n",
      "reward:  -0.9178777761505441\n",
      "\n",
      "env reset!\n",
      "starting_state [718.4       718.4       718.4       718.4       718.4         4.5785327\n",
      "   9.066792   10.567382 ]\n",
      "timestep:  0\n",
      "new state [709.49786   709.6118    711.01843   709.65063   710.02783     5.7981653\n",
      "   6.592948   12.175989 ]\n",
      "reward:  -0.8822801766956038\n",
      "timestep:  1\n",
      "new state [701.17725   701.2671    702.2002    701.29834   700.3829      5.0177617\n",
      "   7.7672243   7.044707 ]\n",
      "reward:  -0.9160622739307233\n",
      "timestep:  2\n",
      "new state [207.6      207.6      207.6      207.6      207.6       58.870045\n",
      "  40.478016 112.15107 ]\n",
      "reward:  -0.867165198717764\n",
      "\n",
      "env reset!\n",
      "starting_state [207.6      207.6      207.6      207.6      207.6       57.144665\n",
      " 110.01752   51.478374]\n",
      "timestep:  0\n",
      "new state [169.20587  170.08832  183.51337  170.37985  190.29279   33.188248\n",
      "  70.582565 142.22348 ]\n",
      "reward:  -1.6851015253467418\n",
      "timestep:  1\n",
      "new state [134.42358 135.45815 148.70032 135.80762 142.65576  95.10848  97.83995\n",
      " 135.98204]\n",
      "reward:  -1.7838497472087436\n",
      "timestep:  2\n",
      "new state [513.9      513.9      513.9      513.9      513.9        9.112249\n",
      "  11.465247  25.486578]\n",
      "reward:  -1.7591190014589542\n",
      "\n",
      "env reset!\n",
      "starting_state [513.9      513.9      513.9      513.9      513.9        8.970219\n",
      "   9.570055  15.914813]\n",
      "timestep:  0\n",
      "new state [502.04614  502.0147   501.53516  502.00433  501.29227   11.024592\n",
      "  15.763436  15.195174]\n",
      "reward:  -0.9092405719337742\n",
      "timestep:  1\n",
      "new state [486.29535  486.41635  488.24405  486.45645  489.25006   43.250664\n",
      "  50.57691   95.89465 ]\n",
      "reward:  -0.8720119254866135\n",
      "timestep:  2\n",
      "new state [405.6      405.6      405.6      405.6      405.6       77.499535\n",
      "  49.584866  76.46602 ]\n",
      "reward:  -0.917817582567218\n",
      "\n",
      "env reset!\n",
      "starting_state [405.6       405.6       405.6       405.6       405.6         6.377598\n",
      "   6.05187     2.2457764]\n",
      "timestep:  0\n",
      "new state [399.67615   399.71628   400.77316   399.7281    403.81598     7.0513844\n",
      "   7.262021   23.258137 ]\n",
      "reward:  -0.8349234096721061\n",
      "timestep:  1\n",
      "new state [388.02097  387.9198   386.35593  387.8865   385.39722   10.442767\n",
      "  10.475312   8.356614]\n",
      "reward:  -0.9509369843564759\n",
      "timestep:  2\n",
      "new state [253.8      253.8      253.8      253.8      253.8       53.514565\n",
      "  42.384403 105.4081  ]\n",
      "reward:  -0.8660161002734924\n",
      "\n",
      "env reset!\n",
      "starting_state [253.8       253.8       253.8       253.8       253.8        28.961609\n",
      "  17.644724    5.6532435]\n",
      "timestep:  0\n",
      "new state [245.14067  245.08232  245.3998   245.0592   251.88524   50.59441\n",
      "  32.11641   36.165215]\n",
      "reward:  -1.7082645820159623\n",
      "timestep:  1\n",
      "new state [202.60709   202.09799   199.0959    201.91438   239.74373     6.5600696\n",
      "   6.290268   15.132929 ]\n",
      "reward:  -0.9478089567611593\n",
      "timestep:  2\n",
      "new state [174.2       174.2       174.2       174.2       174.2         7.4560738\n",
      "   8.290605    1.       ]\n",
      "reward:  -0.9327433158902398\n",
      "\n",
      "env reset!\n",
      "starting_state [174.2      174.2      174.2      174.2      174.2       20.493513\n",
      "  20.03147   56.196392]\n",
      "timestep:  0\n",
      "new state [161.24564  161.10558  158.57709  161.06046  155.37755   21.836515\n",
      "  12.353683  43.92662 ]\n",
      "reward:  -1.803660014634957\n",
      "timestep:  1\n",
      "new state [151.07376   150.71118   144.8918    150.59216   140.66348    13.963061\n",
      "   3.9526715  42.259834 ]\n",
      "reward:  -1.813059811926228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  2\n",
      "new state [330.6      330.6      330.6      330.6      330.6       58.317585\n",
      "  94.88584   52.729427]\n",
      "reward:  -1.308347366084725\n",
      "\n",
      "env reset!\n",
      "starting_state [330.6      330.6      330.6      330.6      330.6       18.382423\n",
      "  27.60437   15.548024]\n",
      "timestep:  0\n",
      "new state [305.87317 306.27347 312.71594 306.40472 318.2689    9.41874  17.17638\n",
      "  26.21136]\n",
      "reward:  -0.8395160469848071\n",
      "timestep:  1\n",
      "new state [287.3353   287.87106  295.57675  288.04977  297.50616   36.315716\n",
      "  62.315144 154.86093 ]\n",
      "reward:  -0.9023141544412717\n",
      "timestep:  2\n",
      "new state [348.7      348.7      348.7      348.7      348.7       24.402864\n",
      "  22.88881   21.793228]\n",
      "reward:  -0.937057424968226\n",
      "\n",
      "env reset!\n",
      "starting_state [348.7      348.7      348.7      348.7      348.7        5.652894\n",
      "   3.737667   8.455528]\n",
      "timestep:  0\n",
      "new state [342.84747  342.7587   341.59683  342.72876  342.00174    8.592444\n",
      "  11.411427   9.920372]\n",
      "reward:  -0.9274669520350772\n",
      "timestep:  1\n",
      "new state [331.4934   331.5103   332.0786   331.51492  334.13858   33.198223\n",
      "  36.86261   25.18001 ]\n",
      "reward:  -0.8664901611189583\n",
      "timestep:  2\n",
      "new state [343.8      343.8      343.8      343.8      343.8       37.02626\n",
      "  61.242004 106.02195 ]\n",
      "reward:  -0.8560706419004399\n",
      "\n",
      "env reset!\n",
      "starting_state [343.8      343.8      343.8      343.8      343.8       28.437876\n",
      "  51.52373   42.579025]\n",
      "timestep:  0\n",
      "new state [296.44824  297.20862  308.03152  297.4626   310.0536    37.663555\n",
      "  54.62608  151.71185 ]\n",
      "reward:  -0.8591165599915066\n",
      "timestep:  1\n",
      "new state [219.1896   219.50629  219.00473  219.6289   259.24768   24.213984\n",
      "  23.079662  28.369877]\n",
      "reward:  -1.0622642210686581\n",
      "timestep:  2\n",
      "new state [276.1      276.1      276.1      276.1      276.1        9.136531\n",
      "  12.523731  21.410742]\n",
      "reward:  -0.8909046277477668\n",
      "\n",
      "env reset!\n",
      "starting_state [276.1       276.1       276.1       276.1       276.1         4.23267\n",
      "   8.1589775  10.029881 ]\n",
      "timestep:  0\n",
      "new state [267.9321   268.02664  269.16214  268.0589   272.738      6.454905\n",
      "  12.391931  10.147669]\n",
      "reward:  -0.9715056371648635\n",
      "timestep:  1\n",
      "new state [256.69138 256.97943 260.83188 257.07645 264.6955   68.53907 105.69028\n",
      " 138.0116 ]\n",
      "reward:  -0.8577696094729744\n",
      "timestep:  2\n",
      "new state [318.4       318.4       318.4       318.4       318.4         7.5205097\n",
      "   6.674473   10.792838 ]\n",
      "reward:  -0.8917834924517822\n",
      "\n",
      "env reset!\n",
      "starting_state [318.4      318.4      318.4      318.4      318.4        5.227116\n",
      "   9.870747  18.93303 ]\n",
      "timestep:  0\n",
      "new state [306.91486  306.9589   306.9709   306.97565  312.05783    9.218391\n",
      "  11.55042   10.210646]\n",
      "reward:  -1.0249011192242796\n",
      "timestep:  1\n",
      "new state [295.21216 295.34833 296.94864 295.39496 303.9645   64.14982  65.71093\n",
      " 160.15898]\n",
      "reward:  -0.8683007878456599\n",
      "timestep:  2\n",
      "new state [290.6      290.6      290.6      290.6      290.6        7.823077\n",
      "   5.89086   13.417999]\n",
      "reward:  -0.9338488471836054\n",
      "\n",
      "env reset!\n",
      "starting_state [290.6      290.6      290.6      290.6      290.6       23.942022\n",
      "  61.929634  66.99105 ]\n",
      "timestep:  0\n",
      "new state [266.4306   266.85785  272.08084  267.003    268.1432    52.322243\n",
      "  59.7715    36.9213  ]\n",
      "reward:  -1.7362549778236727\n",
      "timestep:  1\n",
      "new state [208.02626  208.97214  224.3917   209.28134  238.8595    15.413671\n",
      "  17.957012  19.642666]\n",
      "reward:  -0.8504129029056947\n",
      "timestep:  2\n",
      "new state [491.9      491.9      491.9      491.9      491.9       52.8399\n",
      "  49.007084  89.82153 ]\n",
      "reward:  -0.8821092627296421\n",
      "\n",
      "env reset!\n",
      "starting_state [491.9      491.9      491.9      491.9      491.9       20.87825\n",
      "  10.530228  30.673359]\n",
      "timestep:  0\n",
      "new state [472.20398  471.76077  465.91     471.61142  467.60263   11.344924\n",
      "  14.519432  32.227753]\n",
      "reward:  -0.9398853964613721\n",
      "timestep:  1\n",
      "new state [453.09872  452.5845   444.9821   452.41394  442.07758   58.592712\n",
      "  95.66263  123.06715 ]\n",
      "reward:  -0.9285040263812026\n",
      "timestep:  2\n",
      "new state [443.5      443.5      443.5      443.5      443.5       29.078756\n",
      "  30.836649 125.66759 ]\n",
      "reward:  -0.8904486076543321\n",
      "\n",
      "env reset!\n",
      "starting_state [443.5     443.5     443.5     443.5     443.5     117.20645  80.34187\n",
      " 127.63663]\n",
      "timestep:  0\n",
      "new state [331.59833  330.33704  317.0615   329.901    342.3615    73.03942\n",
      "  62.509537  89.88461 ]\n",
      "reward:  -0.9073729386889424\n",
      "timestep:  1\n",
      "new state [252.67085  250.97977  233.74104  250.39345  271.13928   40.296295\n",
      "  53.416073  80.118095]\n",
      "reward:  -0.9008545352011789\n",
      "timestep:  2\n",
      "new state [621.6      621.6      621.6      621.6      621.6       48.443268\n",
      "  59.809654  74.45893 ]\n",
      "reward:  -0.9019183752877575\n",
      "\n",
      "env reset!\n",
      "starting_state [621.6      621.6      621.6      621.6      621.6       20.759085\n",
      "  48.603493  10.883497]\n",
      "timestep:  0\n",
      "new state [585.681    586.84265  604.3123   587.2275   612.9497    23.406046\n",
      "  40.41084   36.318703]\n",
      "reward:  -0.7855423098591581\n",
      "timestep:  1\n",
      "new state [547.5059   549.20703  574.3171   549.7722   584.1672    25.797628\n",
      "  41.378555  67.28431 ]\n",
      "reward:  -0.86527809227802\n",
      "timestep:  2\n",
      "new state [445.4      445.4      445.4      445.4      445.4       37.50318\n",
      "  46.522472  72.21837 ]\n",
      "reward:  -0.9071237607289573\n",
      "\n",
      "env reset!\n",
      "starting_state [445.4      445.4      445.4      445.4      445.4       35.997913\n",
      "  50.500515  33.465603]\n",
      "timestep:  0\n",
      "new state [398.22717 398.8498  409.06064 399.05334 418.86472  44.61839  39.17722\n",
      " 124.95083]\n",
      "reward:  -0.8497782335099353\n",
      "timestep:  1\n",
      "new state [333.30948  333.00922  327.548    332.91327  319.90924    8.746069\n",
      "   8.905902  18.10315 ]\n",
      "reward:  -0.9495489614056783\n",
      "timestep:  2\n",
      "new state [225.2      225.2      225.2      225.2      225.2       18.012775\n",
      "  18.275724  23.856304]\n",
      "reward:  -0.9221931483317317\n",
      "\n",
      "env reset!\n",
      "starting_state [225.2       225.2       225.2       225.2       225.2         9.678753\n",
      "   6.1305666  15.506537 ]\n",
      "timestep:  0\n",
      "new state [220.92603   220.8539    219.8685    220.82968   220.00392    14.747507\n",
      "  12.7448845  20.188892 ]\n",
      "reward:  -1.7948672529367267\n",
      "timestep:  1\n",
      "new state [204.4514   204.27675  202.15338  204.21732  213.23538   13.55508\n",
      "  20.255032  35.263794]\n",
      "reward:  -0.9872402684489582\n",
      "timestep:  2\n",
      "new state [263.3      263.3      263.3      263.3      263.3       41.887405\n",
      "  62.40885  118.15421 ]\n",
      "reward:  -0.9120141505473744\n",
      "\n",
      "env reset!\n",
      "starting_state [263.3       263.3       263.3       263.3       263.3        11.28861\n",
      "  15.4703665  26.756807 ]\n",
      "timestep:  0\n",
      "new state [255.54771   255.55658   255.47028   255.56015   254.33432     7.3725243\n",
      "   8.209448    6.464558 ]\n",
      "reward:  -1.7728055406483392\n",
      "timestep:  1\n",
      "new state [247.14336  247.2049   248.19905  247.22499  249.20906   31.913866\n",
      "  60.579903  96.16475 ]\n",
      "reward:  -0.8635225482123041\n",
      "timestep:  2\n",
      "new state [366.2      366.2      366.2      366.2      366.2       37.437077\n",
      "  72.17125   80.789856]\n",
      "reward:  -0.9051246850560024\n",
      "\n",
      "env reset!\n",
      "starting_state [366.2      366.2      366.2      366.2      366.2       33.118614\n",
      "  43.576427  21.261703]\n",
      "timestep:  0\n",
      "new state [326.57657 327.13773 336.93274 327.3192  349.33047  55.79978  75.79572\n",
      "  97.11128]\n",
      "reward:  -0.8356352369575234\n",
      "timestep:  1\n",
      "new state [244.37677  245.36127  260.83328  245.68549  272.38943   56.67799\n",
      "  35.558636 131.43857 ]\n",
      "reward:  -0.8911663278478574\n",
      "timestep:  2\n",
      "new state [493.5      493.5      493.5      493.5      493.5       19.104223\n",
      "  21.830187  31.898563]\n",
      "reward:  -0.955061656831874\n",
      "\n",
      "env reset!\n",
      "starting_state [493.5      493.5      493.5      493.5      493.5       75.20923\n",
      "  56.516838  50.81548 ]\n",
      "timestep:  0\n",
      "new state [426.1521   425.83517  425.95126  425.7144   453.20758   55.725857\n",
      "  76.91471   86.83417 ]\n",
      "reward:  -0.8767979083362328\n",
      "timestep:  1\n",
      "new state [345.7356   345.9874   354.3876   346.05612  384.4016    37.662563\n",
      "  29.25563   84.01254 ]\n",
      "reward:  -0.8826362690773197\n",
      "timestep:  2\n",
      "new state [520.5      520.5      520.5      520.5      520.5       37.69594\n",
      "  69.98379   67.860855]\n",
      "reward:  -0.9424073595058412\n",
      "\n",
      "env reset!\n",
      "starting_state [520.5      520.5      520.5      520.5      520.5       27.057447\n",
      "  85.857895  73.049286]\n",
      "timestep:  0\n",
      "new state [447.78912  449.54807  472.2284   450.1432   462.61627   55.360832\n",
      "  46.170242  48.89015 ]\n",
      "reward:  -0.8551840670881523\n",
      "timestep:  1\n",
      "new state [393.06573  394.6457   417.4842   395.17236  423.8631    53.271904\n",
      "  48.278934  40.805588]\n",
      "reward:  -0.8837232262045388\n",
      "timestep:  2\n",
      "new state [472.       472.       472.       472.       472.         9.663223\n",
      "  12.337429  17.854826]\n",
      "reward:  -0.8707235657086497\n",
      "\n",
      "env reset!\n",
      "starting_state [472.       472.       472.       472.       472.        83.950066\n",
      "  73.77508  129.30031 ]\n",
      "timestep:  0\n",
      "new state [374.23157 373.5501  364.87326 373.31964 369.56442  73.37229 110.26625\n",
      "  65.2465 ]\n",
      "reward:  -0.9127472954143664\n",
      "timestep:  1\n",
      "new state [274.75394  275.64166  292.097    275.92612  317.82217   27.074383\n",
      "  73.73301   64.33152 ]\n",
      "reward:  -0.8421443266866195\n",
      "timestep:  2\n",
      "new state [727.9     727.9     727.9     727.9     727.9      73.24871  82.78508\n",
      " 151.20374]\n",
      "reward:  -0.8584451192842032\n",
      "\n",
      "env reset!\n",
      "starting_state [727.9       727.9       727.9       727.9       727.9         5.9131155\n",
      "   4.203285   10.06228  ]\n",
      "timestep:  0\n",
      "new state [721.3366    721.24243   719.93756   721.21094   719.92944     6.363274\n",
      "   5.944884    6.7060013]\n",
      "reward:  -0.9310872954771338\n",
      "timestep:  1\n",
      "new state [714.4469   714.3449   713.17     714.31     714.6147    39.332012\n",
      "  60.89371   75.85275 ]\n",
      "reward:  -0.8860537789762479\n",
      "timestep:  2\n",
      "new state [496.9      496.9      496.9      496.9      496.9       63.87586\n",
      "  88.135025  28.49166 ]\n",
      "reward:  -0.8884877476587366\n",
      "\n",
      "env reset!\n",
      "starting_state [496.9       496.9       496.9       496.9       496.9         3.285375\n",
      "   4.4102817   8.239618 ]\n",
      "timestep:  0\n",
      "new state [491.50705   491.50494   491.3172    491.5048    490.3735      3.955265\n",
      "   5.0899377  12.8673525]\n",
      "reward:  -0.9169039854882374\n",
      "timestep:  1\n",
      "new state [484.45453  484.41248  483.30783  484.40015  480.18292   38.935055\n",
      "  54.17516   12.515893]\n",
      "reward:  -0.9371650689772478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  2\n",
      "new state [340.5      340.5      340.5      340.5      340.5       56.902996\n",
      "  37.050056  75.11639 ]\n",
      "reward:  -0.8058171038832043\n",
      "\n",
      "env reset!\n",
      "starting_state [340.5      340.5      340.5      340.5      340.5       57.523327\n",
      "  85.151634 216.79782 ]\n",
      "timestep:  0\n",
      "new state [291.7016   291.51233  285.68616  291.45874  267.89246   66.74836\n",
      "  50.117027 102.25382 ]\n",
      "reward:  -1.7993861316062063\n",
      "timestep:  1\n",
      "new state [218.76624   217.72546   200.7558    217.3847    233.62193     3.8319468\n",
      "  12.39549    12.854346 ]\n",
      "reward:  -1.0106804606042956\n",
      "timestep:  2\n",
      "new state [407.2      407.2      407.2      407.2      407.2       41.882137\n",
      "  39.20108   12.969887]\n",
      "reward:  -0.8704319708870958\n",
      "\n",
      "env reset!\n",
      "starting_state [407.2      407.2      407.2      407.2      407.2       61.706684\n",
      "  85.55704  109.112495]\n",
      "timestep:  0\n",
      "new state [314.95096 315.4661  322.29163 315.64005 320.75073  72.93623 109.75057\n",
      " 147.65816]\n",
      "reward:  -0.890737451691481\n",
      "timestep:  1\n",
      "new state [196.88467  198.14095  213.75864  198.56848  271.25592   46.134903\n",
      "  54.12429   99.25242 ]\n",
      "reward:  -0.9790962980449016\n",
      "timestep:  2\n",
      "new state [794.3     794.3     794.3     794.3     794.3      52.1105  117.81323\n",
      " 102.40379]\n",
      "reward:  -0.9156015008723742\n",
      "\n",
      "env reset!\n",
      "starting_state [794.3      794.3      794.3      794.3      794.3        3.89895\n",
      "   9.664298  14.835396]\n",
      "timestep:  0\n",
      "new state [784.3095    784.42017   785.4621    784.4589    782.5492      6.561416\n",
      "   3.1944785  10.936631 ]\n",
      "reward:  -0.9021566852489757\n",
      "timestep:  1\n",
      "new state [777.88324   777.83746   776.7274    777.8238    773.88666    12.796289\n",
      "   9.432148    3.5240695]\n",
      "reward:  -0.9482290482307634\n",
      "timestep:  2\n",
      "new state [346.1      346.1      346.1      346.1      346.1       70.32473\n",
      "  25.046865  60.1807  ]\n",
      "reward:  -0.8439704408036067\n",
      "\n",
      "env reset!\n",
      "starting_state [346.1      346.1      346.1      346.1      346.1       15.420512\n",
      "  16.366308  24.298306]\n",
      "timestep:  0\n",
      "new state [326.47507  326.4483   326.18152  326.4391   326.8491    15.952059\n",
      "  16.984915  35.105927]\n",
      "reward:  -0.9019637582175207\n",
      "timestep:  1\n",
      "new state [303.84357  303.69196  301.2188   303.64255  299.04205    9.254173\n",
      "   9.422149  17.19211 ]\n",
      "reward:  -0.9233570724631798\n",
      "timestep:  2\n",
      "new state [376.6      376.6      376.6      376.6      376.6       53.86708\n",
      "  96.352806 215.69995 ]\n",
      "reward:  -0.9152497580389043\n",
      "\n",
      "env reset!\n",
      "starting_state [376.6      376.6      376.6      376.6      376.6       54.086872\n",
      "  73.05046   50.31956 ]\n",
      "timestep:  0\n",
      "new state [307.2605  308.0913  321.98514 308.36206 336.70245  41.91815  63.30721\n",
      " 184.81572]\n",
      "reward:  -0.8526626672891661\n",
      "timestep:  1\n",
      "new state [216.2175  216.48825 215.92206 216.59375 274.8142   61.34222  74.49697\n",
      " 100.05293]\n",
      "reward:  -1.0686458192017965\n",
      "timestep:  2\n",
      "new state [636.2      636.2      636.2      636.2      636.2       58.62291\n",
      "  63.33896   67.319046]\n",
      "reward:  -0.894900493317063\n",
      "\n",
      "env reset!\n",
      "starting_state [636.2     636.2     636.2     636.2     636.2      92.62877 123.22062\n",
      " 243.56802]\n",
      "timestep:  0\n",
      "new state [482.1676  481.95483 473.877   481.901   443.27875 104.73469 146.77966\n",
      "   1.     ]\n",
      "reward:  -0.9207473712778114\n",
      "timestep:  1\n",
      "new state [367.23572  369.78778  410.2681   370.6269   442.36136   41.638336\n",
      "  21.319794  73.203316]\n",
      "reward:  -0.773768543801259\n",
      "timestep:  2\n",
      "new state [467.1      467.1      467.1      467.1      467.1        9.806706\n",
      "   9.496274  14.046153]\n",
      "reward:  -0.9489170231778523\n",
      "\n",
      "env reset!\n",
      "starting_state [467.1      467.1      467.1      467.1      467.1       41.482876\n",
      "  88.303444 131.87953 ]\n",
      "timestep:  0\n",
      "new state [374.73923  375.63922  384.4235   375.95322  362.63663   44.098515\n",
      "  85.35191  157.11702 ]\n",
      "reward:  -0.9003731501079775\n",
      "timestep:  1\n",
      "new state [277.31107  278.68506  289.1421   279.17432  238.19492   43.414757\n",
      " 101.62746  183.9644  ]\n",
      "reward:  -0.9159720995674727\n",
      "timestep:  2\n",
      "new state [711.       711.       711.       711.       711.        45.482166\n",
      "  49.808247  77.601776]\n",
      "reward:  -1.0212273110935437\n",
      "\n",
      "env reset!\n",
      "starting_state [711.        711.        711.        711.        711.          4.5880466\n",
      "   6.8367825   6.174641 ]\n",
      "timestep:  0\n",
      "new state [704.3281    704.40326   705.5337    704.42816   706.1063      4.289804\n",
      "   4.9536605  18.696096 ]\n",
      "reward:  -0.8673572008705399\n",
      "timestep:  1\n",
      "new state [695.89545  695.8592   694.77527  695.849    691.3015     9.119541\n",
      "   8.850144  17.177158]\n",
      "reward:  -0.961570989182715\n",
      "timestep:  2\n",
      "new state [132.7      132.7      132.7      132.7      132.7       17.124409\n",
      "  23.252542  21.89141 ]\n",
      "reward:  -0.9191645285541393\n",
      "\n",
      "env reset!\n",
      "starting_state [132.7     132.7     132.7     132.7     132.7      47.94852  36.80733\n",
      " 126.8989 ]\n",
      "timestep:  0\n",
      "new state [105.16231  104.697815  97.001785 104.546104  90.19978   64.68349\n",
      "  88.64628  108.68382 ]\n",
      "reward:  -1.8142355333763969\n",
      "timestep:  1\n",
      "new state [ 65.08786   64.85851   60.410683  64.78538   53.759686  51.947823\n",
      "  58.184273 112.666374]\n",
      "reward:  -1.749358377876443\n",
      "timestep:  2\n",
      "new state [673.4      673.4      673.4      673.4      673.4       41.7477\n",
      " 143.98477   16.539148]\n",
      "reward:  -1.7803704769274393\n",
      "\n",
      "env reset!\n",
      "starting_state [673.4       673.4       673.4       673.4       673.4         5.5809407\n",
      "   8.710138    6.851326 ]\n",
      "timestep:  0\n",
      "new state [665.22107  665.33356  667.0389   665.3708   667.96924    5.648735\n",
      "   8.916913   8.445515]\n",
      "reward:  -0.8580323178348616\n",
      "timestep:  1\n",
      "new state [656.53894  656.75397  659.94     656.8254   661.2763    17.561708\n",
      "  22.256811  29.074213]\n",
      "reward:  -0.869767406039475\n",
      "timestep:  2\n",
      "new state [262.7      262.7      262.7      262.7      262.7       63.30445\n",
      "  62.452217 127.00237 ]\n",
      "reward:  -0.8928489405723935\n",
      "\n",
      "env reset!\n",
      "starting_state [262.7      262.7      262.7      262.7      262.7       31.882038\n",
      "  33.803192  55.134113]\n",
      "timestep:  0\n",
      "new state [245.0811   245.03745  244.37944  245.0229   244.2204    40.91576\n",
      "  62.745888 118.80581 ]\n",
      "reward:  -1.7691951867630122\n",
      "timestep:  1\n",
      "new state [213.3151   213.31673  211.95163  213.32137  204.41852   42.18849\n",
      "  54.767525  32.818913]\n",
      "reward:  -1.7791005962405262\n",
      "timestep:  2\n",
      "new state [516.3      516.3      516.3      516.3      516.3       77.679985\n",
      " 107.5607   154.96458 ]\n",
      "reward:  -0.8460136995109502\n",
      "\n",
      "env reset!\n",
      "starting_state [516.3      516.3      516.3      516.3      516.3       64.22522\n",
      "  52.925625 116.19393 ]\n",
      "timestep:  0\n",
      "new state [439.44077  438.61786  426.79553  438.34378  424.25995   51.544224\n",
      "  63.988945  99.59933 ]\n",
      "reward:  -0.9264873496840642\n",
      "timestep:  1\n",
      "new state [364.52377  363.77112  352.1783   363.52325  345.35736   53.98272\n",
      "  87.643585 143.02893 ]\n",
      "reward:  -0.904593534345022\n",
      "timestep:  2\n",
      "new state [588.       588.       588.       588.       588.        31.257387\n",
      "  41.715717  66.54332 ]\n",
      "reward:  -0.9073631090978163\n",
      "\n",
      "env reset!\n",
      "starting_state [588.       588.       588.       588.       588.        21.961329\n",
      "  27.850466  32.40772 ]\n",
      "timestep:  0\n",
      "new state [558.073    558.22437  560.5908   558.2743   562.3205    25.696592\n",
      "  17.372793  26.078936]\n",
      "reward:  -0.8852877091787277\n",
      "timestep:  1\n",
      "new state [534.11096  533.99585  533.70264  533.9531   541.65436   10.524293\n",
      "  28.115593 107.66389 ]\n",
      "reward:  -0.9042905748767667\n",
      "timestep:  2\n",
      "new state [343.3      343.3      343.3      343.3      343.3       18.386501\n",
      "  39.33978   50.860443]\n",
      "reward:  -0.9669289644452616\n",
      "\n",
      "env reset!\n",
      "starting_state [343.3      343.3      343.3      343.3      343.3       10.510422\n",
      "   8.959895  20.583656]\n",
      "timestep:  0\n",
      "new state [330.19675  330.0575   327.9669   330.0114   326.99582    8.499482\n",
      "   5.828298  14.759619]\n",
      "reward:  -0.9293916399291964\n",
      "timestep:  1\n",
      "new state [320.81094  320.52554  316.3924   320.4306   315.30466   38.588608\n",
      "  36.916855  28.731676]\n",
      "reward:  -0.9341965435660858\n",
      "timestep:  2\n",
      "new state [373.1      373.1      373.1      373.1      373.1       47.148235\n",
      "  38.63328   85.47568 ]\n",
      "reward:  -0.8655874350591984\n",
      "\n",
      "env reset!\n",
      "starting_state [373.1     373.1     373.1     373.1     373.1     101.98864  95.16695\n",
      "  64.32684]\n",
      "timestep:  0\n",
      "new state [272.69415 272.99362 283.493   273.0734  322.079    75.12408 107.28938\n",
      " 100.2036 ]\n",
      "reward:  -0.8592189568145493\n",
      "timestep:  1\n",
      "new state [227.6835   228.43066  194.38412  228.65796  242.66463   12.218663\n",
      "  10.376433  16.048637]\n",
      "reward:  -1.4332824104922872\n",
      "timestep:  2\n",
      "new state [458.1      458.1      458.1      458.1      458.1       32.819954\n",
      "  27.335163  67.16096 ]\n",
      "reward:  -0.9052192520371237\n",
      "\n",
      "env reset!\n",
      "starting_state [458.1      458.1      458.1      458.1      458.1       14.186366\n",
      "  10.253393  25.420925]\n",
      "timestep:  0\n",
      "new state [441.96555  441.7332   438.43744  441.65564  437.96408   11.315774\n",
      "  11.596023  15.859975]\n",
      "reward:  -0.9332393482319163\n",
      "timestep:  1\n",
      "new state [428.24548  427.99783  424.68243  427.91458  425.39755   86.641014\n",
      "  88.8275    80.19458 ]\n",
      "reward:  -0.8969409807168467\n",
      "timestep:  2\n",
      "new state [324.2      324.2      324.2      324.2      324.2        8.222885\n",
      "   9.859234  15.006166]\n",
      "reward:  -0.8723404854667165\n",
      "\n",
      "env reset!\n",
      "starting_state [324.2      324.2      324.2      324.2      324.2       38.394894\n",
      "  88.88558  139.34015 ]\n",
      "timestep:  0\n",
      "new state [284.74353  285.13547  288.59207  285.2727   277.51593   46.15921\n",
      "  86.276245 132.79741 ]\n",
      "reward:  -1.765071233071861\n",
      "timestep:  1\n",
      "new state [191.7438   192.83386  202.69809  193.21606  233.01836   33.476994\n",
      "  50.054485  66.27632 ]\n",
      "reward:  -0.9982375073803559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  2\n",
      "new state [796.3     796.3     796.3     796.3     796.3      96.69082 115.95339\n",
      " 225.6768 ]\n",
      "reward:  -0.8929002261425006\n",
      "\n",
      "env reset!\n",
      "starting_state [796.3      796.3      796.3      796.3      796.3       53.358135\n",
      "  39.631744  37.793907]\n",
      "timestep:  0\n",
      "new state [748.37146  748.1122   747.6154   748.01526  766.3351    54.07917\n",
      "  59.410973  96.28825 ]\n",
      "reward:  -0.8798252178546391\n",
      "timestep:  1\n",
      "new state [675.8901  675.5011  672.9205  675.36194 690.0546   68.82898  72.75336\n",
      "  51.34048]\n",
      "reward:  -0.9075231336634181\n",
      "timestep:  2\n",
      "new state [439.6      439.6      439.6      439.6      439.6        8.235048\n",
      "   6.769574  13.642383]\n",
      "reward:  -0.8587220590016444\n",
      "\n",
      "env reset!\n",
      "starting_state [439.6      439.6      439.6      439.6      439.6       24.99323\n",
      "  19.304762  52.84357 ]\n",
      "timestep:  0\n",
      "new state [408.637     408.1932    401.43658   408.04663   397.74582     7.6029677\n",
      "  21.218925   16.681393 ]\n",
      "reward:  -0.9395154208662543\n",
      "timestep:  1\n",
      "new state [390.68286 390.66434 389.55457 390.6611  384.5261   44.67073  99.16755\n",
      "  58.75831]\n",
      "reward:  -0.8505311696615664\n",
      "timestep:  2\n",
      "new state [364.3      364.3      364.3      364.3      364.3       11.45339\n",
      "  22.747179  41.27174 ]\n",
      "reward:  -0.834591982534829\n",
      "\n",
      "env reset!\n",
      "starting_state [364.3      364.3      364.3      364.3      364.3       27.08266\n",
      "  51.075848  47.723213]\n",
      "timestep:  0\n",
      "new state [316.4516   317.1784   327.09985  317.4226   326.48227   34.824142\n",
      "  54.057438 145.25854 ]\n",
      "reward:  -0.8669552895099502\n",
      "timestep:  1\n",
      "new state [241.92569  242.32364  242.60452  242.47466  277.83722   63.98186\n",
      "  93.874794 135.20021 ]\n",
      "reward:  -1.0601139724057622\n",
      "timestep:  2\n",
      "new state [401.4      401.4      401.4      401.4      401.4        6.098319\n",
      "   4.772723   9.258717]\n",
      "reward:  -0.8988047902068845\n",
      "\n",
      "env reset!\n",
      "starting_state [401.4      401.4      401.4      401.4      401.4       29.316319\n",
      "  39.61586   49.1508  ]\n",
      "timestep:  0\n",
      "new state [358.75766  358.9911   362.23593  359.0694   362.4568    29.13105\n",
      "  61.092022  81.07897 ]\n",
      "reward:  -0.8890468444604188\n",
      "timestep:  1\n",
      "new state [297.0612   298.00748  309.2179   298.33115  298.22794   60.609123\n",
      "  63.15045   81.72035 ]\n",
      "reward:  -0.8915799064810733\n",
      "timestep:  2\n",
      "new state [503.3      503.3      503.3      503.3      503.3       34.764263\n",
      "  81.447266  73.64049 ]\n",
      "reward:  -0.893406299316554\n",
      "\n",
      "env reset!\n",
      "starting_state [503.3      503.3      503.3      503.3      503.3       39.59024\n",
      "  37.397976  85.21637 ]\n",
      "timestep:  0\n",
      "new state [450.1749   449.70853  442.18423  449.55597  435.8025    59.188087\n",
      "  68.41645   83.03026 ]\n",
      "reward:  -0.929263506556284\n",
      "timestep:  1\n",
      "new state [374.14764  373.88696  370.20154  373.80035  370.01025    9.236551\n",
      "   5.890423  10.723495]\n",
      "reward:  -0.8886797832152794\n",
      "timestep:  2\n",
      "new state [267.6       267.6       267.6       267.6       267.6         9.548276\n",
      "   5.9779587   7.4027944]\n",
      "reward:  -0.9150486033847129\n",
      "\n",
      "env reset!\n",
      "starting_state [267.6      267.6      267.6      267.6      267.6       17.689411\n",
      "  11.085096  20.981953]\n",
      "timestep:  0\n",
      "new state [250.88397  250.63812  259.2199   250.55405  260.5655    15.435555\n",
      "  17.394087  31.969809]\n",
      "reward:  -1.1533641368194225\n",
      "timestep:  1\n",
      "new state [228.92188  228.61049  235.93886  228.50568  235.24113    6.824006\n",
      "  12.543059  27.135523]\n",
      "reward:  -0.9157429546425455\n",
      "timestep:  2\n",
      "new state [114.5      114.5      114.5      114.5      114.5        7.27624\n",
      "   8.514111  10.751683]\n",
      "reward:  -0.9275568774987207\n",
      "\n",
      "env reset!\n",
      "starting_state [114.5      114.5      114.5      114.5      114.5       36.364445\n",
      "  46.98437   10.492073]\n",
      "timestep:  0\n",
      "new state [ 97.557945  97.85501  103.31113   97.9502   110.94789   32.431248\n",
      "  35.023155  49.899723]\n",
      "reward:  -1.6690738020518237\n",
      "timestep:  1\n",
      "new state [80.09035   80.37842   85.82094   80.47017   94.21871   13.806016\n",
      " 18.653427   3.6193054]\n",
      "reward:  -1.7604656936523888\n",
      "timestep:  2\n",
      "new state [339.2      339.2      339.2      339.2      339.2       39.384003\n",
      "  23.200354  65.963104]\n",
      "reward:  -1.6635514358416834\n",
      "\n",
      "env reset!\n",
      "starting_state [339.2      339.2      339.2      339.2      339.2       12.56045\n",
      "  21.951267  22.231857]\n",
      "timestep:  0\n",
      "new state [317.93613  318.20816  321.905    318.2996   321.58356   20.333698\n",
      "  23.062817  37.561985]\n",
      "reward:  -0.8732597458241578\n",
      "timestep:  1\n",
      "new state [289.9737  290.21017 293.226   290.29044 291.82703  51.63069  62.85173\n",
      "  95.64299]\n",
      "reward:  -0.9077863792013585\n",
      "timestep:  2\n",
      "new state [527.4      527.4      527.4      527.4      527.4       60.14454\n",
      "  99.68646  101.030846]\n",
      "reward:  -0.903136922723737\n",
      "\n",
      "env reset!\n",
      "starting_state [527.4      527.4      527.4      527.4      527.4       28.766623\n",
      "  63.268185 124.21661 ]\n",
      "timestep:  0\n",
      "new state [454.68005  455.05322  455.74628  455.19324  429.02164   50.649708\n",
      "  52.236057 122.154495]\n",
      "reward:  -0.9207718945353561\n",
      "timestep:  1\n",
      "new state [381.2824   381.09027  371.81567  381.04816  332.27026   43.792885\n",
      "  26.55208    1.      ]\n",
      "reward:  -0.9312317579587408\n",
      "timestep:  2\n",
      "new state [565.5      565.5      565.5      565.5      565.5       38.850998\n",
      "  36.417805   1.      ]\n",
      "reward:  -0.8260092695415006\n",
      "\n",
      "env reset!\n",
      "starting_state [565.5      565.5      565.5      565.5      565.5       16.779213\n",
      "  11.785979  21.082573]\n",
      "timestep:  0\n",
      "new state [548.67633  548.4783   546.1707   548.4106   548.7963    10.199828\n",
      "  19.59361    9.868646]\n",
      "reward:  -0.9140506299431082\n",
      "timestep:  1\n",
      "new state [532.3301    532.49963   535.70264   532.5538    540.96924     5.8447986\n",
      "   8.5796175  11.765418 ]\n",
      "reward:  -0.8279455072197297\n",
      "timestep:  2\n",
      "new state [108.        108.        108.        108.        108.          7.6562033\n",
      "  10.891478    8.104808 ]\n",
      "reward:  -0.8954081134157502\n",
      "\n",
      "env reset!\n",
      "starting_state [108.       108.       108.       108.       108.        10.436405\n",
      "  11.924848  22.002163]\n",
      "timestep:  0\n",
      "new state [101.6488   101.631485 101.26946  101.626045 100.627335  22.179323\n",
      "  16.982635  25.267923]\n",
      "reward:  -1.7771994665787803\n",
      "timestep:  1\n",
      "new state [92.17632  92.08155  90.95352  92.049164 92.15361   8.970692  8.636539\n",
      " 19.765734]\n",
      "reward:  -1.7645039769350037\n",
      "timestep:  2\n",
      "new state [259.7      259.7      259.7      259.7      259.7       52.912067\n",
      "  20.16191   28.24115 ]\n",
      "reward:  -1.7908070950991637\n",
      "\n",
      "env reset!\n",
      "starting_state [259.7      259.7      259.7      259.7      259.7       45.306343\n",
      "  61.14471   88.674446]\n",
      "timestep:  0\n",
      "new state [230.62723  230.72546  231.74487  230.7593   229.97809   44.86815\n",
      "  59.13619  104.924194]\n",
      "reward:  -1.7607695822926284\n",
      "timestep:  1\n",
      "new state [200.49727  200.60019  200.88979  200.63794  194.82056   35.344025\n",
      "  23.99819   36.622818]\n",
      "reward:  -1.7745733624683642\n",
      "timestep:  2\n",
      "new state [508.6     508.6     508.6     508.6     508.6      46.59111  82.87959\n",
      " 135.54373]\n",
      "reward:  -0.9051776156098061\n",
      "\n",
      "env reset!\n",
      "starting_state [508.6      508.6      508.6      508.6      508.6        6.205319\n",
      "   9.300648  17.036728]\n",
      "timestep:  0\n",
      "new state [497.54294   497.56012   497.41064   497.56717   495.10565     2.5169039\n",
      "  10.28949     8.901958 ]\n",
      "reward:  -0.9155729350303914\n",
      "timestep:  1\n",
      "new state [489.03342   489.27823   491.99838   489.3625    488.05228     4.0241184\n",
      "   3.438509    2.3160698]\n",
      "reward:  -0.8545130412428358\n",
      "timestep:  2\n",
      "new state [158.2      158.2      158.2      158.2      158.2       36.381714\n",
      "  50.08759   28.244116]\n",
      "reward:  -0.8609845494842158\n",
      "\n",
      "env reset!\n",
      "starting_state [158.2      158.2      158.2      158.2      158.2       26.407448\n",
      "  16.20041   12.233514]\n",
      "timestep:  0\n",
      "new state [149.58917  149.50845  149.22842  149.47876  154.0856    30.571407\n",
      "  36.41513   18.17623 ]\n",
      "reward:  -1.7340033785100426\n",
      "timestep:  1\n",
      "new state [135.14792  135.23056  138.08939  135.25275  147.9707    71.504036\n",
      "  97.90251  163.11281 ]\n",
      "reward:  -1.7005355078732385\n",
      "timestep:  2\n",
      "new state [632.1      632.1      632.1      632.1      632.1       85.00664\n",
      "  49.54382   42.874012]\n",
      "reward:  -1.7702337840299078\n",
      "\n",
      "env reset!\n",
      "starting_state [632.1       632.1       632.1       632.1       632.1        10.489874\n",
      "  13.050293    1.7849479]\n",
      "timestep:  0\n",
      "new state [621.1031   621.3023   624.9936   621.366    630.67523    8.194466\n",
      "  13.246318  16.880304]\n",
      "reward:  -0.7987702714765638\n",
      "timestep:  1\n",
      "new state [607.2702   607.58356  612.67224  607.6862   617.3017     8.282765\n",
      "   9.343883  10.975043]\n",
      "reward:  -0.8898340702100823\n",
      "timestep:  2\n",
      "new state [88.4      88.4      88.4      88.4      88.4       7.745594  7.176407\n",
      "  6.834895]\n",
      "reward:  -0.8868138149383339\n",
      "\n",
      "env reset!\n",
      "starting_state [88.4       88.4       88.4       88.4       88.4        9.646631\n",
      "  4.5748014 13.86835  ]\n",
      "timestep:  0\n",
      "new state [84.649605 84.56051  83.38107  84.53049  83.752815  7.150502 10.046663\n",
      " 16.76197 ]\n",
      "reward:  -1.8026792289841769\n",
      "timestep:  1\n",
      "new state [79.7001   79.62122  78.45597  79.59499  78.135994 10.249759 13.550874\n",
      " 43.51639 ]\n",
      "reward:  -1.770299572889159\n",
      "timestep:  2\n",
      "new state [220.       220.       220.       220.       220.        30.658995\n",
      "  24.893032  54.17347 ]\n",
      "reward:  -1.8138771955046646\n",
      "\n",
      "env reset!\n",
      "starting_state [220.       220.       220.       220.       220.        13.196286\n",
      "  17.780426  16.578196]\n",
      "timestep:  0\n",
      "new state [212.4395    212.50586   213.57213   212.52759   214.43777    11.4358635\n",
      "  18.743681   27.334913 ]\n",
      "reward:  -1.731795970562632\n",
      "timestep:  1\n",
      "new state [192.12238  192.31998  194.72583  192.38733  205.27696   26.137577\n",
      "  82.39925   71.503494]\n",
      "reward:  -0.9898308685109035\n",
      "timestep:  2\n",
      "new state [456.2      456.2      456.2      456.2      456.2       40.274456\n",
      "  47.60826   56.760155]\n",
      "reward:  -0.856745841024015\n",
      "\n",
      "env reset!\n",
      "starting_state [456.2      456.2      456.2      456.2      456.2       59.82241\n",
      "  85.882     55.813496]\n",
      "timestep:  0\n",
      "new state [376.6893   377.79428  395.72205  378.15616  411.9441    78.22735\n",
      "  61.886433 130.034   ]\n",
      "reward:  -0.8482411697610165\n",
      "timestep:  1\n",
      "new state [287.1352   287.25705  291.72827  287.28934  308.93652   50.985306\n",
      "  66.80337  223.20316 ]\n",
      "reward:  -0.9237008242388057\n",
      "timestep:  2\n",
      "new state [516.4       516.4       516.4       516.4       516.4         8.163467\n",
      "   5.8351316  11.795287 ]\n",
      "reward:  -1.079730563376177\n",
      "\n",
      "env reset!\n",
      "starting_state [516.4      516.4      516.4      516.4      516.4       29.825026\n",
      "  32.781982  49.62298 ]\n",
      "timestep:  0\n",
      "new state [477.2201   477.18384  476.72653  477.17166  477.08618   41.308857\n",
      "  54.615284  52.681507]\n",
      "reward:  -0.9030938069248329\n",
      "timestep:  1\n",
      "new state [421.61816  422.03122  428.78677  422.16653  435.33447    7.195511\n",
      "   7.078414   9.410249]\n",
      "reward:  -0.8729475751005714\n",
      "timestep:  2\n",
      "new state [412.2      412.2      412.2      412.2      412.2       85.74529\n",
      "  60.292377 135.72963 ]\n",
      "reward:  -0.8954147297569606\n",
      "\n",
      "env reset!\n",
      "starting_state [412.2      412.2      412.2      412.2      412.2       36.132717\n",
      "  43.70706  126.582054]\n",
      "timestep:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new state [347.21545  346.65747  335.0844   346.48343  311.9552    31.277657\n",
      "  61.211998  37.902855]\n",
      "reward:  -0.945664188757322\n",
      "timestep:  1\n",
      "new state [294.70978  295.24457  299.64407  295.43408  281.9043    45.752937\n",
      " 104.93855  131.14943 ]\n",
      "reward:  -0.8395568226754555\n",
      "timestep:  2\n",
      "new state [566.1     566.1     566.1     566.1     566.1      42.18442  34.97069\n",
      "  90.92688]\n",
      "reward:  -0.8866858638707033\n",
      "\n",
      "env reset!\n",
      "starting_state [566.1       566.1       566.1       566.1       566.1         7.4680643\n",
      "   3.575111   19.022127 ]\n",
      "timestep:  0\n",
      "new state [557.3022   557.05646  553.285    556.9754   551.03613   10.686058\n",
      "   7.467669  18.518513]\n",
      "reward:  -0.9708737272188568\n",
      "timestep:  1\n",
      "new state [545.434    545.01013  538.74945  544.86945  536.36743   47.531406\n",
      "  46.26605  139.86356 ]\n",
      "reward:  -0.9330734014215745\n",
      "timestep:  2\n",
      "new state [454.6      454.6      454.6      454.6      454.6       82.09983\n",
      "  64.70097   89.103966]\n",
      "reward:  -0.9470355786629647\n",
      "\n",
      "env reset!\n",
      "starting_state [454.6      454.6      454.6      454.6      454.6       52.061653\n",
      "  52.75246   43.59242 ]\n",
      "timestep:  0\n",
      "new state [398.58188  398.7817   404.15564  398.84027  420.03897   55.48459\n",
      " 101.083145  79.136215]\n",
      "reward:  -0.8677066845014892\n",
      "timestep:  1\n",
      "new state [306.79935  308.54242  336.08978  309.11572  357.31488   54.757347\n",
      "  59.088448 100.32448 ]\n",
      "reward:  -0.8554964909307465\n",
      "timestep:  2\n",
      "new state [587.9      587.9      587.9      587.9      587.9       37.253998\n",
      "  34.592457  80.636795]\n",
      "reward:  -0.9105720506197426\n",
      "\n",
      "env reset!\n",
      "starting_state [587.9      587.9      587.9      587.9      587.9       38.19759\n",
      "  60.128147 100.3493  ]\n",
      "timestep:  0\n",
      "new state [519.3064  519.56335 520.9978  519.6566  508.41235  64.81151  90.60811\n",
      " 127.76511]\n",
      "reward:  -0.9089939734235227\n",
      "timestep:  1\n",
      "new state [418.9707   419.66528  426.06384  419.90912  407.19324   36.44139\n",
      "  34.07788   40.509834]\n",
      "reward:  -0.8975259894858144\n",
      "timestep:  2\n",
      "new state [504.6      504.6      504.6      504.6      504.6       34.460728\n",
      "  77.61331   64.535904]\n",
      "reward:  -0.8890855283342283\n",
      "\n",
      "env reset!\n",
      "starting_state [504.6      504.6      504.6      504.6      504.6       64.09125\n",
      "  34.462917 114.78362 ]\n",
      "timestep:  0\n",
      "new state [438.2102   436.72342  415.80188  436.22656  413.68573   18.004229\n",
      "  60.72966   99.35022 ]\n",
      "reward:  -0.9477647421748561\n",
      "timestep:  1\n",
      "new state [376.15158  375.4631   361.50168  375.24744  334.99875   42.594604\n",
      "  72.69792  136.13284 ]\n",
      "reward:  -0.9067583638856902\n",
      "timestep:  2\n",
      "new state [661.4      661.4      661.4      661.4      661.4       37.498142\n",
      "  39.021225  32.164284]\n",
      "reward:  -0.9171704812971566\n",
      "\n",
      "env reset!\n",
      "starting_state [661.4       661.4       661.4       661.4       661.4         6.2124577\n",
      "  12.030902   17.200745 ]\n",
      "timestep:  0\n",
      "new state [648.80914   648.9253    650.1333    648.9656    647.7745      8.822592\n",
      "   7.6110125   2.9511516]\n",
      "reward:  -0.8973776816452266\n",
      "timestep:  1\n",
      "new state [641.0664   641.21155  643.52435  641.2593   645.43005   19.934557\n",
      "  40.915787  65.71326 ]\n",
      "reward:  -0.839625164628816\n",
      "timestep:  2\n",
      "new state [215.3      215.3      215.3      215.3      215.3       14.84476\n",
      "  14.389273  48.144257]\n",
      "reward:  -0.9058713600848793\n",
      "\n",
      "env reset!\n",
      "starting_state [215.3      215.3      215.3      215.3      215.3       30.050158\n",
      "  33.209988  58.845104]\n",
      "timestep:  0\n",
      "new state [197.71176  197.66309  196.75635  197.64743  195.57999   39.65833\n",
      "  31.506659  29.179987]\n",
      "reward:  -1.77453741006581\n",
      "timestep:  1\n",
      "new state [182.06883   181.9654    181.27603   181.92828   185.78136     6.3918304\n",
      "   7.0348005   4.9815793]\n",
      "reward:  -1.738595751695283\n",
      "timestep:  2\n",
      "new state [333.7     333.7     333.7     333.7     333.7      50.06396  44.31238\n",
      " 122.26987]\n",
      "reward:  -0.8580996022356715\n",
      "\n",
      "env reset!\n",
      "starting_state [333.7       333.7       333.7       333.7       333.7         6.5959435\n",
      "   7.389706    9.841022 ]\n",
      "timestep:  0\n",
      "new state [325.22018   325.2286    325.42133   325.2312    325.90268     4.304062\n",
      "   6.521314    5.3385315]\n",
      "reward:  -0.894782891976198\n",
      "timestep:  1\n",
      "new state [319.0071    319.0945    320.49173   319.1232    321.67117     6.915069\n",
      "   9.548352    1.0468866]\n",
      "reward:  -0.8609436881554099\n",
      "timestep:  2\n",
      "new state [216.7      216.7      216.7      216.7      216.7       39.737335\n",
      "  32.925243  77.16384 ]\n",
      "reward:  -0.7900336034489578\n",
      "\n",
      "env reset!\n",
      "starting_state [216.7      216.7      216.7      216.7      216.7        8.625412\n",
      "  14.075221  25.115183]\n",
      "timestep:  0\n",
      "new state [209.80067   209.82306   209.85056   209.8314    208.28561     9.918766\n",
      "  12.4025755  14.314523 ]\n",
      "reward:  -1.774920174903543\n",
      "timestep:  1\n",
      "new state [196.45488  196.54234  197.61224  196.57208  203.4851   133.57787\n",
      "  79.718735 153.70766 ]\n",
      "reward:  -0.9592798361036833\n",
      "timestep:  2\n",
      "new state [476.7      476.7      476.7      476.7      476.7       31.17636\n",
      "  54.586113  40.58431 ]\n",
      "reward:  -1.779373124720645\n",
      "\n",
      "env reset!\n",
      "starting_state [476.7      476.7      476.7      476.7      476.7        5.629762\n",
      "   7.84565   17.00879 ]\n",
      "timestep:  0\n",
      "new state [466.6344    466.6127    465.87036   466.6069    463.2288      7.9253364\n",
      "   7.194479    1.       ]\n",
      "reward:  -0.927124394144164\n",
      "timestep:  1\n",
      "new state [459.86447  459.8984   460.655    459.9089   462.4296    31.474958\n",
      "  23.769869 114.34436 ]\n",
      "reward:  -0.8144250289165897\n",
      "timestep:  2\n",
      "new state [387.2      387.2      387.2      387.2      387.2       57.397236\n",
      "  63.437225  61.13236 ]\n",
      "reward:  -0.9712922478508228\n",
      "\n",
      "env reset!\n",
      "starting_state [387.2      387.2      387.2      387.2      387.2       53.94307\n",
      "  13.269053  91.94805 ]\n",
      "timestep:  0\n",
      "new state [341.00662  339.22092  314.50708  338.62274  314.37848   20.853426\n",
      "  67.95867  120.57998 ]\n",
      "reward:  -0.9721256705010812\n",
      "timestep:  1\n",
      "new state [269.15927  268.15555  249.20786  267.8363   273.99042   50.799114\n",
      "  50.24758   59.139477]\n",
      "reward:  -1.0228451911880154\n",
      "timestep:  2\n",
      "new state [343.4       343.4       343.4       343.4       343.4         6.9706616\n",
      "   5.670271    1.       ]\n",
      "reward:  -0.8880247898213735\n",
      "\n",
      "env reset!\n",
      "starting_state [343.4      343.4      343.4      343.4      343.4       29.085903\n",
      "  47.19737   89.94591 ]\n",
      "timestep:  0\n",
      "new state [287.27362  287.38672  286.54065  287.43274  313.26776   44.505474\n",
      "  41.59888   91.696526]\n",
      "reward:  -1.0214345676364887\n",
      "timestep:  1\n",
      "new state [228.74069  228.35397  219.62927  228.23589  240.6359    35.116917\n",
      "  17.87208   52.06892 ]\n",
      "reward:  -0.9271388944724429\n",
      "timestep:  2\n",
      "new state [469.5      469.5      469.5      469.5      469.5       33.133133\n",
      "  48.93146   74.913124]\n",
      "reward:  -0.9399715713804938\n",
      "\n",
      "env reset!\n",
      "starting_state [469.5      469.5      469.5      469.5      469.5       25.460798\n",
      "  44.391293  15.7513  ]\n",
      "timestep:  0\n",
      "new state [433.21774  434.05692  447.25427  434.33304  456.99603   33.008034\n",
      "  49.12839   50.76525 ]\n",
      "reward:  -0.8132498648373071\n",
      "timestep:  1\n",
      "new state [383.78635  385.1008   405.1557   385.53543  416.7682    58.96327\n",
      "  59.309258  92.1082  ]\n",
      "reward:  -0.8761222320824131\n",
      "timestep:  2\n",
      "new state [663.1     663.1     663.1     663.1     663.1      85.51604 104.47578\n",
      " 153.50558]\n",
      "reward:  -0.9049882648285952\n",
      "\n",
      "env reset!\n",
      "starting_state [663.1      663.1      663.1      663.1      663.1       55.929287\n",
      "  36.781372  63.06222 ]\n",
      "timestep:  0\n",
      "new state [610.0562   609.3755   601.8238   609.14136  613.1323    37.405754\n",
      "  57.180626  36.73604 ]\n",
      "reward:  -0.9116947660588421\n",
      "timestep:  1\n",
      "new state [558.012     558.1324    563.2035    558.1618    584.004       8.134197\n",
      "   6.5746107   5.8029385]\n",
      "reward:  -0.8463641916457297\n",
      "timestep:  2\n",
      "new state [258.       258.       258.       258.       258.        15.861988\n",
      "  19.140491  12.048944]\n",
      "reward:  -0.8747504439489835\n",
      "\n",
      "env reset!\n",
      "starting_state [258.       258.       258.       258.       258.        11.518289\n",
      "  21.274712  28.710829]\n",
      "timestep:  0\n",
      "new state [248.68391  248.77213  249.74695  248.80238  248.37753   20.099638\n",
      "  27.451147  43.479935]\n",
      "reward:  -1.7545124756672164\n",
      "timestep:  1\n",
      "new state [217.03235  217.19397  218.62022  217.2508   233.80624    5.663736\n",
      "   9.383028  12.512944]\n",
      "reward:  -0.99652338647783\n",
      "timestep:  2\n",
      "new state [298.7      298.7      298.7      298.7      298.7       38.285866\n",
      "  71.02421  125.677246]\n",
      "reward:  -0.892921536045622\n",
      "\n",
      "env reset!\n",
      "starting_state [298.7     298.7     298.7     298.7     298.7      52.69368  76.86482\n",
      " 120.95825]\n",
      "timestep:  0\n",
      "new state [261.82196 261.9516  262.87976 261.99756 258.16504  64.40043  48.75971\n",
      "  87.80043]\n",
      "reward:  -1.766180024073823\n",
      "timestep:  1\n",
      "new state [193.7351   193.16618  230.25131  192.97418  228.7322    44.73864\n",
      "  42.23047   63.062866]\n",
      "reward:  -1.1487089167145585\n",
      "timestep:  2\n",
      "new state [421.9      421.9      421.9      421.9      421.9       20.367168\n",
      "  14.929051  28.97692 ]\n",
      "reward:  -0.9027420274320974\n",
      "\n",
      "env reset!\n",
      "starting_state [421.9      421.9      421.9      421.9      421.9       42.704178\n",
      "  53.84729   65.30015 ]\n",
      "timestep:  0\n",
      "new state [363.34845  363.6087   367.60477  363.6948   370.1588    48.31242\n",
      "  51.394344  89.22318 ]\n",
      "reward:  -0.8880075955028713\n",
      "timestep:  1\n",
      "new state [298.77698  298.82745  299.47598  298.84497  299.4781    30.889675\n",
      "  28.536442  95.86964 ]\n",
      "reward:  -0.9120271109175915\n",
      "timestep:  2\n",
      "new state [532.7      532.7      532.7      532.7      532.7       29.215311\n",
      "  29.297398  90.52053 ]\n",
      "reward:  -0.953027383572906\n",
      "\n",
      "env reset!\n",
      "starting_state [532.7      532.7      532.7      532.7      532.7       15.893612\n",
      "  22.797962  31.012772]\n",
      "timestep:  0\n",
      "new state [507.85208  507.9839   509.5586   508.029    508.13034   10.531451\n",
      "  20.25539   27.191671]\n",
      "reward:  -0.89495551416555\n",
      "timestep:  1\n",
      "new state [487.03812  487.3812   491.31903  487.49902  486.58948   48.773994\n",
      "  41.24159   69.70564 ]\n",
      "reward:  -0.8927693228400359\n",
      "timestep:  2\n",
      "new state [385.8      385.8      385.8      385.8      385.8       53.84964\n",
      "  53.398853  45.083656]\n",
      "reward:  -0.9105690088024604\n",
      "\n",
      "env reset!\n",
      "starting_state [385.8       385.8       385.8       385.8       385.8        88.03877\n",
      "   3.5990686 150.67554  ]\n",
      "timestep:  0\n",
      "new state [320.1465   316.55975  266.9026   315.3582   335.34116   61.643486\n",
      " 101.91466  126.1111  ]\n",
      "reward:  -1.1131492380817034\n",
      "timestep:  1\n",
      "new state [215.04785  212.4123   227.84535  211.5342   235.4273    17.000122\n",
      "  19.378986  21.95446 ]\n",
      "reward:  -0.999856575598038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  2\n",
      "new state [369.3       369.3       369.3       369.3       369.3         9.954162\n",
      "   6.2021093  11.368587 ]\n",
      "reward:  -0.8844804183770909\n",
      "\n",
      "env reset!\n",
      "starting_state [369.3      369.3      369.3      369.3      369.3       68.656334\n",
      "  57.28457   84.397415]\n",
      "timestep:  0\n",
      "new state [295.9367   295.47922  291.02106  295.32     340.99933   51.262974\n",
      "  73.26143   38.579063]\n",
      "reward:  -0.9788072159692502\n",
      "timestep:  1\n",
      "new state [230.1182    230.68735   243.23878   230.86314   310.3971      4.4276123\n",
      "   7.0010343  14.069587 ]\n",
      "reward:  -0.8372051517575029\n",
      "timestep:  2\n",
      "new state [405.9      405.9      405.9      405.9      405.9       35.008423\n",
      "  64.534256  63.143757]\n",
      "reward:  -0.9221084978169882\n",
      "\n",
      "env reset!\n",
      "starting_state [405.9      405.9      405.9      405.9      405.9       53.765198\n",
      "  93.29372   57.67846 ]\n",
      "timestep:  0\n",
      "new state [323.89423  325.4069   348.25244  325.90778  360.16705   58.072224\n",
      "  58.741592 165.6324  ]\n",
      "reward:  -0.8417017944063266\n",
      "timestep:  1\n",
      "new state [234.4682   235.03581  240.84393  235.23337  304.69135   22.718405\n",
      "  18.92584   27.826614]\n",
      "reward:  -1.0546479772544828\n",
      "timestep:  2\n",
      "new state [483.8      483.8      483.8      483.8      483.8       32.634827\n",
      "  52.41685   70.07109 ]\n",
      "reward:  -0.9022830997645095\n",
      "\n",
      "env reset!\n",
      "starting_state [483.8     483.8     483.8     483.8     483.8      67.67647 102.43869\n",
      "  71.08226]\n",
      "timestep:  0\n",
      "new state [389.1291   390.495    411.90848  390.94476  427.4448    67.41368\n",
      "  95.658356  70.84475 ]\n",
      "reward:  -0.8509847228057704\n",
      "timestep:  1\n",
      "new state [298.3085   300.79913  340.28247  301.61783  371.28113   20.258537\n",
      "  24.00422   49.519707]\n",
      "reward:  -0.8559192199420735\n",
      "timestep:  2\n",
      "new state [504.2      504.2      504.2      504.2      504.2       25.789259\n",
      "  24.07652   70.3113  ]\n",
      "reward:  -0.9234416594760434\n",
      "\n",
      "env reset!\n",
      "starting_state [504.2     504.2     504.2     504.2     504.2      69.09545  87.1684\n",
      " 117.49688]\n",
      "timestep:  0\n",
      "new state [406.7078   407.01263  411.1748   407.1153   411.109     75.718445\n",
      "  76.953064  42.86057 ]\n",
      "reward:  -0.8949465840395786\n",
      "timestep:  1\n",
      "new state [329.84833 330.65665 346.78592 330.91183 377.1034   84.30181  95.41798\n",
      " 211.03032]\n",
      "reward:  -0.8484075256640932\n",
      "timestep:  2\n",
      "new state [625.8      625.8      625.8      625.8      625.8        6.914862\n",
      "   7.725626   8.847546]\n",
      "reward:  -0.9279240420707758\n",
      "\n",
      "env reset!\n",
      "starting_state [625.8     625.8     625.8     625.8     625.8      91.13546 113.52861\n",
      " 206.13072]\n",
      "timestep:  0\n",
      "new state [486.1977   486.03745  480.7442   485.9944   462.52045   66.19723\n",
      "  89.615776  66.893295]\n",
      "reward:  -0.9149449841069092\n",
      "timestep:  1\n",
      "new state [399.99396   400.80548   411.58118   401.0797    409.48846     5.382935\n",
      "   2.9284296   4.6989017]\n",
      "reward:  -0.8571765392094859\n",
      "timestep:  2\n",
      "new state [361.2      361.2      361.2      361.2      361.2       15.225042\n",
      "  30.047523  30.504225]\n",
      "reward:  -0.9085058190415924\n",
      "\n",
      "env reset!\n",
      "starting_state [361.2      361.2      361.2      361.2      361.2       53.08944\n",
      "  87.212166 119.767044]\n",
      "timestep:  0\n",
      "new state [268.41806  269.1056   276.82556  269.34222  321.0582    72.977165\n",
      "  61.269924 181.84932 ]\n",
      "reward:  -0.9827385613667079\n",
      "timestep:  1\n",
      "new state [226.39203   226.50049   224.58325   226.5481    260.14792     8.093409\n",
      "   5.7520013  18.94009  ]\n",
      "reward:  -1.80612071900549\n",
      "timestep:  2\n",
      "new state [273.2      273.2      273.2      273.2      273.2        6.601778\n",
      "  11.453204  16.405418]\n",
      "reward:  -0.9497173528219441\n",
      "\n",
      "env reset!\n",
      "starting_state [273.2      273.2      273.2      273.2      273.2       34.82256\n",
      "  53.696167  75.69512 ]\n",
      "timestep:  0\n",
      "new state [248.57178  248.71985  250.31271  248.77075  247.82968   39.66742\n",
      "  27.729004  29.691042]\n",
      "reward:  -1.7583284929447496\n",
      "timestep:  1\n",
      "new state [213.52156  213.39699  213.42375  213.3494   237.86195   15.273366\n",
      "  22.358013  43.79532 ]\n",
      "reward:  -0.9445682896254431\n",
      "timestep:  2\n",
      "new state [351.8      351.8      351.8      351.8      351.8       37.66859\n",
      "  53.746574  35.644295]\n",
      "reward:  -0.9202313052644221\n",
      "\n",
      "env reset!\n",
      "starting_state [351.8      351.8      351.8      351.8      351.8       10.779009\n",
      "  11.067336  23.435661]\n",
      "timestep:  0\n",
      "new state [336.7976    336.701     335.0575    336.66965   333.23694     7.3338127\n",
      "   9.361227   20.569546 ]\n",
      "reward:  -0.9248420864655307\n",
      "timestep:  1\n",
      "new state [324.52158   324.38077   321.64417   324.33624   316.9453     11.904407\n",
      "   4.9091125  22.337868 ]\n",
      "reward:  -0.9278200629041428\n",
      "timestep:  2\n",
      "new state [236.1      236.1      236.1      236.1      236.1       33.18761\n",
      "  65.25444   52.266026]\n",
      "reward:  -0.9609373068316432\n",
      "\n",
      "env reset!\n",
      "starting_state [236.1      236.1      236.1      236.1      236.1       12.941438\n",
      "  14.481087  45.23311 ]\n",
      "timestep:  0\n",
      "new state [226.54713  226.4468   224.42693  226.41512  220.95221   15.168373\n",
      "  27.646135  41.162754]\n",
      "reward:  -1.8111487531418515\n",
      "timestep:  1\n",
      "new state [196.94344 197.07112 197.28375 197.11899 207.15857  63.98094  71.12779\n",
      "  57.12702]\n",
      "reward:  -0.9938646457919367\n",
      "timestep:  2\n",
      "new state [543.5      543.5      543.5      543.5      543.5      106.001465\n",
      "  92.573204 112.9911  ]\n",
      "reward:  -0.8646295846296232\n",
      "\n",
      "env reset!\n",
      "starting_state [543.5      543.5      543.5      543.5      543.5       48.984474\n",
      "  57.27402   80.303246]\n",
      "timestep:  0\n",
      "new state [477.5493   477.6283   478.86203  477.65454  479.8772    48.26404\n",
      "  63.238087 157.48856 ]\n",
      "reward:  -0.8978912594115115\n",
      "timestep:  1\n",
      "new state [390.7644   390.39264  380.91974  390.2829   355.15036   61.764336\n",
      "  36.61974  134.69456 ]\n",
      "reward:  -0.9362479605458074\n",
      "timestep:  2\n",
      "new state [373.6       373.6       373.6       373.6       373.6         7.4688554\n",
      "   6.943538   17.029524 ]\n",
      "reward:  -0.954204482821824\n",
      "\n",
      "env reset!\n",
      "starting_state [373.6      373.6      373.6      373.6      373.6       13.486623\n",
      "  11.047715  27.249176]\n",
      "timestep:  0\n",
      "new state [356.83908  356.63547  353.55954  356.56815  352.01675   13.740166\n",
      "  18.264805  28.609154]\n",
      "reward:  -0.9335675258748992\n",
      "timestep:  1\n",
      "new state [335.73297  335.57214  332.7683   335.5203   329.35318   32.45851\n",
      "  72.69114  111.168365]\n",
      "reward:  -0.9048606681705091\n",
      "timestep:  2\n",
      "new state [417.8     417.8     417.8     417.8     417.8      28.0652   58.87434\n",
      "  65.21824]\n",
      "reward:  -0.902054100729266\n",
      "\n",
      "env reset!\n",
      "starting_state [417.8      417.8      417.8      417.8      417.8       37.554443\n",
      "  29.651537  87.394646]\n",
      "timestep:  0\n",
      "new state [369.0788   368.35623  356.96252  368.11887  348.58304   51.693523\n",
      "  53.992424  77.7959  ]\n",
      "reward:  -0.9440694833816652\n",
      "timestep:  1\n",
      "new state [304.61185  303.80383  291.78998  303.5362   286.9454    53.265434\n",
      "  48.72865   77.82725 ]\n",
      "reward:  -0.9001232412462973\n",
      "timestep:  2\n",
      "new state [539.6      539.6      539.6      539.6      539.6       49.757053\n",
      "  35.54494  107.010925]\n",
      "reward:  -0.9069737602983101\n",
      "Writing to file data.csv\n",
      "Guardrail-0.3\n",
      "\n",
      "env reset!\n",
      "starting_state [539.6      539.6      539.6      539.6      539.6       58.352585\n",
      "  40.66036   56.945507]\n",
      "Lower and Upper Solutions:\n",
      "[[0.20874 0.21857 0.38261 0.2218  0.     ]\n",
      " [0.34123 0.32064 0.      0.3138  0.     ]\n",
      " [0.14398 0.15115 0.25496 0.15355 0.52449]]\n",
      "[[0.74725 0.78042 1.35416 0.7911  0.     ]\n",
      " [1.21872 1.14036 0.      1.11447 0.     ]\n",
      " [0.50777 0.53803 0.91406 0.54821 1.86801]]\n",
      "timestep:  0\n",
      "new state [417.5272  417.05463 408.5093  416.90442 433.1757   38.91278  71.64389\n",
      "   5.44837]\n",
      "reward:  -0.0969944213774563\n",
      "timestep:  1\n",
      "new state [298.36926  302.05508  350.79922  303.2887   422.9428    18.102997\n",
      "  21.45836   31.063812]\n",
      "reward:  0.03265747135477693\n",
      "timestep:  2\n",
      "new state [344.7      344.7      344.7      344.7      344.7       24.134176\n",
      "  29.325552  54.766094]\n",
      "reward:  -0.09655161544116608\n",
      "\n",
      "env reset!\n",
      "starting_state [344.7       344.7       344.7       344.7       344.7         8.275917\n",
      "   6.1462727  23.933739 ]\n",
      "timestep:  0\n",
      "new state [318.8724   318.3553   311.61316  318.18237  332.1398     6.277636\n",
      "   7.163428  17.836748]\n",
      "reward:  -0.3179518791496337\n",
      "timestep:  1\n",
      "new state [296.39426   295.6905    286.8048    295.45444   298.81384     3.2439456\n",
      "   4.6910872   5.753231 ]\n",
      "reward:  -0.13230359228100536\n",
      "timestep:  2\n",
      "new state [314.2     314.2     314.2     314.2     314.2      91.38705 116.69336\n",
      "  95.547  ]\n",
      "reward:  -0.08446314933754637\n",
      "\n",
      "env reset!\n",
      "starting_state [314.2      314.2      314.2      314.2      314.2       77.67342\n",
      "  63.238663 144.01955 ]\n",
      "timestep:  0\n",
      "new state [255.6716  255.17754 247.73055 255.01355 238.59274  76.98636  90.14613\n",
      " 123.91545]\n",
      "reward:  -1.3954929905116873\n",
      "timestep:  1\n",
      "new state [190.99956  190.71635  186.63623  190.6229   173.51675   13.722579\n",
      "  16.198635  23.977694]\n",
      "reward:  -1.3634061666795334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  2\n",
      "new state [491.9      491.9      491.9      491.9      491.9       46.427876\n",
      "  87.64983   11.633492]\n",
      "reward:  -0.21329867772702543\n",
      "\n",
      "env reset!\n",
      "starting_state [491.9       491.9       491.9       491.9       491.9         3.8670585\n",
      "   6.420634   14.785695 ]\n",
      "timestep:  0\n",
      "new state [473.67764  473.60507  473.14514  473.5795   464.27502    9.356492\n",
      "   9.539852  20.92689 ]\n",
      "reward:  -0.12833529843612052\n",
      "timestep:  1\n",
      "new state [444.43353   444.16492   441.34174   444.07336   425.17395     7.4263606\n",
      "  11.283441   20.330017 ]\n",
      "reward:  -0.12371763169726434\n",
      "timestep:  2\n",
      "new state [88.7       88.7       88.7       88.7       88.7        7.0896263\n",
      "  7.5003157 10.886014 ]\n",
      "reward:  -0.11104111663680143\n",
      "\n",
      "env reset!\n",
      "starting_state [88.7      88.7      88.7      88.7      88.7      17.161901 18.034266\n",
      " 41.1559  ]\n",
      "timestep:  0\n",
      "new state [73.03816  72.9457   71.63156  72.91485  67.09654  17.53796  23.187601\n",
      " 35.562305]\n",
      "reward:  -1.396540995398339\n",
      "timestep:  1\n",
      "new state [56.344723 56.302315 55.842804 56.288067 48.424107  6.835262  8.435641\n",
      " 10.474026]\n",
      "reward:  -1.3702488782500197\n",
      "timestep:  2\n",
      "new state [226.5      226.5      226.5      226.5      226.5       27.394936\n",
      "  46.995453  17.307558]\n",
      "reward:  -1.3564967139086623\n",
      "\n",
      "env reset!\n",
      "starting_state [226.5      226.5      226.5      226.5      226.5        5.490476\n",
      "   5.421324   4.744817]\n",
      "timestep:  0\n",
      "new state [222.82085   222.84447   223.18684   222.85243   224.00594     4.982329\n",
      "   7.5733066   7.7726264]\n",
      "reward:  -1.3380062701066269\n",
      "timestep:  1\n",
      "new state [218.0775   218.15234  219.29506  218.17737  219.92299   60.740826\n",
      "  70.336586  74.74761 ]\n",
      "reward:  -1.3422783599491446\n",
      "timestep:  2\n",
      "new state [332.1     332.1     332.1     332.1     332.1      21.95292  37.47287\n",
      "  53.31124]\n",
      "reward:  -1.3471966516649978\n",
      "\n",
      "env reset!\n",
      "starting_state [332.1      332.1      332.1      332.1      332.1       10.202902\n",
      "   9.098642   6.83522 ]\n",
      "timestep:  0\n",
      "new state [309.91647   310.08417   312.0313    310.14117   328.50534     7.4036946\n",
      "   7.3668222  24.090857 ]\n",
      "reward:  -0.129546489144235\n",
      "timestep:  1\n",
      "new state [283.17334 282.94376 279.98135 282.86716 315.86255  65.77657 108.52525\n",
      " 134.97325]\n",
      "reward:  -0.30921268240092814\n",
      "timestep:  2\n",
      "new state [294.4       294.4       294.4       294.4       294.4         7.3839045\n",
      "   8.078552   23.081436 ]\n",
      "reward:  -1.354820618991032\n",
      "\n",
      "env reset!\n",
      "starting_state [294.4      294.4      294.4      294.4      294.4       20.236734\n",
      "  26.302414  66.29913 ]\n",
      "timestep:  0\n",
      "new state [271.65485  271.52213  269.74045  271.47757  259.6035    19.795473\n",
      "  24.024158  47.187183]\n",
      "reward:  -1.40382506094545\n",
      "timestep:  1\n",
      "new state [252.53096  252.35999  250.12364  252.30257  234.83237   42.84446\n",
      "  44.006886  87.89553 ]\n",
      "reward:  -1.3870177437481086\n",
      "timestep:  2\n",
      "new state [271.4      271.4      271.4      271.4      271.4        8.709915\n",
      "  10.102669  18.147213]\n",
      "reward:  -1.3878873008272796\n",
      "\n",
      "env reset!\n",
      "starting_state [271.4      271.4      271.4      271.4      271.4       11.835402\n",
      "  22.375742  25.979523]\n",
      "timestep:  0\n",
      "new state [257.55368  257.71176  260.23672  257.76425  257.7569    17.524372\n",
      "  20.638361  48.990944]\n",
      "reward:  -1.3491020237110476\n",
      "timestep:  1\n",
      "new state [239.7995   239.859    241.03067  239.87846  232.04256   13.752008\n",
      "  36.53962   57.451855]\n",
      "reward:  -1.3995006707051456\n",
      "timestep:  2\n",
      "new state [431.9      431.9      431.9      431.9      431.9       59.223713\n",
      "  45.17748   72.74192 ]\n",
      "reward:  -0.23868995056922857\n",
      "\n",
      "env reset!\n",
      "starting_state [431.9      431.9      431.9      431.9      431.9       15.673986\n",
      "  11.784581  10.755428]\n",
      "timestep:  0\n",
      "new state [400.36423  400.4423   400.83792  400.47052  411.795     19.455704\n",
      "  21.211712  14.576744]\n",
      "reward:  -0.07413563971887148\n",
      "timestep:  1\n",
      "new state [352.57318  353.22696  361.15717  353.44818  384.54517   43.571934\n",
      "  73.98386   28.818937]\n",
      "reward:  -0.053376607041293773\n",
      "timestep:  2\n",
      "new state [251.        251.        251.        251.        251.          6.8050537\n",
      "   9.470165   20.936565 ]\n",
      "reward:  -0.014804050665009819\n",
      "\n",
      "env reset!\n",
      "starting_state [251.        251.        251.        251.        251.          5.7822447\n",
      "   5.622657   14.668379 ]\n",
      "timestep:  0\n",
      "new state [245.76244  245.7162   245.045    245.70078  243.30087    4.964589\n",
      "   7.979662  22.917156]\n",
      "reward:  -1.4047114452956901\n",
      "timestep:  1\n",
      "new state [220.69102  220.41193  217.3705   220.31677  231.27458   27.182522\n",
      "  32.845627  68.26477 ]\n",
      "reward:  -0.3087254251803194\n",
      "timestep:  2\n",
      "new state [424.1      424.1      424.1      424.1      424.1       52.364475\n",
      " 116.56082   95.4568  ]\n",
      "reward:  -1.390785002445755\n",
      "\n",
      "env reset!\n",
      "starting_state [424.1      424.1      424.1      424.1      424.1       23.085138\n",
      "  29.845253  54.713528]\n",
      "timestep:  0\n",
      "new state [342.69473  342.61206  342.81268  342.5812   395.37683   17.51794\n",
      "  23.701492  69.26325 ]\n",
      "reward:  -0.24392788042585806\n",
      "timestep:  1\n",
      "new state [265.54916 264.64676 255.76797 264.33734 359.02832  46.031    76.6831\n",
      "  83.76971]\n",
      "reward:  -0.3058930646418789\n",
      "timestep:  2\n",
      "new state [486.9      486.9      486.9      486.9      486.9       49.756626\n",
      "  67.749756 139.36096 ]\n",
      "reward:  -1.104330302136117\n",
      "\n",
      "env reset!\n",
      "starting_state [486.9      486.9      486.9      486.9      486.9       63.406208\n",
      " 148.30202   60.378918]\n",
      "timestep:  0\n",
      "new state [414.36612 416.36346 345.77374 417.02814 374.0057   79.4938  106.23367\n",
      " 201.20831]\n",
      "reward:  -0.9389592920677357\n",
      "timestep:  1\n",
      "new state [332.5525   334.51312  264.00543  335.16473  268.3811    38.576565\n",
      "  55.349182  65.8818  ]\n",
      "reward:  -1.3846478019010278\n",
      "timestep:  2\n",
      "new state [612.3      612.3      612.3      612.3      612.3       25.025757\n",
      "  45.414127  33.943142]\n",
      "reward:  -0.18931471961586305\n",
      "\n",
      "env reset!\n",
      "starting_state [612.3      612.3      612.3      612.3      612.3       27.968258\n",
      "  66.738335  84.74562 ]\n",
      "timestep:  0\n",
      "new state [467.0341   468.77158  496.93054  469.338    453.94696   43.928947\n",
      "  21.158365  45.88839 ]\n",
      "reward:  -0.08434743840240952\n",
      "timestep:  1\n",
      "new state [385.1213    385.67108   395.4884    385.849     368.19446     4.5594273\n",
      "   8.518999   21.96597  ]\n",
      "reward:  -0.12054949357429855\n",
      "timestep:  2\n",
      "new state [450.7     450.7     450.7     450.7     450.7      77.63267  69.99103\n",
      "  94.91813]\n",
      "reward:  -0.13648674970214558\n",
      "\n",
      "env reset!\n",
      "starting_state [450.7      450.7      450.7      450.7      450.7       47.703785\n",
      "  49.525536  75.24773 ]\n",
      "timestep:  0\n",
      "new state [316.48706  316.50854  317.29575  316.51526  411.18472   67.479576\n",
      "  54.46545  111.912834]\n",
      "reward:  -0.21317786507701406\n",
      "timestep:  1\n",
      "new state [267.7029   267.3801   262.91687  267.27283  352.42657   47.493595\n",
      "  87.26797   78.64809 ]\n",
      "reward:  -1.3892071278989582\n",
      "timestep:  2\n",
      "new state [626.4      626.4      626.4      626.4      626.4       38.041695\n",
      "  35.91565  125.50194 ]\n",
      "reward:  -1.1123043001904904\n",
      "\n",
      "env reset!\n",
      "starting_state [626.4      626.4      626.4      626.4      626.4       68.84266\n",
      "  94.208176 110.56915 ]\n",
      "timestep:  0\n",
      "new state [404.00027 405.75308 432.0621  406.3313  419.77423  37.79522  87.63676\n",
      "  87.71248]\n",
      "reward:  -0.08189483494859841\n",
      "timestep:  1\n",
      "new state [224.41536  229.12753  300.66302  230.6781   373.70718   31.472702\n",
      "  24.848057  79.67594 ]\n",
      "reward:  -0.17325107514197302\n",
      "timestep:  2\n",
      "new state [629.1      629.1      629.1      629.1      629.1       47.327087\n",
      "  26.310238  90.41862 ]\n",
      "reward:  -0.3400383020458711\n",
      "\n",
      "env reset!\n",
      "starting_state [629.1      629.1      629.1      629.1      629.1       24.897203\n",
      "  74.22195   78.3461  ]\n",
      "timestep:  0\n",
      "new state [480.258    482.8774   523.73505  483.73553  482.6991    33.74213\n",
      "  32.012737  87.403915]\n",
      "reward:  -0.06893205511405288\n",
      "timestep:  1\n",
      "new state [371.64856  373.0124   398.13437  373.4492   319.39484    9.608265\n",
      "  11.71757   42.46312 ]\n",
      "reward:  -0.13722758143248662\n",
      "timestep:  2\n",
      "new state [252.3       252.3       252.3       252.3       252.3         7.0822525\n",
      "   7.7232594  10.552965 ]\n",
      "reward:  -0.15617191656903964\n",
      "\n",
      "env reset!\n",
      "starting_state [252.3      252.3      252.3      252.3      252.3       22.690355\n",
      "  21.37716   41.088287]\n",
      "timestep:  0\n",
      "new state [234.3532   234.27571  233.13188  234.25003  230.72757   18.794472\n",
      "  18.828686  42.83466 ]\n",
      "reward:  -1.385325712055668\n",
      "timestep:  1\n",
      "new state [217.8378   217.65611  215.01039  217.59572  208.2424    11.573236\n",
      "  24.75364   18.072481]\n",
      "reward:  -1.3961778419770379\n",
      "timestep:  2\n",
      "new state [180.       180.       180.       180.       180.         9.396008\n",
      "  20.15765   22.25668 ]\n",
      "reward:  -0.1313589318657793\n",
      "\n",
      "env reset!\n",
      "starting_state [180.       180.       180.       180.       180.        45.09914\n",
      "  55.950485  83.77051 ]\n",
      "timestep:  0\n",
      "new state [139.43274  139.5408   141.35852  139.57678  136.01268   31.85227\n",
      "  47.323803  93.19615 ]\n",
      "reward:  -1.368809461427978\n",
      "timestep:  1\n",
      "new state [103.21721   103.318344  105.386566  103.35147    87.092636    6.087017\n",
      "   7.7241664  10.803691 ]\n",
      "reward:  -1.3874296753269912\n",
      "timestep:  2\n",
      "new state [340.2     340.2     340.2     340.2     340.2      56.34593  75.02445\n",
      "  82.67766]\n",
      "reward:  -1.3641849077393746\n",
      "\n",
      "env reset!\n",
      "starting_state [340.2      340.2      340.2      340.2      340.2       95.16671\n",
      "  59.903145  76.07263 ]\n",
      "timestep:  0\n",
      "new state [288.94122 288.6937  284.36285 288.61346 300.22314 106.97602  70.30888\n",
      " 270.05283]\n",
      "reward:  -1.3627105215444182\n",
      "timestep:  1\n",
      "new state [203.73734  201.94962  174.54494  201.35664  158.4945    78.9236\n",
      "  52.114098  42.04996 ]\n",
      "reward:  -1.4244731523493606\n",
      "timestep:  2\n",
      "new state [862.9      862.9      862.9      862.9      862.9       45.03868\n",
      "  46.135635  39.258255]\n",
      "reward:  -1.34091344120536\n",
      "\n",
      "env reset!\n",
      "starting_state [862.9      862.9      862.9      862.9      862.9       86.95109\n",
      "  84.90955   44.371353]\n",
      "timestep:  0\n",
      "new state [671.9144  674.34106 704.55383 675.15906 779.928    75.25718  84.63726\n",
      " 166.01964]\n",
      "reward:  -0.0433642061936655\n",
      "timestep:  1\n",
      "new state [428.2296   429.76837  450.84937  430.28378  469.72168   28.833546\n",
      "  56.928272 183.26923 ]\n",
      "reward:  -0.11665158245515081\n",
      "timestep:  2\n",
      "new state [632.4      632.4      632.4      632.4      632.4       50.193836\n",
      "  74.47444   70.67178 ]\n",
      "reward:  -0.32798091830616216\n",
      "\n",
      "env reset!\n",
      "starting_state [632.4     632.4     632.4     632.4     632.4      68.8054   84.22174\n",
      " 127.70535]\n",
      "timestep:  0\n",
      "new state [413.49753  413.9505   422.45404  414.09613  393.76862   67.63453\n",
      "  54.094967 143.87057 ]\n",
      "reward:  -0.09950911583977559\n",
      "timestep:  1\n",
      "new state [223.97784  222.07272  359.8681   221.43195  318.24908   63.066257\n",
      "  71.81964   87.96967 ]\n",
      "reward:  -0.4762809892803011\n",
      "timestep:  2\n",
      "new state [605.1      605.1      605.1      605.1      605.1        8.978854\n",
      "   6.497436   7.013225]\n",
      "reward:  -0.9971077772322617\n",
      "\n",
      "env reset!\n",
      "starting_state [605.1      605.1      605.1      605.1      605.1       45.38345\n",
      "  62.868977  64.14087 ]\n",
      "timestep:  0\n",
      "new state [461.99872  463.47885  484.9835   463.96887  485.23007   38.236603\n",
      "  60.039486  39.17372 ]\n",
      "reward:  -0.07262521210689288\n",
      "timestep:  1\n",
      "new state [340.36386  344.09497  397.36786  345.33228  412.00403   30.421913\n",
      "  48.387154  82.814674]\n",
      "reward:  -0.0433607185597645\n",
      "timestep:  2\n",
      "new state [486.8      486.8      486.8      486.8      486.8       43.303104\n",
      "  26.81554  104.655334]\n",
      "reward:  -0.10739599266745527\n",
      "\n",
      "env reset!\n",
      "starting_state [486.8       486.8       486.8       486.8       486.8         4.246041\n",
      "   8.46335    12.1051445]\n",
      "timestep:  0\n",
      "new state [467.16605   467.32208   469.9811    467.37262   464.1811      6.9337163\n",
      "   6.9050226   3.1503477]\n",
      "reward:  -0.09394731162785787\n",
      "timestep:  1\n",
      "new state [451.96988  452.34167  457.70868  452.46487  458.28928   28.496254\n",
      "  73.75888  101.782585]\n",
      "reward:  -0.037355899236445125\n",
      "timestep:  2\n",
      "new state [218.7       218.7       218.7       218.7       218.7        10.630719\n",
      "   6.9710045  19.985203 ]\n",
      "reward:  -0.09045735881677694\n",
      "\n",
      "env reset!\n",
      "starting_state [218.7      218.7      218.7      218.7      218.7       22.827225\n",
      "  29.537369  80.270775]\n",
      "timestep:  0\n",
      "new state [192.29861  192.10686  189.48547  192.04251  176.5726    29.131529\n",
      "  24.086033  35.90745 ]\n",
      "reward:  -1.4087298637493726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  1\n",
      "new state [172.82887  172.58922  169.17245  172.50935  157.71289   43.378193\n",
      "  44.497005  85.76919 ]\n",
      "reward:  -1.3699374558425945\n",
      "timestep:  2\n",
      "new state [359.8       359.8       359.8       359.8       359.8        15.8702135\n",
      "  26.540382   56.178318 ]\n",
      "reward:  -1.3855935534625032\n",
      "\n",
      "env reset!\n",
      "starting_state [359.8      359.8      359.8      359.8      359.8       70.43213\n",
      "  40.849953  44.25658 ]\n",
      "timestep:  0\n",
      "new state [324.78668  324.61813  321.54785  324.56384  336.53223   46.474483\n",
      "  35.458675 173.63602 ]\n",
      "reward:  -1.3558672824508977\n",
      "timestep:  1\n",
      "new state [277.98593   276.84564   259.47827   276.46707   245.4209      6.7724886\n",
      "   8.5429325  10.706835 ]\n",
      "reward:  -1.439145474473164\n",
      "timestep:  2\n",
      "new state [415.       415.       415.       415.       415.        20.721453\n",
      "  57.89818   73.81426 ]\n",
      "reward:  -0.08677986892045125\n",
      "\n",
      "env reset!\n",
      "starting_state [415.       415.       415.       415.       415.        68.53038\n",
      "  69.694214 136.3754  ]\n",
      "timestep:  0\n",
      "new state [357.2779   357.06143  353.9745   356.98947  343.40335   38.588337\n",
      "  45.5311    41.92854 ]\n",
      "reward:  -1.3865529220020654\n",
      "timestep:  1\n",
      "new state [251.66304  252.46567  263.37173  252.73355  321.37018   16.848251\n",
      "  18.003662  54.69818 ]\n",
      "reward:  -0.1543546083717261\n",
      "timestep:  2\n",
      "new state [488.7     488.7     488.7     488.7     488.7      52.49309  80.51353\n",
      "  86.61034]\n",
      "reward:  -0.14456702729295856\n",
      "\n",
      "env reset!\n",
      "starting_state [488.7      488.7      488.7      488.7      488.7       24.715092\n",
      "  26.12814   66.91871 ]\n",
      "timestep:  0\n",
      "new state [404.40945  403.6121   394.05103  403.34338  453.5764    28.025057\n",
      "  29.4309    61.69561 ]\n",
      "reward:  -0.2810138307504777\n",
      "timestep:  1\n",
      "new state [316.27252 314.98486 299.6924  314.55075 338.29965  38.65242  71.97519\n",
      " 146.82419]\n",
      "reward:  -0.12086853208131514\n",
      "timestep:  2\n",
      "new state [418.2      418.2      418.2      418.2      418.2       14.621867\n",
      "  28.503355  34.427475]\n",
      "reward:  -1.3901936943497317\n",
      "\n",
      "env reset!\n",
      "starting_state [418.2      418.2      418.2      418.2      418.2       41.140926\n",
      "  24.08108   90.9433  ]\n",
      "timestep:  0\n",
      "new state [311.9311   309.70148  379.26013  308.95975  370.46857   32.88811\n",
      "  51.908463  46.94099 ]\n",
      "reward:  -0.5165661898868887\n",
      "timestep:  1\n",
      "new state [280.59473  278.77405  291.79153  278.1685   345.8061    32.324745\n",
      "  69.80584   79.33678 ]\n",
      "reward:  -1.0130409545577996\n",
      "timestep:  2\n",
      "new state [653.5      653.5      653.5      653.5      653.5       42.000443\n",
      "  48.14922   59.736176]\n",
      "reward:  -0.8526773129950269\n",
      "\n",
      "env reset!\n",
      "starting_state [653.5     653.5     653.5     653.5     653.5      62.09389  69.46917\n",
      "   1.     ]\n",
      "timestep:  0\n",
      "new state [521.9291   525.2828   568.4661   526.408    651.5662    41.883297\n",
      "  62.627632  87.61056 ]\n",
      "reward:  0.0151966026574583\n",
      "timestep:  1\n",
      "new state [369.82022  374.04108  431.63684  375.44855  487.85657  110.85075\n",
      " 101.86062   51.575523]\n",
      "reward:  -0.093338876924483\n",
      "timestep:  2\n",
      "new state [610.5      610.5      610.5      610.5      610.5       29.145187\n",
      "  35.68855   97.507614]\n",
      "reward:  -0.04377876666330493\n",
      "\n",
      "env reset!\n",
      "starting_state [610.5      610.5      610.5      610.5      610.5       55.846092\n",
      "  97.55498   58.32828 ]\n",
      "timestep:  0\n",
      "new state [420.25946  424.28644  481.51114  425.6219   501.46548   45.255993\n",
      "  48.724453  50.271637]\n",
      "reward:  -0.03625356787676063\n",
      "timestep:  1\n",
      "new state [301.53403  306.3567   374.25165  307.9585   407.51056   35.702198\n",
      "  55.011387  43.152588]\n",
      "reward:  -0.0760038692362607\n",
      "timestep:  2\n",
      "new state [403.        403.        403.        403.        403.          5.858639\n",
      "   4.8854113  20.20858  ]\n",
      "reward:  -0.054680735072540676\n",
      "\n",
      "env reset!\n",
      "starting_state [403.       403.       403.       403.       403.        13.502382\n",
      "  13.701265  43.796974]\n",
      "timestep:  0\n",
      "new state [353.97354  353.27402  344.6757   353.03867  380.01532    8.910551\n",
      "   8.320324  21.651993]\n",
      "reward:  -0.30717724108876654\n",
      "timestep:  1\n",
      "new state [326.18076  325.18246  312.814    324.84692  339.56058   22.710562\n",
      "  33.801067  43.468422]\n",
      "reward:  -0.13415895572736047\n",
      "timestep:  2\n",
      "new state [335.5      335.5      335.5      335.5      335.5       33.21482\n",
      "  56.64547   61.598717]\n",
      "reward:  -0.08753634471974688\n",
      "\n",
      "env reset!\n",
      "starting_state [335.5      335.5      335.5      335.5      335.5       43.707058\n",
      "  60.920345  61.202732]\n",
      "timestep:  0\n",
      "new state [296.77676  297.16266  303.14252  297.2913   303.34747   20.881828\n",
      "  46.271496  48.42366 ]\n",
      "reward:  -1.3417524806043437\n",
      "timestep:  1\n",
      "new state [269.65662  270.44278  230.57991  270.70425  277.91617   21.958979\n",
      "  24.4882    37.25161 ]\n",
      "reward:  -1.0340058631854219\n",
      "timestep:  2\n",
      "new state [292.4      292.4      292.4      292.4      292.4       19.154333\n",
      "  27.784224  22.170706]\n",
      "reward:  -0.09999474841980543\n",
      "\n",
      "env reset!\n",
      "starting_state [292.4      292.4      292.4      292.4      292.4       54.086212\n",
      "  44.356434 129.68245 ]\n",
      "timestep:  0\n",
      "new state [247.30261  246.75443  238.62006  246.57188  224.33362   45.74425\n",
      "  23.512518  25.19479 ]\n",
      "reward:  -1.4106652493365857\n",
      "timestep:  1\n",
      "new state [226.10324  225.40886  214.68243  225.17892  211.08458   29.514809\n",
      "  29.299732  81.67291 ]\n",
      "reward:  -1.356807625674065\n",
      "timestep:  2\n",
      "new state [482.5       482.5       482.5       482.5       482.5         7.5077925\n",
      "  33.178036   43.72549  ]\n",
      "reward:  -1.408962523090012\n",
      "\n",
      "env reset!\n",
      "starting_state [482.5       482.5       482.5       482.5       482.5         8.6625185\n",
      "  12.69736     1.       ]\n",
      "timestep:  0\n",
      "new state [460.04465  460.72202  469.84915  460.94806  480.6213    13.120738\n",
      "   9.845924  12.610104]\n",
      "reward:  0.020857638999853424\n",
      "timestep:  1\n",
      "new state [431.8377   432.46982  440.55026  432.68228  457.05402   48.132317\n",
      "  71.776855  94.96901 ]\n",
      "reward:  -0.09165387469024673\n",
      "timestep:  2\n",
      "new state [429.8      429.8      429.8      429.8      429.8       50.115356\n",
      "  84.95765   95.598305]\n",
      "reward:  -0.08948830968387361\n",
      "\n",
      "env reset!\n",
      "starting_state [429.8      429.8      429.8      429.8      429.8       87.4185\n",
      "  80.061104 160.28911 ]\n",
      "timestep:  0\n",
      "new state [361.15457 360.79443 355.44543 360.675   345.6462   64.32462  72.24431\n",
      " 152.33092]\n",
      "reward:  -1.3878521128588843\n",
      "timestep:  1\n",
      "new state [301.1429  300.54578 291.95978 300.3471  265.6819   66.48869  51.24108\n",
      "  90.80584]\n",
      "reward:  -1.3915852871727379\n",
      "timestep:  2\n",
      "new state [591.7      591.7      591.7      591.7      591.7       36.281258\n",
      "  42.12271   60.868942]\n",
      "reward:  -0.4165611219123238\n",
      "\n",
      "env reset!\n",
      "starting_state [591.7      591.7      591.7      591.7      591.7       32.55566\n",
      "  46.56073   91.459564]\n",
      "timestep:  0\n",
      "new state [464.18787  463.98895  463.99164  463.91565  420.81308   37.598133\n",
      "  47.071373  76.60106 ]\n",
      "reward:  -0.11702572421636115\n",
      "timestep:  1\n",
      "new state [339.8301   339.75464  343.03625  339.71866  380.59424   18.218185\n",
      "  14.086759  17.411419]\n",
      "reward:  -0.22726272548061646\n",
      "timestep:  2\n",
      "new state [333.8      333.8      333.8      333.8      333.8       28.786629\n",
      "  46.826946  29.502718]\n",
      "reward:  -0.08948051369958976\n",
      "\n",
      "env reset!\n",
      "starting_state [333.8      333.8      333.8      333.8      333.8       39.51248\n",
      "  50.263527 141.13283 ]\n",
      "timestep:  0\n",
      "new state [288.0804   287.71503  282.67377  287.59247  259.73233   35.394726\n",
      "  60.797546  69.90704 ]\n",
      "reward:  -1.4107595706584717\n",
      "timestep:  1\n",
      "new state [249.88095  249.91823  251.2775   249.92941  223.01869   30.988016\n",
      "  41.87631   13.387293]\n",
      "reward:  -1.3490474457374628\n",
      "timestep:  2\n",
      "new state [477.8     477.8     477.8     477.8     477.8      29.97029  79.58301\n",
      "  71.92901]\n",
      "reward:  -0.014047130813138657\n",
      "\n",
      "env reset!\n",
      "starting_state [477.8      477.8      477.8      477.8      477.8       29.97012\n",
      "  47.961544  19.105997]\n",
      "timestep:  0\n",
      "new state [387.25168   389.43768   419.72766   390.16483   442.07083    44.03313\n",
      "  61.8908      7.9277773]\n",
      "reward:  -0.017526868105600692\n",
      "timestep:  1\n",
      "new state [274.89487 280.23016 352.82236 282.0087  427.2087   71.95437  68.23424\n",
      " 121.90351]\n",
      "reward:  0.011604015162109146\n",
      "timestep:  2\n",
      "new state [714.6      714.6      714.6      714.6      714.6       71.721085\n",
      "  91.92644  256.4721  ]\n",
      "reward:  -0.8020820298736845\n",
      "\n",
      "env reset!\n",
      "starting_state [714.6      714.6      714.6      714.6      714.6       83.69408\n",
      "  66.76063   30.913458]\n",
      "timestep:  0\n",
      "new state [555.0001   556.5199   572.9747   557.0398   656.7781    87.388596\n",
      "  86.80331  148.7227  ]\n",
      "reward:  -0.04467061183737809\n",
      "timestep:  1\n",
      "new state [308.39313  309.3158   318.65167  309.6357   378.8755    41.848778\n",
      "  51.709995  63.689907]\n",
      "reward:  -0.10786236701891508\n",
      "timestep:  2\n",
      "new state [473.3      473.3      473.3      473.3      473.3       11.666571\n",
      "   8.46677   26.66461 ]\n",
      "reward:  -0.08578224432578326\n",
      "\n",
      "env reset!\n",
      "starting_state [473.3      473.3      473.3      473.3      473.3       31.897774\n",
      "  30.293598  37.71321 ]\n",
      "timestep:  0\n",
      "new state [393.39532  393.5699   395.618    393.62958  402.82025   30.410604\n",
      "  61.84637   54.497173]\n",
      "reward:  -0.08831177383947877\n",
      "timestep:  1\n",
      "new state [267.62555  269.9886   304.5926   270.76993  300.97284   29.187922\n",
      "  46.02662   71.41302 ]\n",
      "reward:  -0.058720578636545825\n",
      "timestep:  2\n",
      "new state [275.8      275.8      275.8      275.8      275.8        7.706619\n",
      "  10.654398  12.997147]\n",
      "reward:  -0.22664757498717797\n",
      "\n",
      "env reset!\n",
      "starting_state [275.8      275.8      275.8      275.8      275.8        9.147536\n",
      "   7.465553  25.64343 ]\n",
      "timestep:  0\n",
      "new state [267.6509   267.53085  265.75827  267.4908   262.34195   11.42402\n",
      "  11.975187  20.14769 ]\n",
      "reward:  -1.4201529518094653\n",
      "timestep:  1\n",
      "new state [234.28952  234.11923  231.86613  234.06212  251.76299   58.717133\n",
      "  62.244896 162.72615 ]\n",
      "reward:  -0.22652220389375266\n",
      "timestep:  2\n",
      "new state [479.1      479.1      479.1      479.1      479.1       61.003307\n",
      "  43.146927  54.689846]\n",
      "reward:  -1.4052787733376382\n",
      "\n",
      "env reset!\n",
      "starting_state [479.1       479.1       479.1       479.1       479.1         7.744819\n",
      "   3.7875311   7.7758455]\n",
      "timestep:  0\n",
      "new state [464.7484    464.553     461.5028    464.4892    464.56888     7.655129\n",
      "   7.8068266  21.566545 ]\n",
      "reward:  -0.11776015246798123\n",
      "timestep:  1\n",
      "new state [438.56293   438.07275   431.41953   437.90976   424.27463    12.829673\n",
      "  14.9739895   1.       ]\n",
      "reward:  -0.13836716146381134\n",
      "timestep:  2\n",
      "new state [94.1      94.1      94.1      94.1      94.1       5.184535  6.589685\n",
      "  8.542588]\n",
      "reward:  0.01052296956336653\n",
      "\n",
      "env reset!\n",
      "starting_state [94.1       94.1       94.1       94.1       94.1        6.7454433\n",
      "  8.724924  24.011929 ]\n",
      "timestep:  0\n",
      "new state [86.25751  86.198685 85.392685 86.17895  81.498245  9.141403 12.27315\n",
      " 11.689247]\n",
      "reward:  -1.4095464667252051\n",
      "timestep:  1\n",
      "new state [78.47835  78.49856  78.90867  78.50519  75.35664  37.538708 51.112934\n",
      " 36.43125 ]\n",
      "reward:  -1.3387822313030502\n",
      "timestep:  2\n",
      "new state [319.4      319.4      319.4      319.4      319.4       40.22966\n",
      "  46.932587  55.57324 ]\n",
      "reward:  -1.3212405725951426\n",
      "\n",
      "env reset!\n",
      "starting_state [319.4      319.4      319.4      319.4      319.4       26.7644\n",
      "  23.814106  28.514479]\n",
      "timestep:  0\n",
      "new state [301.5816   301.60437  301.87772  301.6124   304.41916   32.317825\n",
      "  40.683517  88.29138 ]\n",
      "reward:  -1.3567314227385294\n",
      "timestep:  1\n",
      "new state [268.24097  268.15067  266.98148  268.12067  258.0747    13.293848\n",
      "  11.490452  14.483939]\n",
      "reward:  -1.393764736813683\n",
      "timestep:  2\n",
      "new state [204.5       204.5       204.5       204.5       204.5         6.953627\n",
      "   4.6202626  11.862257 ]\n",
      "reward:  -0.08973074176793583\n",
      "\n",
      "env reset!\n",
      "starting_state [204.5      204.5      204.5      204.5      204.5       30.500729\n",
      "  49.106117  36.047768]\n",
      "timestep:  0\n",
      "new state [176.18665  176.63945  183.61482  176.7903   185.5535    44.25565\n",
      "  55.641575  82.57135 ]\n",
      "reward:  -1.3201048262006985\n",
      "timestep:  1\n",
      "new state [136.07352  136.64493  145.60196  136.83524  142.19571   39.81807\n",
      "  55.147755  89.94631 ]\n",
      "reward:  -1.3681737328219135\n",
      "timestep:  2\n",
      "new state [594.3      594.3      594.3      594.3      594.3       39.69959\n",
      "  48.491627  27.505339]\n",
      "reward:  -1.374365754013537\n",
      "\n",
      "env reset!\n",
      "starting_state [594.3      594.3      594.3      594.3      594.3        9.560337\n",
      "  18.160345  16.280468]\n",
      "timestep:  0\n",
      "new state [556.7569   557.3702   566.4634   557.5725   563.874     12.147562\n",
      "  12.095174  11.091602]\n",
      "reward:  -0.060657217788388625\n",
      "timestep:  1\n",
      "new state [527.307     528.1295    539.8692    528.40234   543.1427     10.6206045\n",
      "  17.326115   40.010418 ]\n",
      "reward:  -0.07024646276130336\n",
      "timestep:  2\n",
      "new state [151.8       151.8       151.8       151.8       151.8         7.2141314\n",
      "   7.1654654  17.336367 ]\n",
      "reward:  -0.12848107348616875\n",
      "\n",
      "env reset!\n",
      "starting_state [151.8      151.8      151.8      151.8      151.8       25.72831\n",
      "  15.967594  60.49054 ]\n",
      "timestep:  0\n",
      "new state [132.27142  131.91357  126.525444 131.79451  120.052475  35.91849\n",
      "  36.95268   83.62861 ]\n",
      "reward:  -1.4231174609472679\n",
      "timestep:  1\n",
      "new state [100.12359   99.5739    91.442245  99.39086   76.15367   67.79835\n",
      "  27.307924 127.137474]\n",
      "reward:  -1.3959333281521282\n",
      "timestep:  2\n",
      "new state [530.6      530.6      530.6      530.6      530.6       47.492477\n",
      "  61.085274  29.563437]\n",
      "reward:  -1.428565168588702\n",
      "\n",
      "env reset!\n",
      "starting_state [530.6      530.6      530.6      530.6      530.6       13.346056\n",
      "  25.30514   28.181671]\n",
      "timestep:  0\n",
      "new state [475.47745  476.1649   486.75488  476.39062  477.937     22.105148\n",
      "  25.031742  45.86107 ]\n",
      "reward:  -0.07590519306272528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  1\n",
      "new state [405.16583 405.69376 414.88867 405.86462 392.2445   78.61618  69.34076\n",
      "   7.90992]\n",
      "reward:  -0.11215937978440917\n",
      "timestep:  2\n",
      "new state [567.2      567.2      567.2      567.2      567.2       48.755356\n",
      "  71.0898   147.91473 ]\n",
      "reward:  -0.009883126728084933\n",
      "\n",
      "env reset!\n",
      "starting_state [567.2     567.2     567.2     567.2     567.2      47.41181  67.01342\n",
      "  21.97061]\n",
      "timestep:  0\n",
      "new state [438.94492  441.95862  482.88086  442.96356  526.1015    39.510483\n",
      "  69.15841   52.063046]\n",
      "reward:  -0.013424524089683141\n",
      "timestep:  1\n",
      "new state [298.69992  304.2469   381.75403  306.09036  428.79288   66.06673\n",
      "  58.279484  79.13802 ]\n",
      "reward:  -0.05018645761071643\n",
      "timestep:  2\n",
      "new state [573.4      573.4      573.4      573.4      573.4       55.864265\n",
      "  61.33183   25.775007]\n",
      "reward:  -0.09394105856485205\n",
      "\n",
      "env reset!\n",
      "starting_state [573.4      573.4      573.4      573.4      573.4       52.335735\n",
      "  46.926376 107.326164]\n",
      "timestep:  0\n",
      "new state [422.60504  421.29852  404.40305  420.8619   372.864     35.69795\n",
      "  90.65388  117.951805]\n",
      "reward:  -0.12593240170293718\n",
      "timestep:  1\n",
      "new state [225.55566  226.59947  248.20197  226.92786  310.93628   65.96802\n",
      "  45.721138 153.445   ]\n",
      "reward:  -0.21107090419624103\n",
      "timestep:  2\n",
      "new state [504.1      504.1      504.1      504.1      504.1        4.81735\n",
      "   7.943556   8.392993]\n",
      "reward:  -1.4174001075040588\n",
      "\n",
      "env reset!\n",
      "starting_state [504.1      504.1      504.1      504.1      504.1        8.592334\n",
      "  14.370525   8.916034]\n",
      "timestep:  0\n",
      "new state [475.63846   476.20972   484.30765   476.39923   487.4333      7.1535673\n",
      "   6.5900536  12.893903 ]\n",
      "reward:  -0.03924432425375864\n",
      "timestep:  1\n",
      "new state [455.7144   456.1746   462.83148  456.32706  463.34048   15.133276\n",
      "  19.83358   46.44049 ]\n",
      "reward:  -0.11623344545607005\n",
      "timestep:  2\n",
      "new state [301.       301.       301.       301.       301.        58.405956\n",
      "  79.06392  141.05545 ]\n",
      "reward:  -0.12877592924555642\n",
      "\n",
      "env reset!\n",
      "starting_state [301.       301.       301.       301.       301.        42.817184\n",
      "  60.221004  84.10041 ]\n",
      "timestep:  0\n",
      "new state [259.40436  259.62042  263.14536  259.69217  256.83865   61.794315\n",
      "  60.08196  114.665794]\n",
      "reward:  -1.3636501325176187\n",
      "timestep:  1\n",
      "new state [209.49406  209.51762  210.237    209.52554  196.63666   19.934015\n",
      "  47.369335 108.25264 ]\n",
      "reward:  -1.3849069314539035\n",
      "timestep:  2\n",
      "new state [360.5       360.5       360.5       360.5       360.5         7.5678234\n",
      "  10.192354    9.068209 ]\n",
      "reward:  -1.3987979775039086\n",
      "\n",
      "env reset!\n",
      "starting_state [360.5      360.5      360.5      360.5      360.5       42.87333\n",
      "  66.921486  82.45471 ]\n",
      "timestep:  0\n",
      "new state [316.84317  317.20844  323.04013  317.3298   317.19843   45.661537\n",
      "  60.69222   67.66721 ]\n",
      "reward:  -1.3544910112459534\n",
      "timestep:  1\n",
      "new state [276.85904  277.53995  288.2868   277.76654  281.65448   48.340683\n",
      "  76.10849  134.067   ]\n",
      "reward:  -1.348940441932607\n",
      "timestep:  2\n",
      "new state [669.9      669.9      669.9      669.9      669.9       79.683304\n",
      "  60.88607  108.98051 ]\n",
      "reward:  -1.379627356057747\n",
      "\n",
      "env reset!\n",
      "starting_state [669.9      669.9      669.9      669.9      669.9       33.390385\n",
      "  16.668211  62.076927]\n",
      "timestep:  0\n",
      "new state [593.1144    591.4345    567.9337    590.87744   553.9147     34.57143\n",
      "  36.346233   12.9542265]\n",
      "reward:  -0.1496206878686842\n",
      "timestep:  1\n",
      "new state [516.4072   516.03674  509.25934  515.91956  529.6806    49.942066\n",
      "  47.464767 126.4234  ]\n",
      "reward:  -0.026637929423027302\n",
      "timestep:  2\n",
      "new state [336.6       336.6       336.6       336.6       336.6        10.6723585\n",
      "  11.126039   20.23257  ]\n",
      "reward:  -0.13569974742171875\n",
      "\n",
      "env reset!\n",
      "starting_state [336.6      336.6      336.6      336.6      336.6       39.741768\n",
      "  41.22235    7.326497]\n",
      "timestep:  0\n",
      "new state [313.18314  313.5887   319.50583  313.72473  332.71686   44.275276\n",
      "  41.285793  75.66797 ]\n",
      "reward:  -1.2790396872968282\n",
      "timestep:  1\n",
      "new state [278.9585   279.2364   283.25272  279.33017  292.987     52.866043\n",
      " 112.38886  127.82566 ]\n",
      "reward:  -1.3823264808310782\n",
      "timestep:  2\n",
      "new state [558.5      558.5      558.5      558.5      558.5       22.954668\n",
      "  38.80809   79.71137 ]\n",
      "reward:  -1.3468569297066273\n",
      "\n",
      "env reset!\n",
      "starting_state [558.5       558.5       558.5       558.5       558.5         8.8545\n",
      "   1.7924875   8.052737 ]\n",
      "timestep:  0\n",
      "new state [545.61      545.2131    539.148     545.08295   543.4521      5.609539\n",
      "   7.5100718   4.0235605]\n",
      "reward:  -0.14592470207182312\n",
      "timestep:  1\n",
      "new state [530.22253  530.1063   527.87024  530.06976  535.9295    46.625374\n",
      "  40.536503  65.2993  ]\n",
      "reward:  -0.03628463649611379\n",
      "timestep:  2\n",
      "new state [454.4     454.4     454.4     454.4     454.4      75.72425  94.26665\n",
      "  65.86504]\n",
      "reward:  -0.1042352126220415\n",
      "\n",
      "env reset!\n",
      "starting_state [454.4      454.4      454.4      454.4      454.4       16.239038\n",
      "  26.541824  42.66182 ]\n",
      "timestep:  0\n",
      "new state [388.25592  388.50616  393.401    388.58557  374.68588   18.141928\n",
      "   6.920915  28.72264 ]\n",
      "reward:  -0.10289562433848867\n",
      "timestep:  1\n",
      "new state [351.6802   351.00186  342.57626  350.7743   321.01917   20.395384\n",
      "  17.43484   28.010838]\n",
      "reward:  -0.1518473487925243\n",
      "timestep:  2\n",
      "new state [292.1     292.1     292.1     292.1     292.1      52.04399  50.57515\n",
      "  69.5221 ]\n",
      "reward:  -0.10411163838440113\n",
      "\n",
      "env reset!\n",
      "starting_state [292.1     292.1     292.1     292.1     292.1      44.41743  53.63957\n",
      "  93.22526]\n",
      "timestep:  0\n",
      "new state [251.10231  251.1017   251.30992  251.10138  243.15526   53.171635\n",
      "  53.811844  17.529573]\n",
      "reward:  -1.3788285890102345\n",
      "timestep:  1\n",
      "new state [219.11714  219.57616  226.46968  219.73009  233.90768   47.94509\n",
      "  68.326935 282.14127 ]\n",
      "reward:  -1.2952654353045805\n",
      "timestep:  2\n",
      "new state [488.4      488.4      488.4      488.4      488.4        4.852373\n",
      "   7.818657  14.302141]\n",
      "reward:  -1.4350428875993027\n",
      "\n",
      "env reset!\n",
      "starting_state [488.4     488.4     488.4     488.4     488.4      51.2192   74.98765\n",
      " 128.39836]\n",
      "timestep:  0\n",
      "new state [293.54065  293.8324   301.6397   293.91974  420.99323   56.98157\n",
      "  41.377167  90.498856]\n",
      "reward:  -0.23815990829117056\n",
      "timestep:  1\n",
      "new state [254.49716  254.43185  256.7437   254.40097  373.4783    55.79515\n",
      "  55.610283  71.368744]\n",
      "reward:  -1.3926536209252902\n",
      "timestep:  2\n",
      "new state [623.4      623.4      623.4      623.4      623.4       65.011894\n",
      "  39.646076 116.480385]\n",
      "reward:  -1.127673015165654\n",
      "\n",
      "env reset!\n",
      "starting_state [623.4      623.4      623.4      623.4      623.4       32.77385\n",
      "  47.948257  49.64708 ]\n",
      "timestep:  0\n",
      "new state [515.26495  516.43274  533.6146   516.8187   530.6184    31.615828\n",
      "  55.26149   69.23797 ]\n",
      "reward:  -0.07304788893326018\n",
      "timestep:  1\n",
      "new state [389.13477   391.489     427.48645   392.2632    401.23773     7.408211\n",
      "   5.7085104   5.003377 ]\n",
      "reward:  -0.08484200112808911\n",
      "timestep:  2\n",
      "new state [442.8      442.8      442.8      442.8      442.8       40.825855\n",
      "  86.69175  119.6945  ]\n",
      "reward:  -0.07179947098319171\n",
      "\n",
      "env reset!\n",
      "starting_state [442.8      442.8      442.8      442.8      442.8       43.107773\n",
      "  72.889244  96.54523 ]\n",
      "timestep:  0\n",
      "new state [395.02908 395.4139  296.1406  395.5415  392.10498  59.03257  76.00735\n",
      " 186.46773]\n",
      "reward:  -1.022600508014619\n",
      "timestep:  1\n",
      "new state [329.92303 329.95557 225.97433 329.96484 294.237    46.40552  60.88712\n",
      "  69.12301]\n",
      "reward:  -1.4019995613468839\n",
      "timestep:  2\n",
      "new state [552.8      552.8      552.8      552.8      552.8       35.454304\n",
      "  45.711605  91.2795  ]\n",
      "reward:  -0.34914901940974\n",
      "\n",
      "env reset!\n",
      "starting_state [552.8      552.8      552.8      552.8      552.8       10.137753\n",
      "  15.071907  24.344309]\n",
      "timestep:  0\n",
      "new state [514.4948   514.6029   516.81213  514.637    507.31198   16.575438\n",
      "  20.421974  11.437711]\n",
      "reward:  -0.10339341226673317\n",
      "timestep:  1\n",
      "new state [471.4124   472.22485  483.90137  472.49426  485.92773   50.849857\n",
      "  33.050377  35.747803]\n",
      "reward:  -0.04048020681266772\n",
      "timestep:  2\n",
      "new state [267.1       267.1       267.1       267.1       267.1         5.3387046\n",
      "   6.8743305  10.026472 ]\n",
      "reward:  -0.08429076678576088\n",
      "\n",
      "env reset!\n",
      "starting_state [267.1      267.1      267.1      267.1      267.1       34.193443\n",
      "  31.744572  41.337948]\n",
      "timestep:  0\n",
      "new state [243.17844  243.19954  243.46185  243.20702  245.3857    40.95963\n",
      "  25.543276  84.976944]\n",
      "reward:  -1.3613306196365542\n",
      "timestep:  1\n",
      "new state [213.67741  213.21252  206.1118   213.05847  200.78288    7.120119\n",
      "  11.146607  21.087925]\n",
      "reward:  -1.4159394094048388\n",
      "timestep:  2\n",
      "new state [204.        204.        204.        204.        204.          5.396743\n",
      "   6.1037455   5.957112 ]\n",
      "reward:  -0.25332283612756323\n",
      "\n",
      "env reset!\n",
      "starting_state [204.       204.       204.       204.       204.         9.975209\n",
      "  13.237509  11.401019]\n",
      "timestep:  0\n",
      "new state [195.75922   195.85197   197.26996   195.88293   198.00867     7.8532887\n",
      "   8.1733885  12.701206 ]\n",
      "reward:  -1.3327450484307988\n",
      "timestep:  1\n",
      "new state [189.5022   189.59497  191.02283  189.62599  191.339      8.361709\n",
      "   9.827693  14.049187]\n",
      "reward:  -1.3717454363477701\n",
      "timestep:  2\n",
      "new state [237.8      237.8      237.8      237.8      237.8       32.564133\n",
      "  44.00888   19.04667 ]\n",
      "reward:  -0.2086781873061841\n",
      "\n",
      "env reset!\n",
      "starting_state [237.8       237.8       237.8       237.8       237.8         7.13509\n",
      "   7.0053797   8.972207 ]\n",
      "timestep:  0\n",
      "new state [232.62836   232.63814   232.77899   232.64146   233.0871      6.7450175\n",
      "  10.266819    8.89521  ]\n",
      "reward:  -1.3599666319750203\n",
      "timestep:  1\n",
      "new state [226.43633  226.52742  227.92523  226.55783  228.41315   29.480658\n",
      "  62.709015  28.188992]\n",
      "reward:  -1.3312521096213434\n",
      "timestep:  2\n",
      "new state [216.3      216.3      216.3      216.3      216.3        8.49617\n",
      "   9.870622  19.917051]\n",
      "reward:  -1.0251583776403954\n",
      "\n",
      "env reset!\n",
      "starting_state [216.3      216.3      216.3      216.3      216.3       43.553753\n",
      "  51.018826   1.      ]\n",
      "timestep:  0\n",
      "new state [189.65546  190.27063  199.35544  190.47653  215.72823   28.891655\n",
      "  43.605488  66.644516]\n",
      "reward:  -1.2529946436466866\n",
      "timestep:  1\n",
      "new state [159.14963  159.9008   171.28772  160.1517   180.7376     6.440929\n",
      "  11.940363  19.323053]\n",
      "reward:  -1.369674881583499\n",
      "timestep:  2\n",
      "new state [357.5      357.5      357.5      357.5      357.5       42.459766\n",
      "  47.76331   81.45516 ]\n",
      "reward:  -1.0298611461726583\n",
      "\n",
      "env reset!\n",
      "starting_state [357.5       357.5       357.5       357.5       357.5         6.072765\n",
      "   8.961958    7.5151615]\n",
      "timestep:  0\n",
      "new state [338.22403   338.49744   342.4027    338.5881    353.55084     6.4800186\n",
      "   7.7414865  16.02442  ]\n",
      "reward:  -0.1457909294209959\n",
      "timestep:  1\n",
      "new state [315.81042  315.9906   318.97656  316.04935  323.60995    8.881566\n",
      "  12.235224   1.      ]\n",
      "reward:  -0.12030735552663492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  2\n",
      "new state [323.9      323.9      323.9      323.9      323.9       75.30197\n",
      "  49.787437 157.8408  ]\n",
      "reward:  0.017225488049293775\n",
      "\n",
      "env reset!\n",
      "starting_state [323.9      323.9      323.9      323.9      323.9       48.901306\n",
      "  35.69111   80.94333 ]\n",
      "timestep:  0\n",
      "new state [289.85925  289.53305  284.5347   289.42496  281.40372   75.08307\n",
      "  35.721703 140.8654  ]\n",
      "reward:  -1.3948178775140627\n",
      "timestep:  1\n",
      "new state [241.7153   240.37653  219.87427  239.93217  207.46582   49.725544\n",
      "  55.137745  53.014866]\n",
      "reward:  -1.4222650794874656\n",
      "timestep:  2\n",
      "new state [457.3       457.3       457.3       457.3       457.3        11.368492\n",
      "   9.109175    3.2090178]\n",
      "reward:  -1.341686529550217\n",
      "\n",
      "env reset!\n",
      "starting_state [457.3      457.3      457.3      457.3      457.3       35.169315\n",
      "  48.360188 143.0966  ]\n",
      "timestep:  0\n",
      "new state [299.42203  297.71484  407.33575  297.13458  382.2055    43.604095\n",
      "  53.093307  87.836815]\n",
      "reward:  -0.5031091136593624\n",
      "timestep:  1\n",
      "new state [259.55634  257.8839   267.97418  257.3152   336.08762   12.554457\n",
      "  15.851812  31.110483]\n",
      "reward:  -1.0080242961202852\n",
      "timestep:  2\n",
      "new state [267.4       267.4       267.4       267.4       267.4         5.4419436\n",
      "   8.997729   11.274322 ]\n",
      "reward:  -0.11682543993019302\n",
      "\n",
      "env reset!\n",
      "starting_state [267.4      267.4      267.4      267.4      267.4       72.91635\n",
      "  81.09839   65.628204]\n",
      "timestep:  0\n",
      "new state [215.05708 215.53958 222.72836 215.70126 232.90164  51.48809  77.73339\n",
      " 161.97849]\n",
      "reward:  -1.331844426226993\n",
      "timestep:  1\n",
      "new state [154.46283  154.87836  161.6916   155.01666  147.88094   25.859259\n",
      "  24.853472 117.73947 ]\n",
      "reward:  -1.3913757098202966\n",
      "timestep:  2\n",
      "new state [563.6      563.6      563.6      563.6      563.6       48.089382\n",
      "  51.59186   55.553387]\n",
      "reward:  -1.4396336779353571\n",
      "\n",
      "env reset!\n",
      "starting_state [563.6      563.6      563.6      563.6      563.6       15.902522\n",
      "  15.575613  42.808907]\n",
      "timestep:  0\n",
      "new state [510.99744  510.39505  502.92773  510.19266  483.61676   14.022411\n",
      "  28.343363  17.737574]\n",
      "reward:  -0.13782090961647034\n",
      "timestep:  1\n",
      "new state [456.96997  457.5867   467.71176  457.78778  450.4616    44.991974\n",
      "  64.075874 106.55253 ]\n",
      "reward:  -0.03626087412927663\n",
      "timestep:  2\n",
      "new state [285.7      285.7      285.7      285.7      285.7       14.01077\n",
      "  18.93984   42.794197]\n",
      "reward:  -0.10548234755654046\n",
      "\n",
      "env reset!\n",
      "starting_state [285.7      285.7      285.7      285.7      285.7       78.967766\n",
      "  92.62216  157.21219 ]\n",
      "timestep:  0\n",
      "new state [214.9754  214.97903 215.35703 214.9802  203.15799  71.12784 156.0503\n",
      " 254.4975 ]\n",
      "reward:  -1.3772759694255388\n",
      "timestep:  1\n",
      "new state [110.23659  110.92937  123.1781   111.157364  69.563     29.900322\n",
      "  34.581482  75.42273 ]\n",
      "reward:  -1.3737440283267417\n",
      "timestep:  2\n",
      "new state [594.       594.       594.       594.       594.        22.101727\n",
      "  24.940092  45.279736]\n",
      "reward:  -1.3938785513136873\n",
      "\n",
      "env reset!\n",
      "starting_state [594.       594.       594.       594.       594.        21.276386\n",
      "  29.381393  66.78958 ]\n",
      "timestep:  0\n",
      "new state [508.3798   507.95532  504.124    507.80884  469.21106   33.637905\n",
      "  35.926395  60.168987]\n",
      "reward:  -0.12694486909419203\n",
      "timestep:  1\n",
      "new state [408.90765  408.36188  403.55685  408.17377  356.78       9.708793\n",
      "  12.176678  21.292076]\n",
      "reward:  -0.10632209601815067\n",
      "timestep:  2\n",
      "new state [393.1      393.1      393.1      393.1      393.1       58.966087\n",
      "  73.504585  49.87436 ]\n",
      "reward:  -0.10903075075065792\n",
      "\n",
      "env reset!\n",
      "starting_state [393.1      393.1      393.1      393.1      393.1       45.40345\n",
      "  33.925877  82.01129 ]\n",
      "timestep:  0\n",
      "new state [360.23798  359.90216  354.80164  359.79074  350.04623   33.562126\n",
      "  72.61967   71.638824]\n",
      "reward:  -1.3987172878333347\n",
      "timestep:  1\n",
      "new state [318.13763   318.4535    243.83466   318.55847   312.4193      6.9421844\n",
      "  15.354708   18.528416 ]\n",
      "reward:  -1.0322944596467878\n",
      "timestep:  2\n",
      "new state [464.       464.       464.       464.       464.        41.18397\n",
      "  93.436844 197.89563 ]\n",
      "reward:  -0.08084815007066916\n",
      "\n",
      "env reset!\n",
      "starting_state [464.        464.        464.        464.        464.          8.760305\n",
      "   5.5812435   1.5295761]\n",
      "timestep:  0\n",
      "new state [449.8752    449.9757    450.73624   450.01108   461.13556     7.0143614\n",
      "   6.200111   10.581147 ]\n",
      "reward:  -0.03870469140159631\n",
      "timestep:  1\n",
      "new state [431.70474  431.73822  431.56277  431.7515   441.36325   29.950949\n",
      "  68.60144  108.1626  ]\n",
      "reward:  -0.10773272107059947\n",
      "timestep:  2\n",
      "new state [472.9      472.9      472.9      472.9      472.9      102.919235\n",
      "  66.252045 135.50792 ]\n",
      "reward:  -0.10095128421135965\n",
      "\n",
      "env reset!\n",
      "starting_state [472.9      472.9      472.9      472.9      472.9       33.60332\n",
      "  57.009018  56.126793]\n",
      "timestep:  0\n",
      "new state [349.81238  351.46658  376.06396  352.0123   443.41675   36.321156\n",
      "  32.097343  22.286491]\n",
      "reward:  -0.1673395459942394\n",
      "timestep:  1\n",
      "new state [272.2373   274.5275   306.49207  275.28943  401.75116   19.484802\n",
      "  21.746786  21.200073]\n",
      "reward:  -0.0582581075514257\n",
      "timestep:  2\n",
      "new state [221.7       221.7       221.7       221.7       221.7         9.273838\n",
      "   7.4962244   6.80624  ]\n",
      "reward:  -0.07223405644924247\n",
      "\n",
      "env reset!\n",
      "starting_state [221.7      221.7      221.7      221.7      221.7       18.730669\n",
      "  12.072046  12.40901 ]\n",
      "timestep:  0\n",
      "new state [211.88416  211.85963  211.36362  211.85193  215.1762    14.357786\n",
      "  11.766319  30.252405]\n",
      "reward:  -1.352148673691313\n",
      "timestep:  1\n",
      "new state [200.51634  200.37605  198.15115  200.32985  199.29605    5.742756\n",
      "   8.286935   8.829516]\n",
      "reward:  -1.4029061081115617\n",
      "timestep:  2\n",
      "new state [170.       170.       170.       170.       170.        14.507949\n",
      "  18.000618  64.7807  ]\n",
      "reward:  -0.07506128399425059\n",
      "\n",
      "env reset!\n",
      "starting_state [170.        170.        170.        170.        170.          5.2659383\n",
      "   8.845427    8.063645 ]\n",
      "timestep:  0\n",
      "new state [164.72147  164.794    165.92487  164.81815  165.76364    5.69863\n",
      "   7.238175  16.642036]\n",
      "reward:  -1.3333493202170217\n",
      "timestep:  1\n",
      "new state [158.66592  158.71216  159.49783  158.72746  157.0286    26.489044\n",
      "  44.003128  91.44425 ]\n",
      "reward:  -1.3976460395995716\n",
      "timestep:  2\n",
      "new state [312.5      312.5      312.5      312.5      312.5       49.409008\n",
      "  50.888496  74.72257 ]\n",
      "reward:  -1.3913465688015756\n",
      "\n",
      "env reset!\n",
      "starting_state [312.5      312.5      312.5      312.5      312.5       42.88406\n",
      "  63.042206 135.53072 ]\n",
      "timestep:  0\n",
      "new state [262.52277  262.42752  261.5057   262.39493  241.36253   46.853836\n",
      "  54.501648  81.48021 ]\n",
      "reward:  -1.3934801398486942\n",
      "timestep:  1\n",
      "new state [222.41338  222.39554  222.77751  222.38885  198.5763    53.78755\n",
      "  52.087612  18.043081]\n",
      "reward:  -1.368914818552423\n",
      "timestep:  2\n",
      "new state [640.9      640.9      640.9      640.9      640.9       82.173065\n",
      " 134.53383   57.94256 ]\n",
      "reward:  -0.9606367977002843\n",
      "\n",
      "env reset!\n",
      "starting_state [640.9      640.9      640.9      640.9      640.9       59.432037\n",
      "  85.04154   81.5292  ]\n",
      "timestep:  0\n",
      "new state [451.44952  453.67493  485.85443  454.41196  488.53043   33.977608\n",
      "  73.60994   60.90982 ]\n",
      "reward:  -0.06827931293191607\n",
      "timestep:  1\n",
      "new state [305.4217   310.44498  384.1313   312.10483  374.69647   32.893726\n",
      "  32.738102  51.507683]\n",
      "reward:  -0.05363825293046667\n",
      "timestep:  2\n",
      "new state [358.7      358.7      358.7      358.7      358.7       17.141262\n",
      "  32.127758  15.155621]\n",
      "reward:  -0.10246114592407717\n",
      "\n",
      "env reset!\n",
      "starting_state [358.7      358.7      358.7      358.7      358.7       16.917152\n",
      "  15.609214  16.31908 ]\n",
      "timestep:  0\n",
      "new state [318.74908   318.91724   320.86707   318.97458   350.12454    10.1829605\n",
      "  11.311356    8.105378 ]\n",
      "reward:  -0.1650653254222046\n",
      "timestep:  1\n",
      "new state [293.23883  293.7103   299.66324  293.86923  334.97287   37.911407\n",
      "  57.753685 119.89824 ]\n",
      "reward:  -0.0551608762190533\n",
      "timestep:  2\n",
      "new state [443.6      443.6      443.6      443.6      443.6       84.632385\n",
      "  66.2095   149.5492  ]\n",
      "reward:  -0.2650666210508189\n",
      "\n",
      "env reset!\n",
      "starting_state [443.6      443.6      443.6      443.6      443.6        8.648337\n",
      "  10.505556   9.598814]\n",
      "timestep:  0\n",
      "new state [419.4602   419.70612  423.10962  419.78802  425.65976    8.534402\n",
      "   9.458114  12.112463]\n",
      "reward:  -0.06731453093651349\n",
      "timestep:  1\n",
      "new state [395.40573 395.74316 400.47644 395.8555  403.02457  67.76523  98.37852\n",
      " 188.71396]\n",
      "reward:  -0.08899113483548368\n",
      "timestep:  2\n",
      "new state [398.8      398.8      398.8      398.8      398.8       36.08509\n",
      "  39.236446  37.480347]\n",
      "reward:  -1.0205665765589462\n",
      "\n",
      "env reset!\n",
      "starting_state [398.8      398.8      398.8      398.8      398.8       53.609783\n",
      "  69.15142   93.68984 ]\n",
      "timestep:  0\n",
      "new state [350.52347 350.74857 354.3666  350.82355 349.5992   48.09443  85.16225\n",
      " 178.50134]\n",
      "reward:  -1.3619874137589874\n",
      "timestep:  1\n",
      "new state [285.7237  285.94968 290.41193 286.0234  255.91042  37.23455  54.19108\n",
      "  84.4289 ]\n",
      "reward:  -1.3920559573061515\n",
      "timestep:  2\n",
      "new state [576.5      576.5      576.5      576.5      576.5       27.206663\n",
      "  41.536083   5.398255]\n",
      "reward:  -0.22531706867457504\n",
      "\n",
      "env reset!\n",
      "starting_state [576.5      576.5      576.5      576.5      576.5       39.51871\n",
      "  62.034103 173.62975 ]\n",
      "timestep:  0\n",
      "new state [383.20346  381.49957  364.24634  380.91602  485.38217   70.727875\n",
      "  63.94251   93.313   ]\n",
      "reward:  -0.30483310596538615\n",
      "timestep:  1\n",
      "new state [333.18542  331.4338   313.3621   330.8352   311.0052    35.703125\n",
      "  48.16002   61.922764]\n",
      "reward:  -1.1247956672478796\n",
      "timestep:  2\n",
      "new state [568.2      568.2      568.2      568.2      568.2       53.196083\n",
      "   9.91678   89.91135 ]\n",
      "reward:  -0.08806959110297252\n",
      "\n",
      "env reset!\n",
      "starting_state [568.2     568.2     568.2     568.2     568.2      36.24253  64.35823\n",
      "  59.30623]\n",
      "timestep:  0\n",
      "new state [432.5692   434.61554  464.8802   435.29095  457.36508   43.5855\n",
      "  49.650078  51.289314]\n",
      "reward:  -0.06327011633482485\n",
      "timestep:  1\n",
      "new state [313.44724  316.38638  358.95212  317.35962  361.50952   34.74719\n",
      "  43.892017  81.34888 ]\n",
      "reward:  -0.07545928644097162\n",
      "timestep:  2\n",
      "new state [563.4     563.4     563.4     563.4     563.4      88.398    97.89396\n",
      " 199.51474]\n",
      "reward:  -0.11296067812250736\n",
      "\n",
      "env reset!\n",
      "starting_state [563.4      563.4      563.4      563.4      563.4       19.60891\n",
      "  10.847639  22.760033]\n",
      "timestep:  0\n",
      "new state [523.97015   523.481     516.037     523.3208    520.86884     8.09595\n",
      "  18.542501    7.0146136]\n",
      "reward:  -0.11925039589270088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  1\n",
      "new state [491.76053  492.2436   498.65274  492.40555  507.75214    5.648247\n",
      "  11.647231  20.138252]\n",
      "reward:  -0.005274255797191212\n",
      "timestep:  2\n",
      "new state [113.3       113.3       113.3       113.3       113.3         9.192139\n",
      "   9.424058    9.3811455]\n",
      "reward:  -0.10797518501231433\n",
      "\n",
      "env reset!\n",
      "starting_state [113.3      113.3      113.3      113.3      113.3        9.077349\n",
      "   5.139045  17.247025]\n",
      "timestep:  0\n",
      "new state [107.16837   107.061295  105.42705   107.025734  104.247       6.418506\n",
      "   6.6911726   5.971604 ]\n",
      "reward:  -1.4155026952121057\n",
      "timestep:  1\n",
      "new state [102.685555 102.61034  101.4454   102.58548  101.1084    74.924\n",
      "  49.702732  99.698296]\n",
      "reward:  -1.338267014256519\n",
      "timestep:  2\n",
      "new state [506.3      506.3      506.3      506.3      506.3       67.775085\n",
      "  74.19544   67.98529 ]\n",
      "reward:  -1.3873755467625568\n",
      "\n",
      "env reset!\n",
      "starting_state [506.3      506.3      506.3      506.3      506.3       46.976486\n",
      "  42.63326   92.41359 ]\n",
      "timestep:  0\n",
      "new state [372.31396  371.30005  358.19342  370.96133  457.7852    48.35976\n",
      "  57.512817  76.2418  ]\n",
      "reward:  -0.25417323859872953\n",
      "timestep:  1\n",
      "new state [227.37181  226.95343  222.98825  226.8111   315.31183   39.86509\n",
      "  43.393986  62.079388]\n",
      "reward:  -0.09078714728510633\n",
      "timestep:  2\n",
      "new state [346.        346.        346.        346.        346.          3.2040584\n",
      "  11.306632    1.7282629]\n",
      "reward:  -1.1121766269817568\n",
      "\n",
      "env reset!\n",
      "starting_state [346.        346.        346.        346.        346.          4.8178806\n",
      "  13.26999    20.839603 ]\n",
      "timestep:  0\n",
      "new state [315.64572  315.89514  320.42053  315.9751   335.0608    11.012333\n",
      "  14.259009  30.54517 ]\n",
      "reward:  -0.2390959695236158\n",
      "timestep:  1\n",
      "new state [274.52908  274.60626  277.5808   274.62683  319.02753   43.476906\n",
      "  16.230469  74.36156 ]\n",
      "reward:  -0.26456861127064846\n",
      "timestep:  2\n",
      "new state [302.8      302.8      302.8      302.8      302.8        8.208014\n",
      "  10.970992  18.40127 ]\n",
      "reward:  -0.15647603141663405\n",
      "\n",
      "env reset!\n",
      "starting_state [302.8      302.8      302.8      302.8      302.8       17.698023\n",
      "  15.023893  33.569214]\n",
      "timestep:  0\n",
      "new state [289.1458   289.0405   287.46222  289.00552  285.1769    13.728886\n",
      "  19.553621  47.191288]\n",
      "reward:  -1.39447737731085\n",
      "timestep:  1\n",
      "new state [231.0942   230.6377   225.72566  230.48193  260.4089    67.167595\n",
      "  67.565704 131.93954 ]\n",
      "reward:  -0.28302715341086554\n",
      "timestep:  2\n",
      "new state [554.6      554.6      554.6      554.6      554.6       46.962765\n",
      "  73.49508  152.8346  ]\n",
      "reward:  -1.3864074525049654\n",
      "\n",
      "env reset!\n",
      "starting_state [554.6      554.6      554.6      554.6      554.6       42.640495\n",
      "  66.17611   12.99464 ]\n",
      "timestep:  0\n",
      "new state [435.48843  438.8664   484.94696  439.992    530.2714    42.420963\n",
      "  42.42093  149.11977 ]\n",
      "reward:  0.006536958515590095\n",
      "timestep:  1\n",
      "new state [276.37158   277.15417   291.17657   277.40698   452.01718     3.754453\n",
      "  10.728432    7.5455666]\n",
      "reward:  -0.31808993691529586\n",
      "timestep:  2\n",
      "new state [423.5      423.5      423.5      423.5      423.5       75.334785\n",
      "  48.09658   51.355785]\n",
      "reward:  -0.03888094905696258\n",
      "\n",
      "env reset!\n",
      "starting_state [423.5      423.5      423.5      423.5      423.5       46.966454\n",
      "  42.0583     1.      ]\n",
      "timestep:  0\n",
      "new state [336.63925  338.3468   358.9648   338.92392  421.58746   24.042208\n",
      "  38.755566  82.82533 ]\n",
      "reward:  0.0008800479005587665\n",
      "timestep:  1\n",
      "new state [229.38531 230.82597 250.68112 231.30653 378.115    37.9716   53.52433\n",
      "  59.40087]\n",
      "reward:  -0.2704433597718067\n",
      "timestep:  2\n",
      "new state [473.3      473.3      473.3      473.3      473.3       43.403957\n",
      "  54.507854 140.09032 ]\n",
      "reward:  -0.8463765970581723\n",
      "\n",
      "env reset!\n",
      "starting_state [473.3      473.3      473.3      473.3      473.3       10.125242\n",
      "  19.976053  45.815742]\n",
      "timestep:  0\n",
      "new state [418.12482  417.9679   417.70047  417.91055  387.70068   12.134896\n",
      "  19.819057  36.660152]\n",
      "reward:  -0.12847481255114607\n",
      "timestep:  1\n",
      "new state [366.2882    366.17245   367.74838   366.12543   319.2032      7.1837807\n",
      "   4.037506   11.16719  ]\n",
      "reward:  -0.11290602394394383\n",
      "timestep:  2\n",
      "new state [230.1      230.1      230.1      230.1      230.1       13.681161\n",
      "  47.303646  74.70519 ]\n",
      "reward:  -0.13453553013534678\n",
      "\n",
      "env reset!\n",
      "starting_state [230.1     230.1     230.1     230.1     230.1      51.68909  39.60568\n",
      " 123.81619]\n",
      "timestep:  0\n",
      "new state [187.96872  187.38834  178.73526  187.19513  165.11401   45.431866\n",
      "  30.204258 101.48318 ]\n",
      "reward:  -1.4141353055136887\n",
      "timestep:  1\n",
      "new state [153.56712   152.43442   135.46332   152.0575    111.84929    12.048583\n",
      "   5.3104997  10.341951 ]\n",
      "reward:  -1.4170884897521465\n",
      "timestep:  2\n",
      "new state [322.1      322.1      322.1      322.1      322.1       35.117516\n",
      "  45.045807  39.47191 ]\n",
      "reward:  -0.8818231639616633\n",
      "\n",
      "env reset!\n",
      "starting_state [322.1     322.1     322.1     322.1     322.1      37.10835  80.3216\n",
      "  50.47956]\n",
      "timestep:  0\n",
      "new state [279.67783  280.60492  294.99155  280.91333  295.56528   31.311005\n",
      "  68.57273   87.74197 ]\n",
      "reward:  -1.3055324520852443\n",
      "timestep:  1\n",
      "new state [237.1098   238.51192  260.60666  238.97765  249.49554   89.50899\n",
      " 101.893684  97.4443  ]\n",
      "reward:  -1.3554749602998675\n",
      "timestep:  2\n",
      "new state [645.7      645.7      645.7      645.7      645.7       40.498337\n",
      "  61.951805  56.39791 ]\n",
      "reward:  -1.3410402957475087\n",
      "\n",
      "env reset!\n",
      "starting_state [645.7      645.7      645.7      645.7      645.7       60.89885\n",
      "  93.65985   60.738705]\n",
      "timestep:  0\n",
      "new state [455.2069   458.68814  507.66757  459.84427  532.16223   36.809868\n",
      "  81.66664   84.302216]\n",
      "reward:  -0.04340644944554623\n",
      "timestep:  1\n",
      "new state [285.36584  291.4745   380.72302  293.49365  374.6256    36.449165\n",
      "  73.52696   85.32822 ]\n",
      "reward:  -0.0692403449996614\n",
      "timestep:  2\n",
      "new state [651.5      651.5      651.5      651.5      651.5       56.152573\n",
      "  43.663044 101.74984 ]\n",
      "reward:  -0.3140981646317275\n",
      "\n",
      "env reset!\n",
      "starting_state [651.5      651.5      651.5      651.5      651.5       34.027843\n",
      "  53.530132  50.63875 ]\n",
      "timestep:  0\n",
      "new state [535.1216   536.6552   559.10724  537.1622   556.86255   54.052227\n",
      "  38.05183   64.70092 ]\n",
      "reward:  -0.06635166074196511\n",
      "timestep:  1\n",
      "new state [415.50336 416.26794 426.75232 416.52414 435.95453  35.20498  65.63593\n",
      " 217.53984]\n",
      "reward:  -0.10777400789874272\n",
      "timestep:  2\n",
      "new state [525.6      525.6      525.6      525.6      525.6       51.899887\n",
      "  42.987217 131.81314 ]\n",
      "reward:  -0.3301139421708428\n",
      "\n",
      "env reset!\n",
      "starting_state [525.6       525.6       525.6       525.6       525.6         3.5835872\n",
      "  11.536039   10.604113 ]\n",
      "timestep:  0\n",
      "new state [503.4785   503.9427   511.04868  504.09515  505.7838     2.740631\n",
      "   6.006493  13.085949]\n",
      "reward:  -0.05764257893415436\n",
      "timestep:  1\n",
      "new state [487.46567  487.91364  495.37308  488.05914  481.33475   16.922613\n",
      "  61.15739  110.63368 ]\n",
      "reward:  -0.12500336002901127\n",
      "timestep:  2\n",
      "new state [254.9      254.9      254.9      254.9      254.9       20.224886\n",
      "  33.344955  48.69424 ]\n",
      "reward:  -0.11132358370840971\n",
      "\n",
      "env reset!\n",
      "starting_state [254.9      254.9      254.9      254.9      254.9        9.672476\n",
      "   9.099977  15.319438]\n",
      "timestep:  0\n",
      "new state [247.57008  247.55254  247.28882  247.54677  246.85571    8.313873\n",
      "   8.112054  17.591297]\n",
      "reward:  -1.3769986355634083\n",
      "timestep:  1\n",
      "new state [222.53888  222.3489   219.94695  222.2853   237.62103   22.84295\n",
      "  36.160473  29.250187]\n",
      "reward:  -0.25684990335335167\n",
      "timestep:  2\n",
      "new state [178.4      178.4      178.4      178.4      178.4       19.509071\n",
      "  20.405401  34.33713 ]\n",
      "reward:  -0.056196271914487034\n",
      "\n",
      "env reset!\n",
      "starting_state [178.4     178.4     178.4     178.4     178.4      68.18494 106.23563\n",
      " 141.49883]\n",
      "timestep:  0\n",
      "new state [107.54329  108.04587  116.1821   108.21269  104.09806   60.389053\n",
      " 108.39385  105.72108 ]\n",
      "reward:  -1.3599247527356837\n",
      "timestep:  1\n",
      "new state [42.72872   44.11149   66.0678    44.57094   48.564022  38.870117\n",
      " 60.651524   4.2691054]\n",
      "reward:  -1.3372201986933412\n",
      "timestep:  2\n",
      "new state [629.8      629.8      629.8      629.8      629.8       39.511646\n",
      "  72.20736   86.31831 ]\n",
      "reward:  -1.2448210562497468\n",
      "\n",
      "env reset!\n",
      "starting_state [629.8      629.8      629.8      629.8      629.8       23.630016\n",
      "  53.624878 165.23486 ]\n",
      "timestep:  0\n",
      "new state [462.88745  461.30566  446.73978  460.75955  543.09735   57.01018\n",
      "  60.347954 107.4253  ]\n",
      "reward:  -0.32573462601386577\n",
      "timestep:  1\n",
      "new state [292.192   290.19736 271.31552 289.51117 342.36713  58.90677  73.86163\n",
      " 113.98376]\n",
      "reward:  -0.11027835451963702\n",
      "timestep:  2\n",
      "new state [451.5      451.5      451.5      451.5      451.5        5.199422\n",
      "   8.999567  11.531258]\n",
      "reward:  -1.3708034940214269\n",
      "\n",
      "env reset!\n",
      "starting_state [451.5      451.5      451.5      451.5      451.5       35.979908\n",
      "  42.256226  71.03247 ]\n",
      "timestep:  0\n",
      "new state [337.04736  337.01566  337.82837  337.0023   414.20505   39.213387\n",
      "  42.958088  71.78563 ]\n",
      "reward:  -0.22975026342141788\n",
      "timestep:  1\n",
      "new state [218.94069   218.80223   219.08932   218.75148   376.51312     7.3372307\n",
      "   7.7558074  12.387713 ]\n",
      "reward:  -0.22695985604094232\n",
      "timestep:  2\n",
      "new state [299.8      299.8      299.8      299.8      299.8       22.23724\n",
      "  38.209564  38.80978 ]\n",
      "reward:  -0.10328129642971598\n",
      "\n",
      "env reset!\n",
      "starting_state [299.8     299.8     299.8     299.8     299.8      67.93089  80.40699\n",
      " 217.3624 ]\n",
      "timestep:  0\n",
      "new state [226.88698  226.31631  218.35004  226.12521  185.72142   75.81123\n",
      "  60.455784  25.882843]\n",
      "reward:  -1.4079608255617813\n",
      "timestep:  1\n",
      "new state [186.7062   186.44952  182.71458  186.36494  172.07799   46.51531\n",
      "  46.771637  80.83141 ]\n",
      "reward:  -1.3122411301942543\n",
      "timestep:  2\n",
      "new state [467.4       467.4       467.4       467.4       467.4         7.8861012\n",
      "   4.584201   12.7137   ]\n",
      "reward:  -1.3785877095466428\n",
      "\n",
      "env reset!\n",
      "starting_state [467.4      467.4      467.4      467.4      467.4       52.81623\n",
      "  35.049046  93.748856]\n",
      "timestep:  0\n",
      "new state [337.61523  335.77292  310.16876  335.1619   418.18573   38.648792\n",
      "  47.95612  114.60722 ]\n",
      "reward:  -0.26755162704195745\n",
      "timestep:  1\n",
      "new state [296.68246  294.62592  266.13712  293.94302  358.03207   62.887608\n",
      "  68.63606   48.027397]\n",
      "reward:  -1.4001320007457478\n",
      "timestep:  2\n",
      "new state [394.6       394.6       394.6       394.6       394.6         4.983289\n",
      "   9.993295    1.9410572]\n",
      "reward:  -0.05427762827066033\n",
      "\n",
      "env reset!\n",
      "starting_state [394.6      394.6      394.6      394.6      394.6       15.260735\n",
      "  11.482609  66.36949 ]\n",
      "timestep:  0\n",
      "new state [335.5019   333.88715  313.2631   333.3458   359.7765    23.294195\n",
      "  24.174845  30.15373 ]\n",
      "reward:  -0.36189111812251973\n",
      "timestep:  1\n",
      "new state [273.32178   271.91626   254.14462   271.44504   303.4253      7.01128\n",
      "   7.566665    7.6300273]\n",
      "reward:  -0.0877889159492248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  2\n",
      "new state [308.7      308.7      308.7      308.7      308.7       49.596004\n",
      "  27.82501   10.060733]\n",
      "reward:  -0.07462422724580198\n",
      "\n",
      "env reset!\n",
      "starting_state [308.7      308.7      308.7      308.7      308.7       41.31072\n",
      "  52.407177  95.68648 ]\n",
      "timestep:  0\n",
      "new state [268.41696  268.40387  268.47168  268.39926  258.46655   31.152412\n",
      "  69.70468  113.64171 ]\n",
      "reward:  -1.3821339149958904\n",
      "timestep:  1\n",
      "new state [221.76675  222.06784  227.54352  222.16664  198.81218   11.565746\n",
      "  19.625528  35.917618]\n",
      "reward:  -1.3736967431131257\n",
      "timestep:  2\n",
      "new state [288.7      288.7      288.7      288.7      288.7       20.998123\n",
      "  27.793528  59.579525]\n",
      "reward:  -0.250834290562425\n",
      "\n",
      "env reset!\n",
      "starting_state [288.7      288.7      288.7      288.7      288.7       52.72184\n",
      "  55.522614  90.40519 ]\n",
      "timestep:  0\n",
      "new state [245.73233  245.70908  245.45064  245.7016   241.22928   45.581596\n",
      "  79.116684  74.49585 ]\n",
      "reward:  -1.3747107936184844\n",
      "timestep:  1\n",
      "new state [198.49472  199.11829  208.97765  199.32594  202.0946    20.003832\n",
      "  27.409702  59.636425]\n",
      "reward:  -1.3351574934667552\n",
      "timestep:  2\n",
      "new state [297.4      297.4      297.4      297.4      297.4       11.660681\n",
      "  12.539161  13.080906]\n",
      "reward:  -1.3941409765129966\n",
      "\n",
      "env reset!\n",
      "starting_state [297.4      297.4      297.4      297.4      297.4       61.309956\n",
      "  71.836784 122.0361  ]\n",
      "timestep:  0\n",
      "new state [242.51852  242.51997  242.79195  242.52042  233.3267    51.056732\n",
      "  85.04916  143.0995  ]\n",
      "reward:  -1.3773335667191375\n",
      "timestep:  1\n",
      "new state [182.23615  182.46085  186.72995  182.53467  158.20439   23.894533\n",
      "  40.218304  76.06905 ]\n",
      "reward:  -1.3763257915947862\n",
      "timestep:  2\n",
      "new state [718.4      718.4      718.4      718.4      718.4       54.537197\n",
      "  93.56043  141.97952 ]\n",
      "reward:  -1.384688571918658\n",
      "\n",
      "env reset!\n",
      "starting_state [718.4       718.4       718.4       718.4       718.4         4.5785327\n",
      "   9.066792   10.567382 ]\n",
      "timestep:  0\n",
      "new state [698.56305   698.8019    702.5362    698.8801    698.6532      5.7981653\n",
      "   6.592948   12.175989 ]\n",
      "reward:  -0.0789062293383899\n",
      "timestep:  1\n",
      "new state [680.0128    680.2075    683.5517    680.27057   675.90216     5.0177617\n",
      "   7.7672243   7.044707 ]\n",
      "reward:  -0.11268773879816296\n",
      "timestep:  2\n",
      "new state [207.6      207.6      207.6      207.6      207.6       58.870045\n",
      "  40.478016 112.15107 ]\n",
      "reward:  -0.06379120762809916\n",
      "\n",
      "env reset!\n",
      "starting_state [207.6      207.6      207.6      207.6      207.6       57.144665\n",
      " 110.01752   51.478374]\n",
      "timestep:  0\n",
      "new state [150.71849  152.05292  172.55595  152.49731  180.51653   33.188248\n",
      "  70.582565 142.22348 ]\n",
      "reward:  -1.2907199040948747\n",
      "timestep:  1\n",
      "new state [ 99.228546 100.67029  123.5612   101.14894  105.86984   95.10848\n",
      "  97.83995  135.98204 ]\n",
      "reward:  -1.3894599195240376\n",
      "timestep:  2\n",
      "new state [513.9      513.9      513.9      513.9      513.9        9.112249\n",
      "  11.465247  25.486578]\n",
      "reward:  -1.3647333213975772\n",
      "\n",
      "env reset!\n",
      "starting_state [513.9      513.9      513.9      513.9      513.9        8.970219\n",
      "   9.570055  15.914813]\n",
      "timestep:  0\n",
      "new state [487.45276  487.42352  487.20105  487.41348  484.1617    11.024592\n",
      "  15.763436  15.195174]\n",
      "reward:  -0.10586602893907145\n",
      "timestep:  1\n",
      "new state [452.28778  452.66827  458.37482  452.7939   455.76358   43.250664\n",
      "  50.57691   95.89465 ]\n",
      "reward:  -0.06863786722128026\n",
      "timestep:  2\n",
      "new state [405.6      405.6      405.6      405.6      405.6       77.499535\n",
      "  49.584866  76.46602 ]\n",
      "reward:  -0.11444306488870842\n",
      "\n",
      "env reset!\n",
      "starting_state [405.6       405.6       405.6       405.6       405.6         6.377598\n",
      "   6.05187     2.2457764]\n",
      "timestep:  0\n",
      "new state [392.31848   392.51318   394.90793   392.57892   401.39865     7.0513844\n",
      "   7.262021   23.258137 ]\n",
      "reward:  -0.031549313114458494\n",
      "timestep:  1\n",
      "new state [366.3892   366.21524  364.09625  366.15692  357.94507   10.442767\n",
      "  10.475312   8.356614]\n",
      "reward:  -0.14756213201984777\n",
      "timestep:  2\n",
      "new state [253.8      253.8      253.8      253.8      253.8       53.514565\n",
      "  42.384403 105.4081  ]\n",
      "reward:  -0.06264180640053266\n",
      "\n",
      "env reset!\n",
      "starting_state [253.8       253.8       253.8       253.8       253.8        28.961609\n",
      "  17.644724    5.6532435]\n",
      "timestep:  0\n",
      "new state [240.9197   240.95778  241.26883  240.97134  250.81163   50.59441\n",
      "  32.11641   36.165215]\n",
      "reward:  -1.3138865049723196\n",
      "timestep:  1\n",
      "new state [214.19246   214.13518   212.67416   214.11821   231.80199     6.5600696\n",
      "   6.290268   15.132929 ]\n",
      "reward:  -1.356683344487888\n",
      "timestep:  2\n",
      "new state [174.2       174.2       174.2       174.2       174.2         7.4560738\n",
      "   8.290605    1.       ]\n",
      "reward:  -0.12936859701112338\n",
      "\n",
      "env reset!\n",
      "starting_state [174.2      174.2      174.2      174.2      174.2       20.493513\n",
      "  20.03147   56.196392]\n",
      "timestep:  0\n",
      "new state [154.99568  154.80376  152.02112  154.7397   144.70529   21.836515\n",
      "  12.353683  43.92662 ]\n",
      "reward:  -1.4092702856916526\n",
      "timestep:  1\n",
      "new state [139.89752   139.43036   132.46054   139.27484   121.649124   13.963061\n",
      "   3.9526715  42.259834 ]\n",
      "reward:  -1.4186706695436002\n",
      "timestep:  2\n",
      "new state [330.6      330.6      330.6      330.6      330.6       58.317585\n",
      "  94.88584   52.729427]\n",
      "reward:  -1.4600019695933375\n",
      "\n",
      "env reset!\n",
      "starting_state [330.6      330.6      330.6      330.6      330.6       18.382423\n",
      "  27.60437   15.548024]\n",
      "timestep:  0\n",
      "new state [315.10483 315.381   291.48163 315.47314 322.42224   9.41874  17.17638\n",
      "  26.21136]\n",
      "reward:  -1.0031072716504927\n",
      "timestep:  1\n",
      "new state [273.82413  274.3407   254.7598   274.51007  308.66135   36.315716\n",
      "  62.315144 154.86093 ]\n",
      "reward:  -0.2275535349703532\n",
      "timestep:  2\n",
      "new state [348.7      348.7      348.7      348.7      348.7       24.402864\n",
      "  22.88881   21.793228]\n",
      "reward:  -1.403869157860315\n",
      "\n",
      "env reset!\n",
      "starting_state [348.7      348.7      348.7      348.7      348.7        5.652894\n",
      "   3.737667   8.455528]\n",
      "timestep:  0\n",
      "new state [335.62726  335.47678  333.31436  335.4271   344.26047    8.592444\n",
      "  11.411427   9.920372]\n",
      "reward:  -0.24685918374568241\n",
      "timestep:  1\n",
      "new state [310.26196  310.42047  312.6053   310.47348  325.71912   33.198223\n",
      "  36.86261   25.18001 ]\n",
      "reward:  -0.0631161082533344\n",
      "timestep:  2\n",
      "new state [343.8      343.8      343.8      343.8      343.8       37.02626\n",
      "  61.242004 106.02195 ]\n",
      "reward:  -0.0526965334742554\n",
      "\n",
      "env reset!\n",
      "starting_state [343.8      343.8      343.8      343.8      343.8       28.437876\n",
      "  51.52373   42.579025]\n",
      "timestep:  0\n",
      "new state [314.1519   314.62793  322.03766  314.78632  321.42773   37.663555\n",
      "  54.62608  151.71185 ]\n",
      "reward:  -1.3259244419336107\n",
      "timestep:  1\n",
      "new state [265.80646  265.94925  268.91943  265.9955   241.81024   24.213984\n",
      "  23.079662  28.369877]\n",
      "reward:  -1.4106717354934846\n",
      "timestep:  2\n",
      "new state [276.1      276.1      276.1      276.1      276.1        9.136531\n",
      "  12.523731  21.410742]\n",
      "reward:  -0.08753022242078494\n",
      "\n",
      "env reset!\n",
      "starting_state [276.1       276.1       276.1       276.1       276.1         4.23267\n",
      "   8.1589775  10.029881 ]\n",
      "timestep:  0\n",
      "new state [270.98828  271.04276  271.91925  271.06082  270.83325    6.454905\n",
      "  12.391931  10.147669]\n",
      "reward:  -1.3531282003704577\n",
      "timestep:  1\n",
      "new state [245.90988 246.4142  253.8965  246.58086 265.50146  68.53907 105.69028\n",
      " 138.0116 ]\n",
      "reward:  -0.14508076471189818\n",
      "timestep:  2\n",
      "new state [318.4       318.4       318.4       318.4       318.4         7.5205097\n",
      "   6.674473   10.792838 ]\n",
      "reward:  -1.358592956353344\n",
      "\n",
      "env reset!\n",
      "starting_state [318.4      318.4      318.4      318.4      318.4        5.227116\n",
      "   9.870747  18.93303 ]\n",
      "timestep:  0\n",
      "new state [292.85074  292.8779   294.01077  292.8849   308.46225    9.218391\n",
      "  11.55042   10.210646]\n",
      "reward:  -0.25973547585970885\n",
      "timestep:  1\n",
      "new state [266.7009  267.0184  272.1887  267.12204 289.37827  64.14982  65.71093\n",
      " 160.15898]\n",
      "reward:  -0.06492663352103054\n",
      "timestep:  2\n",
      "new state [290.6      290.6      290.6      290.6      290.6        7.823077\n",
      "   5.89086   13.417999]\n",
      "reward:  -1.4006603027485287\n",
      "\n",
      "env reset!\n",
      "starting_state [290.6      290.6      290.6      290.6      290.6       23.942022\n",
      "  61.929634  66.99105 ]\n",
      "timestep:  0\n",
      "new state [254.82472  255.38419  264.32855  255.56967  255.42093   52.322243\n",
      "  59.7715    36.9213  ]\n",
      "reward:  -1.3418684160734944\n",
      "timestep:  1\n",
      "new state [218.19122  219.20233  234.8662   219.53903  236.00003   15.413671\n",
      "  17.957012  19.642666]\n",
      "reward:  -1.317220139861733\n",
      "timestep:  2\n",
      "new state [491.9      491.9      491.9      491.9      491.9       52.8399\n",
      "  49.007084  89.82153 ]\n",
      "reward:  -0.07873497066479626\n",
      "\n",
      "env reset!\n",
      "starting_state [491.9      491.9      491.9      491.9      491.9       20.87825\n",
      "  10.530228  30.673359]\n",
      "timestep:  0\n",
      "new state [447.89032  447.09476  435.58496  446.83215  434.58615   11.344924\n",
      "  14.519432  32.227753]\n",
      "reward:  -0.13651029198266343\n",
      "timestep:  1\n",
      "new state [405.35342  404.3441   390.75677  404.00812  374.37146   58.592712\n",
      "  95.66263  123.06715 ]\n",
      "reward:  -0.12512946797549668\n",
      "timestep:  2\n",
      "new state [443.5      443.5      443.5      443.5      443.5       29.078756\n",
      "  30.836649 125.66759 ]\n",
      "reward:  -0.20205954103152043\n",
      "\n",
      "env reset!\n",
      "starting_state [443.5     443.5     443.5     443.5     443.5     117.20645  80.34187\n",
      " 127.63663]\n",
      "timestep:  0\n",
      "new state [373.24216  372.8291   366.07324  372.69373  376.4571    73.03942\n",
      "  62.509537  89.88461 ]\n",
      "reward:  -1.374182874971412\n",
      "timestep:  1\n",
      "new state [323.72418  323.23575  315.17938  323.0763   329.24573   40.296295\n",
      "  53.416073  80.118095]\n",
      "reward:  -1.3676642287544192\n",
      "timestep:  2\n",
      "new state [621.6      621.6      621.6      621.6      621.6       48.443268\n",
      "  59.809654  74.45893 ]\n",
      "reward:  -0.09854407598551494\n",
      "\n",
      "env reset!\n",
      "starting_state [621.6      621.6      621.6      621.6      621.6       20.759085\n",
      "  48.603493  10.883497]\n",
      "timestep:  0\n",
      "new state [541.3274   544.11804  583.51636  545.0439   601.2348    23.406046\n",
      "  40.41084   36.318703]\n",
      "reward:  0.017830671054526785\n",
      "timestep:  1\n",
      "new state [456.14618  460.22803  518.60315  461.5804   533.3592    25.797628\n",
      "  41.378555  67.28431 ]\n",
      "reward:  -0.061904193410093816\n",
      "timestep:  2\n",
      "new state [445.4      445.4      445.4      445.4      445.4       37.50318\n",
      "  46.522472  72.21837 ]\n",
      "reward:  -0.10374946889597075\n",
      "\n",
      "env reset!\n",
      "starting_state [445.4      445.4      445.4      445.4      445.4       35.997913\n",
      "  50.500515  33.465603]\n",
      "timestep:  0\n",
      "new state [339.96173 341.71222 366.03824 342.29456 382.84265  44.61839  39.17722\n",
      " 124.95083]\n",
      "reward:  -0.04640434659844258\n",
      "timestep:  1\n",
      "new state [299.2892   300.51187  317.08975  300.91818  317.2653     8.746069\n",
      "   8.905902  18.10315 ]\n",
      "reward:  -1.4163611635333826\n",
      "timestep:  2\n",
      "new state [225.2      225.2      225.2      225.2      225.2       18.012775\n",
      "  18.275724  23.856304]\n",
      "reward:  -0.11881849348383602\n",
      "\n",
      "env reset!\n",
      "starting_state [225.2       225.2       225.2       225.2       225.2         9.678753\n",
      "   6.1305666  15.506537 ]\n",
      "timestep:  0\n",
      "new state [218.85509   218.775     217.54019   218.74844   217.05907    14.747507\n",
      "  12.7448845  20.188892 ]\n",
      "reward:  -1.4004797164529126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  1\n",
      "new state [208.52097  208.41356  206.74391  208.3781   206.45645   13.55508\n",
      "  20.255032  35.263794]\n",
      "reward:  -1.3734185744302652\n",
      "timestep:  2\n",
      "new state [263.3      263.3      263.3      263.3      263.3       41.887405\n",
      "  62.40885  118.15421 ]\n",
      "reward:  -0.24092141695166666\n",
      "\n",
      "env reset!\n",
      "starting_state [263.3       263.3       263.3       263.3       263.3        11.28861\n",
      "  15.4703665  26.756807 ]\n",
      "timestep:  0\n",
      "new state [251.81221   251.82793   252.1512    251.83307   249.25293     7.3725243\n",
      "   8.209448    6.464558 ]\n",
      "reward:  -1.3784176898663283\n",
      "timestep:  1\n",
      "new state [233.01556  233.2344   236.25452  233.30754  245.85454   31.913866\n",
      "  60.579903  96.16475 ]\n",
      "reward:  -0.13612553396364313\n",
      "timestep:  2\n",
      "new state [366.2      366.2      366.2      366.2      366.2       37.437077\n",
      "  72.17125   80.789856]\n",
      "reward:  -1.3719348870457204\n",
      "\n",
      "env reset!\n",
      "starting_state [366.2      366.2      366.2      366.2      366.2       33.118614\n",
      "  43.576427  21.261703]\n",
      "timestep:  0\n",
      "new state [341.356   341.77524 301.89584 341.91528 355.0101   55.79978  75.79572\n",
      "  97.11128]\n",
      "reward:  -0.9911316022012506\n",
      "timestep:  1\n",
      "new state [289.8625   290.59756  255.7489   290.84274  304.0104    56.67799\n",
      "  35.558636 131.43857 ]\n",
      "reward:  -1.3579757039360167\n",
      "timestep:  2\n",
      "new state [493.5      493.5      493.5      493.5      493.5       19.104223\n",
      "  21.830187  31.898563]\n",
      "reward:  -0.5159514809302432\n",
      "\n",
      "env reset!\n",
      "starting_state [493.5      493.5      493.5      493.5      493.5       75.20923\n",
      "  56.516838  50.81548 ]\n",
      "timestep:  0\n",
      "new state [342.61914  343.01544  345.17804  343.15808  398.5103    55.725857\n",
      "  76.91471   86.83417 ]\n",
      "reward:  -0.0734233719886457\n",
      "timestep:  1\n",
      "new state [292.23892  293.04852  301.67908  293.32886  352.90033   37.662563\n",
      "  29.25563   84.01254 ]\n",
      "reward:  -1.3494452322153196\n",
      "timestep:  2\n",
      "new state [520.5      520.5      520.5      520.5      520.5       37.69594\n",
      "  69.98379   67.860855]\n",
      "reward:  -0.13903248795168635\n",
      "\n",
      "env reset!\n",
      "starting_state [520.5      520.5      520.5      520.5      520.5       27.057447\n",
      "  85.857895  73.049286]\n",
      "timestep:  0\n",
      "new state [358.55237  362.1722   417.04553  363.36243  383.98676   55.360832\n",
      "  46.170242  48.89015 ]\n",
      "reward:  -0.05181053060392735\n",
      "timestep:  1\n",
      "new state [236.09044  240.01245  297.3665   241.30905  292.6087    53.271904\n",
      "  48.278934  40.805588]\n",
      "reward:  -0.08034869210601364\n",
      "timestep:  2\n",
      "new state [472.       472.       472.       472.       472.         9.663223\n",
      "  12.337429  17.854826]\n",
      "reward:  -0.8529966288588262\n",
      "\n",
      "env reset!\n",
      "starting_state [472.       472.       472.       472.       472.        83.950066\n",
      "  73.77508  129.30031 ]\n",
      "timestep:  0\n",
      "new state [410.68533 410.45206 406.8766  410.37518 404.10443  73.37229 110.26625\n",
      "  65.2465 ]\n",
      "reward:  -1.3795575944064342\n",
      "timestep:  1\n",
      "new state [348.34924  349.1973   247.82443  349.48105  369.79147   27.074383\n",
      "  73.73301   64.33152 ]\n",
      "reward:  -1.0038018432372149\n",
      "timestep:  2\n",
      "new state [727.9     727.9     727.9     727.9     727.9      73.24871  82.78508\n",
      " 151.20374]\n",
      "reward:  -0.05507150194680483\n",
      "\n",
      "env reset!\n",
      "starting_state [727.9       727.9       727.9       727.9       727.9         5.9131155\n",
      "   4.203285   10.06228  ]\n",
      "timestep:  0\n",
      "new state [713.2495    713.07825   710.6931    713.0215    709.0985      6.363274\n",
      "   5.944884    6.7060013]\n",
      "reward:  -0.12771241871215655\n",
      "timestep:  1\n",
      "new state [697.8443   697.72485  695.94354  697.6858   696.5655    39.332012\n",
      "  60.89371   75.85275 ]\n",
      "reward:  -0.08267937087566742\n",
      "timestep:  2\n",
      "new state [496.9      496.9      496.9      496.9      496.9       63.87586\n",
      "  88.135025  28.49166 ]\n",
      "reward:  -0.08511358164755821\n",
      "\n",
      "env reset!\n",
      "starting_state [496.9       496.9       496.9       496.9       496.9         3.285375\n",
      "   4.4102817   8.239618 ]\n",
      "timestep:  0\n",
      "new state [484.88626   484.87354   484.91736   484.86877   481.50446     3.955265\n",
      "   5.0899377  12.8673525]\n",
      "reward:  -0.11352952379766262\n",
      "timestep:  1\n",
      "new state [469.19382  469.0594   467.7972   469.01318  457.4636    38.935055\n",
      "  54.17516   12.515893]\n",
      "reward:  -0.13379045149160276\n",
      "timestep:  2\n",
      "new state [340.5      340.5      340.5      340.5      340.5       56.902996\n",
      "  37.050056  75.11639 ]\n",
      "reward:  -0.0024435241356768997\n",
      "\n",
      "env reset!\n",
      "starting_state [340.5      340.5      340.5      340.5      340.5       57.523327\n",
      "  85.151634 216.79782 ]\n",
      "timestep:  0\n",
      "new state [268.22174  267.8551   263.17365  267.73145  226.72037   66.74836\n",
      "  50.117027 102.25382 ]\n",
      "reward:  -1.4049957769293793\n",
      "timestep:  1\n",
      "new state [222.46475   221.74072   211.53937   221.49887   173.03082     3.8319468\n",
      "  12.39549    12.854346 ]\n",
      "reward:  -1.388624222732139\n",
      "timestep:  2\n",
      "new state [407.2      407.2      407.2      407.2      407.2       41.882137\n",
      "  39.20108   12.969887]\n",
      "reward:  -0.18158677802966605\n",
      "\n",
      "env reset!\n",
      "starting_state [407.2      407.2      407.2      407.2      407.2       61.706684\n",
      "  85.55704  109.112495]\n",
      "timestep:  0\n",
      "new state [349.41473 349.7874  355.72833 349.91144 349.89798  72.93623 109.75057\n",
      " 147.65816]\n",
      "reward:  -1.3575468069956114\n",
      "timestep:  1\n",
      "new state [275.48     276.3368   290.12042  276.62152  272.3614    46.134903\n",
      "  54.12429   99.25242 ]\n",
      "reward:  -1.360785973096128\n",
      "timestep:  2\n",
      "new state [794.3     794.3     794.3     794.3     794.3      52.1105  117.81323\n",
      " 102.40379]\n",
      "reward:  -1.008134386104797\n",
      "\n",
      "env reset!\n",
      "starting_state [794.3      794.3      794.3      794.3      794.3        3.89895\n",
      "   9.664298  14.835396]\n",
      "timestep:  0\n",
      "new state [772.07544   772.2545    775.4549    772.3121    766.58057     6.561416\n",
      "   3.1944785  10.936631 ]\n",
      "reward:  -0.09878258155299682\n",
      "timestep:  1\n",
      "new state [757.72595   757.60675   756.57135   757.5656    746.14594    12.796289\n",
      "   9.432148    3.5240695]\n",
      "reward:  -0.14485389660905063\n",
      "timestep:  2\n",
      "new state [346.1      346.1      346.1      346.1      346.1       70.32473\n",
      "  25.046865  60.1807  ]\n",
      "reward:  -0.04059602477644433\n",
      "\n",
      "env reset!\n",
      "starting_state [346.1      346.1      346.1      346.1      346.1       15.420512\n",
      "  16.366308  24.298306]\n",
      "timestep:  0\n",
      "new state [302.29312  302.32883  302.99988  302.3405   333.3399    15.952059\n",
      "  16.984915  35.105927]\n",
      "reward:  -0.21084612063471433\n",
      "timestep:  1\n",
      "new state [251.84735  251.62256  249.30083  251.54623  314.91074    9.254173\n",
      "   9.422149  17.19211 ]\n",
      "reward:  -0.2536672987137706\n",
      "timestep:  2\n",
      "new state [376.6      376.6      376.6      376.6      376.6       53.86708\n",
      "  96.352806 215.69995 ]\n",
      "reward:  -0.1118751497586452\n",
      "\n",
      "env reset!\n",
      "starting_state [376.6      376.6      376.6      376.6      376.6       54.086872\n",
      "  73.05046   50.31956 ]\n",
      "timestep:  0\n",
      "new state [333.13788 333.74954 343.03983 333.95374 350.14432  41.91815  63.30721\n",
      " 184.81572]\n",
      "reward:  -1.3194701117949306\n",
      "timestep:  1\n",
      "new state [276.17578 276.35376 279.84924 276.41205 253.15771  61.34222  74.49697\n",
      " 100.05293]\n",
      "reward:  -1.414113399727229\n",
      "timestep:  2\n",
      "new state [636.2      636.2      636.2      636.2      636.2       58.62291\n",
      "  63.33896   67.319046]\n",
      "reward:  -1.3617100218066975\n",
      "\n",
      "env reset!\n",
      "starting_state [636.2     636.2     636.2     636.2     636.2      92.62877 123.22062\n",
      " 243.56802]\n",
      "timestep:  0\n",
      "new state [293.1352  292.3479  288.06845 292.06927 508.34308 104.73469 146.77966\n",
      "   1.     ]\n",
      "reward:  -0.2547446193211897\n",
      "timestep:  1\n",
      "new state [221.04327  222.24146  247.66757  222.62611  506.3493    41.638336\n",
      "  21.319794  73.203316]\n",
      "reward:  -1.2382159168552875\n",
      "timestep:  2\n",
      "new state [467.1      467.1      467.1      467.1      467.1        9.806706\n",
      "   9.496274  14.046153]\n",
      "reward:  -1.0958640284508439\n",
      "\n",
      "env reset!\n",
      "starting_state [467.1      467.1      467.1      467.1      467.1       41.482876\n",
      "  88.303444 131.87953 ]\n",
      "timestep:  0\n",
      "new state [409.32108  409.7859   290.3356   409.9394   397.8656    44.098515\n",
      "  85.35191  157.11702 ]\n",
      "reward:  -1.035256798747851\n",
      "timestep:  1\n",
      "new state [348.3696   349.0318   233.36185  349.2496   315.39456   43.414757\n",
      " 101.62746  183.9644  ]\n",
      "reward:  -1.3827828247619078\n",
      "timestep:  2\n",
      "new state [711.       711.       711.       711.       711.        45.482166\n",
      "  49.808247  77.601776]\n",
      "reward:  -1.381557472711176\n",
      "\n",
      "env reset!\n",
      "starting_state [711.        711.        711.        711.        711.          4.5880466\n",
      "   6.8367825   6.174641 ]\n",
      "timestep:  0\n",
      "new state [696.1042    696.30084   699.13965   696.366     699.46        4.289804\n",
      "   4.9536605  18.696096 ]\n",
      "reward:  -0.06398318602152604\n",
      "timestep:  1\n",
      "new state [677.36816  677.245    676.2387   677.2023   664.5309     9.119541\n",
      "   8.850144  17.177158]\n",
      "reward:  -0.1581961069859397\n",
      "timestep:  2\n",
      "new state [132.7      132.7      132.7      132.7      132.7       17.124409\n",
      "  23.252542  21.89141 ]\n",
      "reward:  -0.11578986834863961\n",
      "\n",
      "env reset!\n",
      "starting_state [132.7     132.7     132.7     132.7     132.7      47.94852  36.80733\n",
      " 126.8989 ]\n",
      "timestep:  0\n",
      "new state [ 91.86056   91.23721   81.981865  91.02955   66.10041   64.68349\n",
      "  88.64628  108.68382 ]\n",
      "reward:  -1.4198454071768762\n",
      "timestep:  1\n",
      "new state [ 32.46146   32.248245  29.478966  32.177147   9.020168  51.947823\n",
      "  58.184273 112.666374]\n",
      "reward:  -1.3549726003709528\n",
      "timestep:  2\n",
      "new state [673.4      673.4      673.4      673.4      673.4       41.7477\n",
      " 143.98477   16.539148]\n",
      "reward:  -1.9995247491783577\n",
      "\n",
      "env reset!\n",
      "starting_state [673.4       673.4       673.4       673.4       673.4         5.5809407\n",
      "   8.710138    6.851326 ]\n",
      "timestep:  0\n",
      "new state [655.13556  655.42566  659.5757   655.5218   660.59454    5.648735\n",
      "   8.916913   8.445515]\n",
      "reward:  -0.05465838853673093\n",
      "timestep:  1\n",
      "new state [635.7589   636.3048   644.2022   636.48553  644.811     17.561708\n",
      "  22.256811  29.074213]\n",
      "reward:  -0.06639337136113048\n",
      "timestep:  2\n",
      "new state [262.7      262.7      262.7      262.7      262.7       63.30445\n",
      "  62.452217 127.00237 ]\n",
      "reward:  -0.08947461116759385\n",
      "\n",
      "env reset!\n",
      "starting_state [262.7      262.7      262.7      262.7      262.7       31.882038\n",
      "  33.803192  55.134113]\n",
      "timestep:  0\n",
      "new state [236.57208  236.55939  236.42773  236.5553   233.74988   40.91576\n",
      "  62.745888 118.80581 ]\n",
      "reward:  -1.3748084262491644\n",
      "timestep:  1\n",
      "new state [189.5149   189.5401   190.45085  189.54788  171.38559   42.18849\n",
      "  54.767525  32.818913]\n",
      "reward:  -1.3847119136225885\n",
      "timestep:  2\n",
      "new state [516.3      516.3      516.3      516.3      516.3       77.679985\n",
      " 107.5607   154.96458 ]\n",
      "reward:  -1.3128207777882692\n",
      "\n",
      "env reset!\n",
      "starting_state [516.3      516.3      516.3      516.3      516.3       64.22522\n",
      "  52.925625 116.19393 ]\n",
      "timestep:  0\n",
      "new state [344.80637  343.30725  323.0941   342.80872  455.29886   51.544224\n",
      "  63.988945  99.59933 ]\n",
      "reward:  -0.25213643809157826\n",
      "timestep:  1\n",
      "new state [297.87177  296.46936  277.9469   296.003    403.00226   53.98272\n",
      "  87.643585 143.02893 ]\n",
      "reward:  -1.371403526665232\n",
      "timestep:  2\n",
      "new state [588.       588.       588.       588.       588.        31.257387\n",
      "  41.715717  66.54332 ]\n",
      "reward:  -1.3741733408264223\n",
      "\n",
      "env reset!\n",
      "starting_state [588.       588.       588.       588.       588.        21.961329\n",
      "  27.850466  32.40772 ]\n",
      "timestep:  0\n",
      "new state [521.19183  521.66504  528.6243   521.82166  527.43713   25.696592\n",
      "  17.372793  26.078936]\n",
      "reward:  -0.08191345935779175\n",
      "timestep:  1\n",
      "new state [467.57538  467.76843  469.98065  467.8349   478.6999    10.524293\n",
      "  28.115593 107.66389 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward:  -0.10091582437720789\n",
      "timestep:  2\n",
      "new state [343.3      343.3      343.3      343.3      343.3       18.386501\n",
      "  39.33978   50.860443]\n",
      "reward:  -0.16355426826473504\n",
      "\n",
      "env reset!\n",
      "starting_state [343.3      343.3      343.3      343.3      343.3       10.510422\n",
      "   8.959895  20.583656]\n",
      "timestep:  0\n",
      "new state [314.0747   313.8053   310.24802  313.71548  332.49432    8.499482\n",
      "   5.828298  14.759619]\n",
      "reward:  -0.2591731100004413\n",
      "timestep:  1\n",
      "new state [293.12592  292.58466  285.24426  292.40472  304.91605   38.588608\n",
      "  36.916855  28.731676]\n",
      "reward:  -0.13082161833628142\n",
      "timestep:  2\n",
      "new state [373.1      373.1      373.1      373.1      373.1       47.148235\n",
      "  38.63328   85.47568 ]\n",
      "reward:  -0.06221312006046286\n",
      "\n",
      "env reset!\n",
      "starting_state [373.1     373.1     373.1     373.1     373.1     101.98864  95.16695\n",
      "  64.32684]\n",
      "timestep:  0\n",
      "new state [310.07532 310.571   317.62976 310.73816 339.26263  75.12408 107.28938\n",
      " 100.2036 ]\n",
      "reward:  -1.3260265589315958\n",
      "timestep:  1\n",
      "new state [243.35625  244.6041   263.28497  245.02197  286.61563   12.218663\n",
      "  10.376433  16.048637]\n",
      "reward:  -1.3368156892859793\n",
      "timestep:  2\n",
      "new state [458.1      458.1      458.1      458.1      458.1       32.819954\n",
      "  27.335163  67.16096 ]\n",
      "reward:  -0.1018446234620832\n",
      "\n",
      "env reset!\n",
      "starting_state [458.1      458.1      458.1      458.1      458.1       14.186366\n",
      "  10.253393  25.420925]\n",
      "timestep:  0\n",
      "new state [422.09525  421.6589   415.648    421.51407  410.60126   11.315774\n",
      "  11.596023  15.859975]\n",
      "reward:  -0.1298644539251809\n",
      "timestep:  1\n",
      "new state [391.454    391.07108  385.82187  390.94415  380.9632    86.641014\n",
      "  88.8275    80.19458 ]\n",
      "reward:  -0.09356650074951839\n",
      "timestep:  2\n",
      "new state [324.2      324.2      324.2      324.2      324.2        8.222885\n",
      "   9.859234  15.006166]\n",
      "reward:  -0.06896616721336332\n",
      "\n",
      "env reset!\n",
      "starting_state [324.2      324.2      324.2      324.2      324.2       38.394894\n",
      "  88.88558  139.34015 ]\n",
      "timestep:  0\n",
      "new state [265.79285  266.24652  273.93915  266.39606  251.05386   46.15921\n",
      "  86.276245 132.79741 ]\n",
      "reward:  -1.3706826805250187\n",
      "timestep:  1\n",
      "new state [207.59735  208.42157  222.37701  208.69342  181.33673   33.476994\n",
      "  50.054485  66.27632 ]\n",
      "reward:  -1.369701376897485\n",
      "timestep:  2\n",
      "new state [796.3     796.3     796.3     796.3     796.3      96.69082 115.95339\n",
      " 225.6768 ]\n",
      "reward:  -1.359709723592359\n",
      "\n",
      "env reset!\n",
      "starting_state [796.3      796.3      796.3      796.3      796.3       53.358135\n",
      "  39.631744  37.793907]\n",
      "timestep:  0\n",
      "new state [688.9375   689.1295   689.4788   689.201    725.6541    54.07917\n",
      "  59.410973  96.28825 ]\n",
      "reward:  -0.0764506159256565\n",
      "timestep:  1\n",
      "new state [527.22925 527.3692  528.204   527.421   545.7299   68.82898  72.75336\n",
      "  51.34048]\n",
      "reward:  -0.10414864084482178\n",
      "timestep:  2\n",
      "new state [439.6      439.6      439.6      439.6      439.6        8.235048\n",
      "   6.769574  13.642383]\n",
      "reward:  -0.0553478953104034\n",
      "\n",
      "env reset!\n",
      "starting_state [439.6      439.6      439.6      439.6      439.6       24.99323\n",
      "  19.304762  52.84357 ]\n",
      "timestep:  0\n",
      "new state [370.56433   369.649     357.44333   369.3439    411.86194     7.6029677\n",
      "  21.218925   16.681393 ]\n",
      "reward:  -0.27709266506331404\n",
      "timestep:  1\n",
      "new state [330.55276 330.54318 331.88928 330.53644 380.68652  44.67073  99.16755\n",
      "  58.75831]\n",
      "reward:  -0.04715766284529926\n",
      "timestep:  2\n",
      "new state [364.3      364.3      364.3      364.3      364.3       11.45339\n",
      "  22.747179  41.27174 ]\n",
      "reward:  -0.03121847687172881\n",
      "\n",
      "env reset!\n",
      "starting_state [364.3      364.3      364.3      364.3      364.3       27.08266\n",
      "  51.075848  47.723213]\n",
      "timestep:  0\n",
      "new state [334.34695  334.79022  341.74484  334.93756  339.23056   34.824142\n",
      "  54.057438 145.25854 ]\n",
      "reward:  -1.3337635807479873\n",
      "timestep:  1\n",
      "new state [287.7174   287.8899   291.35864  287.9459   262.99945   63.98186\n",
      "  93.874794 135.20021 ]\n",
      "reward:  -1.4087831924640448\n",
      "timestep:  2\n",
      "new state [401.4      401.4      401.4      401.4      401.4        6.098319\n",
      "   4.772723   9.258717]\n",
      "reward:  -1.3656145453934527\n",
      "\n",
      "env reset!\n",
      "starting_state [401.4      401.4      401.4      401.4      401.4       29.316319\n",
      "  39.61586   49.1508  ]\n",
      "timestep:  0\n",
      "new state [306.25543  306.90002  316.75443  307.1122   375.58643   29.13105\n",
      "  61.092022  81.07897 ]\n",
      "reward:  -0.19352451165565648\n",
      "timestep:  1\n",
      "new state [267.65442  268.6892   284.90616  269.03058  333.0162    60.609123\n",
      "  63.15045   81.72035 ]\n",
      "reward:  -1.3583894762117001\n",
      "timestep:  2\n",
      "new state [503.3      503.3      503.3      503.3      503.3       34.764263\n",
      "  81.447266  73.64049 ]\n",
      "reward:  -1.1235959784021232\n",
      "\n",
      "env reset!\n",
      "starting_state [503.3      503.3      503.3      503.3      503.3       39.59024\n",
      "  37.397976  85.21637 ]\n",
      "timestep:  0\n",
      "new state [384.8682   383.90686  371.7769   383.58475  458.56635   59.188087\n",
      "  68.41645   83.03026 ]\n",
      "reward:  -0.2620158611695403\n",
      "timestep:  1\n",
      "new state [337.21283  336.48303  327.92734  336.23846  303.40118    9.236551\n",
      "   5.890423  10.723495]\n",
      "reward:  -1.1209600702183966\n",
      "timestep:  2\n",
      "new state [267.6       267.6       267.6       267.6       267.6         9.548276\n",
      "   5.9779587   7.4027944]\n",
      "reward:  -0.11167371098815669\n",
      "\n",
      "env reset!\n",
      "starting_state [267.6      267.6      267.6      267.6      267.6       17.689411\n",
      "  11.085096  20.981953]\n",
      "timestep:  0\n",
      "new state [257.10397  257.00787  255.47676  256.97623  256.58078   15.435555\n",
      "  17.394087  31.969809]\n",
      "reward:  -1.3840183097751453\n",
      "timestep:  1\n",
      "new state [243.34355  243.22464  241.41124  243.1854   239.79652    6.824006\n",
      "  12.543059  27.135523]\n",
      "reward:  -1.3825534791358483\n",
      "timestep:  2\n",
      "new state [114.5      114.5      114.5      114.5      114.5        7.27624\n",
      "   8.514111  10.751683]\n",
      "reward:  -0.12418242045791851\n",
      "\n",
      "env reset!\n",
      "starting_state [114.5      114.5      114.5      114.5      114.5       36.364445\n",
      "  46.98437   10.492073]\n",
      "timestep:  0\n",
      "new state [ 89.366165  89.90088   97.88805   90.07961  108.95534   32.431248\n",
      "  35.023155  49.899723]\n",
      "reward:  -1.2746952951030321\n",
      "timestep:  1\n",
      "new state [63.460953  64.040215  72.73958   64.23399   82.7497    13.806016\n",
      " 18.653427   3.6193054]\n",
      "reward:  -1.3660797043042292\n",
      "timestep:  2\n",
      "new state [339.2      339.2      339.2      339.2      339.2       39.384003\n",
      "  23.200354  65.963104]\n",
      "reward:  -1.2691731658772556\n",
      "\n",
      "env reset!\n",
      "starting_state [339.2      339.2      339.2      339.2      339.2       12.56045\n",
      "  21.951267  22.231857]\n",
      "timestep:  0\n",
      "new state [291.7731   292.40384  301.85892  292.6117   327.52237   20.333698\n",
      "  23.062817  37.561985]\n",
      "reward:  -0.17140392412618677\n",
      "timestep:  1\n",
      "new state [229.39877 230.02562 239.9784  230.23103 307.79977  51.63069  62.85173\n",
      "  95.64299]\n",
      "reward:  -0.22463018458376166\n",
      "timestep:  2\n",
      "new state [527.4      527.4      527.4      527.4      527.4       60.14454\n",
      "  99.68646  101.030846]\n",
      "reward:  -1.3699468594122888\n",
      "\n",
      "env reset!\n",
      "starting_state [527.4      527.4      527.4      527.4      527.4       28.766623\n",
      "  63.268185 124.21661 ]\n",
      "timestep:  0\n",
      "new state [365.7245   365.9692   374.87234  366.03546  462.2036    50.649708\n",
      "  52.236057 122.154495]\n",
      "reward:  -0.2662326531324177\n",
      "timestep:  1\n",
      "new state [319.73956  319.6861   324.32263  319.65286  398.08337   43.792885\n",
      "  26.55208    1.      ]\n",
      "reward:  -1.3980430739937104\n",
      "timestep:  2\n",
      "new state [565.5      565.5      565.5      565.5      565.5       38.850998\n",
      "  36.417805   1.      ]\n",
      "reward:  -0.022634744070630066\n",
      "\n",
      "env reset!\n",
      "starting_state [565.5      565.5      565.5      565.5      565.5       16.779213\n",
      "  11.785979  21.082573]\n",
      "timestep:  0\n",
      "new state [527.8928   527.6218   523.50165  527.53314  526.1033    10.199828\n",
      "  19.59361    9.868646]\n",
      "reward:  -0.11067584889400386\n",
      "timestep:  1\n",
      "new state [491.38086   492.00827   500.65912   492.21747   507.65366     5.8447986\n",
      "   8.5796175  11.765418 ]\n",
      "reward:  -0.024571940581598936\n",
      "timestep:  2\n",
      "new state [108.        108.        108.        108.        108.          7.6562033\n",
      "  10.891478    8.104808 ]\n",
      "reward:  -0.09203387886025204\n",
      "\n",
      "env reset!\n",
      "starting_state [108.       108.       108.       108.       108.        10.436405\n",
      "  11.924848  22.002163]\n",
      "timestep:  0\n",
      "new state [98.58452  98.5697   98.3913   98.56476  96.448906 22.179323 16.982635\n",
      " 25.267923]\n",
      "reward:  -1.382811745406517\n",
      "timestep:  1\n",
      "new state [84.52174  84.45741  83.45447  84.43634  83.17655   8.970692  8.636539\n",
      " 19.765734]\n",
      "reward:  -1.3701188730444076\n",
      "timestep:  2\n",
      "new state [259.7      259.7      259.7      259.7      259.7       52.912067\n",
      "  20.16191   28.24115 ]\n",
      "reward:  -1.3964186114299362\n",
      "\n",
      "env reset!\n",
      "starting_state [259.7      259.7      259.7      259.7      259.7       45.306343\n",
      "  61.14471   88.674446]\n",
      "timestep:  0\n",
      "new state [216.61101  216.78882  219.72635  216.8479   213.13792   44.86815\n",
      "  59.13619  104.924194]\n",
      "reward:  -1.366382799333955\n",
      "timestep:  1\n",
      "new state [171.9592   172.16127  175.7783   172.22809  158.05423   35.344025\n",
      "  23.99819   36.622818]\n",
      "reward:  -1.3801854542657896\n",
      "timestep:  2\n",
      "new state [508.6     508.6     508.6     508.6     508.6      46.59111  82.87959\n",
      " 135.54373]\n",
      "reward:  -1.3719874020641945\n",
      "\n",
      "env reset!\n",
      "starting_state [508.6      508.6      508.6      508.6      508.6        6.205319\n",
      "   9.300648  17.036728]\n",
      "timestep:  0\n",
      "new state [483.97745   483.9849    484.61978   483.986     476.7675      2.5169039\n",
      "  10.28949     8.901958 ]\n",
      "reward:  -0.11219852107702835\n",
      "timestep:  1\n",
      "new state [465.03653   465.4974    473.06943   465.6474    460.13214     4.0241184\n",
      "   3.438509    2.3160698]\n",
      "reward:  -0.05113955217045444\n",
      "timestep:  2\n",
      "new state [158.2      158.2      158.2      158.2      158.2       36.381714\n",
      "  50.08759   28.244116]\n",
      "reward:  -0.05761016951854947\n",
      "\n",
      "env reset!\n",
      "starting_state [158.2      158.2      158.2      158.2      158.2       26.407448\n",
      "  16.20041   12.233514]\n",
      "timestep:  0\n",
      "new state [145.39825  145.38452  144.96909  145.38068  151.76234   30.571407\n",
      "  36.41513   18.17623 ]\n",
      "reward:  -1.3396224802727112\n",
      "timestep:  1\n",
      "new state [123.97383  124.279045 128.61974  124.38191  142.1956    71.504036\n",
      "  97.90251  163.11281 ]\n",
      "reward:  -1.306154617266446\n",
      "timestep:  2\n",
      "new state [632.1      632.1      632.1      632.1      632.1       85.00664\n",
      "  49.54382   42.874012]\n",
      "reward:  -1.3758461442338152\n",
      "\n",
      "env reset!\n",
      "starting_state [632.1       632.1       632.1       632.1       632.1        10.489874\n",
      "  13.050293    1.7849479]\n",
      "timestep:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new state [607.45044  608.0711   616.25696  608.27875  628.7539     8.194466\n",
      "  13.246318  16.880304]\n",
      "reward:  0.004603328380927538\n",
      "timestep:  1\n",
      "new state [576.61224  577.4883   589.7241   577.77954  597.21063    8.282765\n",
      "   9.343883  10.975043]\n",
      "reward:  -0.08645997461943172\n",
      "timestep:  2\n",
      "new state [88.4      88.4      88.4      88.4      88.4       7.745594  7.176407\n",
      "  6.834895]\n",
      "reward:  -0.08343951042920396\n",
      "\n",
      "env reset!\n",
      "starting_state [88.4       88.4       88.4       88.4       88.4        9.646631\n",
      "  4.5748014 13.86835  ]\n",
      "timestep:  0\n",
      "new state [82.82854  82.72847  81.170944 82.69532  81.11908   7.150502 10.046663\n",
      " 16.76197 ]\n",
      "reward:  -1.4082917995634325\n",
      "timestep:  1\n",
      "new state [75.49433  75.41065  74.15643  75.3829   72.31899  10.249759 13.550874\n",
      " 43.51639 ]\n",
      "reward:  -1.375911872994358\n",
      "timestep:  2\n",
      "new state [220.       220.       220.       220.       220.        30.658995\n",
      "  24.893032  54.17347 ]\n",
      "reward:  -1.419485826559771\n",
      "\n",
      "env reset!\n",
      "starting_state [220.       220.       220.       220.       220.        13.196286\n",
      "  17.780426  16.578196]\n",
      "timestep:  0\n",
      "new state [208.79126   208.90878   210.7153    208.94798   211.28941    11.4358635\n",
      "  18.743681   27.334913 ]\n",
      "reward:  -1.3374117621134303\n",
      "timestep:  1\n",
      "new state [196.07256  196.26761  199.36115  196.33246  196.93744   26.137577\n",
      "  82.39925   71.503494]\n",
      "reward:  -1.3661337798361275\n",
      "timestep:  2\n",
      "new state [456.2      456.2      456.2      456.2      456.2       40.274456\n",
      "  47.60826   56.760155]\n",
      "reward:  -1.3235537964927417\n",
      "\n",
      "env reset!\n",
      "starting_state [456.2      456.2      456.2      456.2      456.2       59.82241\n",
      "  85.882     55.813496]\n",
      "timestep:  0\n",
      "new state [406.37115  407.1512   324.13107  407.41147  426.85355   78.22735\n",
      "  61.886433 130.034   ]\n",
      "reward:  -1.0017697094244973\n",
      "timestep:  1\n",
      "new state [350.20218  350.55518  261.0161   350.67395  358.58197   50.985306\n",
      "  66.80337  223.20316 ]\n",
      "reward:  -1.390511664672335\n",
      "timestep:  2\n",
      "new state [516.4       516.4       516.4       516.4       516.4         8.163467\n",
      "   5.8351316  11.795287 ]\n",
      "reward:  -1.4218916286049603\n",
      "\n",
      "env reset!\n",
      "starting_state [516.4      516.4      516.4      516.4      516.4       29.825026\n",
      "  32.781982  49.62298 ]\n",
      "timestep:  0\n",
      "new state [428.96417  429.04205  430.6374   429.0671   423.6725    41.308857\n",
      "  54.615284  52.681507]\n",
      "reward:  -0.09971935906589659\n",
      "timestep:  1\n",
      "new state [304.7853   306.17847  326.5172   306.64005  325.21494    7.195511\n",
      "   7.078414   9.410249]\n",
      "reward:  -0.06957346478375254\n",
      "timestep:  2\n",
      "new state [412.2      412.2      412.2      412.2      412.2       85.74529\n",
      "  60.292377 135.72963 ]\n",
      "reward:  -0.09204025452046222\n",
      "\n",
      "env reset!\n",
      "starting_state [412.2      412.2      412.2      412.2      412.2       36.132717\n",
      "  43.70706  126.582054]\n",
      "timestep:  0\n",
      "new state [371.51822  371.15536  366.08005  371.0338   345.76907   31.277657\n",
      "  61.211998  37.902855]\n",
      "reward:  -1.41247623978216\n",
      "timestep:  1\n",
      "new state [254.29977  256.54907  289.049    257.2924   325.84317   45.752937\n",
      " 104.93855  131.14943 ]\n",
      "reward:  -0.11150212175074056\n",
      "timestep:  2\n",
      "new state [566.1     566.1     566.1     566.1     566.1      42.18442  34.97069\n",
      "  90.92688]\n",
      "reward:  -1.353495148878326\n",
      "\n",
      "env reset!\n",
      "starting_state [566.1       566.1       566.1       566.1       566.1         7.4680643\n",
      "   3.575111   19.022127 ]\n",
      "timestep:  0\n",
      "new state [546.50354  545.9604   538.5979   545.77954  530.5609    10.686058\n",
      "   7.467669  18.518513]\n",
      "reward:  -0.16749848130856904\n",
      "timestep:  1\n",
      "new state [520.0142   519.1414   507.1965   518.85126  495.95908   47.531406\n",
      "  46.26605  139.86356 ]\n",
      "reward:  -0.12969853656511887\n",
      "timestep:  2\n",
      "new state [454.6      454.6      454.6      454.6      454.6       82.09983\n",
      "  64.70097   89.103966]\n",
      "reward:  -0.14366076001806463\n",
      "\n",
      "env reset!\n",
      "starting_state [454.6      454.6      454.6      454.6      454.6       52.061653\n",
      "  52.75246   43.59242 ]\n",
      "timestep:  0\n",
      "new state [329.27155  330.35922  344.22772  330.72522  373.11652   55.48459\n",
      " 101.083145  79.136215]\n",
      "reward:  -0.06433245420705164\n",
      "timestep:  1\n",
      "new state [271.80307  273.85922  302.77167  274.5475   331.53207   54.757347\n",
      "  59.088448 100.32448 ]\n",
      "reward:  -1.3223042031490744\n",
      "timestep:  2\n",
      "new state [587.9      587.9      587.9      587.9      587.9       37.253998\n",
      "  34.592457  80.636795]\n",
      "reward:  -1.0012861428591584\n",
      "\n",
      "env reset!\n",
      "starting_state [587.9      587.9      587.9      587.9      587.9       38.19759\n",
      "  60.128147 100.3493  ]\n",
      "timestep:  0\n",
      "new state [435.12314 435.5312  444.41904 435.6584  400.39737  64.81151  90.60811\n",
      " 127.76511]\n",
      "reward:  -0.10561964643620292\n",
      "timestep:  1\n",
      "new state [372.28055  373.00107  239.82361  373.23203  333.30814   36.44139\n",
      "  34.07788   40.509834]\n",
      "reward:  -1.0129455790578328\n",
      "timestep:  2\n",
      "new state [504.6      504.6      504.6      504.6      504.6       34.460728\n",
      "  77.61331   64.535904]\n",
      "reward:  -0.08571106130970461\n",
      "\n",
      "env reset!\n",
      "starting_state [504.6      504.6      504.6      504.6      504.6       64.09125\n",
      "  34.462917 114.78362 ]\n",
      "timestep:  0\n",
      "new state [356.4235   353.52475  312.87384  352.564    444.34787   18.004229\n",
      "  60.72966   99.35022 ]\n",
      "reward:  -0.2838005668068638\n",
      "timestep:  1\n",
      "new state [218.51031  315.10043  280.62454  314.25845  392.20032   42.594604\n",
      "  72.69792  136.13284 ]\n",
      "reward:  -0.8624331460229963\n",
      "timestep:  2\n",
      "new state [661.4      661.4      661.4      661.4      661.4       37.498142\n",
      "  39.021225  32.164284]\n",
      "reward:  -1.3839812267045095\n",
      "\n",
      "env reset!\n",
      "starting_state [661.4       661.4       661.4       661.4       661.4         6.2124577\n",
      "  12.030902   17.200745 ]\n",
      "timestep:  0\n",
      "new state [633.36145   633.57764   637.25885   633.64764   629.25977     8.822592\n",
      "   7.6110125   2.9511516]\n",
      "reward:  -0.09400352122661856\n",
      "timestep:  1\n",
      "new state [615.99457  616.42523  622.6103   616.568    623.7388    19.934557\n",
      "  40.915787  65.71326 ]\n",
      "reward:  -0.03625095041708912\n",
      "timestep:  2\n",
      "new state [215.3      215.3      215.3      215.3      215.3       14.84476\n",
      "  14.389273  48.144257]\n",
      "reward:  -0.10249715617435784\n",
      "\n",
      "env reset!\n",
      "starting_state [215.3      215.3      215.3      215.3      215.3       30.050158\n",
      "  33.209988  58.845104]\n",
      "timestep:  0\n",
      "new state [189.22256  189.18906  188.78276  189.17792  184.40471   39.65833\n",
      "  31.506659  29.179987]\n",
      "reward:  -1.3801500634363435\n",
      "timestep:  1\n",
      "new state [165.99193   166.00809   166.15361   166.01433   169.06451     6.3918304\n",
      "   7.0348005   4.9815793]\n",
      "reward:  -1.3442131087708675\n",
      "timestep:  2\n",
      "new state [333.7     333.7     333.7     333.7     333.7      50.06396  44.31238\n",
      " 122.26987]\n",
      "reward:  -0.12484517371608349\n",
      "\n",
      "env reset!\n",
      "starting_state [333.7       333.7       333.7       333.7       333.7         6.5959435\n",
      "   7.389706    9.841022 ]\n",
      "timestep:  0\n",
      "new state [314.76825   314.83072   315.76907   314.8514    328.5315      4.304062\n",
      "   6.521314    5.3385315]\n",
      "reward:  -0.19842763153950715\n",
      "timestep:  1\n",
      "new state [300.89365   301.1628    305.05768   301.252     318.55365     6.915069\n",
      "   9.548352    1.0468866]\n",
      "reward:  -0.05756975897643089\n",
      "timestep:  2\n",
      "new state [216.7      216.7      216.7      216.7      216.7       39.737335\n",
      "  32.925243  77.16384 ]\n",
      "reward:  0.013339879081012387\n",
      "\n",
      "env reset!\n",
      "starting_state [216.7      216.7      216.7      216.7      216.7        8.625412\n",
      "  14.075221  25.115183]\n",
      "timestep:  0\n",
      "new state [206.48056   206.50551   206.98943   206.51364   203.51599     9.918766\n",
      "  12.4025755  14.314523 ]\n",
      "reward:  -1.380531691189801\n",
      "timestep:  1\n",
      "new state [198.11697  198.19716  199.53857  198.22374  195.99701  133.57787\n",
      "  79.718735 153.70766 ]\n",
      "reward:  -1.3516822356036264\n",
      "timestep:  2\n",
      "new state [476.7      476.7      476.7      476.7      476.7       31.17636\n",
      "  54.586113  40.58431 ]\n",
      "reward:  -1.3849874870024037\n",
      "\n",
      "env reset!\n",
      "starting_state [476.7      476.7      476.7      476.7      476.7        5.629762\n",
      "   7.84565   17.00879 ]\n",
      "timestep:  0\n",
      "new state [454.29498   454.2083    453.52545   454.17816   444.9207      7.9253364\n",
      "   7.194479    1.       ]\n",
      "reward:  -0.12374986898952885\n",
      "timestep:  1\n",
      "new state [439.09695  439.28088  441.8756   439.3422   443.0451    31.474958\n",
      "  23.769869 114.34436 ]\n",
      "reward:  -0.011051031224126569\n",
      "timestep:  2\n",
      "new state [387.2      387.2      387.2      387.2      387.2       57.397236\n",
      "  63.437225  61.13236 ]\n",
      "reward:  -0.1679171855963115\n",
      "\n",
      "env reset!\n",
      "starting_state [387.2      387.2      387.2      387.2      387.2       53.94307\n",
      "  13.269053  91.94805 ]\n",
      "timestep:  0\n",
      "new state [358.17346  357.25714  343.11115  356.953    338.94058   20.853426\n",
      "  67.95867  120.57998 ]\n",
      "reward:  -1.4389386854761337\n",
      "timestep:  1\n",
      "new state [313.26987  312.6833   304.35538  312.48724  275.6532    50.799114\n",
      "  50.24758   59.139477]\n",
      "reward:  -1.3799938891877805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  2\n",
      "new state [343.4       343.4       343.4       343.4       343.4         6.9706616\n",
      "   5.670271    1.       ]\n",
      "reward:  -0.1803118272607722\n",
      "\n",
      "env reset!\n",
      "starting_state [343.4      343.4      343.4      343.4      343.4       29.085903\n",
      "  47.19737   89.94591 ]\n",
      "timestep:  0\n",
      "new state [308.27304  308.314    309.31522  308.32703  296.18613   44.505474\n",
      "  41.59888   91.696526]\n",
      "reward:  -1.3852030912646054\n",
      "timestep:  1\n",
      "new state [271.58572  271.38824  268.88724  271.322    248.04916   35.116917\n",
      "  17.87208   52.06892 ]\n",
      "reward:  -1.393949973070977\n",
      "timestep:  2\n",
      "new state [469.5      469.5      469.5      469.5      469.5       33.133133\n",
      "  48.93146   74.913124]\n",
      "reward:  -0.26501700361218283\n",
      "\n",
      "env reset!\n",
      "starting_state [469.5      469.5      469.5      469.5      469.5       25.460798\n",
      "  44.391293  15.7513  ]\n",
      "timestep:  0\n",
      "new state [388.37582  390.53314  420.60217  391.25018  440.0415    33.008034\n",
      "  49.12839   50.76525 ]\n",
      "reward:  -0.00987635711695082\n",
      "timestep:  1\n",
      "new state [278.05975  281.43573  329.47696  282.5554   345.17044   58.96327\n",
      "  59.309258  92.1082  ]\n",
      "reward:  -0.07274812264398169\n",
      "timestep:  2\n",
      "new state [663.1     663.1     663.1     663.1     663.1      85.51604 104.47578\n",
      " 153.50558]\n",
      "reward:  -0.994508064346835\n",
      "\n",
      "env reset!\n",
      "starting_state [663.1      663.1      663.1      663.1      663.1       55.929287\n",
      "  36.781372  63.06222 ]\n",
      "timestep:  0\n",
      "new state [544.45953  543.57825  529.7017   543.29126  545.25275   37.405754\n",
      "  57.180626  36.73604 ]\n",
      "reward:  -0.10831997836857846\n",
      "timestep:  1\n",
      "new state [428.16745   429.41446   445.4408    429.8344    476.58215     8.134197\n",
      "   6.5746107   5.8029385]\n",
      "reward:  -0.04299036319381742\n",
      "timestep:  2\n",
      "new state [258.       258.       258.       258.       258.        15.861988\n",
      "  19.140491  12.048944]\n",
      "reward:  -0.07137592153116203\n",
      "\n",
      "env reset!\n",
      "starting_state [258.       258.       258.       258.       258.        11.518289\n",
      "  21.274712  28.710829]\n",
      "timestep:  0\n",
      "new state [244.20232  244.32129  246.26224  244.36069  242.92506   20.099638\n",
      "  27.451147  43.479935]\n",
      "reward:  -1.3601253399816713\n",
      "timestep:  1\n",
      "new state [224.37932  224.55418  227.47255  224.61208  220.0965     5.663736\n",
      "   9.383028  12.512944]\n",
      "reward:  -1.3723752506276312\n",
      "timestep:  2\n",
      "new state [298.7      298.7      298.7      298.7      298.7       38.285866\n",
      "  71.02421  125.677246]\n",
      "reward:  -0.08954735255180113\n",
      "\n",
      "env reset!\n",
      "starting_state [298.7     298.7     298.7     298.7     298.7      52.69368  76.86482\n",
      " 120.95825]\n",
      "timestep:  0\n",
      "new state [244.05658 244.25398 247.66093 244.31923 235.19385  64.40043  48.75971\n",
      "  87.80043]\n",
      "reward:  -1.3717925612935524\n",
      "timestep:  1\n",
      "new state [201.33386  201.27263  200.61072  201.25266  189.08682   44.73864\n",
      "  42.23047   63.062866]\n",
      "reward:  -1.3812349530442072\n",
      "timestep:  2\n",
      "new state [421.9      421.9      421.9      421.9      421.9       20.367168\n",
      "  14.929051  28.97692 ]\n",
      "reward:  -1.369551820277839\n",
      "\n",
      "env reset!\n",
      "starting_state [421.9      421.9      421.9      421.9      421.9       42.704178\n",
      "  53.84729   65.30015 ]\n",
      "timestep:  0\n",
      "new state [291.2071   292.03406  304.35654  292.30734  387.60245   48.31242\n",
      "  51.394344  89.22318 ]\n",
      "reward:  -0.18917315843486573\n",
      "timestep:  1\n",
      "new state [250.73871  251.50925  263.0977   251.76389  340.75592   30.889675\n",
      "  28.536442  95.86964 ]\n",
      "reward:  -1.3788374470918736\n",
      "timestep:  2\n",
      "new state [532.7      532.7      532.7      532.7      532.7       29.215311\n",
      "  29.297398  90.52053 ]\n",
      "reward:  -0.3096105062770082\n",
      "\n",
      "env reset!\n",
      "starting_state [532.7      532.7      532.7      532.7      532.7       15.893612\n",
      "  22.797962  31.012772]\n",
      "timestep:  0\n",
      "new state [477.2918   477.61264  482.8186   477.7174   474.7485    10.531451\n",
      "  20.25539   27.191671]\n",
      "reward:  -0.09158125688624362\n",
      "timestep:  1\n",
      "new state [430.9294   431.6653   443.69238  431.9052   423.93878   48.773994\n",
      "  41.24159   69.70564 ]\n",
      "reward:  -0.08939526160323952\n",
      "timestep:  2\n",
      "new state [385.8      385.8      385.8      385.8      385.8       53.84964\n",
      "  53.398853  45.083656]\n",
      "reward:  -0.1071943266107672\n",
      "\n",
      "env reset!\n",
      "starting_state [385.8       385.8       385.8       385.8       385.8        88.03877\n",
      "   3.5990686 150.67554  ]\n",
      "timestep:  0\n",
      "new state [344.5004   342.62872  313.69745  342.0074   306.72635   61.643486\n",
      " 101.91466  126.1111  ]\n",
      "reward:  -1.4615482993175817\n",
      "timestep:  1\n",
      "new state [278.69913  277.4157   257.90778  276.9897   240.50055   17.000122\n",
      "  19.378986  21.95446 ]\n",
      "reward:  -1.3544524651067125\n",
      "timestep:  2\n",
      "new state [369.3       369.3       369.3       369.3       369.3         9.954162\n",
      "   6.2021093  11.368587 ]\n",
      "reward:  -0.08110611016594012\n",
      "\n",
      "env reset!\n",
      "starting_state [369.3      369.3      369.3      369.3      369.3       68.656334\n",
      "  57.28457   84.397415]\n",
      "timestep:  0\n",
      "new state [323.2699   323.16937  321.48477  323.1369   324.97144   51.262974\n",
      "  73.26143   38.579063]\n",
      "reward:  -1.3692066549957023\n",
      "timestep:  1\n",
      "new state [282.01566   282.64307   216.7663    282.85352   304.67484     4.4276123\n",
      "   7.0010343  14.069587 ]\n",
      "reward:  -0.9985451045604969\n",
      "timestep:  2\n",
      "new state [405.9      405.9      405.9      405.9      405.9       35.008423\n",
      "  64.534256  63.143757]\n",
      "reward:  -0.11873407930975453\n",
      "\n",
      "env reset!\n",
      "starting_state [405.9      405.9      405.9      405.9      405.9       53.765198\n",
      "  93.29372   57.67846 ]\n",
      "timestep:  0\n",
      "new state [354.5379   355.51672  370.57654  355.84277  375.57468   58.072224\n",
      "  58.741592 165.6324  ]\n",
      "reward:  -1.3085088215078435\n",
      "timestep:  1\n",
      "new state [298.52377  298.95364  306.0985   299.09637  288.64374   22.718405\n",
      "  18.92584   27.826614]\n",
      "reward:  -1.4097861995223913\n",
      "timestep:  2\n",
      "new state [483.8      483.8      483.8      483.8      483.8       32.634827\n",
      "  52.41685   70.07109 ]\n",
      "reward:  -0.09890843225287561\n",
      "\n",
      "env reset!\n",
      "starting_state [483.8     483.8     483.8     483.8     483.8      67.67647 102.43869\n",
      "  71.08226]\n",
      "timestep:  0\n",
      "new state [424.4836   425.4179   327.13055  425.7294   446.43298   67.41368\n",
      "  95.658356  70.84475 ]\n",
      "reward:  -1.0064663839035382\n",
      "timestep:  1\n",
      "new state [221.55515  225.60535  283.227    226.95227  314.01276   20.258537\n",
      "  24.00422   49.519707]\n",
      "reward:  -0.18749433830871617\n",
      "timestep:  2\n",
      "new state [504.2      504.2      504.2      504.2      504.2       25.789259\n",
      "  24.07652   70.3113  ]\n",
      "reward:  -0.12006709107332326\n",
      "\n",
      "env reset!\n",
      "starting_state [504.2     504.2     504.2     504.2     504.2      69.09545  87.1684\n",
      " 117.49688]\n",
      "timestep:  0\n",
      "new state [443.11536  287.65634  303.19092  287.97906  442.49594   75.718445\n",
      "  76.953064  42.86057 ]\n",
      "reward:  -0.44867832391398177\n",
      "timestep:  1\n",
      "new state [270.9872  239.95395 263.2541  240.4556  362.35565  84.30181  95.41798\n",
      " 211.03032]\n",
      "reward:  -0.6476131482946147\n",
      "timestep:  2\n",
      "new state [625.8      625.8      625.8      625.8      625.8        6.914862\n",
      "   7.725626   8.847546]\n",
      "reward:  -1.3947351862595347\n",
      "\n",
      "env reset!\n",
      "starting_state [625.8     625.8     625.8     625.8     625.8      91.13546 113.52861\n",
      " 206.13072]\n",
      "timestep:  0\n",
      "new state [314.67242  314.30804  313.9154   314.17557  517.58417   66.19723\n",
      "  89.615776  66.893295]\n",
      "reward:  -0.2415881757836855\n",
      "timestep:  1\n",
      "new state [260.64352   260.994     271.48776   261.10013   392.54892     5.382935\n",
      "   2.9284296   4.6989017]\n",
      "reward:  -1.145277778171713\n",
      "timestep:  2\n",
      "new state [361.2      361.2      361.2      361.2      361.2       15.225042\n",
      "  30.047523  30.504225]\n",
      "reward:  -0.10513093619910123\n",
      "\n",
      "env reset!\n",
      "starting_state [361.2      361.2      361.2      361.2      361.2       53.08944\n",
      "  87.212166 119.767044]\n",
      "timestep:  0\n",
      "new state [303.11465  303.52975  310.30804  303.66736  298.31323   72.977165\n",
      "  61.269924 181.84932 ]\n",
      "reward:  -1.3618500064772725\n",
      "timestep:  1\n",
      "new state [240.7916    240.44702   235.9913    240.33156   202.86795     8.093409\n",
      "   5.7520013  18.94009  ]\n",
      "reward:  -1.411731158079918\n",
      "timestep:  2\n",
      "new state [273.2      273.2      273.2      273.2      273.2        6.601778\n",
      "  11.453204  16.405418]\n",
      "reward:  -0.2960296117415832\n",
      "\n",
      "env reset!\n",
      "starting_state [273.2      273.2      273.2      273.2      273.2       34.82256\n",
      "  53.696167  75.69512 ]\n",
      "timestep:  0\n",
      "new state [236.70982  236.93039  240.55048  237.00352  233.45442   39.66742\n",
      "  27.729004  29.691042]\n",
      "reward:  -1.3639415121358271\n",
      "timestep:  1\n",
      "new state [214.69276  214.88145  217.78943  214.94487  217.84807   15.273366\n",
      "  22.358013  43.79532 ]\n",
      "reward:  -1.353139527548914\n",
      "timestep:  2\n",
      "new state [351.8      351.8      351.8      351.8      351.8       37.66859\n",
      "  53.746574  35.644295]\n",
      "reward:  -0.2562191850286042\n",
      "\n",
      "env reset!\n",
      "starting_state [351.8      351.8      351.8      351.8      351.8       10.779009\n",
      "  11.067336  23.435661]\n",
      "timestep:  0\n",
      "new state [318.35745   318.158     315.77637   318.09082   339.49728     7.3338127\n",
      "   9.361227   20.569546 ]\n",
      "reward:  -0.25556968824644566\n",
      "timestep:  1\n",
      "new state [291.02396   290.69232   287.03873   290.5798    301.06482    11.904407\n",
      "   4.9091125  22.337868 ]\n",
      "reward:  -0.12444553647024878\n",
      "timestep:  2\n",
      "new state [236.1      236.1      236.1      236.1      236.1       33.18761\n",
      "  65.25444   52.266026]\n",
      "reward:  -0.15756202814107018\n",
      "\n",
      "env reset!\n",
      "starting_state [236.1      236.1      236.1      236.1      236.1       12.941438\n",
      "  14.481087  45.23311 ]\n",
      "timestep:  0\n",
      "new state [221.94456  221.7912   219.60861  221.73988  212.36198   15.168373\n",
      "  27.646135  41.162754]\n",
      "reward:  -1.4167579861712558\n",
      "timestep:  1\n",
      "new state [203.41801 203.38965 203.29636 203.37964 190.75113  63.98094  71.12779\n",
      "  57.12702]\n",
      "reward:  -1.367331114587506\n",
      "timestep:  2\n",
      "new state [543.5      543.5      543.5      543.5      543.5      106.001465\n",
      "  92.573204 112.9911  ]\n",
      "reward:  -1.3314375572155936\n",
      "\n",
      "env reset!\n",
      "starting_state [543.5      543.5      543.5      543.5      543.5       48.984474\n",
      "  57.27402   80.303246]\n",
      "timestep:  0\n",
      "new state [396.31976  396.753    403.73657  396.89514  393.4396    48.26404\n",
      "  63.238087 157.48856 ]\n",
      "reward:  -0.09451685335961225\n",
      "timestep:  1\n",
      "new state [341.99118  342.12286  345.08536  342.1637   310.78268   61.764336\n",
      "  36.61974  134.69456 ]\n",
      "reward:  -1.4030595721175831\n",
      "timestep:  2\n",
      "new state [373.6       373.6       373.6       373.6       373.6         7.4688554\n",
      "   6.943538   17.029524 ]\n",
      "reward:  -0.30056745761426673\n",
      "\n",
      "env reset!\n",
      "starting_state [373.6      373.6      373.6      373.6      373.6       13.486623\n",
      "  11.047715  27.249176]\n",
      "timestep:  0\n",
      "new state [336.22174  335.81552  330.42407  335.6801   359.2958    13.740166\n",
      "  18.264805  28.609154]\n",
      "reward:  -0.2665399934683929\n",
      "timestep:  1\n",
      "new state [289.16785  288.8714   285.65808  288.77087  305.83762   32.45851\n",
      "  72.69114  111.168365]\n",
      "reward:  -0.10148629474957356\n",
      "timestep:  2\n",
      "new state [417.8     417.8     417.8     417.8     417.8      28.0652   58.87434\n",
      "  65.21824]\n",
      "reward:  -1.0376491914129766\n",
      "\n",
      "env reset!\n",
      "starting_state [417.8      417.8      417.8      417.8      417.8       37.554443\n",
      "  29.651537  87.394646]\n",
      "timestep:  0\n",
      "new state [309.22412  307.65738  287.0465   307.13428  371.92877   51.693523\n",
      "  53.992424  77.7959  ]\n",
      "reward:  -0.28716773667192064\n",
      "timestep:  1\n",
      "new state [268.80872  267.28775  247.40622  266.78027  331.07275   53.265434\n",
      "  48.72865   77.82725 ]\n",
      "reward:  -1.366932975987807\n",
      "timestep:  2\n",
      "new state [539.6      539.6      539.6      539.6      539.6       49.757053\n",
      "  35.54494  107.010925]\n",
      "reward:  -1.1162818213006476\n",
      "Writing to file data.csv\n",
      "Guardrail-0.25\n",
      "\n",
      "env reset!\n",
      "starting_state [539.6      539.6      539.6      539.6      539.6       58.352585\n",
      "  40.66036   56.945507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower and Upper Solutions:\n",
      "[[0.18104 0.19064 0.32842 0.19385 0.     ]\n",
      " [0.29582 0.27779 0.      0.27181 0.     ]\n",
      " [0.12554 0.13123 0.22564 0.1331  0.44553]]\n",
      "[[0.75602 0.7944  1.36398 0.80696 0.     ]\n",
      " [1.23528 1.15498 0.      1.12855 0.     ]\n",
      " [0.51889 0.54715 0.94188 0.5565  1.8551 ]]\n",
      "timestep:  0\n",
      "new state [415.70886 415.12506 406.35205 414.93436 433.91086  38.91278  71.64389\n",
      "   5.44837]\n",
      "reward:  -0.08398238316131931\n",
      "timestep:  1\n",
      "new state [294.96265  298.48444  348.10828  299.64758  423.74832   18.102997\n",
      "  21.45836   31.063812]\n",
      "reward:  0.045668966475337594\n",
      "timestep:  2\n",
      "new state [344.7      344.7      344.7      344.7      344.7       24.134176\n",
      "  29.325552  54.766094]\n",
      "reward:  -0.08353946611052968\n",
      "\n",
      "env reset!\n",
      "starting_state [344.7       344.7       344.7       344.7       344.7         8.275917\n",
      "   6.1462727  23.933739 ]\n",
      "timestep:  0\n",
      "new state [318.43192  317.93146  310.86603  317.76617  334.0296     6.277636\n",
      "   7.163428  17.836748]\n",
      "reward:  -0.3115442023198107\n",
      "timestep:  1\n",
      "new state [295.58176   294.9115    285.4998    294.68994   300.93393     3.2439456\n",
      "   4.6910872   5.753231 ]\n",
      "reward:  -0.11929123056358647\n",
      "timestep:  2\n",
      "new state [314.2     314.2     314.2     314.2     314.2      91.38705 116.69336\n",
      "  95.547  ]\n",
      "reward:  -0.07145103592631286\n",
      "\n",
      "env reset!\n",
      "starting_state [314.2      314.2      314.2      314.2      314.2       77.67342\n",
      "  63.238663 144.01955 ]\n",
      "timestep:  0\n",
      "new state [263.35052 262.9256  256.16232 262.78513 249.96452  76.98636  90.14613\n",
      " 123.91545]\n",
      "reward:  -1.5387214277187924\n",
      "timestep:  1\n",
      "new state [207.18954  206.9458   202.87311  206.86555  194.67291   13.722579\n",
      "  16.198635  23.977694]\n",
      "reward:  -1.5066345262082002\n",
      "timestep:  2\n",
      "new state [491.9      491.9      491.9      491.9      491.9       46.427876\n",
      "  87.64983   11.633492]\n",
      "reward:  -0.2049952927505302\n",
      "\n",
      "env reset!\n",
      "starting_state [491.9       491.9       491.9       491.9       491.9         3.8670585\n",
      "   6.420634   14.785695 ]\n",
      "timestep:  0\n",
      "new state [473.373    473.3223   472.69583  473.30518  464.4659     9.356492\n",
      "   9.539852  20.92689 ]\n",
      "reward:  -0.11532290947811565\n",
      "timestep:  1\n",
      "new state [443.65616   443.42102   440.21838   443.34283   425.63498     7.4263606\n",
      "  11.283441   20.330017 ]\n",
      "reward:  -0.11070534106590799\n",
      "timestep:  2\n",
      "new state [88.7       88.7       88.7       88.7       88.7        7.0896263\n",
      "  7.5003157 10.886014 ]\n",
      "reward:  -0.09802883944138167\n",
      "\n",
      "env reset!\n",
      "starting_state [88.7      88.7      88.7      88.7      88.7      17.161901 18.034266\n",
      " 41.1559  ]\n",
      "timestep:  0\n",
      "new state [75.0914   75.017624 73.76825  74.993416 70.346214 17.53796  23.187601\n",
      " 35.562305]\n",
      "reward:  -1.5397694087820732\n",
      "timestep:  1\n",
      "new state [60.59248  60.566063 59.97256  60.557716 54.481777  6.835262  8.435641\n",
      " 10.474026]\n",
      "reward:  -1.5134772215042651\n",
      "timestep:  2\n",
      "new state [226.5      226.5      226.5      226.5      226.5       27.394936\n",
      "  46.995453  17.307558]\n",
      "reward:  -1.499725060256452\n",
      "\n",
      "env reset!\n",
      "starting_state [226.5      226.5      226.5      226.5      226.5        5.490476\n",
      "   5.421324   4.744817]\n",
      "timestep:  0\n",
      "new state [223.30661   223.32465   223.62349   223.33057   224.38058     4.982329\n",
      "   7.5733066   7.7726264]\n",
      "reward:  -1.4812346191070083\n",
      "timestep:  1\n",
      "new state [219.18849  219.25102  220.22958  219.2717   220.91136   60.740826\n",
      "  70.336586  74.74761 ]\n",
      "reward:  -1.4855066535595571\n",
      "timestep:  2\n",
      "new state [332.1     332.1     332.1     332.1     332.1      21.95292  37.47287\n",
      "  53.31124]\n",
      "reward:  -1.4904249998428347\n",
      "\n",
      "env reset!\n",
      "starting_state [332.1      332.1      332.1      332.1      332.1       10.202902\n",
      "   9.098642   6.83522 ]\n",
      "timestep:  0\n",
      "new state [309.6003    309.7462    311.74094   309.7946    329.04507     7.4036946\n",
      "   7.3668222  24.090857 ]\n",
      "reward:  -0.11930271838362252\n",
      "timestep:  1\n",
      "new state [282.40237 282.17484 278.94806 282.0997  284.34674  65.77657 108.52525\n",
      " 134.97325]\n",
      "reward:  -0.13557320206939039\n",
      "timestep:  2\n",
      "new state [294.4       294.4       294.4       294.4       294.4         7.3839045\n",
      "   8.078552   23.081436 ]\n",
      "reward:  -1.4980489218618736\n",
      "\n",
      "env reset!\n",
      "starting_state [294.4      294.4      294.4      294.4      294.4       20.236734\n",
      "  26.302414  66.29913 ]\n",
      "timestep:  0\n",
      "new state [274.63235  274.5351   272.78094  274.50342  264.83847   19.795473\n",
      "  24.024158  47.187183]\n",
      "reward:  -1.5470534654558086\n",
      "timestep:  1\n",
      "new state [258.01788  257.89523  255.62039  257.85544  243.79326   42.84446\n",
      "  44.006886  87.89553 ]\n",
      "reward:  -1.5302461208722913\n",
      "timestep:  2\n",
      "new state [271.4      271.4      271.4      271.4      271.4        8.709915\n",
      "  10.102669  18.147213]\n",
      "reward:  -1.5311156970880904\n",
      "\n",
      "env reset!\n",
      "starting_state [271.4      271.4      271.4      271.4      271.4       11.835402\n",
      "  22.375742  25.979523]\n",
      "timestep:  0\n",
      "new state [259.37665  259.51865  261.6398   259.5659   259.80823   17.524372\n",
      "  20.638361  48.990944]\n",
      "reward:  -1.4923303063791504\n",
      "timestep:  1\n",
      "new state [243.94847  244.0156   244.81981  244.03838  237.96222   13.752008\n",
      "  36.53962   57.451855]\n",
      "reward:  -1.542729073062099\n",
      "timestep:  2\n",
      "new state [431.9      431.9      431.9      431.9      431.9       59.223713\n",
      "  45.17748   72.74192 ]\n",
      "reward:  -0.23132174195615327\n",
      "\n",
      "env reset!\n",
      "starting_state [431.9      431.9      431.9      431.9      431.9       15.673986\n",
      "  11.784581  10.755428]\n",
      "timestep:  0\n",
      "new state [399.91202  399.9528   400.38477  399.96683  411.93387   19.455704\n",
      "  21.211712  14.576744]\n",
      "reward:  -0.061123738527913106\n",
      "timestep:  1\n",
      "new state [351.43698  352.0224   360.10742  352.21643  384.87222   43.571934\n",
      "  73.98386   28.818937]\n",
      "reward:  -0.04036474289555274\n",
      "timestep:  2\n",
      "new state [251.        251.        251.        251.        251.          6.8050537\n",
      "   9.470165   20.936565 ]\n",
      "reward:  -0.0017923067321190997\n",
      "\n",
      "env reset!\n",
      "starting_state [251.        251.        251.        251.        251.          5.7822447\n",
      "   5.622657   14.668379 ]\n",
      "timestep:  0\n",
      "new state [246.44843  246.41083  245.7884   246.39845  244.45909    4.964589\n",
      "   7.979662  22.917156]\n",
      "reward:  -1.5479398762430507\n",
      "timestep:  1\n",
      "new state [220.9465   220.71149  217.42761  220.63338  234.24234   27.182522\n",
      "  32.845627  68.26477 ]\n",
      "reward:  -0.30247711096246277\n",
      "timestep:  2\n",
      "new state [424.1      424.1      424.1      424.1      424.1       52.364475\n",
      " 116.56082   95.4568  ]\n",
      "reward:  -1.5340133897338122\n",
      "\n",
      "env reset!\n",
      "starting_state [424.1      424.1      424.1      424.1      424.1       23.085138\n",
      "  29.845253  54.713528]\n",
      "timestep:  0\n",
      "new state [341.38965  341.354    341.06384  341.34128  399.69702   17.51794\n",
      "  23.701492  69.26325 ]\n",
      "reward:  -0.23629566036954736\n",
      "timestep:  1\n",
      "new state [262.92773 262.16562 251.9202  261.91168 368.81757  46.031    76.6831\n",
      "  83.76971]\n",
      "reward:  -0.2995163445106386\n",
      "timestep:  2\n",
      "new state [486.9      486.9      486.9      486.9      486.9       49.756626\n",
      "  67.749756 139.36096 ]\n",
      "reward:  -1.210927717309055\n",
      "\n",
      "env reset!\n",
      "starting_state [486.9      486.9      486.9      486.9      486.9       63.406208\n",
      " 148.30202   60.378918]\n",
      "timestep:  0\n",
      "new state [423.97028 425.6919  343.47134 426.2623  459.89352  79.4938  106.23367\n",
      " 201.20831]\n",
      "reward:  -1.1303504204946928\n",
      "timestep:  1\n",
      "new state [352.89297  354.62198  271.91022  355.19623  370.1563    38.576565\n",
      "  55.349182  65.8818  ]\n",
      "reward:  -1.5278761719518754\n",
      "timestep:  2\n",
      "new state [612.3      612.3      612.3      612.3      612.3       25.025757\n",
      "  45.414127  33.943142]\n",
      "reward:  -0.06948259264413593\n",
      "\n",
      "env reset!\n",
      "starting_state [612.3      612.3      612.3      612.3      612.3       27.968258\n",
      "  66.738335  84.74562 ]\n",
      "timestep:  0\n",
      "new state [464.74124  466.632    494.29828  467.25223  455.04102   43.928947\n",
      "  21.158365  45.88839 ]\n",
      "reward:  -0.07133524760031505\n",
      "timestep:  1\n",
      "new state [381.58255   382.1895    391.14813   382.38815   369.88092     4.5594273\n",
      "   8.518999   21.96597  ]\n",
      "reward:  -0.10753737052626441\n",
      "timestep:  2\n",
      "new state [450.7     450.7     450.7     450.7     450.7      77.63267  69.99103\n",
      "  94.91813]\n",
      "reward:  -0.12347430132298529\n",
      "\n",
      "env reset!\n",
      "starting_state [450.7      450.7      450.7      450.7      450.7       47.703785\n",
      "  49.525536  75.24773 ]\n",
      "timestep:  0\n",
      "new state [314.4118   314.43134  314.73392  314.43756  417.12628   67.479576\n",
      "  54.46545  111.912834]\n",
      "reward:  -0.20478359576928598\n",
      "timestep:  1\n",
      "new state [272.03378  271.75073  267.29303  271.6568   367.20477   47.493595\n",
      "  87.26797   78.64809 ]\n",
      "reward:  -1.5324355710332709\n",
      "timestep:  2\n",
      "new state [626.4      626.4      626.4      626.4      626.4       38.041695\n",
      "  35.91565  125.50194 ]\n",
      "reward:  -1.2222573722263357\n",
      "\n",
      "env reset!\n",
      "starting_state [626.4      626.4      626.4      626.4      626.4       68.84266\n",
      "  94.208176 110.56915 ]\n",
      "timestep:  0\n",
      "new state [400.60687 402.40497 428.31003 402.99637 421.20166  37.79522  87.63676\n",
      "  87.71248]\n",
      "reward:  -0.0688827473695314\n",
      "timestep:  1\n",
      "new state [218.26385  223.16986  294.09967  224.78267  382.0604    31.472702\n",
      "  24.848057  79.67594 ]\n",
      "reward:  -0.16459478061643407\n",
      "timestep:  2\n",
      "new state [629.1      629.1      629.1      629.1      629.1       47.327087\n",
      "  26.310238  90.41862 ]\n",
      "reward:  -0.8046852568721081\n",
      "\n",
      "env reset!\n",
      "starting_state [629.1      629.1      629.1      629.1      629.1       24.897203\n",
      "  74.22195   78.3461  ]\n",
      "timestep:  0\n",
      "new state [477.93927  480.7297   521.311    481.64612  483.71057   33.74213\n",
      "  32.012737  87.403915]\n",
      "reward:  -0.05591991795288552\n",
      "timestep:  1\n",
      "new state [367.53183  369.12784  392.9474   369.64932  321.53467    9.608265\n",
      "  11.71757   42.46312 ]\n",
      "reward:  -0.12421521604996136\n",
      "timestep:  2\n",
      "new state [252.3       252.3       252.3       252.3       252.3         7.0822525\n",
      "   7.7232594  10.552965 ]\n",
      "reward:  -0.14315939996962412\n",
      "\n",
      "env reset!\n",
      "starting_state [252.3      252.3      252.3      252.3      252.3       22.690355\n",
      "  21.37716   41.088287]\n",
      "timestep:  0\n",
      "new state [236.71013  236.64394  235.5662   236.6221   233.97191   18.794472\n",
      "  18.828686  42.83466 ]\n",
      "reward:  -1.528554128217636\n",
      "timestep:  1\n",
      "new state [222.36021  222.20935  219.71909  222.15967  214.86897   11.573236\n",
      "  24.75364   18.072481]\n",
      "reward:  -1.539406260056948\n",
      "timestep:  2\n",
      "new state [180.       180.       180.       180.       180.         9.396008\n",
      "  20.15765   22.25668 ]\n",
      "reward:  -0.03226571268962083\n",
      "\n",
      "env reset!\n",
      "starting_state [180.       180.       180.       180.       180.        45.09914\n",
      "  55.950485  83.77051 ]\n",
      "timestep:  0\n",
      "new state [144.76743  144.86661  146.25859  144.89978  142.6272    31.85227\n",
      "  47.323803  93.19615 ]\n",
      "reward:  -1.5120378238578553\n",
      "timestep:  1\n",
      "new state [113.30171   113.418076  114.745224  113.457726  101.065926    6.087017\n",
      "   7.7241664  10.803691 ]\n",
      "reward:  -1.5306580433888497\n",
      "timestep:  2\n",
      "new state [340.2     340.2     340.2     340.2     340.2      56.34593  75.02445\n",
      "  82.67766]\n",
      "reward:  -1.507413249940177\n",
      "\n",
      "env reset!\n",
      "starting_state [340.2      340.2      340.2      340.2      340.2       95.16671\n",
      "  59.903145  76.07263 ]\n",
      "timestep:  0\n",
      "new state [295.70032 295.43393 291.75037 295.34442 306.22983 106.97602  70.30888\n",
      " 270.05283]\n",
      "reward:  -1.5059389722225442\n",
      "timestep:  1\n",
      "new state [221.63217  220.06989  195.64743  219.55243  185.82455   78.9236\n",
      "  52.114098  42.04996 ]\n",
      "reward:  -1.5677016388667042\n",
      "timestep:  2\n",
      "new state [862.9      862.9      862.9      862.9      862.9       45.03868\n",
      "  46.135635  39.258255]\n",
      "reward:  -1.484141877342113\n",
      "\n",
      "env reset!\n",
      "starting_state [862.9      862.9      862.9      862.9      862.9       86.95109\n",
      "  84.90955   44.371353]\n",
      "timestep:  0\n",
      "new state [669.2523  671.4795  702.4655  672.2167  780.5008   75.25718  84.63726\n",
      " 166.01964]\n",
      "reward:  -0.030352434619840902\n",
      "timestep:  1\n",
      "new state [421.65973  423.1032   443.40332  423.57983  472.4378    28.833546\n",
      "  56.928272 183.26923 ]\n",
      "reward:  -0.10363931864387894\n",
      "timestep:  2\n",
      "new state [632.4      632.4      632.4      632.4      632.4       50.193836\n",
      "  74.47444   70.67178 ]\n",
      "reward:  -0.3221789135480958\n",
      "\n",
      "env reset!\n",
      "starting_state [632.4     632.4     632.4     632.4     632.4      68.8054   84.22174\n",
      " 127.70535]\n",
      "timestep:  0\n",
      "new state [410.07928  410.59262  418.2256   410.76035  395.4173    67.63453\n",
      "  54.094967 143.87057 ]\n",
      "reward:  -0.08649694253043645\n",
      "timestep:  1\n",
      "new state [217.4708   215.66635  363.52304  215.06912  331.25778   63.066257\n",
      "  71.81964   87.96967 ]\n",
      "reward:  -0.48583192686843424\n",
      "timestep:  2\n",
      "new state [605.1      605.1      605.1      605.1      605.1        8.978854\n",
      "   6.497436   7.013225]\n",
      "reward:  -1.07614907374148\n",
      "\n",
      "env reset!\n",
      "starting_state [605.1      605.1      605.1      605.1      605.1       45.38345\n",
      "  62.868977  64.14087 ]\n",
      "timestep:  0\n",
      "new state [459.8463   461.34027  482.75342  461.83215  486.0581    38.236603\n",
      "  60.039486  39.17372 ]\n",
      "reward:  -0.05961317678013958\n",
      "timestep:  1\n",
      "new state [336.44623  340.18683  393.6725   341.419    413.3378    30.421913\n",
      "  48.387154  82.814674]\n",
      "reward:  -0.030348828778552953\n",
      "timestep:  2\n",
      "new state [486.8      486.8      486.8      486.8      486.8       43.303104\n",
      "  26.81554  104.655334]\n",
      "reward:  -0.09438373063732988\n",
      "\n",
      "env reset!\n",
      "starting_state [486.8       486.8       486.8       486.8       486.8         4.246041\n",
      "   8.46335    12.1051445]\n",
      "timestep:  0\n",
      "new state [466.85406   467.0286    469.60266   467.0858    464.33737     6.9337163\n",
      "   6.9050226   3.1503477]\n",
      "reward:  -0.0809350925116419\n",
      "timestep:  1\n",
      "new state [451.44772  451.82156  457.1745   451.94473  458.48624   28.496254\n",
      "  73.75888  101.782585]\n",
      "reward:  -0.024344159921098736\n",
      "timestep:  2\n",
      "new state [218.7       218.7       218.7       218.7       218.7        10.630719\n",
      "   6.9710045  19.985203 ]\n",
      "reward:  -0.07744512546906475\n",
      "\n",
      "env reset!\n",
      "starting_state [218.7      218.7      218.7      218.7      218.7       22.827225\n",
      "  29.537369  80.270775]\n",
      "timestep:  0\n",
      "new state [195.75241  195.6091   193.07602  195.56235  182.91077   29.131529\n",
      "  24.086033  35.90745 ]\n",
      "reward:  -1.5519582647179\n",
      "timestep:  1\n",
      "new state [178.84549  178.65247  175.39444  178.5891   166.8863    43.378193\n",
      "  44.497005  85.76919 ]\n",
      "reward:  -1.5131658671661612\n",
      "timestep:  2\n",
      "new state [359.8       359.8       359.8       359.8       359.8        15.8702135\n",
      "  26.540382   56.178318 ]\n",
      "reward:  -1.5288219628526276\n",
      "\n",
      "env reset!\n",
      "starting_state [359.8      359.8      359.8      359.8      359.8       70.43213\n",
      "  40.849953  44.25658 ]\n",
      "timestep:  0\n",
      "new state [329.40875  329.21732  326.66217  329.15274  340.0267    46.474483\n",
      "  35.458675 173.63602 ]\n",
      "reward:  -1.499095739232954\n",
      "timestep:  1\n",
      "new state [288.70737   287.7211    272.20206   287.39468   262.62567     6.7724886\n",
      "   8.5429325  10.706835 ]\n",
      "reward:  -1.5823739579799212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  2\n",
      "new state [415.       415.       415.       415.       415.        20.721453\n",
      "  57.89818   73.81426 ]\n",
      "reward:  -0.0737677669355793\n",
      "\n",
      "env reset!\n",
      "starting_state [415.       415.       415.       415.       415.        68.53038\n",
      "  69.694214 136.3754  ]\n",
      "timestep:  0\n",
      "new state [364.85574  364.67847  361.68665  364.62024  354.17157   38.588337\n",
      "  45.5311    41.92854 ]\n",
      "reward:  -1.529781335187501\n",
      "timestep:  1\n",
      "new state [257.68222  258.49518  269.5385   258.7636   276.34787   16.848251\n",
      "  18.003662  54.69818 ]\n",
      "reward:  -0.05515232852009794\n",
      "timestep:  2\n",
      "new state [488.7     488.7     488.7     488.7     488.7      52.49309  80.51353\n",
      "  86.61034]\n",
      "reward:  -0.2962872455401173\n",
      "\n",
      "env reset!\n",
      "starting_state [488.7      488.7      488.7      488.7      488.7       24.715092\n",
      "  26.12814   66.91871 ]\n",
      "timestep:  0\n",
      "new state [403.01587  402.2743   391.94666  402.02875  458.8603    28.025057\n",
      "  29.4309    61.69561 ]\n",
      "reward:  -0.27401629319336845\n",
      "timestep:  1\n",
      "new state [313.45972 312.26233 295.59647 311.86578 344.38004  38.65242  71.97519\n",
      " 146.82419]\n",
      "reward:  -0.10785625391744749\n",
      "timestep:  2\n",
      "new state [418.2      418.2      418.2      418.2      418.2       14.621867\n",
      "  28.503355  34.427475]\n",
      "reward:  -1.53342205405124\n",
      "\n",
      "env reset!\n",
      "starting_state [418.2      418.2      418.2      418.2      418.2       41.140926\n",
      "  24.08108   90.9433  ]\n",
      "timestep:  0\n",
      "new state [310.16022  307.9449   384.15604  307.2143   377.64944   32.88811\n",
      "  51.908463  46.94099 ]\n",
      "reward:  -0.5276368252980316\n",
      "timestep:  1\n",
      "new state [282.9576   281.09537  295.0586   280.48184  290.52682   32.324745\n",
      "  69.80584   79.33678 ]\n",
      "reward:  -0.9389530240285611\n",
      "timestep:  2\n",
      "new state [653.5      653.5      653.5      653.5      653.5       42.000443\n",
      "  48.14922   59.736176]\n",
      "reward:  -0.18142071991772374\n",
      "\n",
      "env reset!\n",
      "starting_state [653.5     653.5     653.5     653.5     653.5      62.09389  69.46917\n",
      "   1.     ]\n",
      "timestep:  0\n",
      "new state [520.223    523.38995  567.82855  524.43677  651.5791    41.883297\n",
      "  62.627632  87.61056 ]\n",
      "reward:  0.028208048488570725\n",
      "timestep:  1\n",
      "new state [365.7355   369.84808  428.15063  371.20493  489.0005   110.85075\n",
      " 101.86062   51.575523]\n",
      "reward:  -0.08032670590727302\n",
      "timestep:  2\n",
      "new state [610.5      610.5      610.5      610.5      610.5       29.145187\n",
      "  35.68855   97.507614]\n",
      "reward:  -0.030767009801817867\n",
      "\n",
      "env reset!\n",
      "starting_state [610.5      610.5      610.5      610.5      610.5       55.846092\n",
      "  97.55498   58.32828 ]\n",
      "timestep:  0\n",
      "new state [417.50555  421.5475   479.34003  422.8791   502.2185    45.255993\n",
      "  48.724453  50.271637]\n",
      "reward:  -0.02324169501935049\n",
      "timestep:  1\n",
      "new state [297.01733  301.81424  370.23755  303.39517  408.9126    35.702198\n",
      "  55.011387  43.152588]\n",
      "reward:  -0.06299186640342305\n",
      "timestep:  2\n",
      "new state [403.        403.        403.        403.        403.          5.858639\n",
      "   4.8854113  20.20858  ]\n",
      "reward:  -0.041668784048540596\n",
      "\n",
      "env reset!\n",
      "starting_state [403.       403.       403.       403.       403.        13.502382\n",
      "  13.701265  43.796974]\n",
      "timestep:  0\n",
      "new state [353.1412   352.4855   343.32468  352.26855  383.47354    8.910551\n",
      "   8.320324  21.651993]\n",
      "reward:  -0.30069403485796914\n",
      "timestep:  1\n",
      "new state [324.89172  323.95026  310.77313  323.63885  343.2983    22.710562\n",
      "  33.801067  43.468422]\n",
      "reward:  -0.1211466119058597\n",
      "timestep:  2\n",
      "new state [335.5      335.5      335.5      335.5      335.5       33.21482\n",
      "  56.64547   61.598717]\n",
      "reward:  -0.07452420790221392\n",
      "\n",
      "env reset!\n",
      "starting_state [335.5      335.5      335.5      335.5      335.5       43.707058\n",
      "  60.920345  61.202732]\n",
      "timestep:  0\n",
      "new state [301.88242  302.21298  307.30548  302.32254  308.18002   20.881828\n",
      "  46.271496  48.42366 ]\n",
      "reward:  -1.4849807846724734\n",
      "timestep:  1\n",
      "new state [278.33484  279.02368  233.19067  279.25235  286.57227   21.958979\n",
      "  24.4882    37.25161 ]\n",
      "reward:  -1.1212491252016246\n",
      "timestep:  2\n",
      "new state [292.4      292.4      292.4      292.4      292.4       19.154333\n",
      "  27.784224  22.170706]\n",
      "reward:  -0.08698259040449621\n",
      "\n",
      "env reset!\n",
      "starting_state [292.4      292.4      292.4      292.4      292.4       54.086212\n",
      "  44.356434 129.68245 ]\n",
      "timestep:  0\n",
      "new state [253.20638  252.749    245.35327  252.59813  234.57335   45.74425\n",
      "  23.512518  25.19479 ]\n",
      "reward:  -1.553893706516778\n",
      "timestep:  1\n",
      "new state [234.80641  234.19046  224.63324  233.98624  223.31369   29.514809\n",
      "  29.299732  81.67291 ]\n",
      "reward:  -1.5000361167358498\n",
      "timestep:  2\n",
      "new state [482.5       482.5       482.5       482.5       482.5         7.5077925\n",
      "  33.178036   43.72549  ]\n",
      "reward:  -0.497969248083528\n",
      "\n",
      "env reset!\n",
      "starting_state [482.5       482.5       482.5       482.5       482.5         8.6625185\n",
      "  12.69736     1.       ]\n",
      "timestep:  0\n",
      "new state [459.74728  460.40616  469.73627  460.6236   480.63422   13.120738\n",
      "   9.845924  12.610104]\n",
      "reward:  0.033869137384548983\n",
      "timestep:  1\n",
      "new state [431.122    431.71158  439.9577   431.90656  457.22974   48.132317\n",
      "  71.776855  94.96901 ]\n",
      "reward:  -0.07864185558799419\n",
      "timestep:  2\n",
      "new state [429.8      429.8      429.8      429.8      429.8       50.115356\n",
      "  84.95765   95.598305]\n",
      "reward:  -0.07647616090487061\n",
      "\n",
      "env reset!\n",
      "starting_state [429.8      429.8      429.8      429.8      429.8       87.4185\n",
      "  80.061104 160.28911 ]\n",
      "timestep:  0\n",
      "new state [370.16736 369.85962 364.88232 369.75803 358.30264  64.32462  72.24431\n",
      " 152.33092]\n",
      "reward:  -1.5310805219861325\n",
      "timestep:  1\n",
      "new state [318.0271  317.53766 309.34875 317.37674 290.36636  66.48869  51.24108\n",
      "  90.80584]\n",
      "reward:  -1.534813691200747\n",
      "timestep:  2\n",
      "new state [591.7      591.7      591.7      591.7      591.7       36.281258\n",
      "  42.12271   60.868942]\n",
      "reward:  -0.4236148276728527\n",
      "\n",
      "env reset!\n",
      "starting_state [591.7      591.7      591.7      591.7      591.7       32.55566\n",
      "  46.56073   91.459564]\n",
      "timestep:  0\n",
      "new state [462.1143   462.01898  461.12753  461.98553  421.99384   37.598133\n",
      "  47.071373  76.60106 ]\n",
      "reward:  -0.10401342130678301\n",
      "timestep:  1\n",
      "new state [335.7955   335.87225  337.67188  335.89447  279.84888   18.218185\n",
      "  14.086759  17.411419]\n",
      "reward:  -0.09117711732074188\n",
      "timestep:  2\n",
      "new state [333.8      333.8      333.8      333.8      333.8       28.786629\n",
      "  46.826946  29.502718]\n",
      "reward:  -0.07646850146374591\n",
      "\n",
      "env reset!\n",
      "starting_state [333.8      333.8      333.8      333.8      333.8       39.51248\n",
      "  50.263527 141.13283 ]\n",
      "timestep:  0\n",
      "new state [294.05988  293.78375  288.95294  293.69357  270.8762    35.394726\n",
      "  60.797546  69.90704 ]\n",
      "reward:  -1.553987979344149\n",
      "timestep:  1\n",
      "new state [260.89075  260.97327  261.52438  261.0023   239.6824    30.988016\n",
      "  41.87631   13.387293]\n",
      "reward:  -1.4922757353644542\n",
      "timestep:  2\n",
      "new state [477.8     477.8     477.8     477.8     477.8      29.97029  79.58301\n",
      "  71.92901]\n",
      "reward:  -0.0010354493772738102\n",
      "\n",
      "env reset!\n",
      "starting_state [477.8      477.8      477.8      477.8      477.8       29.97012\n",
      "  47.961544  19.105997]\n",
      "timestep:  0\n",
      "new state [385.98212   388.14325   418.9018    388.8558    442.31747    44.03313\n",
      "  61.8908      7.9277773]\n",
      "reward:  -0.0045151226016018065\n",
      "timestep:  1\n",
      "new state [272.12607 277.34302 351.3435  279.06415 427.55768  71.95437  68.23424\n",
      " 121.90351]\n",
      "reward:  0.024615554801342584\n",
      "timestep:  2\n",
      "new state [714.6      714.6      714.6      714.6      714.6       71.721085\n",
      "  91.92644  256.4721  ]\n",
      "reward:  -0.8591526779487756\n",
      "\n",
      "env reset!\n",
      "starting_state [714.6      714.6      714.6      714.6      714.6       83.69408\n",
      "  66.76063   30.913458]\n",
      "timestep:  0\n",
      "new state [552.81683  554.0919   571.2928   554.5161   657.1772    87.388596\n",
      "  86.80331  148.7227  ]\n",
      "reward:  -0.03165889133573479\n",
      "timestep:  1\n",
      "new state [302.3522   303.0407   311.97415  303.27097  381.1946    41.848778\n",
      "  51.709995  63.689907]\n",
      "reward:  -0.09485018143707426\n",
      "timestep:  2\n",
      "new state [473.3      473.3      473.3      473.3      473.3       11.666571\n",
      "   8.46677   26.66461 ]\n",
      "reward:  -0.07277015353149338\n",
      "\n",
      "env reset!\n",
      "starting_state [473.3      473.3      473.3      473.3      473.3       31.897774\n",
      "  30.293598  37.71321 ]\n",
      "timestep:  0\n",
      "new state [392.19455  392.3371   394.25558  392.38452  403.30713   30.410604\n",
      "  61.84637   54.497173]\n",
      "reward:  -0.0752997224532966\n",
      "timestep:  1\n",
      "new state [264.5279   266.92944  301.4154   267.71997  302.1633    29.187922\n",
      "  46.02662   71.41302 ]\n",
      "reward:  -0.045708552058209\n",
      "timestep:  2\n",
      "new state [275.8      275.8      275.8      275.8      275.8        7.706619\n",
      "  10.654398  12.997147]\n",
      "reward:  -0.21879051214882972\n",
      "\n",
      "env reset!\n",
      "starting_state [275.8      275.8      275.8      275.8      275.8        9.147536\n",
      "   7.465553  25.64343 ]\n",
      "timestep:  0\n",
      "new state [268.7162   268.61707  267.00583  268.58438  264.36676   11.42402\n",
      "  11.975187  20.14769 ]\n",
      "reward:  -1.5633814178097294\n",
      "timestep:  1\n",
      "new state [234.83224  234.68692  232.44101  234.63887  255.37866   58.717133\n",
      "  62.244896 162.72615 ]\n",
      "reward:  -0.21840722029972512\n",
      "timestep:  2\n",
      "new state [479.1      479.1      479.1      479.1      479.1       61.003307\n",
      "  43.146927  54.689846]\n",
      "reward:  -1.5485072001629272\n",
      "\n",
      "env reset!\n",
      "starting_state [479.1       479.1       479.1       479.1       479.1         7.744819\n",
      "   3.7875311   7.7758455]\n",
      "timestep:  0\n",
      "new state [464.5313    464.31845   461.21042   464.24857   464.66928     7.655129\n",
      "   7.8068266  21.566545 ]\n",
      "reward:  -0.10474804796857635\n",
      "timestep:  1\n",
      "new state [437.9096    437.42035   430.45197   437.259     424.65344    12.829673\n",
      "  14.9739895   1.       ]\n",
      "reward:  -0.12535477883559631\n",
      "timestep:  2\n",
      "new state [94.1      94.1      94.1      94.1      94.1       5.184535  6.589685\n",
      "  8.542588]\n",
      "reward:  0.0235344591042606\n",
      "\n",
      "env reset!\n",
      "starting_state [94.1       94.1       94.1       94.1       94.1        6.7454433\n",
      "  8.724924  24.011929 ]\n",
      "timestep:  0\n",
      "new state [87.28334  87.239265 86.46225  87.224884 83.394226  9.141403 12.27315\n",
      " 11.689247]\n",
      "reward:  -1.552774877083995\n",
      "timestep:  1\n",
      "new state [80.530266 80.55321  80.81633  80.56102  78.175606 37.538708 51.112934\n",
      " 36.43125 ]\n",
      "reward:  -1.4820105353961213\n",
      "timestep:  2\n",
      "new state [319.4      319.4      319.4      319.4      319.4       40.22966\n",
      "  46.932587  55.57324 ]\n",
      "reward:  -1.4644688541492439\n",
      "\n",
      "env reset!\n",
      "starting_state [319.4      319.4      319.4      319.4      319.4       26.7644\n",
      "  23.814106  28.514479]\n",
      "timestep:  0\n",
      "new state [303.93018  303.94037  304.16412  303.9435   306.67065   32.317825\n",
      "  40.683517  88.29138 ]\n",
      "reward:  -1.4999598094926847\n",
      "timestep:  1\n",
      "new state [274.96027  274.89136  273.60788  274.86893  267.2977    13.293848\n",
      "  11.490452  14.483939]\n",
      "reward:  -1.5369931281995532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  2\n",
      "new state [204.5       204.5       204.5       204.5       204.5         6.953627\n",
      "   4.6202626  11.862257 ]\n",
      "reward:  -0.07671870164782679\n",
      "\n",
      "env reset!\n",
      "starting_state [204.5      204.5      204.5      204.5      204.5       30.500729\n",
      "  49.106117  36.047768]\n",
      "timestep:  0\n",
      "new state [179.92615  180.3136   186.32458  180.44194  188.39984   44.25565\n",
      "  55.641575  82.57135 ]\n",
      "reward:  -1.4633330868336623\n",
      "timestep:  1\n",
      "new state [145.08821  145.5842   153.13092  145.7488   151.56187   39.81807\n",
      "  55.147755  89.94631 ]\n",
      "reward:  -1.5114020958384644\n",
      "timestep:  2\n",
      "new state [594.3      594.3      594.3      594.3      594.3       39.69959\n",
      "  48.491627  27.505339]\n",
      "reward:  -1.5175941056828461\n",
      "\n",
      "env reset!\n",
      "starting_state [594.3      594.3      594.3      594.3      594.3        9.560337\n",
      "  18.160345  16.280468]\n",
      "timestep:  0\n",
      "new state [556.1913   556.8226   565.91656  557.0302   564.0842    12.147562\n",
      "  12.095174  11.091602]\n",
      "reward:  -0.04764519256184625\n",
      "timestep:  1\n",
      "new state [526.3112    527.1341    538.89453   527.40515   543.4961     10.6206045\n",
      "  17.326115   40.010418 ]\n",
      "reward:  -0.05723451548345214\n",
      "timestep:  2\n",
      "new state [151.8       151.8       151.8       151.8       151.8         7.2141314\n",
      "   7.1654654  17.336367 ]\n",
      "reward:  -0.1154686861480512\n",
      "\n",
      "env reset!\n",
      "starting_state [151.8      151.8      151.8      151.8      151.8       25.72831\n",
      "  15.967594  60.49054 ]\n",
      "timestep:  0\n",
      "new state [134.82463  134.52135  129.69324  134.42113  124.828804  35.91849\n",
      "  36.95268   83.62861 ]\n",
      "reward:  -1.5663459493001102\n",
      "timestep:  1\n",
      "new state [106.89187  106.43417   99.00845  106.28325   87.53332   67.79835\n",
      "  27.307924 127.137474]\n",
      "reward:  -1.5391617360936245\n",
      "timestep:  2\n",
      "new state [530.6      530.6      530.6      530.6      530.6       47.492477\n",
      "  61.085274  29.563437]\n",
      "reward:  -1.5717937100838237\n",
      "\n",
      "env reset!\n",
      "starting_state [530.6      530.6      530.6      530.6      530.6       13.346056\n",
      "  25.30514   28.181671]\n",
      "timestep:  0\n",
      "new state [474.62796  475.35135  485.8398   475.58902  478.30084   22.105148\n",
      "  25.031742  45.86107 ]\n",
      "reward:  -0.06289308298878081\n",
      "timestep:  1\n",
      "new state [403.19797 403.787   412.4807  403.9798  393.2004   78.61618  69.34076\n",
      "   7.90992]\n",
      "reward:  -0.09914714263300332\n",
      "timestep:  2\n",
      "new state [567.2      567.2      567.2      567.2      567.2       48.755356\n",
      "  71.0898   147.91473 ]\n",
      "reward:  0.00312839664290355\n",
      "\n",
      "env reset!\n",
      "starting_state [567.2     567.2     567.2     567.2     567.2      47.41181  67.01342\n",
      "  21.97061]\n",
      "timestep:  0\n",
      "new state [437.17505  440.1157   481.80408  441.08594  526.38513   39.510483\n",
      "  69.15841   52.063046]\n",
      "reward:  -0.0004128344542914603\n",
      "timestep:  1\n",
      "new state [294.8593   300.3657   378.84085  302.18073  429.74863   66.06673\n",
      "  58.279484  79.13802 ]\n",
      "reward:  -0.037174505655746905\n",
      "timestep:  2\n",
      "new state [573.4      573.4      573.4      573.4      573.4       55.864265\n",
      "  61.33183   25.775007]\n",
      "reward:  -0.08092898593273606\n",
      "\n",
      "env reset!\n",
      "starting_state [573.4      573.4      573.4      573.4      573.4       52.335735\n",
      "  46.926376 107.326164]\n",
      "timestep:  0\n",
      "new state [420.17548  418.90198  400.90332  418.4814   525.5334    35.69795\n",
      "  90.65388  117.951805]\n",
      "reward:  -0.2530312874341705\n",
      "timestep:  1\n",
      "new state [220.00018  221.3028   241.07027  221.72697  306.65784   65.96802\n",
      "  45.721138 153.445   ]\n",
      "reward:  -0.0729581391934966\n",
      "timestep:  2\n",
      "new state [504.1      504.1      504.1      504.1      504.1        4.81735\n",
      "   7.943556   8.392993]\n",
      "reward:  -1.5606285898380754\n",
      "\n",
      "env reset!\n",
      "starting_state [504.1      504.1      504.1      504.1      504.1        8.592334\n",
      "  14.370525   8.916034]\n",
      "timestep:  0\n",
      "new state [475.22595   475.7982    483.97522   475.9867    487.5484      7.1535673\n",
      "   6.5900536  12.893903 ]\n",
      "reward:  -0.026232445020475878\n",
      "timestep:  1\n",
      "new state [454.98663  455.44913  462.0701   455.60138  463.62204   15.133276\n",
      "  19.83358   46.44049 ]\n",
      "reward:  -0.10322122014072584\n",
      "timestep:  2\n",
      "new state [301.       301.       301.       301.       301.        58.405956\n",
      "  79.06392  141.05545 ]\n",
      "reward:  -0.11576356904450963\n",
      "\n",
      "env reset!\n",
      "starting_state [301.       301.       301.       301.       301.        42.817184\n",
      "  60.221004  84.10041 ]\n",
      "timestep:  0\n",
      "new state [264.87582  265.07205  267.93146  265.13745  263.47922   61.794315\n",
      "  60.08196  114.665794]\n",
      "reward:  -1.5068784613524953\n",
      "timestep:  1\n",
      "new state [221.51999  221.55383  221.73373  221.56573  212.33122   19.934015\n",
      "  47.369335 108.25264 ]\n",
      "reward:  -1.528135340121762\n",
      "timestep:  2\n",
      "new state [360.5       360.5       360.5       360.5       360.5         7.5678234\n",
      "  10.192354    9.068209 ]\n",
      "reward:  -1.5420263183613847\n",
      "\n",
      "env reset!\n",
      "starting_state [360.5      360.5      360.5      360.5      360.5       42.87333\n",
      "  66.921486  82.45471 ]\n",
      "timestep:  0\n",
      "new state [322.59015  322.916    327.781    323.02435  323.70905   45.661537\n",
      "  60.69222   67.66721 ]\n",
      "reward:  -1.4977193233767674\n",
      "timestep:  1\n",
      "new state [287.87466  288.4714   297.48608  288.66962  293.5081    48.340683\n",
      "  76.10849  134.067   ]\n",
      "reward:  -1.4921687688126544\n",
      "timestep:  2\n",
      "new state [669.9      669.9      669.9      669.9      669.9       79.683304\n",
      "  60.88607  108.98051 ]\n",
      "reward:  -1.5228557053440532\n",
      "\n",
      "env reset!\n",
      "starting_state [669.9      669.9      669.9      669.9      669.9       33.390385\n",
      "  16.668211  62.076927]\n",
      "timestep:  0\n",
      "new state [591.8552    590.15784   565.87885   589.59863   554.71606    34.57143\n",
      "  36.346233   12.9542265]\n",
      "reward:  -0.13660834094776486\n",
      "timestep:  1\n",
      "new state [514.09894  513.6272   506.5046   513.47327  530.64923   49.942066\n",
      "  47.464767 126.4234  ]\n",
      "reward:  -0.01362624185997912\n",
      "timestep:  2\n",
      "new state [336.6       336.6       336.6       336.6       336.6        10.6723585\n",
      "  11.126039   20.23257  ]\n",
      "reward:  -0.12268739134635999\n",
      "\n",
      "env reset!\n",
      "starting_state [336.6      336.6      336.6      336.6      336.6       39.741768\n",
      "  41.22235    7.326497]\n",
      "timestep:  0\n",
      "new state [316.291    316.61102  321.87427  316.71625  333.29535   44.275276\n",
      "  41.285793  75.66797 ]\n",
      "reward:  -1.422267958284411\n",
      "timestep:  1\n",
      "new state [286.56287  286.7717   290.239    286.84018  299.54022   52.866043\n",
      " 112.38886  127.82566 ]\n",
      "reward:  -1.5255548951718652\n",
      "timestep:  2\n",
      "new state [558.5      558.5      558.5      558.5      558.5       22.954668\n",
      "  38.80809   79.71137 ]\n",
      "reward:  -1.4900851967826967\n",
      "\n",
      "env reset!\n",
      "starting_state [558.5       558.5       558.5       558.5       558.5         8.8545\n",
      "   1.7924875   8.052737 ]\n",
      "timestep:  0\n",
      "new state [545.4131    544.9896    538.83704   544.8505    543.556       5.609539\n",
      "   7.5100718   4.0235605]\n",
      "reward:  -0.1329125398111873\n",
      "timestep:  1\n",
      "new state [529.8073   529.65796  527.3923   529.60925  536.0854    46.625374\n",
      "  40.536503  65.2993  ]\n",
      "reward:  -0.023272824919487445\n",
      "timestep:  2\n",
      "new state [454.4     454.4     454.4     454.4     454.4      75.72425  94.26665\n",
      "  65.86504]\n",
      "reward:  -0.09122307695683224\n",
      "\n",
      "env reset!\n",
      "starting_state [454.4      454.4      454.4      454.4      454.4       16.239038\n",
      "  26.541824  42.66182 ]\n",
      "timestep:  0\n",
      "new state [387.1996   387.502    392.0547   387.60065  375.23666   18.141928\n",
      "   6.920915  28.72264 ]\n",
      "reward:  -0.089883383285447\n",
      "timestep:  1\n",
      "new state [350.03076  349.38095  340.25272  349.16608  321.94077   20.395384\n",
      "  17.43484   28.010838]\n",
      "reward:  -0.13883503053702903\n",
      "timestep:  2\n",
      "new state [292.1     292.1     292.1     292.1     292.1      52.04399  50.57515\n",
      "  69.5221 ]\n",
      "reward:  -0.0910995074787198\n",
      "\n",
      "env reset!\n",
      "starting_state [292.1     292.1     292.1     292.1     292.1      44.41743  53.63957\n",
      "  93.22526]\n",
      "timestep:  0\n",
      "new state [256.48752  256.49777  256.45026  256.50165  250.51633   53.171635\n",
      "  53.811844  17.529573]\n",
      "reward:  -1.5220569649001983\n",
      "timestep:  1\n",
      "new state [228.74205  229.11234  235.00534  229.23454  242.65288   47.94509\n",
      "  68.326935 282.14127 ]\n",
      "reward:  -1.4384937416008534\n",
      "timestep:  2\n",
      "new state [488.4      488.4      488.4      488.4      488.4        4.852373\n",
      "   7.818657  14.302141]\n",
      "reward:  -1.5782713240925266\n",
      "\n",
      "env reset!\n",
      "starting_state [488.4     488.4     488.4     488.4     488.4      51.2192   74.98765\n",
      " 128.39836]\n",
      "timestep:  0\n",
      "new state [290.42188  290.84906  297.5647   290.98715  431.13156   56.98157\n",
      "  41.377167  90.498856]\n",
      "reward:  -0.23048558178237605\n",
      "timestep:  1\n",
      "new state [256.50452  256.61575  258.40997  256.64914  390.76242   55.79515\n",
      "  55.610283  71.368744]\n",
      "reward:  -1.5358820764527625\n",
      "timestep:  2\n",
      "new state [623.4      623.4      623.4      623.4      623.4       65.011894\n",
      "  39.646076 116.480385]\n",
      "reward:  -1.2356448671885214\n",
      "\n",
      "env reset!\n",
      "starting_state [623.4      623.4      623.4      623.4      623.4       32.77385\n",
      "  47.948257  49.64708 ]\n",
      "timestep:  0\n",
      "new state [513.6315   514.8208   531.91156  515.2122   531.2594    31.615828\n",
      "  55.26149   69.23797 ]\n",
      "reward:  -0.0600358403652361\n",
      "timestep:  1\n",
      "new state [385.53897   387.99573   423.5467    388.80322   402.77258     7.408211\n",
      "   5.7085104   5.003377 ]\n",
      "reward:  -0.07182985383357911\n",
      "timestep:  2\n",
      "new state [442.8      442.8      442.8      442.8      442.8       40.825855\n",
      "  86.69175  119.6945  ]\n",
      "reward:  -0.058787578307750235\n",
      "\n",
      "env reset!\n",
      "starting_state [442.8      442.8      442.8      442.8      442.8       43.107773\n",
      "  72.889244  96.54523 ]\n",
      "timestep:  0\n",
      "new state [401.3134  401.6644  406.82162 401.78134 399.7282   59.03257  76.00735\n",
      " 186.46773]\n",
      "reward:  -1.502384531165292\n",
      "timestep:  1\n",
      "new state [344.73248 344.82617 345.32156 344.85947 316.58374  46.40552  60.88712\n",
      "  69.12301]\n",
      "reward:  -1.5452279685776542\n",
      "timestep:  2\n",
      "new state [552.8      552.8      552.8      552.8      552.8       35.454304\n",
      "  45.711605  91.2795  ]\n",
      "reward:  -0.06702853187020068\n",
      "\n",
      "env reset!\n",
      "starting_state [552.8      552.8      552.8      552.8      552.8       10.137753\n",
      "  15.071907  24.344309]\n",
      "timestep:  0\n",
      "new state [513.8856   514.0188   516.03534  514.0622   507.62625   16.575438\n",
      "  20.421974  11.437711]\n",
      "reward:  -0.09038118367392038\n",
      "timestep:  1\n",
      "new state [470.1925   471.00616  482.64362  471.27417  486.38965   50.849857\n",
      "  33.050377  35.747803]\n",
      "reward:  -0.0274683910804271\n",
      "timestep:  2\n",
      "new state [267.1       267.1       267.1       267.1       267.1         5.3387046\n",
      "   6.8743305  10.026472 ]\n",
      "reward:  -0.07127883445331139\n",
      "\n",
      "env reset!\n",
      "starting_state [267.1      267.1      267.1      267.1      267.1       34.193443\n",
      "  31.744572  41.337948]\n",
      "timestep:  0\n",
      "new state [246.32938  246.33826  246.52682  246.34103  248.64975   40.95963\n",
      "  25.543276  84.976944]\n",
      "reward:  -1.5045589982240302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  1\n",
      "new state [220.68982  220.28252  213.8879   220.14766  210.75671    7.120119\n",
      "  11.146607  21.087925]\n",
      "reward:  -1.55916788873085\n",
      "timestep:  2\n",
      "new state [204.        204.        204.        204.        204.          5.396743\n",
      "   6.1037455   5.957112 ]\n",
      "reward:  -0.24598229676085778\n",
      "\n",
      "env reset!\n",
      "starting_state [204.       204.       204.       204.       204.         9.975209\n",
      "  13.237509  11.401019]\n",
      "timestep:  0\n",
      "new state [196.84688   196.92493   198.14479   196.95074   198.9089      7.8532887\n",
      "   8.1733885  12.701206 ]\n",
      "reward:  -1.4759733419726582\n",
      "timestep:  1\n",
      "new state [191.41275  191.49051  192.69563  191.51625  193.24213    8.361709\n",
      "   9.827693  14.049187]\n",
      "reward:  -1.5149738260725085\n",
      "timestep:  2\n",
      "new state [237.8      237.8      237.8      237.8      237.8       32.564133\n",
      "  44.00888   19.04667 ]\n",
      "reward:  -0.2002787459994398\n",
      "\n",
      "env reset!\n",
      "starting_state [237.8       237.8       237.8       237.8       237.8         7.13509\n",
      "   7.0053797   8.972207 ]\n",
      "timestep:  0\n",
      "new state [233.30957   233.31631   233.42871   233.31853   233.79555     6.7450175\n",
      "  10.266819    8.89521  ]\n",
      "reward:  -1.5031950111745356\n",
      "timestep:  1\n",
      "new state [210.91217  211.2331   215.84529  211.33876  229.82396   29.480658\n",
      "  62.709015  28.188992]\n",
      "reward:  -0.14065811585114485\n",
      "timestep:  2\n",
      "new state [216.3      216.3      216.3      216.3      216.3        8.49617\n",
      "   9.870622  19.917051]\n",
      "reward:  -1.0173689613505963\n",
      "\n",
      "env reset!\n",
      "starting_state [216.3      216.3      216.3      216.3      216.3       43.553753\n",
      "  51.018826   1.      ]\n",
      "timestep:  0\n",
      "new state [193.1971   193.69316  201.74493  193.85658  215.80719   28.891655\n",
      "  43.605488  66.644516]\n",
      "reward:  -1.396222860773881\n",
      "timestep:  1\n",
      "new state [166.70062  167.32632  177.19687  167.53314  186.07881    6.440929\n",
      "  11.940363  19.323053]\n",
      "reward:  -1.5129032162597162\n",
      "timestep:  2\n",
      "new state [357.5      357.5      357.5      357.5      357.5       42.459766\n",
      "  47.76331   81.45516 ]\n",
      "reward:  -0.22840183581008536\n",
      "\n",
      "env reset!\n",
      "starting_state [357.5       357.5       357.5       357.5       357.5         6.072765\n",
      "   8.961958    7.5151615]\n",
      "timestep:  0\n",
      "new state [337.9388    338.21298   342.134     338.3033    354.14426     6.4800186\n",
      "   7.7414865  16.02442  ]\n",
      "reward:  -0.13630651740839222\n",
      "timestep:  1\n",
      "new state [315.162    315.35623  318.19843  315.41995  324.41025    8.881566\n",
      "  12.235224   1.      ]\n",
      "reward:  -0.10729506043542134\n",
      "timestep:  2\n",
      "new state [323.9      323.9      323.9      323.9      323.9       75.30197\n",
      "  49.787437 157.8408  ]\n",
      "reward:  0.030236988568363526\n",
      "\n",
      "env reset!\n",
      "starting_state [323.9      323.9      323.9      323.9      323.9       48.901306\n",
      "  35.69111   80.94333 ]\n",
      "timestep:  0\n",
      "new state [294.32715  294.04062  289.55792  293.9457   287.795     75.08307\n",
      "  35.721703 140.8654  ]\n",
      "reward:  -1.5380463379290106\n",
      "timestep:  1\n",
      "new state [252.48267  251.31789  233.0964   250.93216  224.97986   49.725544\n",
      "  55.137745  53.014866]\n",
      "reward:  -1.5654936048528598\n",
      "timestep:  2\n",
      "new state [457.3       457.3       457.3       457.3       457.3        11.368492\n",
      "   9.109175    3.2090178]\n",
      "reward:  -1.48491486569755\n",
      "\n",
      "env reset!\n",
      "starting_state [457.3      457.3      457.3      457.3      457.3       35.169315\n",
      "  48.360188 143.0966  ]\n",
      "timestep:  0\n",
      "new state [296.7215   295.21112  413.4372   294.7096   393.5044    43.604095\n",
      "  53.093307  87.836815]\n",
      "reward:  -0.5140053875609596\n",
      "timestep:  1\n",
      "new state [262.0943   260.6228   271.2038   260.13458  354.3221    12.554457\n",
      "  15.851812  31.110483]\n",
      "reward:  -1.084500574295478\n",
      "timestep:  2\n",
      "new state [267.4       267.4       267.4       267.4       267.4         5.4419436\n",
      "   8.997729   11.274322 ]\n",
      "reward:  -0.10381315725825511\n",
      "\n",
      "env reset!\n",
      "starting_state [267.4      267.4      267.4      267.4      267.4       72.91635\n",
      "  81.09839   65.628204]\n",
      "timestep:  0\n",
      "new state [221.96973 222.3585  228.60391 222.4867  238.08365  51.48809  77.73339\n",
      " 161.97849]\n",
      "reward:  -1.4750727531234176\n",
      "timestep:  1\n",
      "new state [169.31845  169.69283  175.1065   169.81769  165.85275   25.859259\n",
      "  24.853472 117.73947 ]\n",
      "reward:  -1.5346040881723724\n",
      "timestep:  2\n",
      "new state [563.6      563.6      563.6      563.6      563.6       48.089382\n",
      "  51.59186   55.553387]\n",
      "reward:  -1.5828621425294336\n",
      "\n",
      "env reset!\n",
      "starting_state [563.6      563.6      563.6      563.6      563.6       15.902522\n",
      "  15.575613  42.808907]\n",
      "timestep:  0\n",
      "new state [510.124    509.5546   501.58063  509.36627  484.16943   14.022411\n",
      "  28.343363  17.737574]\n",
      "reward:  -0.12480853544272962\n",
      "timestep:  1\n",
      "new state [455.30695  455.97406  465.7335   456.19287  451.2433    44.991974\n",
      "  64.075874 106.55253 ]\n",
      "reward:  -0.02324897280039716\n",
      "timestep:  2\n",
      "new state [285.7      285.7      285.7      285.7      285.7       14.01077\n",
      "  18.93984   42.794197]\n",
      "reward:  -0.09247011302586182\n",
      "\n",
      "env reset!\n",
      "starting_state [285.7      285.7      285.7      285.7      285.7       78.967766\n",
      "  92.62216  157.21219 ]\n",
      "timestep:  0\n",
      "new state [224.26779 224.28513 224.24576 224.29153 215.57147  71.12784 156.0503\n",
      " 254.4975 ]\n",
      "reward:  -1.5205043433124559\n",
      "timestep:  1\n",
      "new state [133.2784   133.9784   143.38312  134.21375  102.07162   29.900322\n",
      "  34.581482  75.42273 ]\n",
      "reward:  -1.5169723388098788\n",
      "timestep:  2\n",
      "new state [594.       594.       594.       594.       594.        22.101727\n",
      "  24.940092  45.279736]\n",
      "reward:  -1.5371069435777045\n",
      "\n",
      "env reset!\n",
      "starting_state [594.       594.       594.       594.       594.        21.276386\n",
      "  29.381393  66.78958 ]\n",
      "timestep:  0\n",
      "new state [506.96393  506.6192   502.05698  506.50403  470.0733    33.637905\n",
      "  35.926395  60.168987]\n",
      "reward:  -0.11393251182150706\n",
      "timestep:  1\n",
      "new state [405.93274  405.4815   399.4856   405.3308   358.41904    9.708793\n",
      "  12.176678  21.292076]\n",
      "reward:  -0.0933099065510677\n",
      "timestep:  2\n",
      "new state [393.1      393.1      393.1      393.1      393.1       58.966087\n",
      "  73.504585  49.87436 ]\n",
      "reward:  -0.0960185161311124\n",
      "\n",
      "env reset!\n",
      "starting_state [393.1      393.1      393.1      393.1      393.1       45.40345\n",
      "  33.925877  82.01129 ]\n",
      "timestep:  0\n",
      "new state [364.54852  364.2577   359.66663  364.16144  356.52185   33.562126\n",
      "  72.61967   71.638824]\n",
      "reward:  -1.5419457387217474\n",
      "timestep:  1\n",
      "new state [212.29659   214.52449   246.37708   215.25621   324.5515      6.9421844\n",
      "  15.354708   18.528416 ]\n",
      "reward:  -0.1617751871843125\n",
      "timestep:  2\n",
      "new state [464.       464.       464.       464.       464.        41.18397\n",
      "  93.436844 197.89563 ]\n",
      "reward:  -0.06783598938516647\n",
      "\n",
      "env reset!\n",
      "starting_state [464.        464.        464.        464.        464.          8.760305\n",
      "   5.5812435   1.5295761]\n",
      "timestep:  0\n",
      "new state [449.68896   449.7577    450.60767   449.78085   461.1553      7.0143614\n",
      "   6.200111   10.581147 ]\n",
      "reward:  -0.025693084242648705\n",
      "timestep:  1\n",
      "new state [431.23663  431.23502  431.07095  431.235    441.51962   29.950949\n",
      "  68.60144  108.1626  ]\n",
      "reward:  -0.09472055913038317\n",
      "timestep:  2\n",
      "new state [472.9      472.9      472.9      472.9      472.9      102.919235\n",
      "  66.252045 135.50792 ]\n",
      "reward:  -0.08793900952796721\n",
      "\n",
      "env reset!\n",
      "starting_state [472.9      472.9      472.9      472.9      472.9       33.60332\n",
      "  57.009018  56.126793]\n",
      "timestep:  0\n",
      "new state [347.94946  349.6515   374.17255  350.21136  447.8485    36.321156\n",
      "  32.097343  22.286491]\n",
      "reward:  -0.158376094191403\n",
      "timestep:  1\n",
      "new state [269.2765   271.5321   303.62396  272.27576  406.47064   19.484802\n",
      "  21.746786  21.200073]\n",
      "reward:  -0.045246268290456\n",
      "timestep:  2\n",
      "new state [221.7       221.7       221.7       221.7       221.7         9.273838\n",
      "   7.4962244   6.80624  ]\n",
      "reward:  -0.059222070004180755\n",
      "\n",
      "env reset!\n",
      "starting_state [221.7      221.7      221.7      221.7      221.7       18.730669\n",
      "  12.072046  12.40901 ]\n",
      "timestep:  0\n",
      "new state [213.18002  213.14725  212.74246  213.13611  216.156     14.357786\n",
      "  11.766319  30.252405]\n",
      "reward:  -1.495377119244115\n",
      "timestep:  1\n",
      "new state [203.3021   203.1715   201.19504  203.12805  202.66458    5.742756\n",
      "   8.286935   8.829516]\n",
      "reward:  -1.5461345555059067\n",
      "timestep:  2\n",
      "new state [170.       170.       170.       170.       170.        14.507949\n",
      "  18.000618  64.7807  ]\n",
      "reward:  -0.06204922625803721\n",
      "\n",
      "env reset!\n",
      "starting_state [170.        170.        170.        170.        170.          5.2659383\n",
      "   8.845427    8.063645 ]\n",
      "timestep:  0\n",
      "new state [165.4177   165.48074  166.44666  165.50165  166.40034    5.69863\n",
      "   7.238175  16.642036]\n",
      "reward:  -1.4765775880378609\n",
      "timestep:  1\n",
      "new state [160.15558  160.19974  160.81638  160.21451  158.97935   26.489044\n",
      "  44.003128  91.44425 ]\n",
      "reward:  -1.5408744307510347\n",
      "timestep:  2\n",
      "new state [312.5      312.5      312.5      312.5      312.5       49.409008\n",
      "  50.888496  74.72257 ]\n",
      "reward:  -1.5345749244865372\n",
      "\n",
      "env reset!\n",
      "starting_state [312.5      312.5      312.5      312.5      312.5       42.88406\n",
      "  63.042206 135.53072 ]\n",
      "timestep:  0\n",
      "new state [269.0726   269.0264   267.80334  269.01227  252.06404   46.853836\n",
      "  54.501648  81.48021 ]\n",
      "reward:  -1.5367085139439034\n",
      "timestep:  1\n",
      "new state [234.23848  234.26152  234.00316  234.27054  215.71149   53.78755\n",
      "  52.087612  18.043081]\n",
      "reward:  -1.5121431859971273\n",
      "timestep:  2\n",
      "new state [640.9      640.9      640.9      640.9      640.9       82.173065\n",
      " 134.53383   57.94256 ]\n",
      "reward:  -0.9813766094389682\n",
      "\n",
      "env reset!\n",
      "starting_state [640.9      640.9      640.9      640.9      640.9       59.432037\n",
      "  85.04154   81.5292  ]\n",
      "timestep:  0\n",
      "new state [448.6134   450.85724  483.0027   451.5961   489.58298   33.977608\n",
      "  73.60994   60.90982 ]\n",
      "reward:  -0.055267296771477716\n",
      "timestep:  1\n",
      "new state [300.39127  305.52063  379.25134  307.2087   376.53537   32.893726\n",
      "  32.738102  51.507683]\n",
      "reward:  -0.04062624417480129\n",
      "timestep:  2\n",
      "new state [358.7      358.7      358.7      358.7      358.7       17.141262\n",
      "  32.127758  15.155621]\n",
      "reward:  -0.08944899393822511\n",
      "\n",
      "env reset!\n",
      "starting_state [358.7      358.7      358.7      358.7      358.7       16.917152\n",
      "  15.609214  16.31908 ]\n",
      "timestep:  0\n",
      "new state [318.16074   318.3037    320.24695   318.3512    351.41312    10.1829605\n",
      "  11.311356    8.105378 ]\n",
      "reward:  -0.15558966549448408\n",
      "timestep:  1\n",
      "new state [292.28372  292.71512  298.71765  292.85788  336.3661    37.911407\n",
      "  57.753685 119.89824 ]\n",
      "reward:  -0.04214899587095534\n",
      "timestep:  2\n",
      "new state [443.6      443.6      443.6      443.6      443.6       84.632385\n",
      "  66.2095   149.5492  ]\n",
      "reward:  -0.25794161222689305\n",
      "\n",
      "env reset!\n",
      "starting_state [443.6      443.6      443.6      443.6      443.6        8.648337\n",
      "  10.505556   9.598814]\n",
      "timestep:  0\n",
      "new state [419.10367  419.34406  422.75766  419.42337  425.78366    8.534402\n",
      "   9.458114  12.112463]\n",
      "reward:  -0.054302554840792494\n",
      "timestep:  1\n",
      "new state [394.68304 395.01306 399.70367 395.12192 403.30484  67.76523  98.37852\n",
      " 188.71396]\n",
      "reward:  -0.07597904566441173\n",
      "timestep:  2\n",
      "new state [398.8      398.8      398.8      398.8      398.8       36.08509\n",
      "  39.236446  37.480347]\n",
      "reward:  -1.5288106428055819\n",
      "\n",
      "env reset!\n",
      "starting_state [398.8      398.8      398.8      398.8      398.8       53.609783\n",
      "  69.15142   93.68984 ]\n",
      "timestep:  0\n",
      "new state [356.87628 357.07532 360.0187  357.14157 356.99698  48.09443  85.16225\n",
      " 178.50134]\n",
      "reward:  -1.5052157567693771\n",
      "timestep:  1\n",
      "new state [300.5675  300.82465 303.9039  300.912   277.40265  37.23455  54.19108\n",
      "  84.4289 ]\n",
      "reward:  -1.535284312054958\n",
      "timestep:  2\n",
      "new state [576.5      576.5      576.5      576.5      576.5       27.206663\n",
      "  41.536083   5.398255]\n",
      "reward:  -0.21738665966747808\n",
      "\n",
      "env reset!\n",
      "starting_state [576.5      576.5      576.5      576.5      576.5       39.51871\n",
      "  62.034103 173.62975 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  0\n",
      "new state [379.89883  378.45667  359.0279   377.97644  499.09198   70.727875\n",
      "  63.94251   93.313   ]\n",
      "reward:  -0.2984992178355986\n",
      "timestep:  1\n",
      "new state [336.46426  334.96506  314.71234  334.46567  325.91968   35.703125\n",
      "  48.16002   61.922764]\n",
      "reward:  -1.2310680388622672\n",
      "timestep:  2\n",
      "new state [568.2      568.2      568.2      568.2      568.2       53.196083\n",
      "   9.91678   89.91135 ]\n",
      "reward:  -0.07505746879200134\n",
      "\n",
      "env reset!\n",
      "starting_state [568.2     568.2     568.2     568.2     568.2      36.24253  64.35823\n",
      "  59.30623]\n",
      "timestep:  0\n",
      "new state [430.5261   432.62708  462.8744   433.31833  458.13074   43.5855\n",
      "  49.650078  51.289314]\n",
      "reward:  -0.050258087204407505\n",
      "timestep:  1\n",
      "new state [309.62933  312.59497  355.09143  313.57147  362.93732   34.74719\n",
      "  43.892017  81.34888 ]\n",
      "reward:  -0.06244727613626208\n",
      "timestep:  2\n",
      "new state [563.4     563.4     563.4     563.4     563.4      88.398    97.89396\n",
      " 199.51474]\n",
      "reward:  -0.09994841829703129\n",
      "\n",
      "env reset!\n",
      "starting_state [563.4      563.4      563.4      563.4      563.4       19.60891\n",
      "  10.847639  22.760033]\n",
      "timestep:  0\n",
      "new state [523.3655    522.84076   515.21124   522.66833   521.16266     8.09595\n",
      "  18.542501    7.0146136]\n",
      "reward:  -0.10623825315753432\n",
      "timestep:  1\n",
      "new state [490.69977  491.15506  497.55234  491.30545  508.13654    5.648247\n",
      "  11.647231  20.138252]\n",
      "reward:  0.007737500162500729\n",
      "timestep:  2\n",
      "new state [113.3       113.3       113.3       113.3       113.3         9.192139\n",
      "   9.424058    9.3811455]\n",
      "reward:  -0.09496288438030809\n",
      "\n",
      "env reset!\n",
      "starting_state [113.3      113.3      113.3      113.3      113.3        9.077349\n",
      "   5.139045  17.247025]\n",
      "timestep:  0\n",
      "new state [107.971214  107.87859   106.42463   107.84794   105.608826    6.418506\n",
      "   6.6911726   5.971604 ]\n",
      "reward:  -1.558731198272553\n",
      "timestep:  1\n",
      "new state [104.08015  104.01257  102.96588  103.990166 102.94174   74.924\n",
      "  49.702732  99.698296]\n",
      "reward:  -1.481495366380575\n",
      "timestep:  2\n",
      "new state [506.3      506.3      506.3      506.3      506.3       67.775085\n",
      "  74.19544   67.98529 ]\n",
      "reward:  -1.5306039998715872\n",
      "\n",
      "env reset!\n",
      "starting_state [506.3      506.3      506.3      506.3      506.3       46.976486\n",
      "  42.63326   92.41359 ]\n",
      "timestep:  0\n",
      "new state [370.16833  369.17722  355.16116  368.8499   465.08215   48.35976\n",
      "  57.512817  76.2418  ]\n",
      "reward:  -0.2465348670637355\n",
      "timestep:  1\n",
      "new state [223.00185  222.61838  217.36005  222.49088  323.59308   39.86509\n",
      "  43.393986  62.079388]\n",
      "reward:  -0.0777750331856045\n",
      "timestep:  2\n",
      "new state [346.        346.        346.        346.        346.          3.2040584\n",
      "  11.306632    1.7282629]\n",
      "reward:  -1.2168382294034157\n",
      "\n",
      "env reset!\n",
      "starting_state [346.        346.        346.        346.        346.          4.8178806\n",
      "  13.26999    20.839603 ]\n",
      "timestep:  0\n",
      "new state [315.15198  315.44373  319.79346  315.53906  336.7063    11.012333\n",
      "  14.259009  30.54517 ]\n",
      "reward:  -0.23175015767328783\n",
      "timestep:  1\n",
      "new state [273.36298  273.51385  275.99585  273.56216  280.02933   43.476906\n",
      "  16.230469  74.36156 ]\n",
      "reward:  -0.10976015283987738\n",
      "timestep:  2\n",
      "new state [302.8      302.8      302.8      302.8      302.8        8.208014\n",
      "  10.970992  18.40127 ]\n",
      "reward:  -0.2930504357509589\n",
      "\n",
      "env reset!\n",
      "starting_state [302.8      302.8      302.8      302.8      302.8       17.698023\n",
      "  15.023893  33.569214]\n",
      "timestep:  0\n",
      "new state [290.9373   290.84726  289.40552  290.8175   287.82755   13.728886\n",
      "  19.553621  47.191288]\n",
      "reward:  -1.5377058123852818\n",
      "timestep:  1\n",
      "new state [231.91669  231.53629  226.22128  231.40965  266.78577   67.167595\n",
      "  67.565704 131.93954 ]\n",
      "reward:  -0.2762218514528795\n",
      "timestep:  2\n",
      "new state [554.6      554.6      554.6      554.6      554.6       46.962765\n",
      "  73.49508  152.8346  ]\n",
      "reward:  -1.5296358547429363\n",
      "\n",
      "env reset!\n",
      "starting_state [554.6      554.6      554.6      554.6      554.6       42.640495\n",
      "  66.17611   12.99464 ]\n",
      "timestep:  0\n",
      "new state [433.87408  437.18427  484.16672  438.27625  530.4392    42.420963\n",
      "  42.42093  149.11977 ]\n",
      "reward:  0.019548556295383972\n",
      "timestep:  1\n",
      "new state [272.0245    272.89886   285.83124   273.18494   463.95947     3.754453\n",
      "  10.728432    7.5455666]\n",
      "reward:  -0.311823842709322\n",
      "timestep:  2\n",
      "new state [423.5      423.5      423.5      423.5      423.5       75.334785\n",
      "  48.09658   51.355785]\n",
      "reward:  -0.02586897514966743\n",
      "\n",
      "env reset!\n",
      "starting_state [423.5      423.5      423.5      423.5      423.5       46.966454\n",
      "  42.0583     1.      ]\n",
      "timestep:  0\n",
      "new state [335.51974  337.06622  358.4758   337.57855  421.6004    24.042208\n",
      "  38.755566  82.82533 ]\n",
      "reward:  0.013891507699150705\n",
      "timestep:  1\n",
      "new state [226.49214 227.88731 247.65181 228.34756 384.66785  37.9716   53.52433\n",
      "  59.40087]\n",
      "reward:  -0.263451235251486\n",
      "timestep:  2\n",
      "new state [473.3      473.3      473.3      473.3      473.3       43.403957\n",
      "  54.507854 140.09032 ]\n",
      "reward:  -0.914728862738415\n",
      "\n",
      "env reset!\n",
      "starting_state [473.3      473.3      473.3      473.3      473.3       10.125242\n",
      "  19.976053  45.815742]\n",
      "timestep:  0\n",
      "new state [417.19574  417.11646  416.32645  417.08887  388.29214   12.134896\n",
      "  19.819057  36.660152]\n",
      "reward:  -0.11546240313595894\n",
      "timestep:  1\n",
      "new state [364.51685   364.52728   365.23532   364.52832   320.2679      7.1837807\n",
      "   4.037506   11.16719  ]\n",
      "reward:  -0.09989372559387848\n",
      "timestep:  2\n",
      "new state [230.1      230.1      230.1      230.1      230.1       13.681161\n",
      "  47.303646  74.70519 ]\n",
      "reward:  -0.12152327356927073\n",
      "\n",
      "env reset!\n",
      "starting_state [230.1     230.1     230.1     230.1     230.1      51.68909  39.60568\n",
      " 123.81619]\n",
      "timestep:  0\n",
      "new state [193.48218  192.99554  185.1666   192.83493  174.89053   45.431866\n",
      "  30.204258 101.48318 ]\n",
      "reward:  -1.5573637705802308\n",
      "timestep:  1\n",
      "new state [163.58197   162.62634   147.33209   162.31073   129.63892    12.048583\n",
      "   5.3104997  10.341951 ]\n",
      "reward:  -1.5603169782429032\n",
      "timestep:  2\n",
      "new state [322.1      322.1      322.1      322.1      322.1       35.117516\n",
      "  45.045807  39.47191 ]\n",
      "reward:  -0.42960206107040605\n",
      "\n",
      "env reset!\n",
      "starting_state [322.1     322.1     322.1     322.1     322.1      37.10835  80.3216\n",
      "  50.47956]\n",
      "timestep:  0\n",
      "new state [285.28397  286.08868  298.4825   286.3555   299.55115   31.311005\n",
      "  68.57273   87.74197 ]\n",
      "reward:  -1.4487606431040154\n",
      "timestep:  1\n",
      "new state [248.31511  249.55637  268.36697  249.96866  260.40952   89.50899\n",
      " 101.893684  97.4443  ]\n",
      "reward:  -1.49870323938827\n",
      "timestep:  2\n",
      "new state [645.7      645.7      645.7      645.7      645.7       40.498337\n",
      "  61.951805  56.39791 ]\n",
      "reward:  -1.4842686230492035\n",
      "\n",
      "env reset!\n",
      "starting_state [645.7      645.7      645.7      645.7      645.7       60.89885\n",
      "  93.65985   60.738705]\n",
      "timestep:  0\n",
      "new state [452.4464   455.91354  505.3798   457.05615  532.94635   36.809868\n",
      "  81.66664   84.302216]\n",
      "reward:  -0.030394563800757425\n",
      "timestep:  1\n",
      "new state [279.99268  286.22247  375.72845  288.27298  376.49808   36.449165\n",
      "  73.52696   85.32822 ]\n",
      "reward:  -0.056228246123280846\n",
      "timestep:  2\n",
      "new state [651.5      651.5      651.5      651.5      651.5       56.152573\n",
      "  43.663044 101.74984 ]\n",
      "reward:  -0.5765913751367345\n",
      "\n",
      "env reset!\n",
      "starting_state [651.5      651.5      651.5      651.5      651.5       34.027843\n",
      "  53.530132  50.63875 ]\n",
      "timestep:  0\n",
      "new state [533.37366  534.93506  557.3643   535.449    557.5163    54.052227\n",
      "  38.05183   64.70092 ]\n",
      "reward:  -0.05333963646532279\n",
      "timestep:  1\n",
      "new state [411.93176 412.64575 422.67865 412.88153 437.44357  35.20498  65.63593\n",
      " 217.53984]\n",
      "reward:  -0.09476189329233439\n",
      "timestep:  2\n",
      "new state [525.6      525.6      525.6      525.6      525.6       51.899887\n",
      "  42.987217 131.81314 ]\n",
      "reward:  -0.32433363025293344\n",
      "\n",
      "env reset!\n",
      "starting_state [525.6       525.6       525.6       525.6       525.6         3.5835872\n",
      "  11.536039   10.604113 ]\n",
      "timestep:  0\n",
      "new state [503.1381   503.62723  510.71848  503.78796  505.92072    2.740631\n",
      "   6.006493  13.085949]\n",
      "reward:  -0.04463049227008066\n",
      "timestep:  1\n",
      "new state [486.85626  487.35272  494.65192  487.5154   481.6406    16.922613\n",
      "  61.15739  110.63368 ]\n",
      "reward:  -0.1119909583500136\n",
      "timestep:  2\n",
      "new state [254.9      254.9      254.9      254.9      254.9       20.224886\n",
      "  33.344955  48.69424 ]\n",
      "reward:  -0.09831120906531073\n",
      "\n",
      "env reset!\n",
      "starting_state [254.9      254.9      254.9      254.9      254.9        9.672476\n",
      "   9.099977  15.319438]\n",
      "timestep:  0\n",
      "new state [248.53374  248.51778  248.26213  248.5125   248.06534    8.313873\n",
      "   8.112054  17.591297]\n",
      "reward:  -1.520227031555584\n",
      "timestep:  1\n",
      "new state [223.09967  222.9189   220.34923  222.85912  240.21968   22.84295\n",
      "  36.160473  29.250187]\n",
      "reward:  -0.2493113024613131\n",
      "timestep:  2\n",
      "new state [178.4      178.4      178.4      178.4      178.4       19.509071\n",
      "  20.405401  34.33713 ]\n",
      "reward:  -0.043184306685614744\n",
      "\n",
      "env reset!\n",
      "starting_state [178.4     178.4     178.4     178.4     178.4      68.18494 106.23563\n",
      " 141.49883]\n",
      "timestep:  0\n",
      "new state [116.8654   117.32114  124.02579  117.472946 115.27081   60.389053\n",
      " 108.39385  105.72108 ]\n",
      "reward:  -1.5031530801988162\n",
      "timestep:  1\n",
      "new state [60.595276  61.824062  80.283714  62.23252   68.08451   38.870117\n",
      " 60.651524   4.2691054]\n",
      "reward:  -1.4804484757547303\n",
      "timestep:  2\n",
      "new state [629.8      629.8      629.8      629.8      629.8       39.511646\n",
      "  72.20736   86.31831 ]\n",
      "reward:  -1.3880492099524646\n",
      "\n",
      "env reset!\n",
      "starting_state [629.8      629.8      629.8      629.8      629.8       23.630016\n",
      "  53.624878 165.23486 ]\n",
      "timestep:  0\n",
      "new state [459.95477  458.6844   441.9109   458.25995  556.1443    57.01018\n",
      "  60.347954 107.4253  ]\n",
      "reward:  -0.3199346339771015\n",
      "timestep:  1\n",
      "new state [286.5654  284.91705 262.93823 284.36713 356.8009   58.90677  73.86163\n",
      " 113.98376]\n",
      "reward:  -0.09726614221833722\n",
      "timestep:  2\n",
      "new state [451.5      451.5      451.5      451.5      451.5        5.199422\n",
      "   8.999567  11.531258]\n",
      "reward:  -1.5140318504817378\n",
      "\n",
      "env reset!\n",
      "starting_state [451.5      451.5      451.5      451.5      451.5       35.979908\n",
      "  42.256226  71.03247 ]\n",
      "timestep:  0\n",
      "new state [335.24216  335.24707  335.49893  335.2478   419.81378   39.213387\n",
      "  42.958088  71.78563 ]\n",
      "reward:  -0.22177501710585443\n",
      "timestep:  1\n",
      "new state [215.28194   215.20271   214.37772   215.17511   286.60315     7.3372307\n",
      "   7.7558074  12.387713 ]\n",
      "reward:  -0.09313225560706508\n",
      "timestep:  2\n",
      "new state [299.8      299.8      299.8      299.8      299.8       22.23724\n",
      "  38.209564  38.80978 ]\n",
      "reward:  -0.09026912733296451\n",
      "\n",
      "env reset!\n",
      "starting_state [299.8     299.8     299.8     299.8     299.8      67.93089  80.40699\n",
      " 217.3624 ]\n",
      "timestep:  0\n",
      "new state [236.4281   235.98892  228.40427  235.84523  202.88435   75.81123\n",
      "  60.455784  25.882843]\n",
      "reward:  -1.5511892385552075\n",
      "timestep:  1\n",
      "new state [201.56987  201.34564  197.63591  201.27173  191.28464   46.51531\n",
      "  46.771637  80.83141 ]\n",
      "reward:  -1.4554694992387192\n",
      "timestep:  2\n",
      "new state [467.4       467.4       467.4       467.4       467.4         7.8861012\n",
      "   4.584201   12.7137   ]\n",
      "reward:  -1.5218161163033372\n",
      "\n",
      "env reset!\n",
      "starting_state [467.4      467.4      467.4      467.4      467.4       52.81623\n",
      "  35.049046  93.748856]\n",
      "timestep:  0\n",
      "new state [335.52914  333.66714  307.04202  333.0536   425.58813   38.648792\n",
      "  47.95612  114.60722 ]\n",
      "reward:  -0.2600031665863491\n",
      "timestep:  1\n",
      "new state [299.958    297.9375   268.46503  297.27234  374.4839    62.887608\n",
      "  68.63606   48.027397]\n",
      "reward:  -1.5433604075008274\n",
      "timestep:  2\n",
      "new state [394.6       394.6       394.6       394.6       394.6         4.983289\n",
      "   9.993295    1.9410572]\n",
      "reward:  -0.04126575742106239\n",
      "\n",
      "env reset!\n",
      "starting_state [394.6      394.6      394.6      394.6      394.6       15.260735\n",
      "  11.482609  66.36949 ]\n",
      "timestep:  0\n",
      "new state [334.43988  332.90063  311.26685  332.39188  365.01703   23.294195\n",
      "  24.174845  30.15373 ]\n",
      "reward:  -0.35642317102568477\n",
      "timestep:  1\n",
      "new state [271.31982   269.97565   251.08075   269.5313    309.0551      7.01128\n",
      "   7.566665    7.6300273]\n",
      "reward:  -0.07477684836533074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  2\n",
      "new state [308.7      308.7      308.7      308.7      308.7       49.596004\n",
      "  27.82501   10.060733]\n",
      "reward:  -0.061612233726948164\n",
      "\n",
      "env reset!\n",
      "starting_state [308.7      308.7      308.7      308.7      308.7       41.31072\n",
      "  52.407177  95.68648 ]\n",
      "timestep:  0\n",
      "new state [273.70554  273.7094   273.51584  273.71127  266.02197   31.152412\n",
      "  69.70468  113.64171 ]\n",
      "reward:  -1.525362289868019\n",
      "timestep:  1\n",
      "new state [233.17908  233.49405  237.60779  233.60023  215.34076   11.565746\n",
      "  19.625528  35.917618]\n",
      "reward:  -1.5169250468548707\n",
      "timestep:  2\n",
      "new state [288.7      288.7      288.7      288.7      288.7       20.998123\n",
      "  27.793528  59.579525]\n",
      "reward:  -0.24348709265338075\n",
      "\n",
      "env reset!\n",
      "starting_state [288.7      288.7      288.7      288.7      288.7       52.72184\n",
      "  55.522614  90.40519 ]\n",
      "timestep:  0\n",
      "new state [251.38107  251.36162  250.95831  251.35535  248.36766   45.581596\n",
      "  79.116684  74.49585 ]\n",
      "reward:  -1.5179391806277718\n",
      "timestep:  1\n",
      "new state [210.37247  210.91803  219.1396   211.09924  215.11517   20.003832\n",
      "  27.409702  59.636425]\n",
      "reward:  -1.4783857687111452\n",
      "timestep:  2\n",
      "new state [297.4      297.4      297.4      297.4      297.4       11.660681\n",
      "  12.539161  13.080906]\n",
      "reward:  -0.2611871707002908\n",
      "\n",
      "env reset!\n",
      "starting_state [297.4      297.4      297.4      297.4      297.4       61.309956\n",
      "  71.836784 122.0361  ]\n",
      "timestep:  0\n",
      "new state [249.72928  249.74152  249.69243  249.7461   242.96268   51.056732\n",
      "  85.04916  143.0995  ]\n",
      "reward:  -1.520561941982791\n",
      "timestep:  1\n",
      "new state [197.36201  197.6033   200.59288  197.685    179.1395    23.894533\n",
      "  40.218304  76.06905 ]\n",
      "reward:  -1.5195541343294776\n",
      "timestep:  2\n",
      "new state [718.4      718.4      718.4      718.4      718.4       54.537197\n",
      "  93.56043  141.97952 ]\n",
      "reward:  -1.5279169286774457\n",
      "\n",
      "env reset!\n",
      "starting_state [718.4       718.4       718.4       718.4       718.4         4.5785327\n",
      "   9.066792   10.567382 ]\n",
      "timestep:  0\n",
      "new state [698.25525   698.5089    702.19727   698.5923    698.7897      5.7981653\n",
      "   6.592948   12.175989 ]\n",
      "reward:  -0.06589409572772668\n",
      "timestep:  1\n",
      "new state [679.4096    679.62604   682.8171    679.69696   676.1958      5.0177617\n",
      "   7.7672243   7.044707 ]\n",
      "reward:  -0.09967549820816844\n",
      "timestep:  2\n",
      "new state [207.6      207.6      207.6      207.6      207.6       58.870045\n",
      "  40.478016 112.15107 ]\n",
      "reward:  -0.050779202043634994\n",
      "\n",
      "env reset!\n",
      "starting_state [207.6      207.6      207.6      207.6      207.6       57.144665\n",
      " 110.01752   51.478374]\n",
      "timestep:  0\n",
      "new state [158.24655  159.38867  177.16196  159.76688  184.58127   33.188248\n",
      "  70.582565 142.22348 ]\n",
      "reward:  -1.4339480835396188\n",
      "timestep:  1\n",
      "new state [113.50368 114.79054 134.13568 115.21834 121.16456  95.10848  97.83995\n",
      " 135.98204]\n",
      "reward:  -1.532688259394146\n",
      "timestep:  2\n",
      "new state [513.9      513.9      513.9      513.9      513.9        9.112249\n",
      "  11.465247  25.486578]\n",
      "reward:  -1.507961696292656\n",
      "\n",
      "env reset!\n",
      "starting_state [513.9      513.9      513.9      513.9      513.9        8.970219\n",
      "   9.570055  15.914813]\n",
      "timestep:  0\n",
      "new state [487.03864  487.01306  486.6702   487.00455  484.3672    11.024592\n",
      "  15.763436  15.195174]\n",
      "reward:  -0.0928538417836305\n",
      "timestep:  1\n",
      "new state [451.34692  451.73462  457.31296  451.86218  456.16522   43.250664\n",
      "  50.57691   95.89465 ]\n",
      "reward:  -0.05562584939373903\n",
      "timestep:  2\n",
      "new state [405.6      405.6      405.6      405.6      405.6       77.499535\n",
      "  49.584866  76.46602 ]\n",
      "reward:  -0.10143080901108359\n",
      "\n",
      "env reset!\n",
      "starting_state [405.6       405.6       405.6       405.6       405.6         6.377598\n",
      "   6.05187     2.2457764]\n",
      "timestep:  0\n",
      "new state [392.13736   392.31506   394.7828    392.37393   401.42764     7.0513844\n",
      "   7.262021   23.258137 ]\n",
      "reward:  -0.018537625660727756\n",
      "timestep:  1\n",
      "new state [365.76733  365.60028  363.25485  365.54504  358.27432   10.442767\n",
      "  10.475312   8.356614]\n",
      "reward:  -0.13454968869520245\n",
      "timestep:  2\n",
      "new state [253.8      253.8      253.8      253.8      253.8       53.514565\n",
      "  42.384403 105.4081  ]\n",
      "reward:  -0.04962990473216872\n",
      "\n",
      "env reset!\n",
      "starting_state [253.8       253.8       253.8       253.8       253.8        28.961609\n",
      "  17.644724    5.6532435]\n",
      "timestep:  0\n",
      "new state [242.62743  242.63536  243.00401  242.63733  251.25801   50.59441\n",
      "  32.11641   36.165215]\n",
      "reward:  -1.4571149331134476\n",
      "timestep:  1\n",
      "new state [219.42696   219.32246   218.21143   219.28645   235.10397     6.5600696\n",
      "   6.290268   15.132929 ]\n",
      "reward:  -1.4999117941611588\n",
      "timestep:  2\n",
      "new state [174.2       174.2       174.2       174.2       174.2         7.4560738\n",
      "   8.290605    1.       ]\n",
      "reward:  -0.11635628051372915\n",
      "\n",
      "env reset!\n",
      "starting_state [174.2      174.2      174.2      174.2      174.2       20.493513\n",
      "  20.03147   56.196392]\n",
      "timestep:  0\n",
      "new state [157.50925  157.35391  154.77934  157.30284  149.14256   21.836515\n",
      "  12.353683  43.92662 ]\n",
      "reward:  -1.5524987212625616\n",
      "timestep:  1\n",
      "new state [144.38695   143.99478   137.69002   143.86534   129.55484    13.963061\n",
      "   3.9526715  42.259834 ]\n",
      "reward:  -1.5618991666562656\n",
      "timestep:  2\n",
      "new state [330.6      330.6      330.6      330.6      330.6       58.317585\n",
      "  94.88584   52.729427]\n",
      "reward:  -1.6032305375526026\n",
      "\n",
      "env reset!\n",
      "starting_state [330.6      330.6      330.6      330.6      330.6       18.382423\n",
      "  27.60437   15.548024]\n",
      "timestep:  0\n",
      "new state [317.15424 317.387   321.0408  317.464   323.6499    9.41874  17.17638\n",
      "  26.21136]\n",
      "reward:  -1.449551138458857\n",
      "timestep:  1\n",
      "new state [275.21503  275.72482  283.49728  275.89243  311.95865   36.315716\n",
      "  62.315144 154.86093 ]\n",
      "reward:  -0.21979520955450554\n",
      "timestep:  2\n",
      "new state [348.7      348.7      348.7      348.7      348.7       24.402864\n",
      "  22.88881   21.793228]\n",
      "reward:  -1.5470975373079003\n",
      "\n",
      "env reset!\n",
      "starting_state [348.7      348.7      348.7      348.7      348.7        5.652894\n",
      "   3.737667   8.455528]\n",
      "timestep:  0\n",
      "new state [335.42175  335.266    333.02362  335.21472  344.92813    8.592444\n",
      "  11.411427   9.920372]\n",
      "reward:  -0.23886204922200724\n",
      "timestep:  1\n",
      "new state [309.6818   309.83224  311.9542   309.8819   326.51483   33.198223\n",
      "  36.86261   25.18001 ]\n",
      "reward:  -0.0501041387285499\n",
      "timestep:  2\n",
      "new state [343.8      343.8      343.8      343.8      343.8       37.02626\n",
      "  61.242004 106.02195 ]\n",
      "reward:  -0.03968466918126517\n",
      "\n",
      "env reset!\n",
      "starting_state [343.8      343.8      343.8      343.8      343.8       28.437876\n",
      "  51.52373   42.579025]\n",
      "timestep:  0\n",
      "new state [318.06448  318.47818  324.82712  318.61536  324.78976   37.663555\n",
      "  54.62608  151.71185 ]\n",
      "reward:  -1.469152689516758\n",
      "timestep:  1\n",
      "new state [276.04047  276.21426  278.1981   276.2735   257.15143   24.213984\n",
      "  23.079662  28.369877]\n",
      "reward:  -1.5539001336581708\n",
      "timestep:  2\n",
      "new state [276.1      276.1      276.1      276.1      276.1        9.136531\n",
      "  12.523731  21.410742]\n",
      "reward:  -0.0745181757251925\n",
      "\n",
      "env reset!\n",
      "starting_state [276.1       276.1       276.1       276.1       276.1         4.23267\n",
      "   8.1589775  10.029881 ]\n",
      "timestep:  0\n",
      "new state [271.66098  271.7104   272.4427   271.72684  271.62518    6.454905\n",
      "  12.391931  10.147669]\n",
      "reward:  -1.4963564876747892\n",
      "timestep:  1\n",
      "new state [246.20792 246.71788 254.07425 246.8859  267.09467  68.53907 105.69028\n",
      " 138.0116 ]\n",
      "reward:  -0.1357732824421995\n",
      "timestep:  2\n",
      "new state [318.4       318.4       318.4       318.4       318.4         7.5205097\n",
      "   6.674473   10.792838 ]\n",
      "reward:  -1.5018212795447479\n",
      "\n",
      "env reset!\n",
      "starting_state [318.4      318.4      318.4      318.4      318.4        5.227116\n",
      "   9.870747  18.93303 ]\n",
      "timestep:  0\n",
      "new state [292.4309   292.48785  312.4063   292.50604  309.9572     9.218391\n",
      "  11.55042   10.210646]\n",
      "reward:  -0.44473594378089204\n",
      "timestep:  1\n",
      "new state [265.89542 266.23752 290.20963 266.34973 291.00507  64.14982  65.71093\n",
      " 160.15898]\n",
      "reward:  -0.051914665057426264\n",
      "timestep:  2\n",
      "new state [290.6      290.6      290.6      290.6      290.6        7.823077\n",
      "   5.89086   13.417999]\n",
      "reward:  -1.543888731219493\n",
      "\n",
      "env reset!\n",
      "starting_state [290.6      290.6      290.6      290.6      290.6       23.942022\n",
      "  61.929634  66.99105 ]\n",
      "timestep:  0\n",
      "new state [259.53546  260.04102  267.59015  260.20923  260.71054   52.322243\n",
      "  59.7715    36.9213  ]\n",
      "reward:  -1.4850966616540346\n",
      "timestep:  1\n",
      "new state [227.74634  228.61719  242.04567  228.90585  244.20494   15.413671\n",
      "  17.957012  19.642666]\n",
      "reward:  -1.4604484403334546\n",
      "timestep:  2\n",
      "new state [491.9      491.9      491.9      491.9      491.9       52.8399\n",
      "  49.007084  89.82153 ]\n",
      "reward:  -0.06572293408404083\n",
      "\n",
      "env reset!\n",
      "starting_state [491.9      491.9      491.9      491.9      491.9       20.87825\n",
      "  10.530228  30.673359]\n",
      "timestep:  0\n",
      "new state [447.19174  446.36917  434.52658  446.09848  434.98215   11.344924\n",
      "  14.519432  32.227753]\n",
      "reward:  -0.12349804079573046\n",
      "timestep:  1\n",
      "new state [403.95654  402.9537   388.6904   402.62292  375.1835    58.592712\n",
      "  95.66263  123.06715 ]\n",
      "reward:  -0.11211713298430868\n",
      "timestep:  2\n",
      "new state [443.5      443.5      443.5      443.5      443.5       29.078756\n",
      "  30.836649 125.66759 ]\n",
      "reward:  -0.19374457160662162\n",
      "\n",
      "env reset!\n",
      "starting_state [443.5     443.5     443.5     443.5     443.5     117.20645  80.34187\n",
      " 127.63663]\n",
      "timestep:  0\n",
      "new state [382.49072  382.08783  376.16696  381.95337  386.53528   73.03942\n",
      "  62.509537  89.88461 ]\n",
      "reward:  -1.517411327354047\n",
      "timestep:  1\n",
      "new state [339.49197  339.0035   331.86652  338.84033  346.4212    40.296295\n",
      "  53.416073  80.118095]\n",
      "reward:  -1.510892640769806\n",
      "timestep:  2\n",
      "new state [621.6      621.6      621.6      621.6      621.6       48.443268\n",
      "  59.809654  74.45893 ]\n",
      "reward:  -0.08553189549751297\n",
      "\n",
      "env reset!\n",
      "starting_state [621.6      621.6      621.6      621.6      621.6       20.759085\n",
      "  48.603493  10.883497]\n",
      "timestep:  0\n",
      "new state [540.2194   543.018    583.00977  543.94006  601.3753    23.406046\n",
      "  40.41084   36.318703]\n",
      "reward:  0.03084230552473249\n",
      "timestep:  1\n",
      "new state [453.7599   457.87875  516.8563   459.2353   533.96857   25.797628\n",
      "  41.378555  67.28431 ]\n",
      "reward:  -0.04889217804769167\n",
      "timestep:  2\n",
      "new state [445.4      445.4      445.4      445.4      445.4       37.50318\n",
      "  46.522472  72.21837 ]\n",
      "reward:  -0.09073722622356563\n",
      "\n",
      "env reset!\n",
      "starting_state [445.4      445.4      445.4      445.4      445.4       35.997913\n",
      "  50.500515  33.465603]\n",
      "timestep:  0\n",
      "new state [338.43762 340.16547 364.75372 340.73514 383.2747   44.61839  39.17722\n",
      " 124.95083]\n",
      "reward:  -0.03339246419783224\n",
      "timestep:  1\n",
      "new state [303.08417  304.3791   321.88666  304.80615  327.56345    8.746069\n",
      "   8.905902  18.10315 ]\n",
      "reward:  -1.5595896223998258\n",
      "timestep:  2\n",
      "new state [225.2      225.2      225.2      225.2      225.2       18.012775\n",
      "  18.275724  23.856304]\n",
      "reward:  -0.10580623335008629\n",
      "\n",
      "env reset!\n",
      "starting_state [225.2       225.2       225.2       225.2       225.2         9.678753\n",
      "   6.1305666  15.506537 ]\n",
      "timestep:  0\n",
      "new state [219.68752   219.61691   218.51935   219.5935    218.28346    14.747507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  12.7448845  20.188892 ]\n",
      "reward:  -1.5437081923597213\n",
      "timestep:  1\n",
      "new state [210.71292  210.61566  209.11418  210.58337  209.27496   13.55508\n",
      "  20.255032  35.263794]\n",
      "reward:  -1.5166469917628707\n",
      "timestep:  2\n",
      "new state [263.3      263.3      263.3      263.3      263.3       41.887405\n",
      "  62.40885  118.15421 ]\n",
      "reward:  -0.23331290611497735\n",
      "\n",
      "env reset!\n",
      "starting_state [263.3       263.3       263.3       263.3       263.3        11.28861\n",
      "  15.4703665  26.756807 ]\n",
      "timestep:  0\n",
      "new state [253.3208    253.33911   253.54744   253.34537   251.36565     7.3725243\n",
      "   8.209448    6.464558 ]\n",
      "reward:  -1.5216460488166117\n",
      "timestep:  1\n",
      "new state [234.25166  234.46355  237.39853  234.53374  248.4777    31.913866\n",
      "  60.579903  96.16475 ]\n",
      "reward:  -0.1262173156251641\n",
      "timestep:  2\n",
      "new state [366.2      366.2      366.2      366.2      366.2       37.437077\n",
      "  72.17125   80.789856]\n",
      "reward:  -1.515163214011529\n",
      "\n",
      "env reset!\n",
      "starting_state [366.2      366.2      366.2      366.2      366.2       33.118614\n",
      "  43.576427  21.261703]\n",
      "timestep:  0\n",
      "new state [344.64426 344.991   300.97913 345.10553 356.68893  55.79978  75.79572\n",
      "  97.11128]\n",
      "reward:  -1.080552213976855\n",
      "timestep:  1\n",
      "new state [299.92902  300.5541   260.70328  300.7612   313.35715   56.67799\n",
      "  35.558636 131.43857 ]\n",
      "reward:  -1.5012040375863052\n",
      "timestep:  2\n",
      "new state [493.5      493.5      493.5      493.5      493.5       19.104223\n",
      "  21.830187  31.898563]\n",
      "reward:  -0.5270303076273768\n",
      "\n",
      "env reset!\n",
      "starting_state [493.5      493.5      493.5      493.5      493.5       75.20923\n",
      "  56.516838  50.81548 ]\n",
      "timestep:  0\n",
      "new state [340.45856  340.6743   343.02576  340.7483   399.16632   55.725857\n",
      "  76.91471   86.83417 ]\n",
      "reward:  -0.06041147569910555\n",
      "timestep:  1\n",
      "new state [296.71588  297.2893   305.09256  297.48203  360.41278   37.662563\n",
      "  29.25563   84.01254 ]\n",
      "reward:  -1.492673554297733\n",
      "timestep:  2\n",
      "new state [520.5      520.5      520.5      520.5      520.5       37.69594\n",
      "  69.98379   67.860855]\n",
      "reward:  -0.12602014279048732\n",
      "\n",
      "env reset!\n",
      "starting_state [520.5      520.5      520.5      520.5      520.5       27.057447\n",
      "  85.857895  73.049286]\n",
      "timestep:  0\n",
      "new state [356.08093  359.8725   414.7476   361.11884  384.9298    55.360832\n",
      "  46.170242  48.89015 ]\n",
      "reward:  -0.038798475838743636\n",
      "timestep:  1\n",
      "new state [231.82524  235.8179   293.1648   237.13206  294.18292   53.271904\n",
      "  48.278934  40.805588]\n",
      "reward:  -0.06733672216322123\n",
      "timestep:  2\n",
      "new state [472.       472.       472.       472.       472.         9.663223\n",
      "  12.337429  17.854826]\n",
      "reward:  -0.922327755351648\n",
      "\n",
      "env reset!\n",
      "starting_state [472.       472.       472.       472.       472.        83.950066\n",
      "  73.77508  129.30031 ]\n",
      "timestep:  0\n",
      "new state [418.74518 418.5337  415.21692 418.46362 414.31396  73.37229 110.26625\n",
      "  65.2465 ]\n",
      "reward:  -1.5227860100316624\n",
      "timestep:  1\n",
      "new state [364.65186  365.35284  253.62907  365.58463  293.18335   27.074383\n",
      "  73.73301   64.33152 ]\n",
      "reward:  -0.9758706538834928\n",
      "timestep:  2\n",
      "new state [727.9     727.9     727.9     727.9     727.9      73.24871  82.78508\n",
      " 151.20374]\n",
      "reward:  -0.14712182810776192\n",
      "\n",
      "env reset!\n",
      "starting_state [727.9       727.9       727.9       727.9       727.9         5.9131155\n",
      "   4.203285   10.06228  ]\n",
      "timestep:  0\n",
      "new state [713.0161    712.84235   710.3551    712.7851    709.22845     6.363274\n",
      "   5.944884    6.7060013]\n",
      "reward:  -0.11470016548070301\n",
      "timestep:  1\n",
      "new state [697.3821   697.25195  695.3565   697.2092   696.782     39.332012\n",
      "  60.89371   75.85275 ]\n",
      "reward:  -0.06966735955229467\n",
      "timestep:  2\n",
      "new state [496.9      496.9      496.9      496.9      496.9       63.87586\n",
      "  88.135025  28.49166 ]\n",
      "reward:  -0.07210145230479591\n",
      "\n",
      "env reset!\n",
      "starting_state [496.9       496.9       496.9       496.9       496.9         3.285375\n",
      "   4.4102817   8.239618 ]\n",
      "timestep:  0\n",
      "new state [484.6928    484.688     484.65588   484.68625   481.61084     3.955265\n",
      "   5.0899377  12.8673525]\n",
      "reward:  -0.10051725088713123\n",
      "timestep:  1\n",
      "new state [468.7383   468.62677  467.13895  468.58957  457.73608   38.935055\n",
      "  54.17516   12.515893]\n",
      "reward:  -0.12077806367852237\n",
      "timestep:  2\n",
      "new state [340.5      340.5      340.5      340.5      340.5       56.902996\n",
      "  37.050056  75.11639 ]\n",
      "reward:  0.010568096581061842\n",
      "\n",
      "env reset!\n",
      "starting_state [340.5      340.5      340.5      340.5      340.5       57.523327\n",
      "  85.151634 216.79782 ]\n",
      "timestep:  0\n",
      "new state [277.67963  277.4291   272.64734  277.34824  243.83873   66.74836\n",
      "  50.117027 102.25382 ]\n",
      "reward:  -1.5482241711456781\n",
      "timestep:  1\n",
      "new state [237.93294   237.36342   227.62823   237.17677   198.22314     3.8319468\n",
      "  12.39549    12.854346 ]\n",
      "reward:  -1.531852672588495\n",
      "timestep:  2\n",
      "new state [407.2      407.2      407.2      407.2      407.2       41.882137\n",
      "  39.20108   12.969887]\n",
      "reward:  -0.1732531692738207\n",
      "\n",
      "env reset!\n",
      "starting_state [407.2      407.2      407.2      407.2      407.2       61.706684\n",
      "  85.55704  109.112495]\n",
      "timestep:  0\n",
      "new state [357.02118 357.35052 362.27136 357.46005 358.5135   72.93623 109.75057\n",
      " 147.65816]\n",
      "reward:  -1.5007751354182928\n",
      "timestep:  1\n",
      "new state [292.8134   293.58118  304.9452   293.83676  292.636     46.134903\n",
      "  54.12429   99.25242 ]\n",
      "reward:  -1.504014295510353\n",
      "timestep:  2\n",
      "new state [794.3     794.3     794.3     794.3     794.3      52.1105  117.81323\n",
      " 102.40379]\n",
      "reward:  -0.23338175797761102\n",
      "\n",
      "env reset!\n",
      "starting_state [794.3      794.3      794.3      794.3      794.3        3.89895\n",
      "   9.664298  14.835396]\n",
      "timestep:  0\n",
      "new state [771.71625   771.9234    775.0039    771.99115   766.77203     6.561416\n",
      "   3.1944785  10.936631 ]\n",
      "reward:  -0.08577030848265467\n",
      "timestep:  1\n",
      "new state [757.1347    757.0375    755.75165   757.005     746.47864    12.796289\n",
      "   9.432148    3.5240695]\n",
      "reward:  -0.13184158971995372\n",
      "timestep:  2\n",
      "new state [346.1      346.1      346.1      346.1      346.1       70.32473\n",
      "  25.046865  60.1807  ]\n",
      "reward:  -0.027584355907763352\n",
      "\n",
      "env reset!\n",
      "starting_state [346.1      346.1      346.1      346.1      346.1       15.420512\n",
      "  16.366308  24.298306]\n",
      "timestep:  0\n",
      "new state [301.61667  301.65237  302.17245  301.66406  335.25848   15.952059\n",
      "  16.984915  35.105927]\n",
      "reward:  -0.202419710352798\n",
      "timestep:  1\n",
      "new state [250.35934  250.15462  247.3401   250.08661  319.60126    9.254173\n",
      "   9.422149  17.19211 ]\n",
      "reward:  -0.24611609505815668\n",
      "timestep:  2\n",
      "new state [376.6      376.6      376.6      376.6      376.6       53.86708\n",
      "  96.352806 215.69995 ]\n",
      "reward:  -0.09886293349807983\n",
      "\n",
      "env reset!\n",
      "starting_state [376.6      376.6      376.6      376.6      376.6       54.086872\n",
      "  73.05046   50.31956 ]\n",
      "timestep:  0\n",
      "new state [338.88123 339.39276 347.44617 339.5619  354.11755  41.91815  63.30721\n",
      " 184.81572]\n",
      "reward:  -1.4626983920820273\n",
      "timestep:  1\n",
      "new state [289.36307 289.562   291.94592 289.62955 271.724    61.34222  74.49697\n",
      " 100.05293]\n",
      "reward:  -1.5573418062510713\n",
      "timestep:  2\n",
      "new state [636.2      636.2      636.2      636.2      636.2       58.62291\n",
      "  63.33896   67.319046]\n",
      "reward:  -1.5049383767936202\n",
      "\n",
      "env reset!\n",
      "starting_state [636.2     636.2     636.2     636.2     636.2      92.62877 123.22062\n",
      " 243.56802]\n",
      "timestep:  0\n",
      "new state [552.40186 552.3484  550.75854 552.3324  527.5752  104.73469 146.77966\n",
      "   1.     ]\n",
      "reward:  -1.5307865901675421\n",
      "timestep:  1\n",
      "new state [291.38748  299.07245  406.88727  301.61102  525.59436   41.638336\n",
      "  21.319794  73.203316]\n",
      "reward:  0.04261622792396121\n",
      "timestep:  2\n",
      "new state [467.1      467.1      467.1      467.1      467.1        9.806706\n",
      "   9.496274  14.046153]\n",
      "reward:  -0.13252952835517678\n",
      "\n",
      "env reset!\n",
      "starting_state [467.1      467.1      467.1      467.1      467.1       41.482876\n",
      "  88.303444 131.87953 ]\n",
      "timestep:  0\n",
      "new state [416.91187  417.35535  423.67474  417.50363  408.27884   44.098515\n",
      "  85.35191  157.11702 ]\n",
      "reward:  -1.5104114713792127\n",
      "timestep:  1\n",
      "new state [363.955    364.62003  215.4972   364.84335  338.21378   43.414757\n",
      " 101.62746  183.9644  ]\n",
      "reward:  -1.1116297488639777\n",
      "timestep:  2\n",
      "new state [711.       711.       711.       711.       711.        45.482166\n",
      "  49.808247  77.601776]\n",
      "reward:  -1.5247858018611133\n",
      "\n",
      "env reset!\n",
      "starting_state [711.        711.        711.        711.        711.          4.5880466\n",
      "   6.8367825   6.174641 ]\n",
      "timestep:  0\n",
      "new state [695.882     696.08044   698.9228    696.1458    699.53973     4.289804\n",
      "   4.9536605  18.696096 ]\n",
      "reward:  -0.05097118689765204\n",
      "timestep:  1\n",
      "new state [676.8185   676.7217   675.45966  676.6893   664.852      9.119541\n",
      "   8.850144  17.177158]\n",
      "reward:  -0.1451835834809096\n",
      "timestep:  2\n",
      "new state [132.7      132.7      132.7      132.7      132.7       17.124409\n",
      "  23.252542  21.89141 ]\n",
      "reward:  -0.10277763597380196\n",
      "\n",
      "env reset!\n",
      "starting_state [132.7     132.7     132.7     132.7     132.7      47.94852  36.80733\n",
      " 126.8989 ]\n",
      "timestep:  0\n",
      "new state [ 97.200165  96.68144   88.30087   96.51033   76.120346  64.68349\n",
      "  88.64628  108.68382 ]\n",
      "reward:  -1.5630738771738122\n",
      "timestep:  1\n",
      "new state [ 45.622356  45.462555  42.48978   45.410675  27.62178   51.947823\n",
      "  58.184273 112.666374]\n",
      "reward:  -1.4982009161807441\n",
      "Out of Budget!\n",
      "timestep:  2\n",
      "new state [ 45.622356  45.462555  42.48978   45.410675  27.62178   41.7477\n",
      " 143.98477   16.539148]\n",
      "reward:  -100\n",
      "\n",
      "env reset!\n",
      "starting_state [673.4       673.4       673.4       673.4       673.4         5.5809407\n",
      "   8.710138    6.851326 ]\n",
      "timestep:  0\n",
      "new state [654.86615  655.1578   659.33026  655.25385  660.683      5.648735\n",
      "   8.916913   8.445515]\n",
      "reward:  -0.04164643396394525\n",
      "timestep:  1\n",
      "new state [635.1984   635.7506   643.6664   635.93243  645.0084    17.561708\n",
      "  22.256811  29.074213]\n",
      "reward:  -0.05338134635981577\n",
      "timestep:  2\n",
      "new state [262.7      262.7      262.7      262.7      262.7       63.30445\n",
      "  62.452217 127.00237 ]\n",
      "reward:  -0.07646249213283306\n",
      "\n",
      "env reset!\n",
      "starting_state [262.7      262.7      262.7      262.7      262.7       31.882038\n",
      "  33.803192  55.134113]\n",
      "timestep:  0\n",
      "new state [240.0069   239.99658  239.77194  239.99329  238.10327   40.91576\n",
      "  62.745888 118.80581 ]\n",
      "reward:  -1.5180368215774345\n",
      "timestep:  1\n",
      "new state [199.12314  199.17534  199.49567  199.19376  185.11989   42.18849\n",
      "  54.767525  32.818913]\n",
      "reward:  -1.5279402657113044\n",
      "timestep:  2\n",
      "new state [516.3      516.3      516.3      516.3      516.3       77.679985\n",
      " 107.5607   154.96458 ]\n",
      "reward:  -1.4560490508286283\n",
      "\n",
      "env reset!\n",
      "starting_state [516.3      516.3      516.3      516.3      516.3       64.22522\n",
      "  52.925625 116.19393 ]\n",
      "timestep:  0\n",
      "new state [342.0746   340.57593  319.23087  340.08167  464.47354   51.544224\n",
      "  63.988945  99.59933 ]\n",
      "reward:  -0.2443948556617941\n",
      "timestep:  1\n",
      "new state [301.31012  299.90363  279.79712  299.4403   279.64905   53.98272\n",
      "  87.643585 143.02893 ]\n",
      "reward:  -1.1973813842583938\n",
      "timestep:  2\n",
      "new state [588.       588.       588.       588.       588.        31.257387\n",
      "  41.715717  66.54332 ]\n",
      "reward:  -1.5174016749558377\n",
      "\n",
      "env reset!\n",
      "starting_state [588.       588.       588.       588.       588.        21.961329\n",
      "  27.850466  32.40772 ]\n",
      "timestep:  0\n",
      "new state [520.1776   520.6553   527.5071   520.81256  527.8555    25.696592\n",
      "  17.372793  26.078936]\n",
      "reward:  -0.06890138616980976\n",
      "timestep:  1\n",
      "new state [465.75812  465.9076   467.88553  465.95746  479.45496   10.524293\n",
      "  28.115593 107.66389 ]\n",
      "reward:  -0.08790376655026004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  2\n",
      "new state [343.3      343.3      343.3      343.3      343.3       18.386501\n",
      "  39.33978   50.860443]\n",
      "reward:  -0.1505416430704504\n",
      "\n",
      "env reset!\n",
      "starting_state [343.3      343.3      343.3      343.3      343.3       10.510422\n",
      "   8.959895  20.583656]\n",
      "timestep:  0\n",
      "new state [313.60526  313.33966  309.57217  313.252    334.11963    8.499482\n",
      "   5.828298  14.759619]\n",
      "reward:  -0.2516003119559636\n",
      "timestep:  1\n",
      "new state [292.3213   291.7804   284.07434  291.60202  306.7319    38.588608\n",
      "  36.916855  28.731676]\n",
      "reward:  -0.11780935018740143\n",
      "timestep:  2\n",
      "new state [373.1      373.1      373.1      373.1      373.1       47.148235\n",
      "  38.63328   85.47568 ]\n",
      "reward:  -0.04920123339702264\n",
      "\n",
      "env reset!\n",
      "starting_state [373.1     373.1     373.1     373.1     373.1     101.98864  95.16695\n",
      "  64.32684]\n",
      "timestep:  0\n",
      "new state [318.4081  318.77887 325.0426  318.90027 344.3419   75.12408 107.28938\n",
      " 100.2036 ]\n",
      "reward:  -1.4692549127573242\n",
      "timestep:  1\n",
      "new state [260.48975  261.50357  277.70676  261.83804  299.60696   12.218663\n",
      "  10.376433  16.048637]\n",
      "reward:  -1.4800439824444214\n",
      "timestep:  2\n",
      "new state [458.1      458.1      458.1      458.1      458.1       32.819954\n",
      "  27.335163  67.16096 ]\n",
      "reward:  -0.088832508086116\n",
      "\n",
      "env reset!\n",
      "starting_state [458.1      458.1      458.1      458.1      458.1       14.186366\n",
      "  10.253393  25.420925]\n",
      "timestep:  0\n",
      "new state [421.51837  421.07883  414.8015   420.93396  410.92944   11.315774\n",
      "  11.596023  15.859975]\n",
      "reward:  -0.11685218266890306\n",
      "timestep:  1\n",
      "new state [390.4095   390.01862  384.42303  389.8898   381.49615   86.641014\n",
      "  88.8275    80.19458 ]\n",
      "reward:  -0.08055439879981804\n",
      "timestep:  2\n",
      "new state [324.2      324.2      324.2      324.2      324.2        8.222885\n",
      "   9.859234  15.006166]\n",
      "reward:  -0.05595422023259953\n",
      "\n",
      "env reset!\n",
      "starting_state [324.2      324.2      324.2      324.2      324.2       38.394894\n",
      "  88.88558  139.34015 ]\n",
      "timestep:  0\n",
      "new state [273.4621   273.9033   280.1052   274.051    262.05615   46.15921\n",
      "  86.276245 132.79741 ]\n",
      "reward:  -1.5139109916551552\n",
      "timestep:  1\n",
      "new state [222.9118   223.70981  234.93805  223.97696  202.8247    33.476994\n",
      "  50.054485  66.27632 ]\n",
      "reward:  -1.5129297026145838\n",
      "timestep:  2\n",
      "new state [796.3     796.3     796.3     796.3     796.3      96.69082 115.95339\n",
      " 225.6768 ]\n",
      "reward:  -1.502938048439793\n",
      "\n",
      "env reset!\n",
      "starting_state [796.3      796.3      796.3      796.3      796.3       53.358135\n",
      "  39.631744  37.793907]\n",
      "timestep:  0\n",
      "new state [687.393    687.4595   687.90344  687.4834   726.142     54.07917\n",
      "  59.410973  96.28825 ]\n",
      "reward:  -0.063438701593525\n",
      "timestep:  1\n",
      "new state [523.1559  523.1964  523.4188  523.211   547.46094  68.82898  72.75336\n",
      "  51.34048]\n",
      "reward:  -0.0911364592881414\n",
      "timestep:  2\n",
      "new state [439.6      439.6      439.6      439.6      439.6        8.235048\n",
      "   6.769574  13.642383]\n",
      "reward:  -0.04233602699910119\n",
      "\n",
      "env reset!\n",
      "starting_state [439.6      439.6      439.6      439.6      439.6       24.99323\n",
      "  19.304762  52.84357 ]\n",
      "timestep:  0\n",
      "new state [369.43784   368.5354    355.72778   368.23764   416.03445     7.6029677\n",
      "  21.218925   16.681393 ]\n",
      "reward:  -0.2698382817333391\n",
      "timestep:  1\n",
      "new state [328.82272 328.86096 329.635   328.87253 385.0744   44.67073  99.16755\n",
      "  58.75831]\n",
      "reward:  -0.03414565009689435\n",
      "timestep:  2\n",
      "new state [364.3      364.3      364.3      364.3      364.3       11.45339\n",
      "  22.747179  41.27174 ]\n",
      "reward:  -0.018206585836308787\n",
      "\n",
      "env reset!\n",
      "starting_state [364.3      364.3      364.3      364.3      364.3       27.08266\n",
      "  51.075848  47.723213]\n",
      "timestep:  0\n",
      "new state [338.2965   338.68588  344.6117   338.81512  342.99878   34.824142\n",
      "  54.057438 145.25854 ]\n",
      "reward:  -1.476991838558739\n",
      "timestep:  1\n",
      "new state [297.76492  297.9681   300.37158  298.0372   278.2373    63.98186\n",
      "  93.874794 135.20021 ]\n",
      "reward:  -1.5520115893962998\n",
      "timestep:  2\n",
      "new state [401.4      401.4      401.4      401.4      401.4        6.098319\n",
      "   4.772723   9.258717]\n",
      "reward:  -1.5088428717404676\n",
      "\n",
      "env reset!\n",
      "starting_state [401.4      401.4      401.4      401.4      401.4       29.316319\n",
      "  39.61586   49.1508  ]\n",
      "timestep:  0\n",
      "new state [304.79572  305.46274  315.09915  305.682    379.46738   29.13105\n",
      "  61.092022  81.07897 ]\n",
      "reward:  -0.18491819055745284\n",
      "timestep:  1\n",
      "new state [271.27094  272.29846  287.20673  272.6379   343.29913   60.609123\n",
      "  63.15045   81.72035 ]\n",
      "reward:  -1.5016177738118683\n",
      "timestep:  2\n",
      "new state [503.3      503.3      503.3      503.3      503.3       34.764263\n",
      "  81.447266  73.64049 ]\n",
      "reward:  -1.230915034209441\n",
      "\n",
      "env reset!\n",
      "starting_state [503.3      503.3      503.3      503.3      503.3       39.59024\n",
      "  37.397976  85.21637 ]\n",
      "timestep:  0\n",
      "new state [382.9541   382.02945  369.0174   381.72385  465.29504   59.188087\n",
      "  68.41645   83.03026 ]\n",
      "reward:  -0.25456440563941374\n",
      "timestep:  1\n",
      "new state [210.60968  210.56079  330.8097   210.5437   311.2018     9.236551\n",
      "   5.890423  10.723495]\n",
      "reward:  -0.23215453408943293\n",
      "timestep:  2\n",
      "new state [267.6       267.6       267.6       267.6       267.6         9.548276\n",
      "   5.9779587   7.4027944]\n",
      "reward:  -0.09866159051188818\n",
      "\n",
      "env reset!\n",
      "starting_state [267.6      267.6      267.6      267.6      267.6       17.689411\n",
      "  11.085096  20.981953]\n",
      "timestep:  0\n",
      "new state [258.48425  258.3949   257.05054  258.36517  258.23752   15.435555\n",
      "  17.394087  31.969809]\n",
      "reward:  -1.52724677027395\n",
      "timestep:  1\n",
      "new state [208.73929  208.55078  244.75882  208.488    243.9776     6.824006\n",
      "  12.543059  27.135523]\n",
      "reward:  -0.4329396909836734\n",
      "timestep:  2\n",
      "new state [114.5      114.5      114.5      114.5      114.5        7.27624\n",
      "   8.514111  10.751683]\n",
      "reward:  -0.1111700425036404\n",
      "\n",
      "env reset!\n",
      "starting_state [114.5      114.5      114.5      114.5      114.5       36.364445\n",
      "  46.98437   10.492073]\n",
      "timestep:  0\n",
      "new state [ 92.700485  93.13882  100.16627   93.28343  109.78379   32.431248\n",
      "  35.023155  49.899723]\n",
      "reward:  -1.4179235209122538\n",
      "timestep:  1\n",
      "new state [70.20417   70.6787    78.23831   70.83534   87.51824   13.806016\n",
      " 18.653427   3.6193054]\n",
      "reward:  -1.5093080776638155\n",
      "timestep:  2\n",
      "new state [339.2      339.2      339.2      339.2      339.2       39.384003\n",
      "  23.200354  65.963104]\n",
      "reward:  -1.4124013821044517\n",
      "\n",
      "env reset!\n",
      "starting_state [339.2      339.2      339.2      339.2      339.2       12.56045\n",
      "  21.951267  22.231857]\n",
      "timestep:  0\n",
      "new state [291.05222  291.70456  301.1171   291.9191   329.2778    20.333698\n",
      "  23.062817  37.561985]\n",
      "reward:  -0.16253891117756933\n",
      "timestep:  1\n",
      "new state [227.69995 228.36234 237.99191 228.57983 312.52112  51.63069  62.85173\n",
      "  95.64299]\n",
      "reward:  -0.2165289538835738\n",
      "timestep:  2\n",
      "new state [527.4      527.4      527.4      527.4      527.4       60.14454\n",
      "  99.68646  101.030846]\n",
      "reward:  -1.5131752226647175\n",
      "\n",
      "env reset!\n",
      "starting_state [527.4      527.4      527.4      527.4      527.4       28.766623\n",
      "  63.268185 124.21661 ]\n",
      "timestep:  0\n",
      "new state [363.04318  363.50922  371.13416  363.65866  472.01178   50.649708\n",
      "  52.236057 122.154495]\n",
      "reward:  -0.25930025564812026\n",
      "timestep:  1\n",
      "new state [323.08582  323.31238  326.9107   323.38318  417.53683   43.792885\n",
      "  26.55208    1.      ]\n",
      "reward:  -1.5412714959970555\n",
      "timestep:  2\n",
      "new state [565.5      565.5      565.5      565.5      565.5       38.850998\n",
      "  36.417805   1.      ]\n",
      "reward:  -0.009623267432282272\n",
      "\n",
      "env reset!\n",
      "starting_state [565.5      565.5      565.5      565.5      565.5       16.779213\n",
      "  11.785979  21.082573]\n",
      "timestep:  0\n",
      "new state [527.31604  527.0227   522.75037  526.92633  526.3754    10.199828\n",
      "  19.59361    9.868646]\n",
      "reward:  -0.09766371510413496\n",
      "timestep:  1\n",
      "new state [490.28043   490.8901    499.53314   491.09122   508.0532      5.8447986\n",
      "   8.5796175  11.765418 ]\n",
      "reward:  -0.01156011374407316\n",
      "timestep:  2\n",
      "new state [108.        108.        108.        108.        108.          7.6562033\n",
      "  10.891478    8.104808 ]\n",
      "reward:  -0.07902171860204635\n",
      "\n",
      "env reset!\n",
      "starting_state [108.       108.       108.       108.       108.        10.436405\n",
      "  11.924848  22.002163]\n",
      "timestep:  0\n",
      "new state [99.82083  99.810455 99.601944 99.80712  98.186195 22.179323 16.982635\n",
      " 25.267923]\n",
      "reward:  -1.5260401357771247\n",
      "timestep:  1\n",
      "new state [87.60955  87.548676 86.607864 87.52845  86.909     8.970692  8.636539\n",
      " 19.765734]\n",
      "reward:  -1.5133473073010117\n",
      "timestep:  2\n",
      "new state [259.7      259.7      259.7      259.7      259.7       52.912067\n",
      "  20.16191   28.24115 ]\n",
      "reward:  -1.5396470414512287\n",
      "\n",
      "env reset!\n",
      "starting_state [259.7      259.7      259.7      259.7      259.7       45.306343\n",
      "  61.14471   88.674446]\n",
      "timestep:  0\n",
      "new state [222.27774  222.44067  224.78143  222.49506  220.13966   44.86815\n",
      "  59.13619  104.924194]\n",
      "reward:  -1.5096111539734753\n",
      "timestep:  1\n",
      "new state [183.48895  183.69037  186.34117  183.75815  173.34079   35.344025\n",
      "  23.99819   36.622818]\n",
      "reward:  -1.5234138249976628\n",
      "timestep:  2\n",
      "new state [508.6     508.6     508.6     508.6     508.6      46.59111  82.87959\n",
      " 135.54373]\n",
      "reward:  -1.5152158446132635\n",
      "\n",
      "env reset!\n",
      "starting_state [508.6      508.6      508.6      508.6      508.6        6.205319\n",
      "   9.300648  17.036728]\n",
      "timestep:  0\n",
      "new state [483.57956   483.60678   484.08487   483.6154    476.98743     2.5169039\n",
      "  10.28949     8.901958 ]\n",
      "reward:  -0.0991862391102588\n",
      "timestep:  1\n",
      "new state [464.3472    464.85248   472.26215   465.0182    460.467       4.0241184\n",
      "   3.438509    2.3160698]\n",
      "reward:  -0.03812747142108965\n",
      "timestep:  2\n",
      "new state [158.2      158.2      158.2      158.2      158.2       36.381714\n",
      "  50.08759   28.244116]\n",
      "reward:  -0.04459834289989487\n",
      "\n",
      "env reset!\n",
      "starting_state [158.2      158.2      158.2      158.2      158.2       26.407448\n",
      "  16.20041   12.233514]\n",
      "timestep:  0\n",
      "new state [147.09099  147.05997  146.75879  147.0492   152.7283    30.571407\n",
      "  36.41513   18.17623 ]\n",
      "reward:  -1.4828509274447137\n",
      "timestep:  1\n",
      "new state [128.50217  128.7308   132.59903  128.80568  144.59676   71.504036\n",
      "  97.90251  163.11281 ]\n",
      "reward:  -1.449382890381786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep:  2\n",
      "new state [632.1      632.1      632.1      632.1      632.1       85.00664\n",
      "  49.54382   42.874012]\n",
      "reward:  -1.519074505481724\n",
      "\n",
      "env reset!\n",
      "starting_state [632.1       632.1       632.1       632.1       632.1        10.489874\n",
      "  13.050293    1.7849479]\n",
      "timestep:  0\n",
      "new state [607.12244  607.71735  616.10425  607.9138   628.777      8.194466\n",
      "  13.246318  16.880304]\n",
      "reward:  0.017614873586854027\n",
      "timestep:  1\n",
      "new state [575.8053   576.67236  589.0213   576.9582   597.4516     8.282765\n",
      "   9.343883  10.975043]\n",
      "reward:  -0.07344783109683554\n",
      "timestep:  2\n",
      "new state [88.4      88.4      88.4      88.4      88.4       7.745594  7.176407\n",
      "  6.834895]\n",
      "reward:  -0.07042745236267046\n",
      "\n",
      "env reset!\n",
      "starting_state [88.4       88.4       88.4       88.4       88.4        9.646631\n",
      "  4.5748014 13.86835  ]\n",
      "timestep:  0\n",
      "new state [83.55923  83.47019  82.10031  83.44065  82.21413   7.150502 10.046663\n",
      " 16.76197 ]\n",
      "reward:  -1.5515203157316444\n",
      "timestep:  1\n",
      "new state [77.1884   77.116486 75.96475  77.09273  74.737564 10.249759 13.550874\n",
      " 43.51639 ]\n",
      "reward:  -1.5191402242690475\n",
      "timestep:  2\n",
      "new state [220.       220.       220.       220.       220.        30.658995\n",
      "  24.893032  54.17347 ]\n",
      "reward:  -1.5627142488712829\n",
      "\n",
      "env reset!\n",
      "starting_state [220.       220.       220.       220.       220.        13.196286\n",
      "  17.780426  16.578196]\n",
      "timestep:  0\n",
      "new state [210.26991   210.36948   211.91647   210.40245   212.59843    11.4358635\n",
      "  18.743681   27.334913 ]\n",
      "reward:  -1.48064006504909\n",
      "timestep:  1\n",
      "new state [199.22319  199.39537  201.98349  199.4526   200.40482   26.137577\n",
      "  82.39925   71.503494]\n",
      "reward:  -1.5093621044534409\n",
      "timestep:  2\n",
      "new state [456.2      456.2      456.2      456.2      456.2       40.274456\n",
      "  47.60826   56.760155]\n",
      "reward:  -1.4667819889137166\n",
      "\n",
      "env reset!\n",
      "starting_state [456.2      456.2      456.2      456.2      456.2       59.82241\n",
      "  85.882     55.813496]\n",
      "timestep:  0\n",
      "new state [412.95734  413.6139   321.9909   413.8311   431.26056   78.22735\n",
      "  61.886433 130.034   ]\n",
      "reward:  -1.0899889448694768\n",
      "timestep:  1\n",
      "new state [209.89548  208.8444   266.92767  208.49889  373.25647   50.985306\n",
      "  66.80337  223.20316 ]\n",
      "reward:  -0.44966994828993656\n",
      "timestep:  2\n",
      "new state [516.4       516.4       516.4       516.4       516.4         8.163467\n",
      "   5.8351316  11.795287 ]\n",
      "reward:  -1.5651200581226778\n",
      "\n",
      "env reset!\n",
      "starting_state [516.4      516.4      516.4      516.4      516.4       29.825026\n",
      "  32.781982  49.62298 ]\n",
      "timestep:  0\n",
      "new state [427.6079   427.69327  428.964    427.72113  424.31314   41.308857\n",
      "  54.615284  52.681507]\n",
      "reward:  -0.08670720515606291\n",
      "timestep:  1\n",
      "new state [301.5765   302.97327  322.97256  303.4332   326.5357     7.195511\n",
      "   7.078414   9.410249]\n",
      "reward:  -0.05656145752692612\n",
      "timestep:  2\n",
      "new state [412.2      412.2      412.2      412.2      412.2       85.74529\n",
      "  60.292377 135.72963 ]\n",
      "reward:  -0.07902817115653613\n",
      "\n",
      "env reset!\n",
      "starting_state [412.2      412.2      412.2      412.2      412.2       36.132717\n",
      "  43.70706  126.582054]\n",
      "timestep:  0\n",
      "new state [376.838    376.55893  371.74948  376.4676   355.76398   31.277657\n",
      "  61.211998  37.902855]\n",
      "reward:  -1.5557046518228554\n",
      "timestep:  1\n",
      "new state [257.9101   260.27478  293.35684  261.05402  285.40414   45.752937\n",
      " 104.93855  131.14943 ]\n",
      "reward:  -0.02317135568328089\n",
      "timestep:  2\n",
      "new state [566.1     566.1     566.1     566.1     566.1      42.18442  34.97069\n",
      "  90.92688]\n",
      "reward:  -1.496723408755849\n",
      "\n",
      "env reset!\n",
      "starting_state [566.1       566.1       566.1       566.1       566.1         7.4680643\n",
      "   3.575111   19.022127 ]\n",
      "timestep:  0\n",
      "new state [546.1673   545.6302   537.99536  545.45306  530.8065    10.686058\n",
      "   7.467669  18.518513]\n",
      "reward:  -0.15448600719412833\n",
      "timestep:  1\n",
      "new state [519.2547   518.3838   505.97385  518.0967   496.44376   47.531406\n",
      "  46.26605  139.86356 ]\n",
      "reward:  -0.11668627338429648\n",
      "timestep:  2\n",
      "new state [454.6      454.6      454.6      454.6      454.6       82.09983\n",
      "  64.70097   89.103966]\n",
      "reward:  -0.13064834970146236\n",
      "\n",
      "env reset!\n",
      "starting_state [454.6      454.6      454.6      454.6      454.6       52.061653\n",
      "  52.75246   43.59242 ]\n",
      "timestep:  0\n",
      "new state [327.4566   328.4626   342.50375  328.79535  435.12585   55.48459\n",
      " 101.083145  79.136215]\n",
      "reward:  -0.13053979792119347\n",
      "timestep:  1\n",
      "new state [277.5745   279.42007  306.37466  280.03122  288.24197   54.757347\n",
      "  59.088448 100.32448 ]\n",
      "reward:  -1.2354622498269232\n",
      "timestep:  2\n",
      "new state [587.9      587.9      587.9      587.9      587.9       37.253998\n",
      "  34.592457  80.636795]\n",
      "reward:  -1.0764757307342343\n",
      "\n",
      "env reset!\n",
      "starting_state [587.9      587.9      587.9      587.9      587.9       38.19759\n",
      "  60.128147 100.3493  ]\n",
      "timestep:  0\n",
      "new state [432.6765  433.20294 441.25223 433.37408 401.69287  64.81151  90.60811\n",
      " 127.76511]\n",
      "reward:  -0.0926073955980774\n",
      "timestep:  1\n",
      "new state [378.09973  207.15945  232.46593  207.71674  344.692     36.44139\n",
      "  34.07788   40.509834]\n",
      "reward:  -0.4663536294102667\n",
      "timestep:  2\n",
      "new state [504.6      504.6      504.6      504.6      504.6       34.460728\n",
      "  77.61331   64.535904]\n",
      "reward:  -0.4550836648645843\n",
      "\n",
      "env reset!\n",
      "starting_state [504.6      504.6      504.6      504.6      504.6       64.09125\n",
      "  34.462917 114.78362 ]\n",
      "timestep:  0\n",
      "new state [354.0143   351.07806  309.0512   350.11072  453.4112    18.004229\n",
      "  60.72966   99.35022 ]\n",
      "reward:  -0.2764832282958024\n",
      "timestep:  1\n",
      "new state [213.83278  212.27449  280.69052  211.75717  409.10834   42.594604\n",
      "  72.69792  136.13284 ]\n",
      "reward:  -0.417839581422582\n",
      "timestep:  2\n",
      "new state [661.4      661.4      661.4      661.4      661.4       37.498142\n",
      "  39.021225  32.164284]\n",
      "reward:  -1.5272095752760628\n",
      "\n",
      "env reset!\n",
      "starting_state [661.4       661.4       661.4       661.4       661.4         6.2124577\n",
      "  12.030902   17.200745 ]\n",
      "timestep:  0\n",
      "new state [632.91644   633.158     636.7193    633.2371    629.4818      8.822592\n",
      "   7.6110125   2.9511516]\n",
      "reward:  -0.08099130574294248\n",
      "timestep:  1\n",
      "new state [615.31335  615.7441   621.90204  615.8859   623.9989    19.934557\n",
      "  40.915787  65.71326 ]\n",
      "reward:  -0.0232392615432764\n",
      "timestep:  2\n",
      "new state [215.3      215.3      215.3      215.3      215.3       14.84476\n",
      "  14.389273  48.144257]\n",
      "reward:  -0.08948488585160116\n",
      "\n",
      "env reset!\n",
      "starting_state [215.3      215.3      215.3      215.3      215.3       30.050158\n",
      "  33.209988  58.845104]\n",
      "timestep:  0\n",
      "new state [192.64813  192.6236   192.13652  192.61569  189.05112   39.65833\n",
      "  31.506659  29.179987]\n",
      "reward:  -1.5233784445194083\n",
      "timestep:  1\n",
      "new state [172.48483   172.48161   172.51201   172.48024   176.01497     6.3918304\n",
      "   7.0348005   4.9815793]\n",
      "reward:  -1.487441510438605\n",
      "timestep:  2\n",
      "new state [333.7     333.7     333.7     333.7     333.7      50.06396  44.31238\n",
      " 122.26987]\n",
      "reward:  -0.11469771239450922\n",
      "\n",
      "env reset!\n",
      "starting_state [333.7       333.7       333.7       333.7       333.7         6.5959435\n",
      "   7.389706    9.841022 ]\n",
      "timestep:  0\n",
      "new state [314.47858   314.5407    315.4305    314.56116   329.30856     4.304062\n",
      "   6.521314    5.3385315]\n",
      "reward:  -0.18978729244748213\n",
      "timestep:  1\n",
      "new state [300.39886   300.6686    304.52835   300.75742   319.39963     6.915069\n",
      "   9.548352    1.0468866]\n",
      "reward:  -0.044557794266014986\n",
      "timestep:  2\n",
      "new state [216.7      216.7      216.7      216.7      216.7       39.737335\n",
      "  32.925243  77.16384 ]\n",
      "reward:  0.026351404358142507\n",
      "\n",
      "env reset!\n",
      "starting_state [216.7      216.7      216.7      216.7      216.7        8.625412\n",
      "  14.075221  25.115183]\n",
      "timestep:  0\n",
      "new state [207.82176   207.84982   208.1932    207.85934   205.49908     9.918766\n",
      "  12.4025755  14.314523 ]\n",
      "reward:  -1.5237600298961833\n",
      "timestep:  1\n",
      "new state [200.56009  200.6351   201.69955  200.66019  199.11038  133.57787\n",
      "  79.718735 153.70766 ]\n",
      "reward:  -1.494910571136582\n",
      "timestep:  2\n",
      "new state [476.7      476.7      476.7      476.7      476.7       31.17636\n",
      "  54.586113  40.58431 ]\n",
      "reward:  -1.5282159546709222\n",
      "\n",
      "env reset!\n",
      "starting_state [476.7      476.7      476.7      476.7      476.7        5.629762\n",
      "   7.84565   17.00879 ]\n",
      "timestep:  0\n",
      "new state [453.92654   453.8598    452.99698   453.83743   445.14026     7.9253364\n",
      "   7.194479    1.       ]\n",
      "reward:  -0.11073752979975761\n",
      "timestep:  1\n",
      "new state [438.52875  438.70728  441.24152  438.76617  443.2776    31.474958\n",
      "  23.769869 114.34436 ]\n",
      "reward:  0.0019605097621457766\n",
      "timestep:  2\n",
      "new state [387.2      387.2      387.2      387.2      387.2       57.397236\n",
      "  63.437225  61.13236 ]\n",
      "reward:  -0.15490464972657317\n",
      "\n",
      "env reset!\n",
      "starting_state [387.2      387.2      387.2      387.2      387.2       53.94307\n",
      "  13.269053  91.94805 ]\n",
      "timestep:  0\n",
      "new state [361.96576  361.16394  348.73022  360.8982   346.2008    20.853426\n",
      "  67.95867  120.57998 ]\n",
      "reward:  -1.5821672743675448\n",
      "timestep:  1\n",
      "new state [322.9493   322.48648  314.6399   322.33472  292.4344    50.799114\n",
      "  50.24758   59.139477]\n",
      "reward:  -1.5232221855496593\n",
      "timestep:  2\n",
      "new state [343.4       343.4       343.4       343.4       343.4         6.9706616\n",
      "   5.670271    1.       ]\n",
      "reward:  -0.07163832913946033\n",
      "\n",
      "env reset!\n",
      "starting_state [343.4      343.4      343.4      343.4      343.4       29.085903\n",
      "  47.19737   89.94591 ]\n",
      "timestep:  0\n",
      "new state [312.88055  312.9405   313.5286   312.96118  303.28824   44.505474\n",
      "  41.59888   91.696526]\n",
      "reward:  -1.5284314396790324\n",
      "timestep:  1\n",
      "new state [281.00592  280.86688  278.2009   280.822    262.39163   35.116917\n",
      "  17.87208   52.06892 ]\n",
      "reward:  -1.537178402529882\n",
      "timestep:  2\n",
      "new state [469.5      469.5      469.5      469.5      469.5       33.133133\n",
      "  48.93146   74.913124]\n",
      "reward:  -0.25725077110412436\n",
      "\n",
      "env reset!\n",
      "starting_state [469.5      469.5      469.5      469.5      469.5       25.460798\n",
      "  44.391293  15.7513  ]\n",
      "timestep:  0\n",
      "new state [387.24225  389.38458  419.91394  390.09076  440.24484   33.008034\n",
      "  49.12839   50.76525 ]\n",
      "reward:  0.0031353655657112424\n",
      "timestep:  1\n",
      "new state [275.2586   278.6445   327.0523   279.7599   346.02914   58.96327\n",
      "  59.309258  92.1082  ]\n",
      "reward:  -0.059736072145736764\n",
      "timestep:  2\n",
      "new state [663.1     663.1     663.1     663.1     663.1      85.51604 104.47578\n",
      " 153.50558]\n",
      "reward:  -1.0699539010232506\n",
      "\n",
      "env reset!\n",
      "starting_state [663.1      663.1      663.1      663.1      663.1       55.929287\n",
      "  36.781372  63.06222 ]\n",
      "timestep:  0\n",
      "new state [542.6587   541.68353  527.3981   541.3635   546.0669    37.405754\n",
      "  57.180626  36.73604 ]\n",
      "reward:  -0.09530787567256209\n",
      "timestep:  1\n",
      "new state [424.68314   425.8258    441.74783   426.2038    477.87057     8.134197\n",
      "   6.5746107   5.8029385]\n",
      "reward:  -0.029978481074024003\n",
      "timestep:  2\n",
      "new state [258.       258.       258.       258.       258.        15.861988\n",
      "  19.140491  12.048944]\n",
      "reward:  -0.05836401874099932\n",
      "\n",
      "env reset!\n",
      "starting_state [258.       258.       258.       258.       258.        11.518289\n",
      "  21.274712  28.710829]\n",
      "timestep:  0\n",
      "new state [246.01689  246.12653  247.72821  246.16309  245.19206   20.099638\n",
      "  27.451147  43.479935]\n",
      "reward:  -1.5033536407832817\n",
      "timestep:  1\n",
      "new state [228.79898  228.96321  231.30255  229.0181   225.79668    5.663736\n",
      "   9.383028  12.512944]\n",
      "reward:  -1.5156036099589436\n",
      "timestep:  2\n",
      "new state [298.7      298.7      298.7      298.7      298.7       38.285866\n",
      "  71.02421  125.677246]\n",
      "reward:  -0.07653518605334723\n",
      "\n",
      "env reset!\n",
      "starting_state [298.7     298.7     298.7     298.7     298.7      52.69368  76.86482\n",
      " 120.95825]\n",
      "timestep:  0\n",
      "new state [251.23709 251.42886 254.0629  251.49316 244.7447   64.40043  48.75971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  87.80043]\n",
      "reward:  -1.5150209066404712\n",
      "timestep:  1\n",
      "new state [214.13147  214.08456  213.07684  214.06952  205.5704    44.73864\n",
      "  42.23047   63.062866]\n",
      "reward:  -1.5244633875849405\n",
      "timestep:  2\n",
      "new state [421.9      421.9      421.9      421.9      421.9       20.367168\n",
      "  14.929051  28.97692 ]\n",
      "reward:  -1.5127802083918778\n",
      "\n",
      "env reset!\n",
      "starting_state [421.9      421.9      421.9      421.9      421.9       42.704178\n",
      "  53.84729   65.30015 ]\n",
      "timestep:  0\n",
      "new state [289.21472  290.05426  302.1205   290.33054  392.75854   48.31242\n",
      "  51.394344  89.22318 ]\n",
      "reward:  -0.18043155665007307\n",
      "timestep:  1\n",
      "new state [254.06369  254.85838  266.09573  255.12007  352.9571    30.889675\n",
      "  28.536442  95.86964 ]\n",
      "reward:  -1.522065837822788\n",
      "timestep:  2\n",
      "new state [532.7      532.7      532.7      532.7      532.7       29.215311\n",
      "  29.297398  90.52053 ]\n",
      "reward:  -0.3031324041755763\n",
      "\n",
      "env reset!\n",
      "starting_state [532.7      532.7      532.7      532.7      532.7       15.893612\n",
      "  22.797962  31.012772]\n",
      "timestep:  0\n",
      "new state [476.43005  476.7743   481.79974  476.88727  475.14886   10.531451\n",
      "  20.25539   27.191671]\n",
      "reward:  -0.07856910305073497\n",
      "timestep:  1\n",
      "new state [429.3375   430.13562  441.81363  430.39743  424.6902    48.773994\n",
      "  41.24159   69.70564 ]\n",
      "reward:  -0.07638307381854305\n",
      "timestep:  2\n",
      "new state [385.8      385.8      385.8      385.8      385.8       53.84964\n",
      "  53.398853  45.083656]\n",
      "reward:  -0.09418217664417101\n",
      "\n",
      "env reset!\n",
      "starting_state [385.8       385.8       385.8       385.8       385.8        88.03877\n",
      "   3.5990686 150.67554  ]\n",
      "timestep:  0\n",
      "new state [349.88098  348.24335  322.88608  347.7005   318.6237    61.643486\n",
      " 101.91466  126.1111  ]\n",
      "reward:  -1.6047769509171008\n",
      "timestep:  1\n",
      "new state [292.74066  291.6312   274.13446  291.2641   262.35562   17.000122\n",
      "  19.378986  21.95446 ]\n",
      "reward:  -1.4976807669414995\n",
      "timestep:  2\n",
      "new state [369.3       369.3       369.3       369.3       369.3         9.954162\n",
      "   6.2021093  11.368587 ]\n",
      "reward:  -0.06809406386274443\n",
      "\n",
      "env reset!\n",
      "starting_state [369.3      369.3      369.3      369.3      369.3       68.656334\n",
      "  57.28457   84.397415]\n",
      "timestep:  0\n",
      "new state [329.32928  329.22278  327.6798   329.18713  331.63544   51.262974\n",
      "  73.26143   38.579063]\n",
      "reward:  -1.5124350673588445\n",
      "timestep:  1\n",
      "new state [293.53323   294.03598   221.38466   294.20175   314.38504     4.4276123\n",
      "   7.0010343  14.069587 ]\n",
      "reward:  -1.08862923434996\n",
      "timestep:  2\n",
      "new state [405.9      405.9      405.9      405.9      405.9       35.008423\n",
      "  64.534256  63.143757]\n",
      "reward:  -0.10572175224076022\n",
      "\n",
      "env reset!\n",
      "starting_state [405.9      405.9      405.9      405.9      405.9       53.765198\n",
      "  93.29372   57.67846 ]\n",
      "timestep:  0\n",
      "new state [361.32724  362.16498  375.1812   362.44244  380.12897   58.072224\n",
      "  58.741592 165.6324  ]\n",
      "reward:  -1.4517370544343422\n",
      "timestep:  1\n",
      "new state [312.64343  313.0403   318.70648  313.1729   306.27637   22.718405\n",
      "  18.92584   27.826614]\n",
      "reward:  -1.5530146265612477\n",
      "timestep:  2\n",
      "new state [483.8      483.8      483.8      483.8      483.8       32.634827\n",
      "  52.41685   70.07109 ]\n",
      "reward:  -0.0858963396614308\n",
      "\n",
      "env reset!\n",
      "starting_state [483.8     483.8     483.8     483.8     483.8      67.67647 102.43869\n",
      "  71.08226]\n",
      "timestep:  0\n",
      "new state [432.32077  433.1136   324.48846  433.376    452.04565   67.41368\n",
      "  95.658356  70.84475 ]\n",
      "reward:  -1.0947421763090637\n",
      "timestep:  1\n",
      "new state [226.42918  230.31396  286.31522  231.5955   320.54      20.258537\n",
      "  24.00422   49.519707]\n",
      "reward:  -0.18373010432559575\n",
      "timestep:  2\n",
      "new state [504.2      504.2      504.2      504.2      504.2       25.789259\n",
      "  24.07652   70.3113  ]\n",
      "reward:  -0.10705479834195739\n",
      "\n",
      "env reset!\n",
      "starting_state [504.2     504.2     504.2     504.2     504.2      69.09545  87.1684\n",
      " 117.49688]\n",
      "timestep:  0\n",
      "new state [451.15427  451.39404  299.24365  451.4738   451.7735    75.718445\n",
      "  76.953064  42.86057 ]\n",
      "reward:  -1.0848942782889652\n",
      "timestep:  1\n",
      "new state [276.61108 278.9129  264.66666 279.67474 372.18652  84.30181  95.41798\n",
      " 211.03032]\n",
      "reward:  -0.18919984757267969\n",
      "timestep:  2\n",
      "new state [625.8      625.8      625.8      625.8      625.8        6.914862\n",
      "   7.725626   8.847546]\n",
      "reward:  -1.537963584057187\n",
      "\n",
      "env reset!\n",
      "starting_state [625.8     625.8     625.8     625.8     625.8      91.13546 113.52861\n",
      " 206.13072]\n",
      "timestep:  0\n",
      "new state [309.70096  309.4943   307.2859   309.42282  533.8602    66.19723\n",
      "  89.615776  66.893295]\n",
      "reward:  -0.2338871921396122\n",
      "timestep:  1\n",
      "new state [262.8087    263.2017    270.4068    263.32852   409.68857     5.382935\n",
      "   2.9284296   4.6989017]\n",
      "reward:  -1.2613856428661776\n",
      "timestep:  2\n",
      "new state [361.2      361.2      361.2      361.2      361.2       15.225042\n",
      "  30.047523  30.504225]\n",
      "reward:  -0.09211890042424495\n",
      "\n",
      "env reset!\n",
      "starting_state [361.2      361.2      361.2      361.2      361.2       53.08944\n",
      "  87.212166 119.767044]\n",
      "timestep:  0\n",
      "new state [310.75403  311.13535  316.69653  311.26248  307.77005   72.977165\n",
      "  61.269924 181.84932 ]\n",
      "reward:  -1.5050783158319845\n",
      "timestep:  1\n",
      "new state [256.588     256.3387    251.66626   256.25793   226.6836      8.093409\n",
      "   5.7520013  18.94009  ]\n",
      "reward:  -1.554959613210545\n",
      "timestep:  2\n",
      "new state [273.2      273.2      273.2      273.2      273.2        6.601778\n",
      "  11.453204  16.405418]\n",
      "reward:  -0.13332998737414545\n",
      "\n",
      "env reset!\n",
      "starting_state [273.2      273.2      273.2      273.2      273.2       34.82256\n",
      "  53.696167  75.69512 ]\n",
      "timestep:  0\n",
      "new state [241.50858  241.7117   244.65689  241.77948  239.4313    39.66742\n",
      "  27.729004  29.691042]\n",
      "reward:  -1.5071698498491113\n",
      "timestep:  1\n",
      "new state [222.39697  222.55031  224.91597  222.60106  226.16936   15.273366\n",
      "  22.358013  43.79532 ]\n",
      "reward:  -1.4963679562625147\n",
      "timestep:  2\n",
      "new state [351.8      351.8      351.8      351.8      351.8       37.66859\n",
      "  53.746574  35.644295]\n",
      "reward:  -0.24889987789194726\n",
      "\n",
      "env reset!\n",
      "starting_state [351.8      351.8      351.8      351.8      351.8       10.779009\n",
      "  11.067336  23.435661]\n",
      "timestep:  0\n",
      "new state [317.81906   317.63177   315.01852   317.56976   341.34778     7.3338127\n",
      "   9.361227   20.569546 ]\n",
      "reward:  -0.24803553288861552\n",
      "timestep:  1\n",
      "new state [290.03748   289.73914   285.63663   289.6401    303.18088    11.904407\n",
      "   4.9091125  22.337868 ]\n",
      "reward:  -0.11143320643719383\n",
      "timestep:  2\n",
      "new state [236.1      236.1      236.1      236.1      236.1       33.18761\n",
      "  65.25444   52.266026]\n",
      "reward:  -0.14454965178304655\n",
      "\n",
      "env reset!\n",
      "starting_state [236.1      236.1      236.1      236.1      236.1       12.941438\n",
      "  14.481087  45.23311 ]\n",
      "timestep:  0\n",
      "new state [223.79472  223.67421  221.63614  223.63467  215.9336    15.168373\n",
      "  27.646135  41.162754]\n",
      "reward:  -1.5599864201691238\n",
      "timestep:  1\n",
      "new state [207.70279 207.7009  207.35275 207.70102 197.57294  63.98094  71.12779\n",
      "  57.12702]\n",
      "reward:  -1.5105594273230256\n",
      "timestep:  2\n",
      "new state [543.5      543.5      543.5      543.5      543.5      106.001465\n",
      "  92.573204 112.9911  ]\n",
      "reward:  -1.4746658893623694\n",
      "\n",
      "env reset!\n",
      "starting_state [543.5      543.5      543.5      543.5      543.5       48.984474\n",
      "  57.27402   80.303246]\n",
      "timestep:  0\n",
      "new state [394.04877  394.49847  401.02148  394.64612  394.47632   48.26404\n",
      "  63.238087 157.48856 ]\n",
      "reward:  -0.08150471918578411\n",
      "timestep:  1\n",
      "new state [346.83282  347.0633   349.60327  347.13965  324.2547    61.764336\n",
      "  36.61974  134.69456 ]\n",
      "reward:  -1.546287968374398\n",
      "timestep:  2\n",
      "new state [373.6       373.6       373.6       373.6       373.6         7.4688554\n",
      "   6.943538   17.029524 ]\n",
      "reward:  -0.29367192383743934\n",
      "\n",
      "env reset!\n",
      "starting_state [373.6      373.6      373.6      373.6      373.6       13.486623\n",
      "  11.047715  27.249176]\n",
      "timestep:  0\n",
      "new state [335.6175   335.21695  329.53354  335.08478  361.44742   13.740166\n",
      "  18.264805  28.609154]\n",
      "reward:  -0.2590975297742243\n",
      "timestep:  1\n",
      "new state [287.8225   287.5528   283.8367   287.46326  308.35858   32.45851\n",
      "  72.69114  111.168365]\n",
      "reward:  -0.0884740953348687\n",
      "timestep:  2\n",
      "new state [417.8     417.8     417.8     417.8     417.8      28.0652   58.87434\n",
      "  65.21824]\n",
      "reward:  -1.1194667715845636\n",
      "\n",
      "env reset!\n",
      "starting_state [417.8      417.8      417.8      417.8      417.8       37.554443\n",
      "  29.651537  87.394646]\n",
      "timestep:  0\n",
      "new state [307.43192  305.90182  385.7318   305.39667  378.82944   51.693523\n",
      "  53.992424  77.7959  ]\n",
      "reward:  -0.501024222118214\n",
      "timestep:  1\n",
      "new state [272.33478  270.83926  241.92148  270.34558  344.11618   53.265434\n",
      "  48.72865   77.82725 ]\n",
      "reward:  -1.071654954162176\n",
      "timestep:  2\n",
      "new state [539.6      539.6      539.6      539.6      539.6       49.757053\n",
      "  35.54494  107.010925]\n",
      "reward:  -0.26246801563408817\n",
      "Writing to file data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter 0\n",
      "episode 0\n",
      "step 0\n",
      "oldState [346.37134  346.59894  350.8377   346.67175  357.542     10.932322\n",
      "   7.617694  10.668706]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9003692079730182\n",
      "newState [382.08      381.97922   381.04694   381.94394   383.84515     7.2902865\n",
      "  13.422441    1.0207489]\n",
      "info {'type': array([ 7.29028633, 13.42244012,  1.02074885])}\n",
      "\n",
      "iter 0\n",
      "episode 0\n",
      "step 1\n",
      "oldState [382.08      381.97922   381.04694   381.94394   383.84515     7.2902865\n",
      "  13.422441    1.0207489]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.7707156249571203\n",
      "newState [372.10687  372.30737  376.20197  372.3709   383.02676   18.746086\n",
      "  22.220646  32.167324]\n",
      "info {'type': array([18.74608702, 22.22064651, 32.16732254])}\n",
      "\n",
      "iter 0\n",
      "episode 0\n",
      "step 2\n",
      "oldState [372.10687  372.30737  376.20197  372.3709   383.02676   18.746086\n",
      "  22.220646  32.167324]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8999260161235547\n",
      "newState [263.3      263.3      263.3      263.3      263.3       34.28867\n",
      "  41.664326  77.80902 ]\n",
      "info {'type': array([34.28867118, 41.66432681, 77.80901932])}\n",
      "\n",
      "iter 1\n",
      "episode 0\n",
      "step 0\n",
      "oldState [236.64151   236.38402   240.70935   236.30121   236.60004     8.275917\n",
      "   6.1462727  23.933739 ]\n",
      "action [[3.2850e-01 3.5372e-01 2.5356e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 1.8536e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.2417541461107364\n",
      "newState [251.69704  251.47697  256.76212  251.4052   255.28503    6.277636\n",
      "   7.163428  17.836748]\n",
      "info {'type': array([ 6.27763623,  7.16342792, 17.83674722])}\n",
      "\n",
      "iter 1\n",
      "episode 0\n",
      "step 1\n",
      "oldState [251.69704  251.47697  256.76212  251.4052   255.28503    6.277636\n",
      "   7.163428  17.836748]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9356782413748699\n",
      "newState [241.60078   241.30925   245.1806    241.21497   241.15839     3.2439456\n",
      "   4.6910872   5.753231 ]\n",
      "info {'type': array([3.24394553, 4.69108711, 5.75323122])}\n",
      "\n",
      "iter 1\n",
      "episode 0\n",
      "step 2\n",
      "oldState [241.60078   241.30925   245.1806    241.21497   241.15839     3.2439456\n",
      "   4.6910872   5.753231 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8878373456148962\n",
      "newState [314.2     314.2     314.2     314.2     314.2      91.38705 116.69336\n",
      "  95.547  ]\n",
      "info {'type': array([ 91.38704446, 116.69336287,  95.54699897])}\n",
      "\n",
      "iter 2\n",
      "episode 0\n",
      "step 0\n",
      "oldState [212.23123  211.86652  206.488    211.74512  205.4041    77.67342\n",
      "  63.238663 144.01955 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7898808322881936\n",
      "newState [274.74924 274.30692 267.77805 274.15988 265.94348  76.98636  90.14613\n",
      " 123.91545]\n",
      "info {'type': array([ 76.98635864,  90.14613227, 123.91544956])}\n",
      "\n",
      "iter 2\n",
      "episode 0\n",
      "step 1\n",
      "oldState [274.74924 274.30692 267.77805 274.15988 265.94348  76.98636  90.14613\n",
      " 123.91545]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7577921940782366\n",
      "newState [231.13269  230.75491  225.24335  230.6289   224.40028   13.722579\n",
      "  16.198635  23.977694]\n",
      "info {'type': array([13.72257877, 16.19863448, 23.97769297])}\n",
      "\n",
      "iter 2\n",
      "episode 0\n",
      "step 2\n",
      "oldState [231.13269  230.75491  225.24335  230.6289   224.40028   13.722579\n",
      "  16.198635  23.977694]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.901404191643661\n",
      "newState [491.9      491.9      491.9      491.9      491.9       46.427876\n",
      "  87.64983   11.633492]\n",
      "info {'type': array([46.42787668, 87.6498326 , 11.63349278])}\n",
      "\n",
      "iter 3\n",
      "episode 0\n",
      "step 0\n",
      "oldState [457.28256   457.20944   454.95108   457.18918   447.5116      3.8670585\n",
      "   6.420634   14.785695 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9317098013995301\n",
      "newState [483.7059   483.69818  483.10464  483.69724  480.1902     9.356492\n",
      "   9.539852  20.92689 ]\n",
      "info {'type': array([ 9.35649198,  9.53985225, 20.92688897])}\n",
      "\n",
      "iter 3\n",
      "episode 0\n",
      "step 1\n",
      "oldState [483.7059   483.69818  483.10464  483.69724  480.1902     9.356492\n",
      "   9.539852  20.92689 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9270922781004894\n",
      "newState [470.58527   470.48538   468.31644   470.4546    463.6146      7.4263606\n",
      "  11.283441   20.330017 ]\n",
      "info {'type': array([ 7.42636063, 11.28344045, 20.3300178 ])}\n",
      "\n",
      "iter 3\n",
      "episode 0\n",
      "step 2\n",
      "oldState [470.58527   470.48538   468.31644   470.4546    463.6146      7.4263606\n",
      "  11.283441   20.330017 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9144155133428208\n",
      "newState [88.7       88.7       88.7       88.7       88.7        7.0896263\n",
      "  7.5003157 10.886014 ]\n",
      "info {'type': array([ 7.08962623,  7.50031553, 10.88601422])}\n",
      "\n",
      "iter 4\n",
      "episode 0\n",
      "step 0\n",
      "oldState [62.951427 62.9181   61.981575 62.908295 59.481625 17.161901 18.034266\n",
      " 41.1559  ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7909297262278212\n",
      "newState [78.13555  78.06215  76.710754 78.03856  74.91246  17.53796  23.187601\n",
      " 35.562305]\n",
      "info {'type': array([17.53796036, 23.18760197, 35.56230735])}\n",
      "\n",
      "iter 4\n",
      "episode 0\n",
      "step 1\n",
      "oldState [78.13555  78.06215  76.710754 78.03856  74.91246  17.53796  23.187601\n",
      " 35.562305]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.764635884128887\n",
      "newState [66.87238  66.82445  65.66041  66.80985  62.99366   6.835262  8.435641\n",
      " 10.474026]\n",
      "info {'type': array([ 6.83526198,  8.4356414 , 10.47402529])}\n",
      "\n",
      "iter 4\n",
      "episode 0\n",
      "step 2\n",
      "oldState [66.87238  66.82445  65.66041  66.80985  62.99366   6.835262  8.435641\n",
      " 10.474026]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7508823092055157\n",
      "newState [226.5      226.5      226.5      226.5      226.5       27.394936\n",
      "  46.995453  17.307558]\n",
      "info {'type': array([27.39493476, 46.99545302, 17.3075575 ])}\n",
      "\n",
      "iter 5\n",
      "episode 0\n",
      "step 0\n",
      "oldState [140.77109  141.17325  148.52399  141.30243  163.06294    5.490476\n",
      "   5.421324   4.744817]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7323892647243422\n",
      "newState [224.02081   224.02672   224.22563   224.02832   224.90703     4.982329\n",
      "   7.5733066   7.7726264]\n",
      "info {'type': array([4.98232872, 7.57330645, 7.77262629])}\n",
      "\n",
      "iter 5\n",
      "episode 0\n",
      "step 1\n",
      "oldState [224.02081   224.02672   224.22563   224.02832   224.90703     4.982329\n",
      "   7.5733066   7.7726264]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.9482827038720988\n",
      "newState [216.44785  216.53021  217.82301  216.55734  222.30019   60.740826\n",
      "  70.336586  74.74761 ]\n",
      "info {'type': array([60.74082531, 70.33658681, 74.74760896])}\n",
      "\n",
      "iter 5\n",
      "episode 0\n",
      "step 2\n",
      "oldState [216.44785  216.53021  217.82301  216.55734  222.30019   60.740826\n",
      "  70.336586  74.74761 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8803878563055683\n",
      "newState [332.1     332.1     332.1     332.1     332.1      21.95292  37.47287\n",
      "  53.31124]\n",
      "info {'type': array([21.95292172, 37.47287024, 53.31124002])}\n",
      "\n",
      "iter 6\n",
      "episode 0\n",
      "step 0\n",
      "oldState [198.05615  198.91473  209.29288  199.20781  200.66658   10.202902\n",
      "   9.098642   6.83522 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8651589819060344\n",
      "newState [322.1939    322.20435   322.96115   322.20584   326.67944     7.4036946\n",
      "   7.3668222  24.090857 ]\n",
      "info {'type': array([ 7.40369443,  7.36682209, 24.09085729])}\n",
      "\n",
      "iter 6\n",
      "episode 0\n",
      "step 1\n",
      "oldState [322.1939    322.20435   322.96115   322.20584   326.67944     7.4036946\n",
      "   7.3668222  24.090857 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9519604788300866\n",
      "newState [310.17352 310.0294  307.96765 309.98135 307.60126  65.77657 108.52525\n",
      " 134.97325]\n",
      "info {'type': array([ 65.77657426, 108.52525445, 134.97325186])}\n",
      "\n",
      "iter 6\n",
      "episode 0\n",
      "step 2\n",
      "oldState [310.17352 310.0294  307.96765 309.98135 307.60126  65.77657 108.52525\n",
      " 134.97325]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8880113425168532\n",
      "newState [294.4       294.4       294.4       294.4       294.4         7.3839045\n",
      "   8.078552   23.081436 ]\n",
      "info {'type': array([ 7.38390424,  8.07855216, 23.08143556])}\n",
      "\n",
      "iter 7\n",
      "episode 0\n",
      "step 0\n",
      "oldState [169.10707  168.49408  180.15373  168.301    165.19485   20.236734\n",
      "  26.302414  66.29913 ]\n",
      "action [[3.2850e-01 3.5372e-01 2.5356e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 1.8536e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.197481680716297\n",
      "newState [258.06696  257.86746  276.9664   257.80698  272.19437   19.795473\n",
      "  24.024158  47.187183]\n",
      "info {'type': array([19.79547373, 24.02415888, 47.18718453])}\n",
      "\n",
      "iter 7\n",
      "episode 0\n",
      "step 1\n",
      "oldState [258.06696  257.86746  276.9664   257.80698  272.19437   19.795473\n",
      "  24.024158  47.187183]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9202069776725016\n",
      "newState [227.5347   227.25294  244.4043   227.16766  234.81813   42.84446\n",
      "  44.006886  87.89553 ]\n",
      "info {'type': array([42.84445865, 44.00688481, 87.89552885])}\n",
      "\n",
      "iter 7\n",
      "episode 0\n",
      "step 2\n",
      "oldState [227.5347   227.25294  244.4043   227.16766  234.81813   42.84446\n",
      "  44.006886  87.89553 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9210765485098565\n",
      "newState [271.4      271.4      271.4      271.4      271.4        8.709915\n",
      "  10.102669  18.147213]\n",
      "info {'type': array([ 8.70991551, 10.1026686 , 18.14721213])}\n",
      "\n",
      "iter 8\n",
      "episode 0\n",
      "step 0\n",
      "oldState [183.16544  183.69608  198.17795  183.88582  200.77501   11.835402\n",
      "  22.375742  25.979523]\n",
      "action [[3.2850e-01 3.5372e-01 2.5356e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 1.8536e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.0877134171866942\n",
      "newState [249.27742  249.5461   263.57227  249.63739  262.69067   17.524372\n",
      "  20.638361  48.990944]\n",
      "info {'type': array([17.5243714 , 20.63836191, 48.99094499])}\n",
      "\n",
      "iter 8\n",
      "episode 0\n",
      "step 1\n",
      "oldState [249.27742  249.5461   263.57227  249.63739  262.69067   17.524372\n",
      "  20.638361  48.990944]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.0397354709956006\n",
      "newState [220.92726  221.02806  231.59174  221.06696  246.2802    13.752008\n",
      "  36.53962   57.451855]\n",
      "info {'type': array([13.75200859, 36.53962079, 57.45185496])}\n",
      "\n",
      "iter 8\n",
      "episode 0\n",
      "step 2\n",
      "oldState [220.92726  221.02806  231.59174  221.06696  246.2802    13.752008\n",
      "  36.53962   57.451855]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9038991639977927\n",
      "newState [431.9      431.9      431.9      431.9      431.9       59.223713\n",
      "  45.17748   72.74192 ]\n",
      "info {'type': array([59.2237147 , 45.17747783, 72.7419208 ])}\n",
      "\n",
      "iter 9\n",
      "episode 0\n",
      "step 0\n",
      "oldState [335.02927  336.4532   360.7641   336.9155   388.94003   15.673986\n",
      "  11.784581  10.755428]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8775101762473392\n",
      "newState [417.82285  417.75537  417.75027  417.72977  423.37204   19.455704\n",
      "  21.211712  14.576744]\n",
      "info {'type': array([19.45570371, 21.21171266, 14.576744  ])}\n",
      "\n",
      "iter 9\n",
      "episode 0\n",
      "step 1\n",
      "oldState [417.82285  417.75537  417.75027  417.72977  423.37204   19.455704\n",
      "  21.211712  14.576744]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8567507498900703\n",
      "newState [396.46463  396.54416  399.64734  396.56436  411.81247   43.571934\n",
      "  73.98386   28.818937]\n",
      "info {'type': array([43.57193191, 73.98385681, 28.81893654])}\n",
      "\n",
      "iter 9\n",
      "episode 0\n",
      "step 2\n",
      "oldState [396.46463  396.54416  399.64734  396.56436  411.81247   43.571934\n",
      "  73.98386   28.818937]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8181775844307972\n",
      "newState [251.        251.        251.        251.        251.          6.8050537\n",
      "   9.470165   20.936565 ]\n",
      "info {'type': array([ 6.80505385,  9.47016532, 20.9365648 ])}\n",
      "\n",
      "iter 10\n",
      "episode 0\n",
      "step 0\n",
      "oldState [193.53603   193.2894    187.57147   193.21451   184.34268     5.7822447\n",
      "   5.622657   14.668379 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7991007270435377\n",
      "newState [247.46732  247.43225  246.81212  247.42091  246.08655    4.964589\n",
      "   7.979662  22.917156]\n",
      "info {'type': array([ 4.96458921,  7.97966189, 22.91715623])}\n",
      "\n",
      "iter 10\n",
      "episode 0\n",
      "step 1\n",
      "oldState [247.46732  247.43225  246.81212  247.42091  246.08655    4.964589\n",
      "   7.979662  22.917156]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.0682117148931949\n",
      "newState [236.18373  236.08987  233.80077  236.0617   238.41246   27.182522\n",
      "  32.845627  68.26477 ]\n",
      "info {'type': array([27.18252145, 32.84562773, 68.26477042])}\n",
      "\n",
      "iter 10\n",
      "episode 0\n",
      "step 2\n",
      "oldState [236.18373  236.08987  233.80077  236.0617   238.41246   27.182522\n",
      "  32.845627  68.26477 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9239740325249155\n",
      "newState [424.1      424.1      424.1      424.1      424.1       52.364475\n",
      " 116.56082   95.4568  ]\n",
      "info {'type': array([ 52.36447411, 116.56082352,  95.45680364])}\n",
      "\n",
      "iter 11\n",
      "episode 0\n",
      "step 0\n",
      "oldState [276.46722  277.0207   281.0416   277.2187   259.5353    23.085138\n",
      "  29.845253  54.713528]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9156011261211648\n",
      "newState [387.5662   387.54086  386.26355  387.53558  380.76123   17.51794\n",
      "  23.701492  69.26325 ]\n",
      "info {'type': array([17.51793986, 23.70149244, 69.26325041])}\n",
      "\n",
      "iter 11\n",
      "episode 0\n",
      "step 1\n",
      "oldState [387.5662   387.54086  386.26355  387.53558  380.76123   17.51794\n",
      "  23.701492  69.26325 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9468276901850825\n",
      "newState [352.86523 352.58353 345.42496 352.50012 325.91043  46.031    76.6831\n",
      "  83.76971]\n",
      "info {'type': array([46.03099867, 76.6831016 , 83.76970596])}\n",
      "\n",
      "iter 11\n",
      "episode 0\n",
      "step 2\n",
      "oldState [352.86523 352.58353 345.42496 352.50012 325.91043  46.031    76.6831\n",
      "  83.76971]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8788957958517524\n",
      "newState [486.9      486.9      486.9      486.9      486.9       49.756626\n",
      "  67.749756 139.36096 ]\n",
      "info {'type': array([ 49.75662579,  67.74975253, 139.36096161])}\n",
      "\n",
      "iter 12\n",
      "episode 0\n",
      "step 0\n",
      "oldState [182.20877  185.80835  234.2858   187.02     227.42328   63.406208\n",
      " 148.30202   60.378918]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8119045961865505\n",
      "newState [371.0118  374.28427 422.23633 375.3725  438.99698  79.4938  106.23367\n",
      " 201.20831]\n",
      "info {'type': array([ 79.49379957, 106.23367531, 201.20831317])}\n",
      "\n",
      "iter 12\n",
      "episode 0\n",
      "step 1\n",
      "oldState [371.0118  374.28427 422.23633 375.3725  438.99698  79.4938  106.23367\n",
      " 201.20831]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9178371039810845\n",
      "newState [240.36018  243.5458   286.34924  244.61841  279.6236    38.576565\n",
      "  55.349182  65.8818  ]\n",
      "info {'type': array([38.57656385, 55.34918214, 65.88179476])}\n",
      "\n",
      "iter 12\n",
      "episode 0\n",
      "step 2\n",
      "oldState [240.36018  243.5458   286.34924  244.61841  279.6236    38.576565\n",
      "  55.349182  65.8818  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8858688193741905\n",
      "newState [612.3      612.3      612.3      612.3      612.3       25.025757\n",
      "  45.414127  33.943142]\n",
      "info {'type': array([25.02575613, 45.41412874, 33.94314293])}\n",
      "\n",
      "iter 13\n",
      "episode 0\n",
      "step 0\n",
      "oldState [499.23193  499.34308  499.49283  499.38528  491.41238   27.968258\n",
      "  66.738335  84.74562 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8877214229974669\n",
      "newState [547.0507   547.9648   558.3771   548.2787   545.1663    43.928947\n",
      "  21.158365  45.88839 ]\n",
      "info {'type': array([43.92894843, 21.15836518, 45.88838824])}\n",
      "\n",
      "iter 13\n",
      "episode 0\n",
      "step 1\n",
      "oldState [547.0507   547.9648   558.3771   548.2787   545.1663    43.928947\n",
      "  21.158365  45.88839 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9239245855471359\n",
      "newState [510.458     510.58832   511.8446    510.6342    508.80762     4.5594273\n",
      "   8.518999   21.96597  ]\n",
      "info {'type': array([ 4.55942705,  8.51899896, 21.96596842])}\n",
      "\n",
      "iter 13\n",
      "episode 0\n",
      "step 2\n",
      "oldState [510.458     510.58832   511.8446    510.6342    508.80762     4.5594273\n",
      "   8.518999   21.96597  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9398612760725984\n",
      "newState [450.7     450.7     450.7     450.7     450.7      77.63267  69.99103\n",
      "  94.91813]\n",
      "info {'type': array([77.63267112, 69.99103147, 94.91812673])}\n",
      "\n",
      "iter 14\n",
      "episode 0\n",
      "step 0\n",
      "oldState [231.30505  231.61497  236.42102  231.71794  240.1036    47.703785\n",
      "  49.525536  75.24773 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9035085777889277\n",
      "newState [390.57523  390.4509   389.04712  390.40842  391.0838    67.479576\n",
      "  54.46545  111.912834]\n",
      "info {'type': array([ 67.47957788,  54.46545123, 111.91283756])}\n",
      "\n",
      "iter 14\n",
      "episode 0\n",
      "step 1\n",
      "oldState [390.57523  390.4509   389.04712  390.40842  391.0838    67.479576\n",
      "  54.46545  111.912834]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9223963438748287\n",
      "newState [312.79233  311.86243  299.4524   311.5498   302.4304    47.493595\n",
      "  87.26797   78.64809 ]\n",
      "info {'type': array([47.49359518, 87.26796744, 78.6480903 ])}\n",
      "\n",
      "iter 14\n",
      "episode 0\n",
      "step 2\n",
      "oldState [312.79233  311.86243  299.4524   311.5498   302.4304    47.493595\n",
      "  87.26797   78.64809 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.864758552313635\n",
      "newState [626.4      626.4      626.4      626.4      626.4       38.041695\n",
      "  35.91565  125.50194 ]\n",
      "info {'type': array([ 38.04169435,  35.91564804, 125.50193762])}\n",
      "\n",
      "iter 15\n",
      "episode 0\n",
      "step 0\n",
      "oldState [403.8289   405.20703  421.60367  405.67844  406.19083   68.84266\n",
      "  94.208176 110.56915 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.885269018689979\n",
      "newState [526.7381  527.378   536.5515  527.59174 538.78973  37.79522  87.63676\n",
      "  87.71248]\n",
      "info {'type': array([37.79521827, 87.63675672, 87.71247658])}\n",
      "\n",
      "iter 15\n",
      "episode 0\n",
      "step 1\n",
      "oldState [526.7381  527.378   536.5515  527.59174 538.78973  37.79522  87.63676\n",
      "  87.71248]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8699967322668389\n",
      "newState [446.14368  448.1914   475.4011   448.88196  469.29205   31.472702\n",
      "  24.848057  79.67594 ]\n",
      "info {'type': array([31.4727026 , 24.84805678, 79.67594028])}\n",
      "\n",
      "iter 15\n",
      "episode 0\n",
      "step 2\n",
      "oldState [446.14368  448.1914   475.4011   448.88196  469.29205   31.472702\n",
      "  24.848057  79.67594 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9490478603311706\n",
      "newState [629.1      629.1      629.1      629.1      629.1       47.327087\n",
      "  26.310238  90.41862 ]\n",
      "info {'type': array([47.32708582, 26.31023837, 90.41861677])}\n",
      "\n",
      "iter 16\n",
      "episode 0\n",
      "step 0\n",
      "oldState [494.11594  494.6754   496.92084  494.88153  464.1812    24.897203\n",
      "  74.22195   78.3461  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8723058356371355\n",
      "newState [562.2421   563.5735   579.82056  564.027    567.0301    33.74213\n",
      "  32.012737  87.403915]\n",
      "info {'type': array([33.74213105, 32.0127356 , 87.40391403])}\n",
      "\n",
      "iter 16\n",
      "episode 0\n",
      "step 1\n",
      "oldState [562.2421   563.5735   579.82056  564.027    567.0301    33.74213\n",
      "  32.012737  87.403915]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.940602369544975\n",
      "newState [513.47943  514.2714   521.27466  514.55023  497.80652    9.608265\n",
      "  11.71757   42.46312 ]\n",
      "info {'type': array([ 9.60826514, 11.71756994, 42.46311827])}\n",
      "\n",
      "iter 16\n",
      "episode 0\n",
      "step 2\n",
      "oldState [513.47943  514.2714   521.27466  514.55023  497.80652    9.608265\n",
      "  11.71757   42.46312 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9595467266729447\n",
      "newState [252.3       252.3       252.3       252.3       252.3         7.0822525\n",
      "   7.7232594  10.552965 ]\n",
      "info {'type': array([ 7.08225248,  7.72325933, 10.55296482])}\n",
      "\n",
      "iter 17\n",
      "episode 0\n",
      "step 0\n",
      "oldState [192.33011  192.48619  193.98203  192.54079  209.85551   22.690355\n",
      "  21.37716   41.088287]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7797130559736978\n",
      "newState [240.2001   240.1199   238.91983  240.09326  238.53065   18.794472\n",
      "  18.828686  42.83466 ]\n",
      "info {'type': array([18.79447106, 18.82868497, 42.83465922])}\n",
      "\n",
      "iter 17\n",
      "episode 0\n",
      "step 1\n",
      "oldState [240.2001   240.1199   238.91983  240.09326  238.53065   18.794472\n",
      "  18.828686  42.83466 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.0307503767760844\n",
      "newState [213.84308  213.55745  208.86575  213.4642   224.18022   11.573236\n",
      "  24.75364   18.072481]\n",
      "info {'type': array([11.57323621, 24.75363845, 18.07248204])}\n",
      "\n",
      "iter 17\n",
      "episode 0\n",
      "step 2\n",
      "oldState [213.84308  213.55745  208.86575  213.4642   224.18022   11.573236\n",
      "  24.75364   18.072481]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8486513853785529\n",
      "newState [180.       180.       180.       180.       180.         9.396008\n",
      "  20.15765   22.25668 ]\n",
      "info {'type': array([ 9.39600727, 20.15764952, 22.256679  ])}\n",
      "\n",
      "iter 18\n",
      "episode 0\n",
      "step 0\n",
      "oldState [119.470146 119.54321  124.08417  119.57159  117.07878   45.09914\n",
      "  55.950485  83.77051 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7631961764821718\n",
      "newState [152.63414  152.67444  153.00899  152.68849  151.92154   31.85227\n",
      "  47.323803  93.19615 ]\n",
      "info {'type': array([31.85227042, 47.3238025 , 93.19615553])}\n",
      "\n",
      "iter 18\n",
      "episode 0\n",
      "step 1\n",
      "oldState [152.63414  152.67444  153.00899  152.68849  151.92154   31.85227\n",
      "  47.323803  93.19615 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7818185340212085\n",
      "newState [128.18787   128.23694   127.634026  128.25711   120.70038     6.087017\n",
      "   7.7241664  10.803691 ]\n",
      "info {'type': array([ 6.08701702,  7.72416627, 10.80369073])}\n",
      "\n",
      "iter 18\n",
      "episode 0\n",
      "step 2\n",
      "oldState [128.18787   128.23694   127.634026  128.25711   120.70038     6.087017\n",
      "   7.7241664  10.803691 ]\n",
      "action [[3.2850e-01 3.5372e-01 2.5356e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 1.8536e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.1165369904688565\n",
      "newState [340.2     340.2     340.2     340.2     340.2      56.34593  75.02445\n",
      "  82.67766]\n",
      "info {'type': array([56.34592778, 75.02445372, 82.67765849])}\n",
      "\n",
      "iter 19\n",
      "episode 0\n",
      "step 0\n",
      "oldState [137.04295  134.44536  158.76866  133.54892  190.87408   95.16671\n",
      "  59.903145  76.07263 ]\n",
      "action [[3.2850e-01 3.5372e-01 2.5356e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 1.8536e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.1093456313729666\n",
      "newState [258.61627 257.66968 301.93878 257.33624 314.6701  106.97602  70.30888\n",
      " 270.05283]\n",
      "info {'type': array([106.9760208 ,  70.30888452, 270.05281375])}\n",
      "\n",
      "iter 19\n",
      "episode 0\n",
      "step 1\n",
      "oldState [258.61627 257.66968 301.93878 257.33624 314.6701  106.97602  70.30888\n",
      " 270.05283]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.8188633403888161\n",
      "newState [201.18018  199.06842  224.7218   198.35231  224.22717   78.9236\n",
      "  52.114098  42.04996 ]\n",
      "info {'type': array([78.92359939, 52.11409747, 42.04996187])}\n",
      "\n",
      "iter 19\n",
      "episode 0\n",
      "step 2\n",
      "oldState [201.18018  199.06842  224.7218   198.35231  224.22717   78.9236\n",
      "  52.114098  42.04996 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.874105248053091\n",
      "newState [862.9      862.9      862.9      862.9      862.9       45.03868\n",
      "  46.135635  39.258255]\n",
      "info {'type': array([45.03868107, 46.13563723, 39.25825446])}\n",
      "\n",
      "iter 20\n",
      "episode 0\n",
      "step 0\n",
      "oldState [585.4243   585.0462   575.6347   584.93427  551.062     86.95109\n",
      "  84.90955   44.371353]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.846738367822145\n",
      "newState [777.6495  778.1482  791.07965 778.2958  827.68884  75.25718  84.63726\n",
      " 166.01964]\n",
      "info {'type': array([ 75.25718192,  84.63726132, 166.01964242])}\n",
      "\n",
      "iter 20\n",
      "episode 0\n",
      "step 1\n",
      "oldState [777.6495  778.1482  791.07965 778.2958  827.68884  75.25718  84.63726\n",
      " 166.01964]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9200261888742641\n",
      "newState [668.32263  668.3946   673.1357   668.40704  696.18445   28.833546\n",
      "  56.928272 183.26923 ]\n",
      "info {'type': array([ 28.83354541,  56.92827288, 183.26923049])}\n",
      "\n",
      "iter 20\n",
      "episode 0\n",
      "step 2\n",
      "oldState [668.32263  668.3946   673.1357   668.40704  696.18445   28.833546\n",
      "  56.928272 183.26923 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9548446090371185\n",
      "newState [632.4      632.4      632.4      632.4      632.4       50.193836\n",
      "  74.47444   70.67178 ]\n",
      "info {'type': array([50.19383445, 74.47443812, 70.67178456])}\n",
      "\n",
      "iter 21\n",
      "episode 0\n",
      "step 0\n",
      "oldState [368.9528  368.0978  354.95386 367.81653 347.5717   68.8054   84.22174\n",
      " 127.70535]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.902883538754635\n",
      "newState [534.25977  534.36163  535.08923  534.3983   531.2294    67.63453\n",
      "  54.094967 143.87057 ]\n",
      "info {'type': array([ 67.6345319 ,  54.09496746, 143.87057025])}\n",
      "\n",
      "iter 21\n",
      "episode 0\n",
      "step 1\n",
      "oldState [534.25977  534.36163  535.08923  534.3983   531.2294    67.63453\n",
      "  54.094967 143.87057 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.938002654433394\n",
      "newState [449.25537  448.21606  431.43356  447.87634  417.27768   63.066257\n",
      "  71.81964   87.96967 ]\n",
      "info {'type': array([63.06625719, 71.81964097, 87.96967643])}\n",
      "\n",
      "iter 21\n",
      "episode 0\n",
      "step 2\n",
      "oldState [449.25537  448.21606  431.43356  447.87634  417.27768   63.066257\n",
      "  71.81964   87.96967 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8893718790254584\n",
      "newState [605.1      605.1      605.1      605.1      605.1        8.978854\n",
      "   6.497436   7.013225]\n",
      "info {'type': array([8.9788539 , 6.49743601, 7.01322525])}\n",
      "\n",
      "iter 22\n",
      "episode 0\n",
      "step 0\n",
      "oldState [430.98615  432.57886  454.95703  433.1121   457.61365   45.38345\n",
      "  62.868977  64.14087 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8759993387271586\n",
      "newState [541.0005   541.53754  549.69275  541.7154   554.2706    38.236603\n",
      "  60.039486  39.17372 ]\n",
      "info {'type': array([38.23660374, 60.03948556, 39.17371994])}\n",
      "\n",
      "iter 22\n",
      "episode 0\n",
      "step 1\n",
      "oldState [541.0005   541.53754  549.69275  541.7154   554.2706    38.236603\n",
      "  60.039486  39.17372 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8467345105536046\n",
      "newState [486.557    487.95538  509.50504  488.41724  523.2108    30.421913\n",
      "  48.387154  82.814674]\n",
      "info {'type': array([30.42191394, 48.38715234, 82.81467756])}\n",
      "\n",
      "iter 22\n",
      "episode 0\n",
      "step 2\n",
      "oldState [486.557    487.95538  509.50504  488.41724  523.2108    30.421913\n",
      "  48.387154  82.814674]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.910770291922945\n",
      "newState [486.8      486.8      486.8      486.8      486.8       43.303104\n",
      "  26.81554  104.655334]\n",
      "info {'type': array([ 43.30310479,  26.81553973, 104.65533422])}\n",
      "\n",
      "iter 23\n",
      "episode 0\n",
      "step 0\n",
      "oldState [398.00635   399.12997   411.6984    399.5166    394.0859      4.246041\n",
      "   8.46335    12.1051445]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.897321453519963\n",
      "newState [477.9824    478.06717   478.9469    478.09656   477.21097     6.9337163\n",
      "   6.9050226   3.1503477]\n",
      "info {'type': array([6.93371648, 6.90502273, 3.15034775])}\n",
      "\n",
      "iter 23\n",
      "episode 0\n",
      "step 1\n",
      "oldState [477.9824    478.06717   478.9469    478.09656   477.21097     6.9337163\n",
      "   6.9050226   3.1503477]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8407300275353763\n",
      "newState [471.20044  471.33377  473.38925  471.3778   474.71017   28.496254\n",
      "  73.75888  101.782585]\n",
      "info {'type': array([ 28.49625358,  73.75888041, 101.78258529])}\n",
      "\n",
      "iter 23\n",
      "episode 0\n",
      "step 2\n",
      "oldState [471.20044  471.33377  473.38925  471.3778   474.71017   28.496254\n",
      "  73.75888  101.782585]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8938313549047445\n",
      "newState [218.7       218.7       218.7       218.7       218.7        10.630719\n",
      "   6.9710045  19.985203 ]\n",
      "info {'type': array([10.63071949,  6.9710047 , 19.98520213])}\n",
      "\n",
      "iter 24\n",
      "episode 0\n",
      "step 0\n",
      "oldState [129.381    128.87297  157.04433  128.7077   151.0357    22.827225\n",
      "  29.537369  80.270775]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.8031202142203526\n",
      "newState [200.8794   200.76224  198.01816  200.72643  191.81682   29.131529\n",
      "  24.086033  35.90745 ]\n",
      "info {'type': array([29.13152946, 24.08603193, 35.90745135])}\n",
      "\n",
      "iter 24\n",
      "episode 0\n",
      "step 1\n",
      "oldState [200.8794   200.76224  198.01816  200.72643  191.81682   29.131529\n",
      "  24.086033  35.90745 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.764322812745801\n",
      "newState [187.76149  187.55893  183.96371  187.49341  179.77629   43.378193\n",
      "  44.497005  85.76919 ]\n",
      "info {'type': array([43.37819182, 44.49700633, 85.76918864])}\n",
      "\n",
      "iter 24\n",
      "episode 0\n",
      "step 2\n",
      "oldState [187.76149  187.55893  183.96371  187.49341  179.77629   43.378193\n",
      "  44.497005  85.76919 ]\n",
      "action [[3.2850e-01 3.5372e-01 2.5356e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 1.8536e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.1592404488779324\n",
      "newState [359.8       359.8       359.8       359.8       359.8        15.8702135\n",
      "  26.540382   56.178318 ]\n",
      "info {'type': array([15.87021386, 26.54038186, 56.17831681])}\n",
      "\n",
      "iter 25\n",
      "episode 0\n",
      "step 0\n",
      "oldState [220.0109   217.74817  185.33188  216.99408  258.09045   70.43213\n",
      "  40.849953  44.25658 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.889058421051478\n",
      "newState [304.1052   303.3959   298.00378  303.14386  324.70996   46.474483\n",
      "  35.458675 173.63602 ]\n",
      "info {'type': array([ 46.47448391,  35.45867638, 173.63601813])}\n",
      "\n",
      "iter 25\n",
      "episode 0\n",
      "step 1\n",
      "oldState [304.1052   303.3959   298.00378  303.14386  324.70996   46.474483\n",
      "  35.458675 173.63602 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.1017137699919186\n",
      "newState [229.37936   227.07874   194.09595   226.31204   266.57385     6.7724886\n",
      "   8.5429325  10.706835 ]\n",
      "info {'type': array([ 6.77248862,  8.54293227, 10.70683451])}\n",
      "\n",
      "iter 25\n",
      "episode 0\n",
      "step 2\n",
      "oldState [229.37936   227.07874   194.09595   226.31204   266.57385     6.7724886\n",
      "   8.5429325  10.706835 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.890154187887482\n",
      "newState [415.       415.       415.       415.       415.        20.721453\n",
      "  57.89818   73.81426 ]\n",
      "info {'type': array([20.72145353, 57.89817826, 73.81426546])}\n",
      "\n",
      "iter 26\n",
      "episode 0\n",
      "step 0\n",
      "oldState [247.6357   247.107    238.41002  246.93501  230.42227   68.53038\n",
      "  69.694214 136.3754  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9197421845229932\n",
      "newState [322.89703  322.38348  314.07275  322.21567  306.9734    38.588337\n",
      "  45.5311    41.92854 ]\n",
      "info {'type': array([38.58833682, 45.53110279, 41.92853749])}\n",
      "\n",
      "iter 26\n",
      "episode 0\n",
      "step 1\n",
      "oldState [322.89703  322.38348  314.07275  322.21567  306.9734    38.588337\n",
      "  45.5311    41.92854 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8715385203744318\n",
      "newState [275.63922  275.41537  272.47635  275.34033  273.73987   16.848251\n",
      "  18.003662  54.69818 ]\n",
      "info {'type': array([16.84825223, 18.00366152, 54.69818298])}\n",
      "\n",
      "iter 26\n",
      "episode 0\n",
      "step 2\n",
      "oldState [275.63922  275.41537  272.47635  275.34033  273.73987   16.848251\n",
      "  18.003662  54.69818 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.947941814095319\n",
      "newState [488.7     488.7     488.7     488.7     488.7      52.49309  80.51353\n",
      "  86.61034]\n",
      "info {'type': array([52.49309333, 80.51352832, 86.6103366 ])}\n",
      "\n",
      "iter 27\n",
      "episode 0\n",
      "step 0\n",
      "oldState [325.3608   325.02127  313.18997  324.93158  270.54794   24.715092\n",
      "  26.12814   66.91871 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.937148091423154\n",
      "newState [450.8482   450.5232   444.54892  450.41928  435.7004    28.025057\n",
      "  29.4309    61.69561 ]\n",
      "info {'type': array([28.02505624, 29.43090077, 61.6956092 ])}\n",
      "\n",
      "iter 27\n",
      "episode 0\n",
      "step 1\n",
      "oldState [450.8482   450.5232   444.54892  450.41928  435.7004    28.025057\n",
      "  29.4309    61.69561 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.92424317681603\n",
      "newState [411.30737 410.7477  400.68494 410.56808 386.8322   38.65242  71.97519\n",
      " 146.82419]\n",
      "info {'type': array([ 38.6524185 ,  71.97518947, 146.82418552])}\n",
      "\n",
      "iter 27\n",
      "episode 0\n",
      "step 2\n",
      "oldState [411.30737 410.7477  400.68494 410.56808 386.8322   38.65242  71.97519\n",
      " 146.82419]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.923382591329428\n",
      "newState [418.2      418.2      418.2      418.2      418.2       14.621867\n",
      "  28.503355  34.427475]\n",
      "info {'type': array([14.62186739, 28.50335573, 34.4274762 ])}\n",
      "\n",
      "iter 28\n",
      "episode 0\n",
      "step 0\n",
      "oldState [253.3882   253.92447  259.1124   254.11206  246.1174    41.140926\n",
      "  24.08108   90.9433  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9555127545688616\n",
      "newState [370.52924  369.47534  353.65363  369.12646  346.17487   32.88811\n",
      "  51.908463  46.94099 ]\n",
      "info {'type': array([32.88811247, 51.90846164, 46.94098857])}\n",
      "\n",
      "iter 28\n",
      "episode 0\n",
      "step 1\n",
      "oldState [370.52924  369.47534  353.65363  369.12646  346.17487   32.88811\n",
      "  51.908463  46.94099 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8667403338946311\n",
      "newState [320.49875  320.06378  313.2974   319.92084  308.97305   32.324745\n",
      "  69.80584   79.33678 ]\n",
      "info {'type': array([32.32474554, 69.80584173, 79.33677415])}\n",
      "\n",
      "iter 28\n",
      "episode 0\n",
      "step 2\n",
      "oldState [320.49875  320.06378  313.2974   319.92084  308.97305   32.324745\n",
      "  69.80584   79.33678 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8798972700730561\n",
      "newState [653.5      653.5      653.5      653.5      653.5       42.000443\n",
      "  48.14922   59.736176]\n",
      "info {'type': array([42.00044189, 48.14921864, 59.73617599])}\n",
      "\n",
      "iter 29\n",
      "episode 0\n",
      "step 0\n",
      "oldState [422.5989  424.4191  462.6866  424.98676 542.30145  62.09389  69.46917\n",
      "   1.     ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.7881770128930966\n",
      "newState [594.86835  595.8558   615.61914  596.1668   652.6426    41.883297\n",
      "  62.627632  87.61056 ]\n",
      "info {'type': array([41.88329878, 62.62763049, 87.61055846])}\n",
      "\n",
      "iter 29\n",
      "episode 0\n",
      "step 1\n",
      "oldState [594.86835  595.8558   615.61914  596.1668   652.6426    41.883297\n",
      "  62.627632  87.61056 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8967131114716983\n",
      "newState [526.63574  528.0061   552.06287  528.449    583.2361   110.85075\n",
      " 101.86062   51.575523]\n",
      "info {'type': array([110.85075362, 101.86061707,  51.57552323])}\n",
      "\n",
      "iter 29\n",
      "episode 0\n",
      "step 2\n",
      "oldState [526.63574  528.0061   552.06287  528.449    583.2361   110.85075\n",
      " 101.86062   51.575523]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8471529818275081\n",
      "newState [610.5      610.5      610.5      610.5      610.5       29.145187\n",
      "  35.68855   97.507614]\n",
      "info {'type': array([29.1451868 , 35.68854932, 97.50761552])}\n",
      "\n",
      "iter 30\n",
      "episode 0\n",
      "step 0\n",
      "oldState [420.4313   422.89877  461.65378  423.71115  490.20062   55.846092\n",
      "  97.55498   58.32828 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8396272991556087\n",
      "newState [525.3296   526.94055  551.3126   527.4739   564.24945   45.255993\n",
      "  48.724453  50.271637]\n",
      "info {'type': array([45.25599383, 48.72445168, 50.27163565])}\n",
      "\n",
      "iter 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0\n",
      "step 1\n",
      "oldState [525.3296   526.94055  551.3126   527.4739   564.24945   45.255993\n",
      "  48.724453  50.271637]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8793782206761427\n",
      "newState [472.20963  473.97693  502.05112  474.5578   524.40643   35.702198\n",
      "  55.011387  43.152588]\n",
      "info {'type': array([35.70219698, 55.0113853 , 43.15258931])}\n",
      "\n",
      "iter 30\n",
      "episode 0\n",
      "step 2\n",
      "oldState [472.20963  473.97693  502.05112  474.5578   524.40643   35.702198\n",
      "  55.011387  43.152588]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8580546083904961\n",
      "newState [403.        403.        403.        403.        403.          5.858639\n",
      "   4.8854113  20.20858  ]\n",
      "info {'type': array([ 5.85863872,  4.88541134, 20.20857924])}\n",
      "\n",
      "iter 31\n",
      "episode 0\n",
      "step 0\n",
      "oldState [332.50974  332.34784  328.18246  332.3002   316.72833   13.502382\n",
      "  13.701265  43.796974]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9507190112737954\n",
      "newState [380.96436  380.6936   375.71616  380.60703  368.31583    8.910551\n",
      "   8.320324  21.651993]\n",
      "info {'type': array([ 8.91055135,  8.3203239 , 21.65199267])}\n",
      "\n",
      "iter 31\n",
      "episode 0\n",
      "step 1\n",
      "oldState [380.96436  380.6936   375.71616  380.60703  368.31583    8.910551\n",
      "   8.320324  21.651993]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9375337709269572\n",
      "newState [368.49005  368.08615  360.8803   367.9563   351.16705   22.710562\n",
      "  33.801067  43.468422]\n",
      "info {'type': array([22.71056083, 33.80106682, 43.46842096])}\n",
      "\n",
      "iter 31\n",
      "episode 0\n",
      "step 2\n",
      "oldState [368.49005  368.08615  360.8803   367.9563   351.16705   22.710562\n",
      "  33.801067  43.468422]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8909105659518229\n",
      "newState [335.5      335.5      335.5      335.5      335.5       33.21482\n",
      "  56.64547   61.598717]\n",
      "info {'type': array([33.21481991, 56.6454699 , 61.59871594])}\n",
      "\n",
      "iter 32\n",
      "episode 0\n",
      "step 0\n",
      "oldState [201.14578  202.36058  219.09657  202.76839  247.09142   43.707058\n",
      "  60.920345  61.202732]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.9452266337295956\n",
      "newState [273.69507  274.23175  282.3879   274.40942  314.9705    20.881828\n",
      "  46.271496  48.42366 ]\n",
      "info {'type': array([20.88182916, 46.27149699, 48.42366117])}\n",
      "\n",
      "iter 32\n",
      "episode 0\n",
      "step 1\n",
      "oldState [273.69507  274.23175  282.3879   274.40942  314.9705    20.881828\n",
      "  46.271496  48.42366 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8736304193012967\n",
      "newState [230.35025  231.5859   248.61978  232.00056  276.60376   21.958979\n",
      "  24.4882    37.25161 ]\n",
      "info {'type': array([21.95897845, 24.48819899, 37.25161066])}\n",
      "\n",
      "iter 32\n",
      "episode 0\n",
      "step 2\n",
      "oldState [230.35025  231.5859   248.61978  232.00056  276.60376   21.958979\n",
      "  24.4882    37.25161 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9033691671447311\n",
      "newState [292.4      292.4      292.4      292.4      292.4       19.154333\n",
      "  27.784224  22.170706]\n",
      "info {'type': array([19.15433297, 27.78422388, 22.17070487])}\n",
      "\n",
      "iter 33\n",
      "episode 0\n",
      "step 0\n",
      "oldState [183.72218  182.28516  162.55014  181.80316  175.81401   54.086212\n",
      "  44.356434 129.68245 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.8050546409894894\n",
      "newState [261.99225  261.5678   254.62578  261.42886  248.96161   45.74425\n",
      "  23.512518  25.19479 ]\n",
      "info {'type': array([45.74425254, 23.51251805, 25.19478951])}\n",
      "\n",
      "iter 33\n",
      "episode 0\n",
      "step 1\n",
      "oldState [261.99225  261.5678   254.62578  261.42886  248.96161   45.74425\n",
      "  23.512518  25.19479 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.9407962985730742\n",
      "newState [228.2898   227.32861  216.04306  226.99977  240.49731   29.514809\n",
      "  29.299732  81.67291 ]\n",
      "info {'type': array([29.51480961, 29.29973195, 81.67291002])}\n",
      "\n",
      "iter 33\n",
      "episode 0\n",
      "step 2\n",
      "oldState [228.2898   227.32861  216.04306  226.99977  240.49731   29.514809\n",
      "  29.299732  81.67291 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9421506921700764\n",
      "newState [482.5       482.5       482.5       482.5       482.5         7.5077925\n",
      "  33.178036   43.72549  ]\n",
      "info {'type': array([ 7.50779237, 33.17803622, 43.72549243])}\n",
      "\n",
      "iter 34\n",
      "episode 0\n",
      "step 0\n",
      "oldState [382.8835    383.5203    392.87485   383.73224   396.46448     8.6625185\n",
      "  12.69736     1.       ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.7825157041816789\n",
      "newState [472.47754  472.71765  476.83777  472.79553  481.6977    13.120738\n",
      "   9.845924  12.610104]\n",
      "info {'type': array([13.12073784,  9.84592398, 12.61010391])}\n",
      "\n",
      "iter 34\n",
      "episode 0\n",
      "step 1\n",
      "oldState [472.47754  472.71765  476.83777  472.79553  481.6977    13.120738\n",
      "   9.845924  12.610104]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8950285058348366\n",
      "newState [459.87177  460.0188   463.41663  460.0637   471.7038    48.132317\n",
      "  71.776855  94.96901 ]\n",
      "info {'type': array([48.13231849, 71.77685875, 94.96900576])}\n",
      "\n",
      "iter 34\n",
      "episode 0\n",
      "step 2\n",
      "oldState [459.87177  460.0188   463.41663  460.0637   471.7038    48.132317\n",
      "  71.776855  94.96901 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8928625589025297\n",
      "newState [429.8      429.8      429.8      429.8      429.8       50.115356\n",
      "  84.95765   95.598305]\n",
      "info {'type': array([50.11535456, 84.9576484 , 95.5983059 ])}\n",
      "\n",
      "iter 35\n",
      "episode 0\n",
      "step 0\n",
      "oldState [153.6823   151.6753   121.89694  151.01033  183.48767   87.4185\n",
      "  80.061104 160.28911 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.0141688486890545\n",
      "newState [320.30368 319.45837 307.03625 319.1779  376.08673  64.32462  72.24431\n",
      " 152.33092]\n",
      "info {'type': array([ 64.32462436,  72.24431216, 152.3309177 ])}\n",
      "\n",
      "iter 35\n",
      "episode 0\n",
      "step 1\n",
      "oldState [320.30368 319.45837 307.03625 319.1779  376.08673  64.32462  72.24431\n",
      " 152.33092]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9247742741858764\n",
      "newState [224.50601 223.18855 201.66785 222.75864 255.43024  66.48869  51.24108\n",
      "  90.80584]\n",
      "info {'type': array([66.48869263, 51.24108295, 90.80584062])}\n",
      "\n",
      "iter 35\n",
      "episode 0\n",
      "step 2\n",
      "oldState [224.50601 223.18855 201.66785 222.75864 255.43024  66.48869  51.24108\n",
      "  90.80584]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9134775791924854\n",
      "newState [591.7      591.7      591.7      591.7      591.7       36.281258\n",
      "  42.12271   60.868942]\n",
      "info {'type': array([36.28125816, 42.12271284, 60.86894049])}\n",
      "\n",
      "iter 36\n",
      "episode 0\n",
      "step 0\n",
      "oldState [460.95007  460.85077  457.34128  460.82498  444.77856   32.55566\n",
      "  46.56073   91.459564]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9204001673424881\n",
      "newState [534.43286  534.4199   532.089    534.42285  519.2592    37.598133\n",
      "  47.071373  76.60106 ]\n",
      "info {'type': array([37.59813128, 47.07137339, 76.60106239])}\n",
      "\n",
      "iter 36\n",
      "episode 0\n",
      "step 1\n",
      "oldState [534.43286  534.4199   532.089    534.42285  519.2592    37.598133\n",
      "  47.071373  76.60106 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9075637275603561\n",
      "newState [478.65808  478.67166  475.93405  478.68622  458.57794   18.218185\n",
      "  14.086759  17.411419]\n",
      "info {'type': array([18.21818629, 14.08675842, 17.41141957])}\n",
      "\n",
      "iter 36\n",
      "episode 0\n",
      "step 2\n",
      "oldState [478.65808  478.67166  475.93405  478.68622  458.57794   18.218185\n",
      "  14.086759  17.411419]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8928551488785788\n",
      "newState [333.8      333.8      333.8      333.8      333.8       28.786629\n",
      "  46.826946  29.502718]\n",
      "info {'type': array([28.78662886, 46.82694571, 29.50271766])}\n",
      "\n",
      "iter 37\n",
      "episode 0\n",
      "step 0\n",
      "oldState [163.5692   164.30885  221.14597  164.56621  220.5129    39.51248\n",
      "  50.263527 141.13283 ]\n",
      "action [[3.2850e-01 3.5372e-01 2.5356e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 1.8536e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.2115474344111565\n",
      "newState [260.7613   260.21527  297.5957   260.04694  286.53488   35.394726\n",
      "  60.797546  69.90704 ]\n",
      "info {'type': array([35.39472478, 60.79754824, 69.90704162])}\n",
      "\n",
      "iter 37\n",
      "episode 0\n",
      "step 1\n",
      "oldState [260.7613   260.21527  297.5957   260.04694  286.53488   35.394726\n",
      "  60.797546  69.90704 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8822384412401337\n",
      "newState [199.74588  199.85506  245.68713  199.90851  231.14697   30.988016\n",
      "  41.87631   13.387293]\n",
      "info {'type': array([30.9880157 , 41.87630808, 13.3872924 ])}\n",
      "\n",
      "iter 37\n",
      "episode 0\n",
      "step 2\n",
      "oldState [199.74588  199.85506  245.68713  199.90851  231.14697   30.988016\n",
      "  41.87631   13.387293]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8174208175723034\n",
      "newState [477.8     477.8     477.8     477.8     477.8      29.97029  79.58301\n",
      "  71.92901]\n",
      "info {'type': array([29.97028918, 79.58300891, 71.92900584])}\n",
      "\n",
      "iter 38\n",
      "episode 0\n",
      "step 0\n",
      "oldState [298.06784  299.47626  324.68127  299.93002  359.73624   29.97012\n",
      "  47.961544  19.105997]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8209004714661026\n",
      "newState [437.3093    438.13312   451.36954   438.4033    462.63632    44.03313\n",
      "  61.8908      7.9277773]\n",
      "info {'type': array([44.03313108, 61.89080062,  7.92777735])}\n",
      "\n",
      "iter 38\n",
      "episode 0\n",
      "step 1\n",
      "oldState [437.3093    438.13312   451.36954   438.4033    462.63632    44.03313\n",
      "  61.8908      7.9277773]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.7917693910691611\n",
      "newState [387.15796 389.07614 421.3454  389.7004  456.3076   71.95437  68.23424\n",
      " 121.90351]\n",
      "info {'type': array([ 71.9543668 ,  68.23424072, 121.9035077 ])}\n",
      "\n",
      "iter 38\n",
      "episode 0\n",
      "step 2\n",
      "oldState [387.15796 389.07614 421.3454  389.7004  456.3076   71.95437  68.23424\n",
      " 121.90351]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9139102138775407\n",
      "newState [714.6      714.6      714.6      714.6      714.6       71.721085\n",
      "  91.92644  256.4721  ]\n",
      "info {'type': array([ 71.72108652,  91.92643951, 256.47210783])}\n",
      "\n",
      "iter 39\n",
      "episode 0\n",
      "step 0\n",
      "oldState [476.21667  476.00006  479.86414  475.90573  521.7691    83.69408\n",
      "  66.76063   30.913458]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8480449471153941\n",
      "newState [643.4527   643.4978   650.63293  643.49176  690.05304   87.388596\n",
      "  86.80331  148.7227  ]\n",
      "info {'type': array([ 87.38859465,  86.80330676, 148.72270063])}\n",
      "\n",
      "iter 39\n",
      "episode 0\n",
      "step 1\n",
      "oldState [643.4527   643.4978   650.63293  643.49176  690.05304   87.388596\n",
      "  86.80331  148.7227  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9112369217618426\n",
      "newState [532.9465   532.5109   532.93915  532.34436  572.2341    41.848778\n",
      "  51.709995  63.689907]\n",
      "info {'type': array([41.84877866, 51.70999565, 63.68990668])}\n",
      "\n",
      "iter 39\n",
      "episode 0\n",
      "step 2\n",
      "oldState [532.9465   532.5109   532.93915  532.34436  572.2341    41.848778\n",
      "  51.709995  63.689907]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8891564992583139\n",
      "newState [473.3      473.3      473.3      473.3      473.3       11.666571\n",
      "   8.46677   26.66461 ]\n",
      "info {'type': array([11.66657054,  8.4667699 , 26.6646093 ])}\n",
      "\n",
      "iter 40\n",
      "episode 0\n",
      "step 0\n",
      "oldState [329.90826  331.07098  346.59314  331.463    343.6576    31.897774\n",
      "  30.293598  37.71321 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8916862166322888\n",
      "newState [437.54828  437.4864   437.58438  437.46265  443.41437   30.410604\n",
      "  61.84637   54.497173]\n",
      "info {'type': array([30.41060541, 61.84637047, 54.49717172])}\n",
      "\n",
      "iter 40\n",
      "episode 0\n",
      "step 1\n",
      "oldState [437.54828  437.4864   437.58438  437.46265  443.41437   30.410604\n",
      "  61.84637   54.497173]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8620943695139035\n",
      "newState [381.15173  382.0628   395.4132   382.36597  400.22717   29.187922\n",
      "  46.02662   71.41302 ]\n",
      "info {'type': array([29.18792085, 46.0266172 , 71.41301933])}\n",
      "\n",
      "iter 40\n",
      "episode 0\n",
      "step 2\n",
      "oldState [381.15173  382.0628   395.4132   382.36597  400.22717   29.187922\n",
      "  46.02662   71.41302 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9038256151835553\n",
      "newState [275.8      275.8      275.8      275.8      275.8        7.706619\n",
      "  10.654398  12.997147]\n",
      "info {'type': array([ 7.70661858, 10.65439823, 12.99714646])}\n",
      "\n",
      "iter 41\n",
      "episode 0\n",
      "step 0\n",
      "oldState [156.95842  155.89821  146.50052  155.55779  196.7455     9.147536\n",
      "   7.465553  25.64343 ]\n",
      "action [[3.2850e-01 3.5372e-01 2.5356e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 1.8536e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.2291415834577621\n",
      "newState [262.79453  262.58417  268.72354  262.5157   267.2119    11.42402\n",
      "  11.975187  20.14769 ]\n",
      "info {'type': array([11.42401937, 11.97518749, 20.14769041])}\n",
      "\n",
      "iter 41\n",
      "episode 0\n",
      "step 1\n",
      "oldState [262.79453  262.58417  268.72354  262.5157   267.2119    11.42402\n",
      "  11.975187  20.14769 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9100151064514815\n",
      "newState [247.84224  247.58517  253.02908  247.50127  251.2509    58.717133\n",
      "  62.244896 162.72615 ]\n",
      "info {'type': array([ 58.71713252,  62.24489599, 162.72615615])}\n",
      "\n",
      "iter 41\n",
      "episode 0\n",
      "step 2\n",
      "oldState [247.84224  247.58517  253.02908  247.50127  251.2509    58.717133\n",
      "  62.244896 162.72615 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.0477009537810793\n",
      "newState [479.1      479.1      479.1      479.1      479.1       61.003307\n",
      "  43.146927  54.689846]\n",
      "info {'type': array([61.00330713, 43.14692715, 54.68984566])}\n",
      "\n",
      "iter 42\n",
      "episode 0\n",
      "step 0\n",
      "oldState [448.29178   448.25827   448.81775   448.24377   455.05298     7.744819\n",
      "   3.7875311   7.7758455]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9211351620505973\n",
      "newState [472.68982   472.5569    471.03357   472.51132   472.93872     7.655129\n",
      "   7.8068266  21.566545 ]\n",
      "info {'type': array([ 7.65512915,  7.80682656, 21.5665452 ])}\n",
      "\n",
      "iter 42\n",
      "episode 0\n",
      "step 1\n",
      "oldState [472.68982   472.5569    471.03357   472.51132   472.93872     7.655129\n",
      "   7.8068266  21.566545 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9417418736078451\n",
      "newState [460.92856   460.67603   456.99167   460.5921    455.8585     12.829673\n",
      "  14.9739895   1.       ]\n",
      "info {'type': array([12.82967249, 14.97398909,  1.        ])}\n",
      "\n",
      "iter 42\n",
      "episode 0\n",
      "step 2\n",
      "oldState [460.92856   460.67603   456.99167   460.5921    455.8585     12.829673\n",
      "  14.9739895   1.       ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.7928506878365486\n",
      "newState [94.1      94.1      94.1      94.1      94.1       5.184535  6.589685\n",
      "  8.542588]\n",
      "info {'type': array([5.18453491, 6.58968491, 8.54258846])}\n",
      "\n",
      "iter 43\n",
      "episode 0\n",
      "step 0\n",
      "oldState [62.973488  63.22342   67.14689   63.3055    69.90316    6.7454433\n",
      "  8.724924  24.011929 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.8039369112431276\n",
      "newState [88.80636  88.770485 87.93441  88.75951  86.05835   9.141403 12.27315\n",
      " 11.689247]\n",
      "info {'type': array([ 9.14140365, 12.27315051, 11.68924724])}\n",
      "\n",
      "iter 43\n",
      "episode 0\n",
      "step 1\n",
      "oldState [88.80636  88.770485 87.93441  88.75951  86.05835   9.141403 12.27315\n",
      " 11.689247]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7331665431513035\n",
      "newState [83.55916  83.56773  83.44366  83.571304 82.13666  37.538708 51.112934\n",
      " 36.43125 ]\n",
      "info {'type': array([37.53870652, 51.11293455, 36.43125093])}\n",
      "\n",
      "iter 43\n",
      "episode 0\n",
      "step 2\n",
      "oldState [83.55916  83.56773  83.44366  83.571304 82.13666  37.538708 51.112934\n",
      " 36.43125 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7156234147461362\n",
      "newState [319.4      319.4      319.4      319.4      319.4       40.22966\n",
      "  46.932587  55.57324 ]\n",
      "info {'type': array([40.22965943, 46.93258615, 55.57323827])}\n",
      "\n",
      "iter 44\n",
      "episode 0\n",
      "step 0\n",
      "oldState [223.764    223.4363   218.37549  223.32855  228.42644   26.7644\n",
      "  23.814106  28.514479]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.9585767427703974\n",
      "newState [291.00153  290.92154  290.80078  290.8916   309.83432   32.317825\n",
      "  40.683517  88.29138 ]\n",
      "info {'type': array([32.31782711, 40.6835178 , 88.29138542])}\n",
      "\n",
      "iter 44\n",
      "episode 0\n",
      "step 1\n",
      "oldState [291.00153  290.92154  290.80078  290.8916   309.83432   32.317825\n",
      "  40.683517  88.29138 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9269535903783603\n",
      "newState [237.7586   237.4863   232.72073  237.39862  239.9046    13.293848\n",
      "  11.490452  14.483939]\n",
      "info {'type': array([13.2938483 , 11.49045135, 14.48393873])}\n",
      "\n",
      "iter 44\n",
      "episode 0\n",
      "step 2\n",
      "oldState [237.7586   237.4863   232.72073  237.39862  239.9046    13.293848\n",
      "  11.490452  14.483939]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8931053058836429\n",
      "newState [204.5       204.5       204.5       204.5       204.5         6.953627\n",
      "   4.6202626  11.862257 ]\n",
      "info {'type': array([ 6.95362711,  4.62026242, 11.86225709])}\n",
      "\n",
      "iter 45\n",
      "episode 0\n",
      "step 0\n",
      "oldState [131.28795  131.68268  136.70888  131.81587  134.58095   30.500729\n",
      "  49.106117  36.047768]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7144882314526981\n",
      "newState [185.39499  185.68175  190.05988  185.7764   192.39934   44.25565\n",
      "  55.641575  82.57135 ]\n",
      "info {'type': array([44.25564903, 55.64157429, 82.57134638])}\n",
      "\n",
      "iter 45\n",
      "episode 0\n",
      "step 1\n",
      "oldState [185.39499  185.68175  190.05988  185.7764   192.39934   44.25565\n",
      "  55.641575  82.57135 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7625604425021626\n",
      "newState [158.33469  158.67088  163.50516  158.78267  164.72267   39.81807\n",
      "  55.147755  89.94631 ]\n",
      "info {'type': array([39.81806766, 55.14775521, 89.94631202])}\n",
      "\n",
      "iter 45\n",
      "episode 0\n",
      "step 2\n",
      "oldState [158.33469  158.67088  163.50516  158.78267  164.72267   39.81807\n",
      "  55.147755  89.94631 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7687532810048745\n",
      "newState [594.3      594.3      594.3      594.3      594.3       39.69959\n",
      "  48.491627  27.505339]\n",
      "info {'type': array([39.69958955, 48.49162776, 27.50533806])}\n",
      "\n",
      "iter 46\n",
      "episode 0\n",
      "step 0\n",
      "oldState [542.10406  542.3741   545.34863  542.4672   540.9187     9.560337\n",
      "  18.160345  16.280468]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8640310358927383\n",
      "newState [577.46857  577.7356   581.41547  577.8252   581.3982    12.147562\n",
      "  12.095174  11.091602]\n",
      "info {'type': array([12.14756242, 12.09517384, 11.09160211])}\n",
      "\n",
      "iter 46\n",
      "episode 0\n",
      "step 1\n",
      "oldState [577.46857  577.7356   581.41547  577.8252   581.3982    12.147562\n",
      "  12.095174  11.091602]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8736207645881805\n",
      "newState [564.30237   564.599     569.24316   564.6967    572.6057     10.6206045\n",
      "  17.326115   40.010418 ]\n",
      "info {'type': array([10.62060443, 17.32611392, 40.01041961])}\n",
      "\n",
      "iter 46\n",
      "episode 0\n",
      "step 2\n",
      "oldState [564.30237   564.599     569.24316   564.6967    572.6057     10.6206045\n",
      "  17.326115   40.010418 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9318555650571965\n",
      "newState [151.8       151.8       151.8       151.8       151.8         7.2141314\n",
      "   7.1654654  17.336367 ]\n",
      "info {'type': array([ 7.21413126,  7.16546556, 17.33636628])}\n",
      "\n",
      "iter 47\n",
      "episode 0\n",
      "step 0\n",
      "oldState [88.827    87.57135  68.657646 87.15536  60.93813  25.72831  15.967594\n",
      " 60.49054 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.8175073428711568\n",
      "newState [138.63823 138.36183 134.05582 138.27072 131.54024  35.91849  36.95268\n",
      "  83.62861]\n",
      "info {'type': array([35.91849178, 36.95267785, 83.62860642])}\n",
      "\n",
      "iter 47\n",
      "episode 0\n",
      "step 1\n",
      "oldState [138.63823 138.36183 134.05582 138.27072 131.54024  35.91849  36.95268\n",
      "  83.62861]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7903219219141158\n",
      "newState [116.95483  116.522896 109.42845  116.381584 103.52334   67.79835\n",
      "  27.307924 127.137474]\n",
      "info {'type': array([ 67.79835039,  27.30792375, 127.13747458])}\n",
      "\n",
      "iter 47\n",
      "episode 0\n",
      "step 2\n",
      "oldState [116.95483  116.522896 109.42845  116.381584 103.52334   67.79835\n",
      "  27.307924 127.137474]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.8229544945771397\n",
      "newState [530.6      530.6      530.6      530.6      530.6       47.492477\n",
      "  61.085274  29.563437]\n",
      "info {'type': array([47.49247822, 61.08527293, 29.56343597])}\n",
      "\n",
      "iter 48\n",
      "episode 0\n",
      "step 0\n",
      "oldState [408.75107  409.47495  426.00006  409.69653  465.60776   13.346056\n",
      "  25.30514   28.181671]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.879279135404279\n",
      "newState [505.87054  506.18732  510.2295   506.29468  508.27148   22.105148\n",
      "  25.031742  45.86107 ]\n",
      "info {'type': array([22.1051475 , 25.03174143, 45.86107004])}\n",
      "\n",
      "iter 48\n",
      "episode 0\n",
      "step 1\n",
      "oldState [505.87054  506.18732  510.2295   506.29468  508.27148   22.105148\n",
      "  25.031742  45.86107 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9155339461885259\n",
      "newState [474.33432 474.56097 476.855   474.63986 471.9434   78.61618  69.34076\n",
      "   7.90992]\n",
      "info {'type': array([78.61617676, 69.34076256,  7.90992036])}\n",
      "\n",
      "iter 48\n",
      "episode 0\n",
      "step 2\n",
      "oldState [474.33432 474.56097 476.855   474.63986 471.9434   78.61618  69.34076\n",
      "   7.90992]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8132571328535337\n",
      "newState [567.2      567.2      567.2      567.2      567.2       48.755356\n",
      "  71.0898   147.91473 ]\n",
      "info {'type': array([ 48.75535459,  71.08979958, 147.91473999])}\n",
      "\n",
      "iter 49\n",
      "episode 0\n",
      "step 0\n",
      "oldState [375.22876 377.02158 407.98624 377.60275 445.77252  47.41181  67.01342\n",
      "  21.97061]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8167981593767041\n",
      "newState [509.89648  510.95496  529.0001   511.29865  549.7504    39.510483\n",
      "  69.15841   52.063046]\n",
      "info {'type': array([39.51048301, 69.15840989, 52.06304528])}\n",
      "\n",
      "iter 49\n",
      "episode 0\n",
      "step 1\n",
      "oldState [509.89648  510.95496  529.0001   511.29865  549.7504    39.510483\n",
      "  69.15841   52.063046]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8535602828657106\n",
      "newState [447.0722   449.16812  482.40686  449.85693  508.48193   66.06673\n",
      "  58.279484  79.13802 ]\n",
      "info {'type': array([66.06672693, 58.27948221, 79.13802578])}\n",
      "\n",
      "iter 49\n",
      "episode 0\n",
      "step 2\n",
      "oldState [447.0722   449.16812  482.40686  449.85693  508.48193   66.06673\n",
      "  58.279484  79.13802 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8973156604614242\n",
      "newState [573.4      573.4      573.4      573.4      573.4       55.864265\n",
      "  61.33183   25.775007]\n",
      "info {'type': array([55.86426396, 61.33182995, 25.77500745])}\n",
      "\n",
      "iter 50\n",
      "episode 0\n",
      "step 0\n",
      "oldState [335.1565   334.26807  315.00006  333.9942   273.4267    52.335735\n",
      "  46.926376 107.326164]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.929307101159776\n",
      "newState [505.77435  505.11816  494.93732  504.9021   488.38885   35.69795\n",
      "  90.65388  117.951805]\n",
      "info {'type': array([ 35.69794684,  90.65387468, 117.9518043 ])}\n",
      "\n",
      "iter 50\n",
      "episode 0\n",
      "step 1\n",
      "oldState [505.77435  505.11816  494.93732  504.9021   488.38885   35.69795\n",
      "  90.65388  117.951805]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8893443444187586\n",
      "newState [417.24152  417.85654  421.8322   418.07806  394.95267   65.96802\n",
      "  45.721138 153.445   ]\n",
      "info {'type': array([ 65.96801909,  45.72113779, 153.44500169])}\n",
      "\n",
      "iter 50\n",
      "episode 0\n",
      "step 2\n",
      "oldState [417.24152  417.85654  421.8322   418.07806  394.95267   65.96802\n",
      "  45.721138 153.445   ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9505879278776587\n",
      "newState [504.1      504.1      504.1      504.1      504.1        4.81735\n",
      "   7.943556   8.392993]\n",
      "info {'type': array([4.81734998, 7.94355563, 8.39299253])}\n",
      "\n",
      "iter 51\n",
      "episode 0\n",
      "step 0\n",
      "oldState [455.893    455.94043  455.6459   455.95966  450.0358     8.592334\n",
      "  14.370525   8.916034]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8426180164041714\n",
      "newState [491.35892   491.58377   495.01935   491.6581    497.03043     7.1535673\n",
      "   6.5900536  12.893903 ]\n",
      "info {'type': array([ 7.15356734,  6.59005368, 12.8939023 ])}\n",
      "\n",
      "iter 51\n",
      "episode 0\n",
      "step 1\n",
      "oldState [491.35892   491.58377   495.01935   491.6581    497.03043     7.1535673\n",
      "   6.5900536  12.893903 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9196081146830385\n",
      "newState [482.42902  482.58832  485.07077  482.64087  486.81647   15.133276\n",
      "  19.83358   46.44049 ]\n",
      "info {'type': array([15.13327632, 19.83357932, 46.44048967])}\n",
      "\n",
      "iter 51\n",
      "episode 0\n",
      "step 2\n",
      "oldState [482.42902  482.58832  485.07077  482.64087  486.81647   15.133276\n",
      "  19.83358   46.44049 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9321504998169425\n",
      "newState [301.       301.       301.       301.       301.        58.405956\n",
      "  79.06392  141.05545 ]\n",
      "info {'type': array([ 58.40595552,  79.06391562, 141.05544939])}\n",
      "\n",
      "iter 52\n",
      "episode 0\n",
      "step 0\n",
      "oldState [135.87183  135.68686  178.22415  135.64267  148.65575   42.817184\n",
      "  60.221004  84.10041 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7580367588324253\n",
      "newState [272.93256  273.06186  274.52432  273.10605  272.81018   61.794315\n",
      "  60.08196  114.665794]\n",
      "info {'type': array([ 61.79431566,  60.0819582 , 114.66579809])}\n",
      "\n",
      "iter 52\n",
      "episode 0\n",
      "step 1\n",
      "oldState [272.93256  273.06186  274.52432  273.10605  272.81018   61.794315\n",
      "  60.08196  114.665794]\n",
      "action [[3.2850e-01 3.5372e-01 2.5356e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 1.8536e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.1575737048611672\n",
      "newState [193.3096   192.95654  237.57126  192.84134  234.38435   19.934015\n",
      "  47.369335 108.25264 ]\n",
      "info {'type': array([ 19.93401604,  47.36933686, 108.25263681])}\n",
      "\n",
      "iter 52\n",
      "episode 0\n",
      "step 2\n",
      "oldState [193.3096   192.95654  237.57126  192.84134  234.38435   19.934015\n",
      "  47.369335 108.25264 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9319864513998734\n",
      "newState [360.5       360.5       360.5       360.5       360.5         7.5678234\n",
      "  10.192354    9.068209 ]\n",
      "info {'type': array([ 7.56782341, 10.19235402,  9.0682083 ])}\n",
      "\n",
      "iter 53\n",
      "episode 0\n",
      "step 0\n",
      "oldState [138.5221   139.75975  153.72566  140.18568  173.04515   42.87333\n",
      "  66.921486  82.45471 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.9693571817860329\n",
      "newState [290.78278  291.35046  298.59857  291.54297  332.8574    45.661537\n",
      "  60.69222   67.66721 ]\n",
      "info {'type': array([45.66153836, 60.69221767, 67.66721112])}\n",
      "\n",
      "iter 53\n",
      "episode 0\n",
      "step 1\n",
      "oldState [290.78278  291.35046  298.59857  291.54297  332.8574    45.661537\n",
      "  60.69222   67.66721 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.882131516867014\n",
      "newState [226.9691   227.95146  241.48367  228.28134  279.2375    48.340683\n",
      "  76.10849  134.067   ]\n",
      "info {'type': array([ 48.34068485,  76.10848861, 134.06699887])}\n",
      "\n",
      "iter 53\n",
      "episode 0\n",
      "step 2\n",
      "oldState [226.9691   227.95146  241.48367  228.28134  279.2375    48.340683\n",
      "  76.10849  134.067   ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9128168497594619\n",
      "newState [669.9      669.9      669.9      669.9      669.9       79.683304\n",
      "  60.88607  108.98051 ]\n",
      "info {'type': array([ 79.68330363,  60.88607001, 108.98050553])}\n",
      "\n",
      "iter 54\n",
      "episode 0\n",
      "step 0\n",
      "oldState [529.72186  528.45154  510.76767  528.0267   510.31537   33.390385\n",
      "  16.668211  62.076927]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9529958566963374\n",
      "newState [635.49054   634.6458    622.6434    634.36395   620.73364    34.57143\n",
      "  36.346233   12.9542265]\n",
      "info {'type': array([34.57142894, 36.34623232, 12.95422611])}\n",
      "\n",
      "iter 54\n",
      "episode 0\n",
      "step 1\n",
      "oldState [635.49054   634.6458    622.6434    634.36395   620.73364    34.57143\n",
      "  36.346233   12.9542265]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8300119442581188\n",
      "newState [601.26184  600.7575   596.1354   600.581    610.44336   49.942066\n",
      "  47.464767 126.4234  ]\n",
      "info {'type': array([ 49.94206455,  47.46476606, 126.42340446])}\n",
      "\n",
      "iter 54\n",
      "episode 0\n",
      "step 2\n",
      "oldState [601.26184  600.7575   596.1354   600.581    610.44336   49.942066\n",
      "  47.464767 126.4234  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9390745386283977\n",
      "newState [336.6       336.6       336.6       336.6       336.6        10.6723585\n",
      "  11.126039   20.23257  ]\n",
      "info {'type': array([10.67235844, 11.12603884, 20.23256987])}\n",
      "\n",
      "iter 55\n",
      "episode 0\n",
      "step 0\n",
      "oldState [136.37508  138.01694  161.89284  138.56401  169.54471   39.741768\n",
      "  41.22235    7.326497]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8122344436515816\n",
      "newState [299.30377  299.7497   309.4344   299.8877   330.75974   44.275276\n",
      "  41.285793  75.66797 ]\n",
      "info {'type': array([44.27527428, 41.28579499, 75.66796913])}\n",
      "\n",
      "iter 55\n",
      "episode 0\n",
      "step 1\n",
      "oldState [299.30377  299.7497   309.4344   299.8877   330.75974   44.275276\n",
      "  41.285793  75.66797 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9155160057904533\n",
      "newState [244.71584  244.81569  249.66745  244.83806  270.81668   52.866043\n",
      " 112.38886  127.82566 ]\n",
      "info {'type': array([ 52.86604224, 112.38886433, 127.82566179])}\n",
      "\n",
      "iter 55\n",
      "episode 0\n",
      "step 2\n",
      "oldState [244.71584  244.81569  249.66745  244.83806  270.81668   52.866043\n",
      " 112.38886  127.82566 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8800479544159521\n",
      "newState [558.5      558.5      558.5      558.5      558.5       22.954668\n",
      "  38.80809   79.71137 ]\n",
      "info {'type': array([22.95466724, 38.80809018, 79.71137143])}\n",
      "\n",
      "iter 56\n",
      "episode 0\n",
      "step 0\n",
      "oldState [493.31558   492.8441    487.85263   492.68124   497.19247     8.8545\n",
      "   1.7924875   8.052737 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9493003203452854\n",
      "newState [552.7528    552.5155    549.645     552.43463   552.12        5.609539\n",
      "   7.5100718   4.0235605]\n",
      "info {'type': array([5.60953884, 7.51007188, 4.02356041])}\n",
      "\n",
      "iter 56\n",
      "episode 0\n",
      "step 1\n",
      "oldState [552.7528    552.5155    549.645     552.43463   552.12        5.609539\n",
      "   7.5100718   4.0235605]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8396585025478865\n",
      "newState [545.87335  545.7317   544.5032   545.6818   548.9283    46.625374\n",
      "  40.536503  65.2993  ]\n",
      "info {'type': array([46.62537359, 40.53650154, 65.29930487])}\n",
      "\n",
      "iter 56\n",
      "episode 0\n",
      "step 2\n",
      "oldState [545.87335  545.7317   544.5032   545.6818   548.9283    46.625374\n",
      "  40.536503  65.2993  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9076098209698429\n",
      "newState [454.4     454.4     454.4     454.4     454.4      75.72425  94.26665\n",
      "  65.86504]\n",
      "info {'type': array([75.72424984, 94.26664829, 65.86504437])}\n",
      "\n",
      "iter 57\n",
      "episode 0\n",
      "step 0\n",
      "oldState [385.62994  385.13763  377.93127  384.97418  375.66388   16.239038\n",
      "  26.541824  42.66182 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9062699301163597\n",
      "newState [424.70282  424.84818  425.95715  424.89996  420.60666   18.141928\n",
      "   6.920915  28.72264 ]\n",
      "info {'type': array([18.14192729,  6.92091527, 28.72263998])}\n",
      "\n",
      "iter 57\n",
      "episode 0\n",
      "step 1\n",
      "oldState [424.70282  424.84818  425.95715  424.89996  420.60666   18.141928\n",
      "   6.920915  28.72264 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9552226060752397\n",
      "newState [408.33023  407.98764  402.4701   407.87555  397.85672   20.395384\n",
      "  17.43484   28.010838]\n",
      "info {'type': array([20.3953834 , 17.43483864, 28.01083827])}\n",
      "\n",
      "iter 57\n",
      "episode 0\n",
      "step 2\n",
      "oldState [408.33023  407.98764  402.4701   407.87555  397.85672   20.395384\n",
      "  17.43484   28.010838]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9074862298578679\n",
      "newState [292.1     292.1     292.1     292.1     292.1      52.04399  50.57515\n",
      "  69.5221 ]\n",
      "info {'type': array([52.04399049, 50.57514858, 69.52210491])}\n",
      "\n",
      "iter 58\n",
      "episode 0\n",
      "step 0\n",
      "oldState [163.55353 163.37883 159.31929 163.32465 152.47247  44.41743  53.63957\n",
      "  93.22526]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7732161098133217\n",
      "newState [264.44244  264.41516  263.53046  264.40747  260.85968   53.171635\n",
      "  53.811844  17.529573]\n",
      "info {'type': array([53.17163471, 53.81184248, 17.52957363])}\n",
      "\n",
      "iter 58\n",
      "episode 0\n",
      "step 1\n",
      "oldState [264.44244  264.41516  263.53046  264.40747  260.85968   53.171635\n",
      "  53.811844  17.529573]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8284593460472416\n",
      "newState [213.49338  213.93634  223.80812  214.07242  246.92943   47.94509\n",
      "  68.326935 282.14127 ]\n",
      "info {'type': array([ 47.94509284,  68.32693277, 282.14125431])}\n",
      "\n",
      "iter 58\n",
      "episode 0\n",
      "step 2\n",
      "oldState [213.49338  213.93634  223.80812  214.07242  246.92943   47.94509\n",
      "  68.326935 282.14127 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.829435744085184\n",
      "newState [488.4      488.4      488.4      488.4      488.4        4.852373\n",
      "   7.818657  14.302141]\n",
      "info {'type': array([ 4.85237314,  7.81865689, 14.30214072])}\n",
      "\n",
      "iter 59\n",
      "episode 0\n",
      "step 0\n",
      "oldState [273.47818 272.79996 262.64645 272.57596 258.45166  51.2192   74.98765\n",
      " 128.39836]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.910864024660186\n",
      "newState [400.9284   401.12616  401.38593  401.20087  386.69418   56.98157\n",
      "  41.377167  90.498856]\n",
      "info {'type': array([56.98157112, 41.37716811, 90.49885204])}\n",
      "\n",
      "iter 59\n",
      "episode 0\n",
      "step 1\n",
      "oldState [400.9284   401.12616  401.38593  401.20087  386.69418   56.98157\n",
      "  41.377167  90.498856]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9258427134182321\n",
      "newState [338.69467  338.08173  327.48178  337.8838   315.0043    55.79515\n",
      "  55.610283  71.368744]\n",
      "info {'type': array([55.79515182, 55.61028148, 71.36874587])}\n",
      "\n",
      "iter 59\n",
      "episode 0\n",
      "step 2\n",
      "oldState [338.69467  338.08173  327.48178  337.8838   315.0043    55.79515\n",
      "  55.610283  71.368744]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8931818937025467\n",
      "newState [623.4      623.4      623.4      623.4      623.4       65.011894\n",
      "  39.646076 116.480385]\n",
      "info {'type': array([ 65.01189717,  39.64607513, 116.48038627])}\n",
      "\n",
      "iter 60\n",
      "episode 0\n",
      "step 0\n",
      "oldState [511.64716  512.62274  525.9423   512.9507   525.2371    32.77385\n",
      "  47.948257  49.64708 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8764219874263419\n",
      "newState [574.94916  575.3979   581.9319   575.54736  584.05804   31.615828\n",
      "  55.26149   69.23797 ]\n",
      "info {'type': array([31.61582759, 55.26149016, 69.23796832])}\n",
      "\n",
      "iter 60\n",
      "episode 0\n",
      "step 1\n",
      "oldState [574.94916  575.3979   581.9319   575.54736  584.05804   31.615828\n",
      "  55.26149   69.23797 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8882160563155166\n",
      "newState [518.358     519.35956   532.59515   519.69763   529.20447     7.408211\n",
      "   5.7085104   5.003377 ]\n",
      "info {'type': array([7.408211  , 5.7085104 , 5.00337686])}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 60\n",
      "episode 0\n",
      "step 2\n",
      "oldState [518.358     519.35956   532.59515   519.69763   529.20447     7.408211\n",
      "   5.7085104   5.003377 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8751740167183147\n",
      "newState [442.8      442.8      442.8      442.8      442.8       40.825855\n",
      "  86.69175  119.6945  ]\n",
      "info {'type': array([ 40.82585612,  86.69175306, 119.69450615])}\n",
      "\n",
      "iter 61\n",
      "episode 0\n",
      "step 0\n",
      "oldState [197.99567  198.48665  199.29411  198.67172  249.08615   43.107773\n",
      "  72.889244  96.54523 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.892346687451813\n",
      "newState [366.4901  367.13193 374.59583 367.35193 366.31485  59.03257  76.00735\n",
      " 186.46773]\n",
      "info {'type': array([ 59.03256864,  76.00734602, 186.46773425])}\n",
      "\n",
      "iter 61\n",
      "episode 0\n",
      "step 1\n",
      "oldState [366.4901  367.13193 374.59583 367.35193 366.31485  59.03257  76.00735\n",
      " 186.46773]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.045634887241442\n",
      "newState [262.49628 262.59857 257.4936  262.65497 303.85895  46.40552  60.88712\n",
      "  69.12301]\n",
      "info {'type': array([46.40552286, 60.88711975, 69.12300887])}\n",
      "\n",
      "iter 61\n",
      "episode 0\n",
      "step 2\n",
      "oldState [262.49628 262.59857 257.4936  262.65497 303.85895  46.40552  60.88712\n",
      "  69.12301]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8834148163442817\n",
      "newState [552.8      552.8      552.8      552.8      552.8       35.454304\n",
      "  45.711605  91.2795  ]\n",
      "info {'type': array([35.45430542, 45.71160527, 91.27950058])}\n",
      "\n",
      "iter 62\n",
      "episode 0\n",
      "step 0\n",
      "oldState [473.31998  473.18146  474.77356  473.12375  496.10248   10.137753\n",
      "  15.071907  24.344309]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9067677159087697\n",
      "newState [535.6079   535.6662   536.0447   535.6872   533.5159    16.575438\n",
      "  20.421974  11.437711]\n",
      "info {'type': array([16.57543767, 20.42197469, 11.43771087])}\n",
      "\n",
      "iter 62\n",
      "episode 0\n",
      "step 1\n",
      "oldState [535.6079   535.6662   536.0447   535.6872   533.5159    16.575438\n",
      "  20.421974  11.437711]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8438541498631115\n",
      "newState [516.3521   516.63214  521.0494   516.7243   524.4431    50.849857\n",
      "  33.050377  35.747803]\n",
      "info {'type': array([50.8498557 , 33.05037715, 35.74780378])}\n",
      "\n",
      "iter 62\n",
      "episode 0\n",
      "step 2\n",
      "oldState [516.3521   516.63214  521.0494   516.7243   524.4431    50.849857\n",
      "  33.050377  35.747803]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8876654622137088\n",
      "newState [267.1       267.1       267.1       267.1       267.1         5.3387046\n",
      "   6.8743305  10.026472 ]\n",
      "info {'type': array([ 5.33870471,  6.87433035, 10.02647231])}\n",
      "\n",
      "iter 63\n",
      "episode 0\n",
      "step 0\n",
      "oldState [190.64201  189.6848   211.08977  189.36768  208.06859   34.193443\n",
      "  31.744572  41.337948]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.755715568709453\n",
      "newState [250.9787   250.93555  250.75165  250.91974  253.23619   40.95963\n",
      "  25.543276  84.976944]\n",
      "info {'type': array([40.95962772, 25.54327635, 84.9769454 ])}\n",
      "\n",
      "iter 63\n",
      "episode 0\n",
      "step 1\n",
      "oldState [250.9787   250.93555  250.75165  250.91974  253.23619   40.95963\n",
      "  25.543276  84.976944]\n",
      "action [[3.2850e-01 3.5372e-01 2.5356e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 1.8536e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.2193319020833677\n",
      "newState [203.94412  202.965    224.60182  202.6387   224.77135    7.120119\n",
      "  11.146607  21.087925]\n",
      "info {'type': array([ 7.12011906, 11.14660738, 21.08792574])}\n",
      "\n",
      "iter 63\n",
      "episode 0\n",
      "step 2\n",
      "oldState [203.94412  202.965    224.60182  202.6387   224.77135    7.120119\n",
      "  11.146607  21.087925]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9178547525267405\n",
      "newState [204.        204.        204.        204.        204.          5.396743\n",
      "   6.1037455   5.957112 ]\n",
      "info {'type': array([5.39674304, 6.10374524, 5.95711207])}\n",
      "\n",
      "iter 64\n",
      "episode 0\n",
      "step 0\n",
      "oldState [177.09598  177.13678  183.81813  177.14993  184.78555    9.975209\n",
      "  13.237509  11.401019]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.727128775583157\n",
      "newState [198.44194   198.49362   199.35077   198.51047   200.17384     7.8532887\n",
      "   8.1733885  12.701206 ]\n",
      "info {'type': array([ 7.85328874,  8.17338891, 12.70120604])}\n",
      "\n",
      "iter 64\n",
      "episode 0\n",
      "step 1\n",
      "oldState [198.44194   198.49362   199.35077   198.51047   200.17384     7.8532887\n",
      "   8.1733885  12.701206 ]\n",
      "action [[3.2850e-01 3.5372e-01 2.5356e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 1.8536e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.1309673787022558\n",
      "newState [188.46046  188.4893   195.00111  188.49841  195.91626    8.361709\n",
      "   9.827693  14.049187]\n",
      "info {'type': array([ 8.36170845,  9.82769275, 14.04918628])}\n",
      "\n",
      "iter 64\n",
      "episode 0\n",
      "step 2\n",
      "oldState [188.46046  188.4893   195.00111  188.49841  195.91626    8.361709\n",
      "   9.827693  14.049187]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8991355224461031\n",
      "newState [237.8      237.8      237.8      237.8      237.8       32.564133\n",
      "  44.00888   19.04667 ]\n",
      "info {'type': array([32.56413389, 44.0088816 , 19.04667057])}\n",
      "\n",
      "iter 65\n",
      "episode 0\n",
      "step 0\n",
      "oldState [173.93651   175.3422    196.25482   175.80862   209.44528     7.13509\n",
      "   7.0053797   8.972207 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7543516965018005\n",
      "newState [234.31415   234.30962   234.32423   234.30785   234.79102     6.7450175\n",
      "  10.266819    8.89521  ]\n",
      "info {'type': array([ 6.74501751, 10.26681883,  8.89520991])}\n",
      "\n",
      "iter 65\n",
      "episode 0\n",
      "step 1\n",
      "oldState [234.31415   234.30962   234.32423   234.30785   234.79102     6.7450175\n",
      "  10.266819    8.89521  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.9298292384727518\n",
      "newState [224.42964  224.54533  226.36766  224.58342  231.80635   29.480658\n",
      "  62.709015  28.188992]\n",
      "info {'type': array([29.48065688, 62.70901589, 28.18899225])}\n",
      "\n",
      "iter 65\n",
      "episode 0\n",
      "step 2\n",
      "oldState [224.42964  224.54533  226.36766  224.58342  231.80635   29.480658\n",
      "  62.709015  28.188992]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8194241109330509\n",
      "newState [216.3      216.3      216.3      216.3      216.3        8.49617\n",
      "   9.870622  19.917051]\n",
      "info {'type': array([ 8.49617008,  9.87062173, 19.91705053])}\n",
      "\n",
      "iter 66\n",
      "episode 0\n",
      "step 0\n",
      "oldState [164.654    165.15448  173.01294  165.31914  178.27826   43.553753\n",
      "  51.018826   1.      ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.6473706619688657\n",
      "newState [198.34927  198.6715   205.04564  198.77332  215.91814   28.891655\n",
      "  43.605488  66.644516]\n",
      "info {'type': array([28.89165412, 43.60548594, 66.64451462])}\n",
      "\n",
      "iter 66\n",
      "episode 0\n",
      "step 1\n",
      "oldState [198.34927  198.6715   205.04564  198.77332  215.91814   28.891655\n",
      "  43.605488  66.644516]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7640622499569474\n",
      "newState [177.76004  178.17462  185.34485  178.30879  193.58397    6.440929\n",
      "  11.940363  19.323053]\n",
      "info {'type': array([ 6.4409289 , 11.94036278, 19.32305287])}\n",
      "\n",
      "iter 66\n",
      "episode 0\n",
      "step 2\n",
      "oldState [177.76004  178.17462  185.34485  178.30879  193.58397    6.440929\n",
      "  11.940363  19.323053]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9065726846760415\n",
      "newState [357.5      357.5      357.5      357.5      357.5       42.459766\n",
      "  47.76331   81.45516 ]\n",
      "info {'type': array([42.45976715, 47.76331087, 81.45516353])}\n",
      "\n",
      "iter 67\n",
      "episode 0\n",
      "step 0\n",
      "oldState [328.96616   329.24924   333.84668   329.34198   338.0488      6.072765\n",
      "   8.961958    7.5151615]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8628116746696252\n",
      "newState [348.86856   348.9713    350.55228   349.00528   351.54333     6.4800186\n",
      "   7.7414865  16.02442  ]\n",
      "info {'type': array([ 6.48001853,  7.7414864 , 16.02441965])}\n",
      "\n",
      "iter 67\n",
      "episode 0\n",
      "step 1\n",
      "oldState [348.86856   348.9713    350.55228   349.00528   351.54333     6.4800186\n",
      "   7.7414865  16.02442  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9236818965408458\n",
      "newState [338.80774  338.8733   339.64066  338.8958   338.85098    8.881566\n",
      "  12.235224   1.      ]\n",
      "info {'type': array([ 8.88156631, 12.2352238 ,  1.        ])}\n",
      "\n",
      "iter 67\n",
      "episode 0\n",
      "step 2\n",
      "oldState [338.80774  338.8733   339.64066  338.8958   338.85098    8.881566\n",
      "  12.235224   1.      ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.7861479041350209\n",
      "newState [323.9      323.9      323.9      323.9      323.9       75.30197\n",
      "  49.787437 157.8408  ]\n",
      "info {'type': array([ 75.30197357,  49.78743576, 157.84080256])}\n",
      "\n",
      "iter 68\n",
      "episode 0\n",
      "step 0\n",
      "oldState [134.19948  131.75377  198.1559   130.93106  207.56946   48.901306\n",
      "  35.69111   80.94333 ]\n",
      "action [[3.2850e-01 3.5372e-01 2.5356e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 1.8536e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.1764906667218826\n",
      "newState [269.63586  268.91418  296.47906  268.67215  296.77567   75.08307\n",
      "  35.721703 140.8654  ]\n",
      "info {'type': array([ 75.08306914,  35.72170099, 140.86539915])}\n",
      "\n",
      "iter 68\n",
      "episode 0\n",
      "step 1\n",
      "oldState [269.63586  268.91418  296.47906  268.67215  296.77567   75.08307\n",
      "  35.721703 140.8654  ]\n",
      "action [[3.2850e-01 3.5372e-01 2.5356e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 1.8536e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.2312472257306066\n",
      "newState [192.92905  190.2303   251.31233  189.3286   249.58951   49.725544\n",
      "  55.137745  53.014866]\n",
      "info {'type': array([49.72554338, 55.13774662, 53.0148653 ])}\n",
      "\n",
      "iter 68\n",
      "episode 0\n",
      "step 2\n",
      "oldState [192.92905  190.2303   251.31233  189.3286   249.58951   49.725544\n",
      "  55.137745  53.014866]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8748780693936893\n",
      "newState [457.3       457.3       457.3       457.3       457.3        11.368492\n",
      "   9.109175    3.2090178]\n",
      "info {'type': array([11.368492  ,  9.10917432,  3.20901775])}\n",
      "\n",
      "iter 69\n",
      "episode 0\n",
      "step 0\n",
      "oldState [302.66815  302.0861   287.68842  301.91248  249.7565    35.169315\n",
      "  48.360188 143.0966  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9477101373460158\n",
      "newState [386.27618  385.74988  373.54446  385.59     343.9801    43.604095\n",
      "  53.093307  87.836815]\n",
      "info {'type': array([43.60409733, 53.09330875, 87.83681434])}\n",
      "\n",
      "iter 69\n",
      "episode 0\n",
      "step 1\n",
      "oldState [386.27618  385.74988  373.54446  385.59     343.9801    43.604095\n",
      "  53.093307  87.836815]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9087123992260143\n",
      "newState [322.64185  322.101    308.85736  321.93924  274.39838   12.554457\n",
      "  15.851812  31.110483]\n",
      "info {'type': array([12.55445696, 15.8518121 , 31.11048384])}\n",
      "\n",
      "iter 69\n",
      "episode 0\n",
      "step 2\n",
      "oldState [322.64185  322.101    308.85736  321.93924  274.39838   12.554457\n",
      "  15.851812  31.110483]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9201999291299048\n",
      "newState [267.4       267.4       267.4       267.4       267.4         5.4419436\n",
      "   8.997729   11.274322 ]\n",
      "info {'type': array([ 5.4419436 ,  8.99772973, 11.27432163])}\n",
      "\n",
      "iter 70\n",
      "episode 0\n",
      "step 0\n",
      "oldState [141.9558   141.24425  126.53543  141.0215   151.6871    72.91635\n",
      "  81.09839   65.628204]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7262273744170529\n",
      "newState [232.11708 232.3256  236.70593 232.3906  245.3651   51.48809  77.73339\n",
      " 161.97849]\n",
      "info {'type': array([ 51.48809017,  77.7333919 , 161.97848093])}\n",
      "\n",
      "iter 70\n",
      "episode 0\n",
      "step 1\n",
      "oldState [232.11708 232.3256  236.70593 232.3906  245.3651   51.48809  77.73339\n",
      " 161.97849]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.785764961955495\n",
      "newState [191.2115   191.40652  193.58742  191.4731   191.10573   25.859259\n",
      "  24.853472 117.73947 ]\n",
      "info {'type': array([ 25.85925814,  24.85347157, 117.73946976])}\n",
      "\n",
      "iter 70\n",
      "episode 0\n",
      "step 2\n",
      "oldState [191.2115   191.40652  193.58742  191.4731   191.10573   25.859259\n",
      "  24.853472 117.73947 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.105922908789607\n",
      "newState [563.6      563.6      563.6      563.6      563.6       48.089382\n",
      "  51.59186   55.553387]\n",
      "info {'type': array([48.08938334, 51.59186068, 55.55338486])}\n",
      "\n",
      "iter 71\n",
      "episode 0\n",
      "step 0\n",
      "oldState [441.3581   441.79105  445.37762  441.94452  431.22958   15.902522\n",
      "  15.575613  42.808907]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9411956977380714\n",
      "newState [539.9785   539.7262   535.3011   539.64484  529.69586   14.022411\n",
      "  28.343363  17.737574]\n",
      "info {'type': array([14.02241097, 28.34336372, 17.73757285])}\n",
      "\n",
      "iter 71\n",
      "episode 0\n",
      "step 1\n",
      "oldState [539.9785   539.7262   535.3011   539.64484  529.69586   14.022411\n",
      "  28.343363  17.737574]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8396344767256435\n",
      "newState [515.7745   516.0379   519.0864   516.12836  515.63324   44.991974\n",
      "  64.075874 106.55253 ]\n",
      "info {'type': array([ 44.99197489,  64.07587686, 106.5525297 ])}\n",
      "\n",
      "iter 71\n",
      "episode 0\n",
      "step 2\n",
      "oldState [515.7745   516.0379   519.0864   516.12836  515.63324   44.991974\n",
      "  64.075874 106.55253 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9088567188430828\n",
      "newState [285.7      285.7      285.7      285.7      285.7       14.01077\n",
      "  18.93984   42.794197]\n",
      "info {'type': array([14.0107699 , 18.93984013, 42.7941967 ])}\n",
      "\n",
      "iter 72\n",
      "episode 0\n",
      "step 0\n",
      "oldState [121.10167  121.42525  149.62375  121.55122  122.48361   78.967766\n",
      "  92.62216  157.21219 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7716632505909728\n",
      "newState [237.99298 237.93727 236.48978 237.9205  233.01416  71.12784 156.0503\n",
      " 254.4975 ]\n",
      "info {'type': array([ 71.12783975, 156.05028954, 254.49749135])}\n",
      "\n",
      "iter 72\n",
      "episode 0\n",
      "step 1\n",
      "oldState [237.99298 237.93727 236.48978 237.9205  233.01416  71.12784 156.0503\n",
      " 254.4975 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7681326775728994\n",
      "newState [167.24326  167.79532  171.20291  167.99287  147.7508    29.900322\n",
      "  34.581482  75.42273 ]\n",
      "info {'type': array([29.90032195, 34.58148322, 75.4227286 ])}\n",
      "\n",
      "iter 72\n",
      "episode 0\n",
      "step 2\n",
      "oldState [167.24326  167.79532  171.20291  167.99287  147.7508    29.900322\n",
      "  34.581482  75.42273 ]\n",
      "action [[3.2850e-01 3.5372e-01 2.5356e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 1.8536e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.1767237089339257\n",
      "newState [594.       594.       594.       594.       594.        22.101727\n",
      "  24.940092  45.279736]\n",
      "info {'type': array([22.10172647, 24.94009285, 45.27973719])}\n",
      "\n",
      "iter 73\n",
      "episode 0\n",
      "step 0\n",
      "oldState [496.17908  495.93335  490.2325   495.85892  476.5708    21.276386\n",
      "  29.381393  66.78958 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9303194491420187\n",
      "newState [555.52795  555.41095  551.9754   555.37787  541.1027    33.637905\n",
      "  35.926395  60.168987]\n",
      "info {'type': array([33.63790452, 35.92639566, 60.16898759])}\n",
      "\n",
      "iter 73\n",
      "episode 0\n",
      "step 1\n",
      "oldState [555.52795  555.41095  551.9754   555.37787  541.1027    33.637905\n",
      "  35.926395  60.168987]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9096965957025107\n",
      "newState [510.94217  510.70383  505.3939   510.6309   493.43695    9.708793\n",
      "  12.176678  21.292076]\n",
      "info {'type': array([ 9.70879277, 12.17667728, 21.29207617])}\n",
      "\n",
      "iter 73\n",
      "episode 0\n",
      "step 2\n",
      "oldState [510.94217  510.70383  505.3939   510.6309   493.43695    9.708793\n",
      "  12.176678  21.292076]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9124051926185746\n",
      "newState [393.1      393.1      393.1      393.1      393.1       58.966087\n",
      "  73.504585  49.87436 ]\n",
      "info {'type': array([58.96608897, 73.50458878, 49.87435979])}\n",
      "\n",
      "iter 74\n",
      "episode 0\n",
      "step 0\n",
      "oldState [258.46875  259.08713  266.02902  259.30008  256.6961    45.40345\n",
      "  33.925877  82.01129 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9319060758664073\n",
      "newState [340.70416  339.99496  329.8846   339.75845  328.13855   33.562126\n",
      "  72.61967   71.638824]\n",
      "info {'type': array([33.56212786, 72.61967022, 71.63882207])}\n",
      "\n",
      "iter 74\n",
      "episode 0\n",
      "step 1\n",
      "oldState [340.70416  339.99496  329.8846   339.75845  328.13855   33.562126\n",
      "  72.61967   71.638824]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8695087406071257\n",
      "newState [273.4239    273.83514   278.3173    273.9773    271.37473     6.9421844\n",
      "  15.354708   18.528416 ]\n",
      "info {'type': array([ 6.94218451, 15.35470812, 18.52841648])}\n",
      "\n",
      "iter 74\n",
      "episode 0\n",
      "step 2\n",
      "oldState [273.4239    273.83514   278.3173    273.9773    271.37473     6.9421844\n",
      "  15.354708   18.528416 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8842220774765469\n",
      "newState [464.       464.       464.       464.       464.        41.18397\n",
      "  93.436844 197.89563 ]\n",
      "info {'type': array([ 41.18396962,  93.43684536, 197.89562992])}\n",
      "\n",
      "iter 75\n",
      "episode 0\n",
      "step 0\n",
      "oldState [377.2563    377.87247   383.8441    378.08765   368.7262      8.760305\n",
      "   5.5812435   1.5295761]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8420792044793243\n",
      "newState [457.71613   457.6859    458.05093   457.67322   462.78198     7.0143614\n",
      "   6.200111   10.581147 ]\n",
      "info {'type': array([ 7.01436119,  6.20011081, 10.58114737])}\n",
      "\n",
      "iter 75\n",
      "episode 0\n",
      "step 1\n",
      "oldState [457.71613   457.6859    458.05093   457.67322   462.78198     7.0143614\n",
      "   6.200111   10.581147 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.911107344804218\n",
      "newState [449.57886  449.49524  449.19727  449.46442  454.39914   29.950949\n",
      "  68.60144  108.1626  ]\n",
      "info {'type': array([ 29.95094798,  68.60144076, 108.1625977 ])}\n",
      "\n",
      "iter 75\n",
      "episode 0\n",
      "step 2\n",
      "oldState [449.57886  449.49524  449.19727  449.46442  454.39914   29.950949\n",
      "  68.60144  108.1626  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9043253848886877\n",
      "newState [472.9      472.9      472.9      472.9      472.9      102.919235\n",
      "  66.252045 135.50792 ]\n",
      "info {'type': array([102.91923753,  66.25204109, 135.50792114])}\n",
      "\n",
      "iter 76\n",
      "episode 0\n",
      "step 0\n",
      "oldState [359.90402  360.74847  375.44104  361.02188  393.94394   33.60332\n",
      "  57.009018  56.126793]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8716054769700391\n",
      "newState [417.72495  418.42264  428.0955   418.65656  428.42358   36.321156\n",
      "  32.097343  22.286491]\n",
      "info {'type': array([36.32115678, 32.09734295, 22.28649114])}\n",
      "\n",
      "iter 76\n",
      "episode 0\n",
      "step 1\n",
      "oldState [417.72495  418.42264  428.0955   418.65656  428.42358   36.321156\n",
      "  32.097343  22.286491]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8616324109152725\n",
      "newState [383.09265  383.83698  396.45663  384.07904  410.74695   19.484802\n",
      "  21.746786  21.200073]\n",
      "info {'type': array([19.48480262, 21.74678544, 21.20007295])}\n",
      "\n",
      "iter 76\n",
      "episode 0\n",
      "step 2\n",
      "oldState [383.09265  383.83698  396.45663  384.07904  410.74695   19.484802\n",
      "  21.746786  21.200073]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8756082906627898\n",
      "newState [221.7       221.7       221.7       221.7       221.7         9.273838\n",
      "   7.4962244   6.80624  ]\n",
      "info {'type': array([9.27383798, 7.49622441, 6.80624013])}\n",
      "\n",
      "iter 77\n",
      "episode 0\n",
      "step 0\n",
      "oldState [188.5045   188.28499  185.44315  188.21095  200.40123   18.730669\n",
      "  12.072046  12.40901 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7465311532838894\n",
      "newState [215.09465  215.03098  214.64449  215.00807  217.53279   14.357786\n",
      "  11.766319  30.252405]\n",
      "info {'type': array([14.35778572, 11.76631959, 30.25240597])}\n",
      "\n",
      "iter 77\n",
      "episode 0\n",
      "step 1\n",
      "oldState [215.09465  215.03098  214.64449  215.00807  217.53279   14.357786\n",
      "  11.766319  30.252405]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.0382833444533834\n",
      "newState [196.96152  196.6689   192.76619  196.5705   207.39787    5.742756\n",
      "   8.286935   8.829516]\n",
      "info {'type': array([5.74275599, 8.28693532, 8.82951612])}\n",
      "\n",
      "iter 77\n",
      "episode 0\n",
      "step 2\n",
      "oldState [196.96152  196.6689   192.76619  196.5705   207.39787    5.742756\n",
      "   8.286935   8.829516]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8784354063785779\n",
      "newState [170.       170.       170.       170.       170.        14.507949\n",
      "  18.000618  64.7807  ]\n",
      "info {'type': array([14.50794852, 18.00061787, 64.78070366])}\n",
      "\n",
      "iter 78\n",
      "episode 0\n",
      "step 0\n",
      "oldState [139.58905   139.64099   138.94366   139.66267   131.0898      5.2659383\n",
      "   8.845427    8.063645 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.727733961079378\n",
      "newState [166.43745  166.48505  167.16566  166.5009   167.29501    5.69863\n",
      "   7.238175  16.642036]\n",
      "info {'type': array([ 5.69863   ,  7.23817472, 16.64203725])}\n",
      "\n",
      "iter 78\n",
      "episode 0\n",
      "step 1\n",
      "oldState [166.43745  166.48505  167.16566  166.5009   167.29501    5.69863\n",
      "   7.238175  16.642036]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.792035372105724\n",
      "newState [162.35081  162.38109  162.63234  162.39172  161.72046   26.489044\n",
      "  44.003128  91.44425 ]\n",
      "info {'type': array([26.48904491, 44.00312683, 91.44425265])}\n",
      "\n",
      "iter 78\n",
      "episode 0\n",
      "step 2\n",
      "oldState [162.35081  162.38109  162.63234  162.39172  161.72046   26.489044\n",
      "  44.003128  91.44425 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7857360052921074\n",
      "newState [312.5      312.5      312.5      312.5      312.5       49.409008\n",
      "  50.888496  74.72257 ]\n",
      "info {'type': array([49.40900962, 50.88849783, 74.72257411])}\n",
      "\n",
      "iter 79\n",
      "episode 0\n",
      "step 0\n",
      "oldState [164.43054  164.79512  172.28845  164.90916  225.45264   42.88406\n",
      "  63.042206 135.53072 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7878694803328956\n",
      "newState [278.7629   278.72278  276.47284  278.71448  267.10117   46.853836\n",
      "  54.501648  81.48021 ]\n",
      "info {'type': array([46.85383532, 54.5016465 , 81.48020605])}\n",
      "\n",
      "iter 79\n",
      "episode 0\n",
      "step 1\n",
      "oldState [278.7629   278.72278  276.47284  278.71448  267.10117   46.853836\n",
      "  54.501648  81.48021 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.9869706800208755\n",
      "newState [214.75719  214.73578  212.60547  214.73444  239.78883   53.78755\n",
      "  52.087612  18.043081]\n",
      "info {'type': array([53.78755239, 52.0876104 , 18.04308097])}\n",
      "\n",
      "iter 79\n",
      "episode 0\n",
      "step 2\n",
      "oldState [214.75719  214.73578  212.60547  214.73444  239.78883   53.78755\n",
      "  52.087612  18.043081]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8319889851817535\n",
      "newState [640.9      640.9      640.9      640.9      640.9       82.173065\n",
      " 134.53383   57.94256 ]\n",
      "info {'type': array([ 82.17306816, 134.53383221,  57.94255708])}\n",
      "\n",
      "iter 80\n",
      "episode 0\n",
      "step 0\n",
      "oldState [449.9623   451.90942  479.94333  452.559    487.20908   59.432037\n",
      "  85.04154   81.5292  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8716533861580598\n",
      "newState [556.0442   556.87213  569.4181   557.1463   576.28766   33.977608\n",
      "  73.60994   60.90982 ]\n",
      "info {'type': array([33.97760867, 73.60994281, 60.90982149])}\n",
      "\n",
      "iter 80\n",
      "episode 0\n",
      "step 1\n",
      "oldState [556.0442   556.87213  569.4181   557.1463   576.28766   33.977608\n",
      "  73.60994   60.90982 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8570119407542316\n",
      "newState [490.5611   492.6423   522.2893   493.33743  528.0164    32.893726\n",
      "  32.738102  51.507683]\n",
      "info {'type': array([32.89372542, 32.73810108, 51.50768448])}\n",
      "\n",
      "iter 80\n",
      "episode 0\n",
      "step 2\n",
      "oldState [490.5611   492.6423   522.2893   493.33743  528.0164    32.893726\n",
      "  32.738102  51.507683]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9058356828178444\n",
      "newState [358.7      358.7      358.7      358.7      358.7       17.141262\n",
      "  32.127758  15.155621]\n",
      "info {'type': array([17.14126276, 32.1277573 , 15.1556208 ])}\n",
      "\n",
      "iter 81\n",
      "episode 0\n",
      "step 0\n",
      "oldState [257.72455  257.77344  256.41168  257.79688  244.37643   16.917152\n",
      "  15.609214  16.31908 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8818719879098776\n",
      "newState [340.83856   340.82553   341.3677    340.81885   345.76523    10.1829605\n",
      "  11.311356    8.105378 ]\n",
      "info {'type': array([10.1829605 , 11.31135512,  8.10537859])}\n",
      "\n",
      "iter 81\n",
      "episode 0\n",
      "step 1\n",
      "oldState [340.83856   340.82553   341.3677    340.81885   345.76523    10.1829605\n",
      "  11.311356    8.105378 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8585350436954079\n",
      "newState [329.43552  329.5024   331.6846   329.52078  339.3381    37.911407\n",
      "  57.753685 119.89824 ]\n",
      "info {'type': array([ 37.91140699,  57.75368426, 119.89824205])}\n",
      "\n",
      "iter 81\n",
      "episode 0\n",
      "step 2\n",
      "oldState [329.43552  329.5024   331.6846   329.52078  339.3381    37.911407\n",
      "  57.753685 119.89824 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9243217022111463\n",
      "newState [443.6      443.6      443.6      443.6      443.6       84.632385\n",
      "  66.2095   149.5492  ]\n",
      "info {'type': array([ 84.63238684,  66.2095012 , 149.54919312])}\n",
      "\n",
      "iter 82\n",
      "episode 0\n",
      "step 0\n",
      "oldState [302.40622  302.53693  300.39252  302.5942   276.92154    8.648337\n",
      "  10.505556   9.598814]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8706887250955091\n",
      "newState [432.79733  432.87137  434.18912  432.89523  435.99182    8.534402\n",
      "   9.458114  12.112463]\n",
      "info {'type': array([ 8.53440145,  9.45811379, 12.11246269])}\n",
      "\n",
      "iter 82\n",
      "episode 0\n",
      "step 1\n",
      "oldState [432.79733  432.87137  434.18912  432.89523  435.99182    8.534402\n",
      "   9.458114  12.112463]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8923655162200569\n",
      "newState [422.02515 422.11243 423.74875 422.14032 426.39435  67.76523  98.37852\n",
      " 188.71396]\n",
      "info {'type': array([ 67.76523078,  98.37851692, 188.71396038])}\n",
      "\n",
      "iter 82\n",
      "episode 0\n",
      "step 2\n",
      "oldState [422.02515 422.11243 423.74875 422.14032 426.39435  67.76523  98.37852\n",
      " 188.71396]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9187714845698794\n",
      "newState [398.8      398.8      398.8      398.8      398.8       36.08509\n",
      "  39.236446  37.480347]\n",
      "info {'type': array([36.0850925 , 39.23644829, 37.48034726])}\n",
      "\n",
      "iter 83\n",
      "episode 0\n",
      "step 0\n",
      "oldState [156.8167   157.45811  159.12276  157.69763  197.90094   53.609783\n",
      "  69.15142   93.68984 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8951778640567909\n",
      "newState [321.74377 322.0112  325.51865 322.1017  324.57184  48.09443  85.16225\n",
      " 178.50134]\n",
      "info {'type': array([ 48.09442909,  85.16224882, 178.50134942])}\n",
      "\n",
      "iter 83\n",
      "episode 0\n",
      "step 1\n",
      "oldState [321.74377 322.0112  325.51865 322.1017  324.57184  48.09443  85.16225\n",
      " 178.50134]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.0342795902411956\n",
      "newState [218.17291 218.5938  218.4835  218.755   264.78223  37.23455  54.19108\n",
      "  84.4289 ]\n",
      "info {'type': array([37.23455122, 54.1910788 , 84.42889885])}\n",
      "\n",
      "iter 83\n",
      "episode 0\n",
      "step 2\n",
      "oldState [218.17291 218.5938  218.4835  218.755   264.78223  37.23455  54.19108\n",
      "  84.4289 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9042909208869079\n",
      "newState [576.5      576.5      576.5      576.5      576.5       27.206663\n",
      "  41.536083   5.398255]\n",
      "info {'type': array([27.206663  , 41.53608193,  5.39825488])}\n",
      "\n",
      "iter 84\n",
      "episode 0\n",
      "step 0\n",
      "oldState [357.4182   356.8908   344.74683  356.73077  316.00348   39.51871\n",
      "  62.034103 173.62975 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9447190244642071\n",
      "newState [489.5225   489.08728  476.7722   488.96246  439.00043   70.727875\n",
      "  63.94251   93.313   ]\n",
      "info {'type': array([70.72787319, 63.94250944, 93.31300192])}\n",
      "\n",
      "iter 84\n",
      "episode 0\n",
      "step 1\n",
      "oldState [489.5225   489.08728  476.7722   488.96246  439.00043   70.727875\n",
      "  63.94251   93.313   ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9015028041344424\n",
      "newState [409.77945  408.99152  393.34518  408.74365  365.06464   35.703125\n",
      "  48.16002   61.922764]\n",
      "info {'type': array([35.70312662, 48.16001881, 61.92276465])}\n",
      "\n",
      "iter 84\n",
      "episode 0\n",
      "step 2\n",
      "oldState [409.77945  408.99152  393.34518  408.74365  365.06464   35.703125\n",
      "  48.16002   61.922764]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8914438742246426\n",
      "newState [568.2      568.2      568.2      568.2      568.2       53.196083\n",
      "   9.91678   89.91135 ]\n",
      "info {'type': array([53.1960828,  9.9167801, 89.9113448])}\n",
      "\n",
      "iter 85\n",
      "episode 0\n",
      "step 0\n",
      "oldState [399.89728 400.92435 415.2009  401.2689  416.11676  36.24253  64.35823\n",
      "  59.30623]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8666440654812873\n",
      "newState [507.40405  508.27472  520.4122   508.5664   521.2017    43.5855\n",
      "  49.650078  51.289314]\n",
      "info {'type': array([43.58549855, 49.65007595, 51.28931505])}\n",
      "\n",
      "iter 85\n",
      "episode 0\n",
      "step 1\n",
      "oldState [507.40405  508.27472  520.4122   508.5664   521.2017    43.5855\n",
      "  49.650078  51.289314]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8788334911360451\n",
      "newState [454.09167  455.18488  471.7118   455.547    480.55347   34.74719\n",
      "  43.892017  81.34888 ]\n",
      "info {'type': array([34.74718873, 43.89201699, 81.34887493])}\n",
      "\n",
      "iter 85\n",
      "episode 0\n",
      "step 2\n",
      "oldState [454.09167  455.18488  471.7118   455.547    480.55347   34.74719\n",
      "  43.892017  81.34888 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9163351637989795\n",
      "newState [563.4     563.4     563.4     563.4     563.4      88.398    97.89396\n",
      " 199.51474]\n",
      "info {'type': array([ 88.39799907,  97.8939557 , 199.51473723])}\n",
      "\n",
      "iter 86\n",
      "episode 0\n",
      "step 0\n",
      "oldState [518.47815  518.65466  521.47015  518.7127   523.85077   19.60891\n",
      "  10.847639  22.760033]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9226253528455718\n",
      "newState [545.7731    545.4524    541.6333    545.34296   545.3675      8.09595\n",
      "  18.542501    7.0146136]\n",
      "info {'type': array([ 8.09595053, 18.54250206,  7.01461381])}\n",
      "\n",
      "iter 86\n",
      "episode 0\n",
      "step 1\n",
      "oldState [545.7731    545.4524    541.6333    545.34296   545.3675      8.09595\n",
      "  18.542501    7.0146136]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.808647515126313\n",
      "newState [531.35144  531.44104  533.68066  531.46783  539.8013     5.648247\n",
      "  11.647231  20.138252]\n",
      "info {'type': array([ 5.6482469 , 11.64723069, 20.13825166])}\n",
      "\n",
      "iter 86\n",
      "episode 0\n",
      "step 2\n",
      "oldState [531.35144  531.44104  533.68066  531.46783  539.8013     5.648247\n",
      "  11.647231  20.138252]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9113494040957532\n",
      "newState [113.3       113.3       113.3       113.3       113.3         9.192139\n",
      "   9.424058    9.3811455]\n",
      "info {'type': array([9.19213865, 9.42405804, 9.38114569])}\n",
      "\n",
      "iter 87\n",
      "episode 0\n",
      "step 0\n",
      "oldState [74.524506 74.007324 67.5585   73.83172  72.09848   9.077349  5.139045\n",
      " 17.247025]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.8098915126989727\n",
      "newState [109.1694    109.08115   107.798874  109.05176   107.522385    6.418506\n",
      "   6.6911726   5.971604 ]\n",
      "info {'type': array([6.41850613, 6.69117256, 5.97160383])}\n",
      "\n",
      "iter 87\n",
      "episode 0\n",
      "step 1\n",
      "oldState [109.1694    109.08115   107.798874  109.05176   107.522385    6.418506\n",
      "   6.6911726   5.971604 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7326503000844442\n",
      "newState [106.148094 106.07046  105.06116  106.04422  105.51785   74.924\n",
      "  49.702732  99.698296]\n",
      "info {'type': array([74.92400534, 49.70273298, 99.69829373])}\n",
      "\n",
      "iter 87\n",
      "episode 0\n",
      "step 2\n",
      "oldState [106.148094 106.07046  105.06116  106.04422  105.51785   74.924\n",
      "  49.702732  99.698296]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7817618371292365\n",
      "newState [506.3      506.3      506.3      506.3      506.3       67.775085\n",
      "  74.19544   67.98529 ]\n",
      "info {'type': array([67.77508236, 74.19544586, 67.98528921])}\n",
      "\n",
      "iter 88\n",
      "episode 0\n",
      "step 0\n",
      "oldState [330.12762  329.71866  323.92758  329.5827   323.50635   46.976486\n",
      "  42.63326   92.41359 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9259972202864303\n",
      "newState [446.22403  445.69293  437.586    445.51767  433.09872   48.35976\n",
      "  57.512817  76.2418  ]\n",
      "info {'type': array([48.35975986, 57.51281723, 76.24179958])}\n",
      "\n",
      "iter 88\n",
      "episode 0\n",
      "step 1\n",
      "oldState [446.22403  445.69293  437.586    445.51767  433.09872   48.35976\n",
      "  57.512817  76.2418  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8941614832992889\n",
      "newState [381.28497  380.89783  375.09943  380.77002  372.69125   39.86509\n",
      "  43.393986  62.079388]\n",
      "info {'type': array([39.86508752, 43.39398546, 62.07938741])}\n",
      "\n",
      "iter 88\n",
      "episode 0\n",
      "step 2\n",
      "oldState [381.28497  380.89783  375.09943  380.77002  372.69125   39.86509\n",
      "  43.393986  62.079388]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8994975256877425\n",
      "newState [346.        346.        346.        346.        346.          3.2040584\n",
      "  11.306632    1.7282629]\n",
      "info {'type': array([ 3.20405849, 11.30663229,  1.72826291])}\n",
      "\n",
      "iter 89\n",
      "episode 0\n",
      "step 0\n",
      "oldState [273.56677   272.43466   255.288     272.06036   246.40514     4.8178806\n",
      "  13.26999    20.839603 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9037568281655672\n",
      "newState [332.34985  332.51068  333.98242  332.56708  329.4939    11.012333\n",
      "  14.259009  30.54517 ]\n",
      "info {'type': array([11.01233296, 14.25900949, 30.54516994])}\n",
      "\n",
      "iter 89\n",
      "episode 0\n",
      "step 1\n",
      "oldState [332.34985  332.51068  333.98242  332.56708  329.4939    11.012333\n",
      "  14.259009  30.54517 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9261470103193747\n",
      "newState [313.88452  313.98987  313.99042  314.03003  305.3011    43.476906\n",
      "  16.230469  74.36156 ]\n",
      "info {'type': array([43.47690744, 16.23046956, 74.36155508])}\n",
      "\n",
      "iter 89\n",
      "episode 0\n",
      "step 2\n",
      "oldState [313.88452  313.98987  313.99042  314.03003  305.3011    43.476906\n",
      "  16.230469  74.36156 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9598512981434271\n",
      "newState [302.8      302.8      302.8      302.8      302.8        8.208014\n",
      "  10.970992  18.40127 ]\n",
      "info {'type': array([ 8.20801364, 10.97099253, 18.40126969])}\n",
      "\n",
      "iter 90\n",
      "episode 0\n",
      "step 0\n",
      "oldState [165.46008  164.62625  150.38487  164.35622  149.66447   17.698023\n",
      "  15.023893  33.569214]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.024099606890963\n",
      "newState [281.02228  280.7963   277.45804  280.72134  291.55203   13.728886\n",
      "  19.553621  47.191288]\n",
      "info {'type': array([13.72888547, 19.55362045, 47.19128717])}\n",
      "\n",
      "iter 90\n",
      "episode 0\n",
      "step 1\n",
      "oldState [281.02228  280.7963   277.45804  280.72134  291.55203   13.728886\n",
      "  19.553621  47.191288]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9344547610438768\n",
      "newState [254.92755  254.6073   248.55125  254.50551  254.17783   67.167595\n",
      "  67.565704 131.93954 ]\n",
      "info {'type': array([ 67.1675945 ,  67.5657036 , 131.93954895])}\n",
      "\n",
      "iter 90\n",
      "episode 0\n",
      "step 2\n",
      "oldState [254.92755  254.6073   248.55125  254.50551  254.17783   67.167595\n",
      "  67.565704 131.93954 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9195967656322597\n",
      "newState [554.6      554.6      554.6      554.6      554.6       46.962765\n",
      "  73.49508  152.8346  ]\n",
      "info {'type': array([ 46.96276351,  73.49507913, 152.83459141])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter 91\n",
      "episode 0\n",
      "step 0\n",
      "oldState [421.00302  421.47806  426.879    421.64157  420.18964   42.640495\n",
      "  66.17611   12.99464 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.7968364281292858\n",
      "newState [501.39282  502.63     523.1981   503.03342  544.2587    42.420963\n",
      "  42.42093  149.11977 ]\n",
      "info {'type': array([ 42.42096342,  42.42093047, 149.11976329])}\n",
      "\n",
      "iter 91\n",
      "episode 0\n",
      "step 1\n",
      "oldState [501.39282  502.63     523.1981   503.03342  544.2587    42.420963\n",
      "  42.42093  149.11977 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9563161477492784\n",
      "newState [429.84625   430.09515   432.4442    430.18262   426.1701      3.754453\n",
      "  10.728432    7.5455666]\n",
      "info {'type': array([ 3.75445302, 10.72843143,  7.54556638])}\n",
      "\n",
      "iter 91\n",
      "episode 0\n",
      "step 2\n",
      "oldState [429.84625   430.09515   432.4442    430.18262   426.1701      3.754453\n",
      "  10.728432    7.5455666]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8422544506629585\n",
      "newState [423.5      423.5      423.5      423.5      423.5       75.334785\n",
      "  48.09658   51.355785]\n",
      "info {'type': array([75.33478485, 48.09657877, 51.35578494])}\n",
      "\n",
      "iter 92\n",
      "episode 0\n",
      "step 0\n",
      "oldState [281.1651   281.94864  295.1767   282.20383  309.99762   46.966454\n",
      "  42.0583     1.      ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8024939474242101\n",
      "newState [384.8328   385.1903   394.7465   385.29507  422.66388   24.042208\n",
      "  38.755566  82.82533 ]\n",
      "info {'type': array([24.04220688, 38.75556666, 82.8253293 ])}\n",
      "\n",
      "iter 92\n",
      "episode 0\n",
      "step 1\n",
      "oldState [384.8328   385.1903   394.7465   385.29507  422.66388   24.042208\n",
      "  38.755566  82.82533 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9264449732732591\n",
      "newState [336.62424 336.98138 344.04218 337.0944  357.06628  37.9716   53.52433\n",
      "  59.40087]\n",
      "info {'type': array([37.9716009 , 53.52433124, 59.40087247])}\n",
      "\n",
      "iter 92\n",
      "episode 0\n",
      "step 2\n",
      "oldState [336.62424 336.98138 344.04218 337.0944  357.06628  37.9716   53.52433\n",
      "  59.40087]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8813316885548589\n",
      "newState [473.3      473.3      473.3      473.3      473.3       43.403957\n",
      "  54.507854 140.09032 ]\n",
      "info {'type': array([ 43.40395789,  54.50785491, 140.09031246])}\n",
      "\n",
      "iter 93\n",
      "episode 0\n",
      "step 0\n",
      "oldState [418.0437   417.9868   414.6107   417.97644  399.13358   10.125242\n",
      "  19.976053  45.815742]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9318492511163774\n",
      "newState [448.47534  448.50122  447.16525  448.51556  437.0163    12.134896\n",
      "  19.819057  36.660152]\n",
      "info {'type': array([12.13489637, 19.8190569 , 36.66015151])}\n",
      "\n",
      "iter 93\n",
      "episode 0\n",
      "step 1\n",
      "oldState [448.47534  448.50122  447.16525  448.51556  437.0163    12.134896\n",
      "  19.819057  36.660152]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9162804071122453\n",
      "newState [425.18878   425.27518   423.8215    425.31302   407.9794      7.1837807\n",
      "   4.037506   11.16719  ]\n",
      "info {'type': array([ 7.18378058,  4.03750606, 11.16718985])}\n",
      "\n",
      "iter 93\n",
      "episode 0\n",
      "step 2\n",
      "oldState [425.18878   425.27518   423.8215    425.31302   407.9794      7.1837807\n",
      "   4.037506   11.16719  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9379105332475655\n",
      "newState [230.1      230.1      230.1      230.1      230.1       13.681161\n",
      "  47.303646  74.70519 ]\n",
      "info {'type': array([13.68116058, 47.30364674, 74.70519463])}\n",
      "\n",
      "iter 94\n",
      "episode 0\n",
      "step 0\n",
      "oldState [169.2597  168.1657  151.89601 167.8025  151.16698  51.68909  39.60568\n",
      " 123.81619]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.8085248483388463\n",
      "newState [201.69516  201.24692  194.02335  201.09987  188.62793   45.431866\n",
      "  30.204258 101.48318 ]\n",
      "info {'type': array([ 45.43186613,  30.20425773, 101.48317903])}\n",
      "\n",
      "iter 94\n",
      "episode 0\n",
      "step 1\n",
      "oldState [201.69516  201.24692  194.02335  201.09987  188.62793   45.431866\n",
      "  30.204258 101.48318 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.8114779541318635\n",
      "newState [178.50887   177.62567   163.67761   177.33505   154.63586    12.048583\n",
      "   5.3104997  10.341951 ]\n",
      "info {'type': array([12.04858284,  5.31049953, 10.3419513 ])}\n",
      "\n",
      "iter 94\n",
      "episode 0\n",
      "step 2\n",
      "oldState [178.50887   177.62567   163.67761   177.33505   154.63586    12.048583\n",
      "   5.3104997  10.341951 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.9893628370724512\n",
      "newState [322.1      322.1      322.1      322.1      322.1       35.117516\n",
      "  45.045807  39.47191 ]\n",
      "info {'type': array([35.11751709, 45.04580863, 39.47191024])}\n",
      "\n",
      "iter 95\n",
      "episode 0\n",
      "step 0\n",
      "oldState [140.78435 143.4002  123.82663 144.27724 158.40903  37.10835  80.3216\n",
      "  50.47956]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.8959762987571421\n",
      "newState [254.32333  255.84906  277.64044  256.35834  305.15182   31.311005\n",
      "  68.57273   87.74197 ]\n",
      "info {'type': array([31.31100492, 68.57273423, 87.74196296])}\n",
      "\n",
      "iter 95\n",
      "episode 0\n",
      "step 1\n",
      "oldState [254.32333  255.84906  277.64044  256.35834  305.15182   31.311005\n",
      "  68.57273   87.74197 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8886655529086533\n",
      "newState [186.28113  188.6745   220.39314  189.4816   235.64359   89.50899\n",
      " 101.893684  97.4443  ]\n",
      "info {'type': array([ 89.5089896 , 101.89368407,  97.44429684])}\n",
      "\n",
      "iter 95\n",
      "episode 0\n",
      "step 2\n",
      "oldState [186.28113  188.6745   220.39314  189.4816   235.64359   89.50899\n",
      " 101.893684  97.4443  ]\n",
      "action [[1.3917e-01 1.4981e-01 6.0246e-01 1.5351e-01 5.0000e-04]\n",
      " [2.3113e-01 2.1565e-01 5.0000e-04 2.1047e-01 5.0000e-04]\n",
      " [9.7380e-02 1.0151e-01 4.3707e-01 1.0281e-01 7.9162e-01]]\n",
      "reward -1.4303422330759046\n",
      "newState [645.7      645.7      645.7      645.7      645.7       40.498337\n",
      "  61.951805  56.39791 ]\n",
      "info {'type': array([40.49833848, 61.95180503, 56.39790939])}\n",
      "\n",
      "iter 96\n",
      "episode 0\n",
      "step 0\n",
      "oldState [412.34308  415.85016  464.06335  417.02722  463.1437    60.89885\n",
      "  93.65985   60.738705]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8467802631505602\n",
      "newState [560.44446  561.7603   582.417    562.1935   597.5408    36.809868\n",
      "  81.66664   84.302216]\n",
      "info {'type': array([36.80986819, 81.66663952, 84.30221555])}\n",
      "\n",
      "iter 96\n",
      "episode 0\n",
      "step 1\n",
      "oldState [560.44446  561.7603   582.417    562.1935   597.5408    36.809868\n",
      "  81.66664   84.302216]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8726142318566452\n",
      "newState [484.22647  486.7887   523.3537   487.64417  530.7462    36.449165\n",
      "  73.52696   85.32822 ]\n",
      "info {'type': array([36.44916521, 73.52696154, 85.32821649])}\n",
      "\n",
      "iter 96\n",
      "episode 0\n",
      "step 2\n",
      "oldState [484.22647  486.7887   523.3537   487.64417  530.7462    36.449165\n",
      "  73.52696   85.32822 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8818529287381127\n",
      "newState [651.5      651.5      651.5      651.5      651.5       56.152573\n",
      "  43.663044 101.74984 ]\n",
      "info {'type': array([ 56.15257221,  43.66304297, 101.74984035])}\n",
      "\n",
      "iter 97\n",
      "episode 0\n",
      "step 0\n",
      "oldState [448.19284  447.57275  431.65543  447.38986  387.84567   34.027843\n",
      "  53.530132  50.63875 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8697257080725642\n",
      "newState [599.3548   599.968    608.84015  600.1724   611.36957   54.052227\n",
      "  38.05183   64.70092 ]\n",
      "info {'type': array([54.05222579, 38.05183143, 64.70091654])}\n",
      "\n",
      "iter 97\n",
      "episode 0\n",
      "step 1\n",
      "oldState [599.3548   599.968    608.84015  600.1724   611.36957   54.052227\n",
      "  38.05183   64.70092 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9111487881612518\n",
      "newState [545.8546  545.8649  547.97797 545.8623  560.105    35.20498  65.63593\n",
      " 217.53984]\n",
      "info {'type': array([ 35.20497967,  65.6359361 , 217.53984575])}\n",
      "\n",
      "iter 97\n",
      "episode 0\n",
      "step 2\n",
      "oldState [545.8546  545.8649  547.97797 545.8623  560.105    35.20498  65.63593\n",
      " 217.53984]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9564465434402604\n",
      "newState [525.6      525.6      525.6      525.6      525.6       51.899887\n",
      "  42.987217 131.81314 ]\n",
      "info {'type': array([ 51.89988692,  42.98721738, 131.81314018])}\n",
      "\n",
      "iter 98\n",
      "episode 0\n",
      "step 0\n",
      "oldState [443.91943   444.90067   452.84644   445.2483    419.21567     3.5835872\n",
      "  11.536039   10.604113 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.861016162009252\n",
      "newState [515.6654   515.8952   518.8005   515.97314  517.198      2.740631\n",
      "   6.006493  13.085949]\n",
      "info {'type': array([ 2.74063114,  6.00649292, 13.08594868])}\n",
      "\n",
      "iter 98\n",
      "episode 0\n",
      "step 1\n",
      "oldState [515.6654   515.8952   518.8005   515.97314  517.198      2.740631\n",
      "   6.006493  13.085949]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9283777521408685\n",
      "newState [508.46005  508.7122   511.42688  508.79926  506.83453   16.922613\n",
      "  61.15739  110.63368 ]\n",
      "info {'type': array([ 16.92261392,  61.15739247, 110.63367916])}\n",
      "\n",
      "iter 98\n",
      "episode 0\n",
      "step 2\n",
      "oldState [508.46005  508.7122   511.42688  508.79926  506.83453   16.922613\n",
      "  61.15739  110.63368 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.91469770036615\n",
      "newState [254.9      254.9      254.9      254.9      254.9       20.224886\n",
      "  33.344955  48.69424 ]\n",
      "info {'type': array([20.22488575, 33.34495417, 48.69423951])}\n",
      "\n",
      "iter 99\n",
      "episode 0\n",
      "step 0\n",
      "oldState [204.6972   205.05371  210.3374   205.17216  212.64665    9.672476\n",
      "   9.099977  15.319438]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7713851453495515\n",
      "newState [249.95879  249.93347  249.60329  249.92491  249.76503    8.313873\n",
      "   8.112054  17.591297]\n",
      "info {'type': array([ 8.31387322,  8.11205394, 17.59129753])}\n",
      "\n",
      "iter 99\n",
      "episode 0\n",
      "step 1\n",
      "oldState [249.95879  249.93347  249.60329  249.92491  249.76503    8.313873\n",
      "   8.112054  17.591297]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9262311613737902\n",
      "newState [238.73132  238.62062  236.90182  238.58418  235.83119   22.84295\n",
      "  36.160473  29.250187]\n",
      "info {'type': array([22.84295059, 36.16047233, 29.25018666])}\n",
      "\n",
      "iter 99\n",
      "episode 0\n",
      "step 2\n",
      "oldState [238.73132  238.62062  236.90182  238.58418  235.83119   22.84295\n",
      "  36.160473  29.250187]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8595701352253544\n",
      "newState [178.4      178.4      178.4      178.4      178.4       19.509071\n",
      "  20.405401  34.33713 ]\n",
      "info {'type': array([19.50907193, 20.40540177, 34.33713057])}\n",
      "\n",
      "iter 100\n",
      "episode 0\n",
      "step 0\n",
      "oldState [ 66.9811    68.4222    89.189224  68.901665  94.03544   68.18494\n",
      " 106.23563  141.49883 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.754311415156608\n",
      "newState [130.5773   130.91196  134.82968  131.02602  130.97011   60.389053\n",
      " 108.39385  105.72108 ]\n",
      "info {'type': array([ 60.38905429, 108.39385404, 105.72107424])}\n",
      "\n",
      "iter 100\n",
      "episode 0\n",
      "step 1\n",
      "oldState [130.5773   130.91196  134.82968  131.02602  130.97011   60.389053\n",
      " 108.39385  105.72108 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7316054043221834\n",
      "newState [86.82477   87.758194  99.866776  88.07285   95.51356   38.870117\n",
      " 60.651524   4.2691054]\n",
      "info {'type': array([38.8701169 , 60.65152335,  4.26910565])}\n",
      "\n",
      "iter 100\n",
      "episode 0\n",
      "step 2\n",
      "oldState [86.82477   87.758194  99.866776  88.07285   95.51356   38.870117\n",
      " 60.651524   4.2691054]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.639197977259475\n",
      "newState [629.8      629.8      629.8      629.8      629.8       39.511646\n",
      "  72.20736   86.31831 ]\n",
      "info {'type': array([39.51164458, 72.20736064, 86.31831162])}\n",
      "\n",
      "iter 101\n",
      "episode 0\n",
      "step 0\n",
      "oldState [391.99747  391.56207  376.6441   391.44635  323.56122   23.630016\n",
      "  53.624878 165.23486 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9525489932000739\n",
      "newState [554.57904  554.31775  543.3178   554.2548   498.95813   57.01018\n",
      "  60.347954 107.4253  ]\n",
      "info {'type': array([ 57.01017954,  60.34795538, 107.4253027 ])}\n",
      "\n",
      "iter 101\n",
      "episode 0\n",
      "step 1\n",
      "oldState [554.57904  554.31775  543.3178   554.2548   498.95813   57.01018\n",
      "  60.347954 107.4253  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9136528689380348\n",
      "newState [478.05267 477.51154 461.9889  477.35727 413.85944  58.90677  73.86163\n",
      " 113.98376]\n",
      "info {'type': array([ 58.90676953,  73.86163208, 113.98375668])}\n",
      "\n",
      "iter 101\n",
      "episode 0\n",
      "step 2\n",
      "oldState [478.05267 477.51154 461.9889  477.35727 413.85944  58.90677  73.86163\n",
      " 113.98376]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9039935178992105\n",
      "newState [451.5      451.5      451.5      451.5      451.5        5.199422\n",
      "   8.999567  11.531258]\n",
      "info {'type': array([ 5.19942174,  8.99956745, 11.53125801])}\n",
      "\n",
      "iter 102\n",
      "episode 0\n",
      "step 0\n",
      "oldState [337.7203   337.5252   333.89636  337.4633   328.54825   35.979908\n",
      "  42.256226  71.03247 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9098219363446061\n",
      "newState [400.17572  400.1208   398.75626  400.10455  395.23016   39.213387\n",
      "  42.958088  71.78563 ]\n",
      "info {'type': array([39.21338702, 42.95808732, 71.78563219])}\n",
      "\n",
      "iter 102\n",
      "episode 0\n",
      "step 1\n",
      "oldState [400.17572  400.1208   398.75626  400.10455  395.23016   39.213387\n",
      "  42.958088  71.78563 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9095189371356003\n",
      "newState [347.2315    347.0585    343.73492   347.00397   338.36212     7.3372307\n",
      "   7.7558074  12.387713 ]\n",
      "info {'type': array([ 7.33723078,  7.75580763, 12.38771347])}\n",
      "\n",
      "iter 102\n",
      "episode 0\n",
      "step 2\n",
      "oldState [347.2315    347.0585    343.73492   347.00397   338.36212     7.3372307\n",
      "   7.7558074  12.387713 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9066558184816755\n",
      "newState [299.8      299.8      299.8      299.8      299.8       22.23724\n",
      "  38.209564  38.80978 ]\n",
      "info {'type': array([22.23724028, 38.20956359, 38.8097784 ])}\n",
      "\n",
      "iter 103\n",
      "episode 0\n",
      "step 0\n",
      "oldState [127.13069 126.56471 154.81837 126.36459 154.23828  67.93089  80.40699\n",
      " 217.3624 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.802350911024998\n",
      "newState [250.59482  250.21904  242.24493  250.10162  227.0007    75.81123\n",
      "  60.455784  25.882843]\n",
      "info {'type': array([75.81123178, 60.45578549, 25.88284242])}\n",
      "\n",
      "iter 103\n",
      "episode 0\n",
      "step 1\n",
      "oldState [250.59482  250.21904  242.24493  250.10162  227.0007    75.81123\n",
      "  60.455784  25.882843]\n",
      "action [[3.2850e-01 3.5372e-01 2.5356e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 1.8536e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.0070801586495186\n",
      "newState [186.6468   186.33234  218.19437  186.21588  218.27269   46.51531\n",
      "  46.771637  80.83141 ]\n",
      "info {'type': array([46.51530663, 46.77163843, 80.8314109 ])}\n",
      "\n",
      "iter 103\n",
      "episode 0\n",
      "step 2\n",
      "oldState [186.6468   186.33234  218.19437  186.21588  218.27269   46.51531\n",
      "  46.771637  80.83141 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9117773765689712\n",
      "newState [467.4       467.4       467.4       467.4       467.4         7.8861012\n",
      "   4.584201   12.7137   ]\n",
      "info {'type': array([ 7.88610138,  4.58420076, 12.71370015])}\n",
      "\n",
      "iter 104\n",
      "episode 0\n",
      "step 0\n",
      "oldState [274.58704  273.73877  262.27533  273.45438  264.2887    52.81623\n",
      "  35.049046  93.748856]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9371743709145983\n",
      "newState [409.24655  408.27502  394.58798  407.9505   393.14258   38.648792\n",
      "  47.95612  114.60722 ]\n",
      "info {'type': array([ 38.64879302,  47.95612037, 114.60722158])}\n",
      "\n",
      "iter 104\n",
      "episode 0\n",
      "step 1\n",
      "oldState [409.24655  408.27502  394.58798  407.9505   393.14258   38.648792\n",
      "  47.95612  114.60722 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9333205206260511\n",
      "newState [343.87384  342.55682  321.18826  342.12634  302.3739    62.887608\n",
      "  68.63606   48.027397]\n",
      "info {'type': array([62.88760661, 68.63606381, 48.02739822])}\n",
      "\n",
      "iter 104\n",
      "episode 0\n",
      "step 2\n",
      "oldState [343.87384  342.55682  321.18826  342.12634  302.3739    62.887608\n",
      "  68.63606   48.027397]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8576518278273149\n",
      "newState [394.6       394.6       394.6       394.6       394.6         4.983289\n",
      "   9.993295    1.9410572]\n",
      "info {'type': array([4.98328891, 9.99329491, 1.94105715])}\n",
      "\n",
      "iter 105\n",
      "episode 0\n",
      "step 0\n",
      "oldState [331.95554  331.36496  321.60434  331.17255  312.1058    15.260735\n",
      "  11.482609  66.36949 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9805761581498549\n",
      "newState [367.99252  367.37097  356.39218  367.17062  342.0472    23.294195\n",
      "  24.174845  30.15373 ]\n",
      "info {'type': array([23.29419478, 24.17484467, 30.15373071])}\n",
      "\n",
      "iter 105\n",
      "episode 0\n",
      "step 1\n",
      "oldState [367.99252  367.37097  356.39218  367.17062  342.0472    23.294195\n",
      "  24.174845  30.15373 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8911633095804856\n",
      "newState [340.15845   339.54144   329.167     339.34094   318.15317     7.01128\n",
      "   7.566665    7.6300273]\n",
      "info {'type': array([7.01127991, 7.56666522, 7.63002734])}\n",
      "\n",
      "iter 105\n",
      "episode 0\n",
      "step 2\n",
      "oldState [340.15845   339.54144   329.167     339.34094   318.15317     7.01128\n",
      "   7.566665    7.6300273]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8779984905524812\n",
      "newState [308.7      308.7      308.7      308.7      308.7       49.596004\n",
      "  27.82501   10.060733]\n",
      "info {'type': array([49.59600614, 27.82501036, 10.06073254])}\n",
      "\n",
      "iter 106\n",
      "episode 0\n",
      "step 0\n",
      "oldState [184.11266  184.81999  189.31407  185.07457  210.11699   41.31072\n",
      "  52.407177  95.68648 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7765218780571874\n",
      "newState [281.52     281.49652  280.46262  281.49072  276.63837   31.152412\n",
      "  69.70468  113.64171 ]\n",
      "info {'type': array([ 31.15241267,  69.70468157, 113.64170462])}\n",
      "\n",
      "iter 106\n",
      "episode 0\n",
      "step 1\n",
      "oldState [281.52     281.49652  280.46262  281.49072  276.63837   31.152412\n",
      "  69.70468  113.64171 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.0077778316809731\n",
      "newState [206.93506  207.56729  211.9903   207.7934   238.56569   11.565746\n",
      "  19.625528  35.917618]\n",
      "info {'type': array([11.56574593, 19.62552863, 35.91761696])}\n",
      "\n",
      "iter 106\n",
      "episode 0\n",
      "step 2\n",
      "oldState [206.93506  207.56729  211.9903   207.7934   238.56569   11.565746\n",
      "  19.625528  35.917618]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9155292048983489\n",
      "newState [288.7      288.7      288.7      288.7      288.7       20.998123\n",
      "  27.793528  59.579525]\n",
      "info {'type': array([20.99812335, 27.79352853, 59.57952586])}\n",
      "\n",
      "iter 107\n",
      "episode 0\n",
      "step 0\n",
      "oldState [148.95903  149.82634  160.35555  150.12207  186.17787   52.72184\n",
      "  55.522614  90.40519 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7690974973939713\n",
      "newState [259.7261   259.65128  258.5466   259.62628  258.39813   45.581596\n",
      "  79.116684  74.49585 ]\n",
      "info {'type': array([45.58159811, 79.11668359, 74.49584847])}\n",
      "\n",
      "iter 107\n",
      "episode 0\n",
      "step 1\n",
      "oldState [259.7261   259.65128  258.5466   259.62628  258.39813   45.581596\n",
      "  79.116684  74.49585 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.9395682895532309\n",
      "newState [184.28409  185.23785  198.48605  185.55742  233.41096   20.003832\n",
      "  27.409702  59.636425]\n",
      "info {'type': array([20.00383256, 27.40970236, 59.63642568])}\n",
      "\n",
      "iter 107\n",
      "episode 0\n",
      "step 2\n",
      "oldState [184.28409  185.23785  198.48605  185.55742  233.41096   20.003832\n",
      "  27.409702  59.636425]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9273297779218599\n",
      "newState [297.4      297.4      297.4      297.4      297.4       11.660681\n",
      "  12.539161  13.080906]\n",
      "info {'type': array([11.66068123, 12.53916056, 13.08090626])}\n",
      "\n",
      "iter 108\n",
      "episode 0\n",
      "step 0\n",
      "oldState [172.28053  172.54309  172.02121  172.6442   148.30646   61.309956\n",
      "  71.836784 122.0361  ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.771720853115346\n",
      "newState [260.37997  260.33566  259.19772  260.32227  256.50256   51.056732\n",
      "  85.04916  143.0995  ]\n",
      "info {'type': array([ 51.0567322 ,  85.04915957, 143.09949815])}\n",
      "\n",
      "iter 108\n",
      "episode 0\n",
      "step 1\n",
      "oldState [260.37997  260.33566  259.19772  260.32227  256.50256   51.056732\n",
      "  85.04916  143.0995  ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.77071401025103\n",
      "newState [219.68198  219.81998  219.68433  219.8722   208.55627   23.894533\n",
      "  40.218304  76.06905 ]\n",
      "info {'type': array([23.89453224, 40.21830387, 76.06905696])}\n",
      "\n",
      "iter 108\n",
      "episode 0\n",
      "step 2\n",
      "oldState [219.68198  219.81998  219.68433  219.8722   208.55627   23.894533\n",
      "  40.218304  76.06905 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9178777761505441\n",
      "newState [718.4      718.4      718.4      718.4      718.4       54.537197\n",
      "  93.56043  141.97952 ]\n",
      "info {'type': array([ 54.53719763,  93.56043088, 141.97952564])}\n",
      "\n",
      "iter 109\n",
      "episode 0\n",
      "step 0\n",
      "oldState [693.6545    693.8343    696.0943    693.89545   694.79974     4.5785327\n",
      "   9.066792   10.567382 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8822801766956038\n",
      "newState [709.49786   709.6118    711.01843   709.65063   710.02783     5.7981653\n",
      "   6.592948   12.175989 ]\n",
      "info {'type': array([ 5.79816553,  6.59294782, 12.17598877])}\n",
      "\n",
      "iter 109\n",
      "episode 0\n",
      "step 1\n",
      "oldState [709.49786   709.6118    711.01843   709.65063   710.02783     5.7981653\n",
      "   6.592948   12.175989 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9160622739307233\n",
      "newState [701.17725   701.2671    702.2002    701.29834   700.3829      5.0177617\n",
      "   7.7672243   7.044707 ]\n",
      "info {'type': array([5.01776184, 7.76722415, 7.04470673])}\n",
      "\n",
      "iter 109\n",
      "episode 0\n",
      "step 2\n",
      "oldState [701.17725   701.2671    702.2002    701.29834   700.3829      5.0177617\n",
      "   7.7672243   7.044707 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.867165198717764\n",
      "newState [207.6      207.6      207.6      207.6      207.6       58.870045\n",
      "  40.478016 112.15107 ]\n",
      "info {'type': array([ 58.87004412,  40.47801765, 112.1510694 ])}\n",
      "\n",
      "iter 110\n",
      "episode 0\n",
      "step 0\n",
      "oldState [ 85.33167   86.30722   99.33006   86.63483   97.062416  57.144665\n",
      " 110.01752   51.478374]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.6851015253467418\n",
      "newState [169.20587  170.08832  183.51337  170.37985  190.29279   33.188248\n",
      "  70.582565 142.22348 ]\n",
      "info {'type': array([ 33.18824906,  70.58256754, 142.22348296])}\n",
      "\n",
      "iter 110\n",
      "episode 0\n",
      "step 1\n",
      "oldState [169.20587  170.08832  183.51337  170.37985  190.29279   33.188248\n",
      "  70.582565 142.22348 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7838497472087436\n",
      "newState [134.42358 135.45815 148.70032 135.80762 142.65576  95.10848  97.83995\n",
      " 135.98204]\n",
      "info {'type': array([ 95.10847905,  97.83994958, 135.98204054])}\n",
      "\n",
      "iter 110\n",
      "episode 0\n",
      "step 2\n",
      "oldState [134.42358 135.45815 148.70032 135.80762 142.65576  95.10848  97.83995\n",
      " 135.98204]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7591190014589542\n",
      "newState [513.9      513.9      513.9      513.9      513.9        9.112249\n",
      "  11.465247  25.486578]\n",
      "info {'type': array([ 9.11224897, 11.46524676, 25.48657725])}\n",
      "\n",
      "iter 111\n",
      "episode 0\n",
      "step 0\n",
      "oldState [422.2946   422.23694  420.2493   422.22183  413.29102    8.970219\n",
      "   9.570055  15.914813]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9092405719337742\n",
      "newState [502.04614  502.0147   501.53516  502.00433  501.29227   11.024592\n",
      "  15.763436  15.195174]\n",
      "info {'type': array([11.02459196, 15.76343608, 15.19517436])}\n",
      "\n",
      "iter 111\n",
      "episode 0\n",
      "step 1\n",
      "oldState [502.04614  502.0147   501.53516  502.00433  501.29227   11.024592\n",
      "  15.763436  15.195174]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8720119254866135\n",
      "newState [486.29535  486.41635  488.24405  486.45645  489.25006   43.250664\n",
      "  50.57691   95.89465 ]\n",
      "info {'type': array([43.25066312, 50.57690905, 95.89465537])}\n",
      "\n",
      "iter 111\n",
      "episode 0\n",
      "step 2\n",
      "oldState [486.29535  486.41635  488.24405  486.45645  489.25006   43.250664\n",
      "  50.57691   95.89465 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.917817582567218\n",
      "newState [405.6      405.6      405.6      405.6      405.6       77.499535\n",
      "  49.584866  76.46602 ]\n",
      "info {'type': array([77.49953434, 49.58486567, 76.46601895])}\n",
      "\n",
      "iter 112\n",
      "episode 0\n",
      "step 0\n",
      "oldState [376.93195   376.87082   376.40692   376.84918   378.77148     6.377598\n",
      "   6.05187     2.2457764]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8349234096721061\n",
      "newState [399.67615   399.71628   400.77316   399.7281    403.81598     7.0513844\n",
      "   7.262021   23.258137 ]\n",
      "info {'type': array([ 7.05138452,  7.26202095, 23.25813614])}\n",
      "\n",
      "iter 112\n",
      "episode 0\n",
      "step 1\n",
      "oldState [399.67615   399.71628   400.77316   399.7281    403.81598     7.0513844\n",
      "   7.262021   23.258137 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9509369843564759\n",
      "newState [388.02097  387.9198   386.35593  387.8865   385.39722   10.442767\n",
      "  10.475312   8.356614]\n",
      "info {'type': array([10.442767  , 10.47531228,  8.35661414])}\n",
      "\n",
      "iter 112\n",
      "episode 0\n",
      "step 2\n",
      "oldState [388.02097  387.9198   386.35593  387.8865   385.39722   10.442767\n",
      "  10.475312   8.356614]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8660161002734924\n",
      "newState [253.8      253.8      253.8      253.8      253.8       53.514565\n",
      "  42.384403 105.4081  ]\n",
      "info {'type': array([ 53.51456388,  42.38440285, 105.40809654])}\n",
      "\n",
      "iter 113\n",
      "episode 0\n",
      "step 0\n",
      "oldState [193.51955   192.92654   188.52643   192.71562   227.75777    28.961609\n",
      "  17.644724    5.6532435]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7082645820159623\n",
      "newState [245.14067  245.08232  245.3998   245.0592   251.88524   50.59441\n",
      "  32.11641   36.165215]\n",
      "info {'type': array([50.59440838, 32.1164095 , 36.16521332])}\n",
      "\n",
      "iter 113\n",
      "episode 0\n",
      "step 1\n",
      "oldState [245.14067  245.08232  245.3998   245.0592   251.88524   50.59441\n",
      "  32.11641   36.165215]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.9478089567611593\n",
      "newState [202.60709   202.09799   199.0959    201.91438   239.74373     6.5600696\n",
      "   6.290268   15.132929 ]\n",
      "info {'type': array([ 6.56006942,  6.2902679 , 15.13292914])}\n",
      "\n",
      "iter 113\n",
      "episode 0\n",
      "step 2\n",
      "oldState [202.60709   202.09799   199.0959    201.91438   239.74373     6.5600696\n",
      "   6.290268   15.132929 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9327433158902398\n",
      "newState [174.2       174.2       174.2       174.2       174.2         7.4560738\n",
      "   8.290605    1.       ]\n",
      "info {'type': array([7.45607393, 8.29060416, 1.        ])}\n",
      "\n",
      "iter 114\n",
      "episode 0\n",
      "step 0\n",
      "oldState [134.5744   133.58504  133.51607  133.25964  126.51523   20.493513\n",
      "  20.03147   56.196392]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.803660014634957\n",
      "newState [161.24564  161.10558  158.57709  161.06046  155.37755   21.836515\n",
      "  12.353683  43.92662 ]\n",
      "info {'type': array([21.83651454, 12.35368377, 43.92661995])}\n",
      "\n",
      "iter 114\n",
      "episode 0\n",
      "step 1\n",
      "oldState [161.24564  161.10558  158.57709  161.06046  155.37755   21.836515\n",
      "  12.353683  43.92662 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.813059811926228\n",
      "newState [151.07376   150.71118   144.8918    150.59216   140.66348    13.963061\n",
      "   3.9526715  42.259834 ]\n",
      "info {'type': array([13.96306171,  3.95267146, 42.25983585])}\n",
      "\n",
      "iter 114\n",
      "episode 0\n",
      "step 2\n",
      "oldState [151.07376   150.71118   144.8918    150.59216   140.66348    13.963061\n",
      "   3.9526715  42.259834 ]\n",
      "action [[3.2850e-01 3.5372e-01 2.5356e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 1.8536e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.308347366084725\n",
      "newState [330.6      330.6      330.6      330.6      330.6       58.317585\n",
      "  94.88584   52.729427]\n",
      "info {'type': array([58.31758641, 94.88584389, 52.72942772])}\n",
      "\n",
      "iter 115\n",
      "episode 0\n",
      "step 0\n",
      "oldState [205.58656  205.96501  205.98177  206.10945  174.86584   18.382423\n",
      "  27.60437   15.548024]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8395160469848071\n",
      "newState [305.87317 306.27347 312.71594 306.40472 318.2689    9.41874  17.17638\n",
      "  26.21136]\n",
      "info {'type': array([ 9.41874068, 17.17638053, 26.21136122])}\n",
      "\n",
      "iter 115\n",
      "episode 0\n",
      "step 1\n",
      "oldState [305.87317 306.27347 312.71594 306.40472 318.2689    9.41874  17.17638\n",
      "  26.21136]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9023141544412717\n",
      "newState [287.3353   287.87106  295.57675  288.04977  297.50616   36.315716\n",
      "  62.315144 154.86093 ]\n",
      "info {'type': array([ 36.31571667,  62.31514522, 154.86092562])}\n",
      "\n",
      "iter 115\n",
      "episode 0\n",
      "step 2\n",
      "oldState [287.3353   287.87106  295.57675  288.04977  297.50616   36.315716\n",
      "  62.315144 154.86093 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.937057424968226\n",
      "newState [348.7      348.7      348.7      348.7      348.7       24.402864\n",
      "  22.88881   21.793228]\n",
      "info {'type': array([24.40286521, 22.88880877, 21.79322894])}\n",
      "\n",
      "iter 116\n",
      "episode 0\n",
      "step 0\n",
      "oldState [294.61258  294.90192  301.05417  294.99197  314.17056    5.652894\n",
      "   3.737667   8.455528]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9274669520350772\n",
      "newState [342.84747  342.7587   341.59683  342.72876  342.00174    8.592444\n",
      "  11.411427   9.920372]\n",
      "info {'type': array([ 8.59244466, 11.41142634,  9.92037154])}\n",
      "\n",
      "iter 116\n",
      "episode 0\n",
      "step 1\n",
      "oldState [342.84747  342.7587   341.59683  342.72876  342.00174    8.592444\n",
      "  11.411427   9.920372]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8664901611189583\n",
      "newState [331.4934   331.5103   332.0786   331.51492  334.13858   33.198223\n",
      "  36.86261   25.18001 ]\n",
      "info {'type': array([33.19822326, 36.86261022, 25.18001004])}\n",
      "\n",
      "iter 116\n",
      "episode 0\n",
      "step 2\n",
      "oldState [331.4934   331.5103   332.0786   331.51492  334.13858   33.198223\n",
      "  36.86261   25.18001 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8560706419004399\n",
      "newState [343.8      343.8      343.8      343.8      343.8       37.02626\n",
      "  61.242004 106.02195 ]\n",
      "info {'type': array([ 37.02625863,  61.24200421, 106.02194848])}\n",
      "\n",
      "iter 117\n",
      "episode 0\n",
      "step 0\n",
      "oldState [192.06409  192.33945  192.00562  192.44588  236.76587   28.437876\n",
      "  51.52373   42.579025]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8591165599915066\n",
      "newState [296.44824  297.20862  308.03152  297.4626   310.0536    37.663555\n",
      "  54.62608  151.71185 ]\n",
      "info {'type': array([ 37.66355536,  54.62607969, 151.71184964])}\n",
      "\n",
      "iter 117\n",
      "episode 0\n",
      "step 1\n",
      "oldState [296.44824  297.20862  308.03152  297.4626   310.0536    37.663555\n",
      "  54.62608  151.71185 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.0622642210686581\n",
      "newState [219.1896   219.50629  219.00473  219.6289   259.24768   24.213984\n",
      "  23.079662  28.369877]\n",
      "info {'type': array([24.21398375, 23.07966156, 28.36987612])}\n",
      "\n",
      "iter 117\n",
      "episode 0\n",
      "step 2\n",
      "oldState [219.1896   219.50629  219.00473  219.6289   259.24768   24.213984\n",
      "  23.079662  28.369877]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8909046277477668\n",
      "newState [276.1      276.1      276.1      276.1      276.1        9.136531\n",
      "  12.523731  21.410742]\n",
      "info {'type': array([ 9.13653078, 12.52373166, 21.41074185])}\n",
      "\n",
      "iter 118\n",
      "episode 0\n",
      "step 0\n",
      "oldState [144.51639   145.60265   159.16626   145.97192   155.35564     4.23267\n",
      "   8.1589775  10.029881 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.9715056371648635\n",
      "newState [267.9321   268.02664  269.16214  268.0589   272.738      6.454905\n",
      "  12.391931  10.147669]\n",
      "info {'type': array([ 6.45490488, 12.39193042, 10.14766923])}\n",
      "\n",
      "iter 118\n",
      "episode 0\n",
      "step 1\n",
      "oldState [267.9321   268.02664  269.16214  268.0589   272.738      6.454905\n",
      "  12.391931  10.147669]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8577696094729744\n",
      "newState [256.69138 256.97943 260.83188 257.07645 264.6955   68.53907 105.69028\n",
      " 138.0116 ]\n",
      "info {'type': array([ 68.53906835, 105.69027436, 138.01159485])}\n",
      "\n",
      "iter 118\n",
      "episode 0\n",
      "step 2\n",
      "oldState [256.69138 256.97943 260.83188 257.07645 264.6955   68.53907 105.69028\n",
      " 138.0116 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8917834924517822\n",
      "newState [318.4       318.4       318.4       318.4       318.4         7.5205097\n",
      "   6.674473   10.792838 ]\n",
      "info {'type': array([ 7.52050956,  6.67447302, 10.79283769])}\n",
      "\n",
      "iter 119\n",
      "episode 0\n",
      "step 0\n",
      "oldState [201.2399   200.58936  188.2674   200.3827   177.11453    5.227116\n",
      "   9.870747  18.93303 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.0249011192242796\n",
      "newState [306.91486  306.9589   306.9709   306.97565  312.05783    9.218391\n",
      "  11.55042   10.210646]\n",
      "info {'type': array([ 9.21839175, 11.55042007, 10.21064572])}\n",
      "\n",
      "iter 119\n",
      "episode 0\n",
      "step 1\n",
      "oldState [306.91486  306.9589   306.9709   306.97565  312.05783    9.218391\n",
      "  11.55042   10.210646]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8683007878456599\n",
      "newState [295.21216 295.34833 296.94864 295.39496 303.9645   64.14982  65.71093\n",
      " 160.15898]\n",
      "info {'type': array([ 64.14982038,  65.71093355, 160.15897645])}\n",
      "\n",
      "iter 119\n",
      "episode 0\n",
      "step 2\n",
      "oldState [295.21216 295.34833 296.94864 295.39496 303.9645   64.14982  65.71093\n",
      " 160.15898]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9338488471836054\n",
      "newState [290.6      290.6      290.6      290.6      290.6        7.823077\n",
      "   5.89086   13.417999]\n",
      "info {'type': array([ 7.82307718,  5.89086022, 13.41799947])}\n",
      "\n",
      "iter 120\n",
      "episode 0\n",
      "step 0\n",
      "oldState [188.60753  189.6319   206.51138  189.96617  223.29332   23.942022\n",
      "  61.929634  66.99105 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7362549778236727\n",
      "newState [266.4306   266.85785  272.08084  267.003    268.1432    52.322243\n",
      "  59.7715    36.9213  ]\n",
      "info {'type': array([52.3222425 , 59.77150117, 36.92129823])}\n",
      "\n",
      "iter 120\n",
      "episode 0\n",
      "step 1\n",
      "oldState [266.4306   266.85785  272.08084  267.003    268.1432    52.322243\n",
      "  59.7715    36.9213  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8504129029056947\n",
      "newState [208.02626  208.97214  224.3917   209.28134  238.8595    15.413671\n",
      "  17.957012  19.642666]\n",
      "info {'type': array([15.41367066, 17.95701148, 19.64266602])}\n",
      "\n",
      "iter 120\n",
      "episode 0\n",
      "step 2\n",
      "oldState [208.02626  208.97214  224.3917   209.28134  238.8595    15.413671\n",
      "  17.957012  19.642666]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8821092627296421\n",
      "newState [491.9      491.9      491.9      491.9      491.9       52.8399\n",
      "  49.007084  89.82153 ]\n",
      "info {'type': array([52.83990169, 49.00708221, 89.82152948])}\n",
      "\n",
      "iter 121\n",
      "episode 0\n",
      "step 0\n",
      "oldState [353.12473  353.43823  355.84552  353.55014  344.57803   20.87825\n",
      "  10.530228  30.673359]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9398853964613721\n",
      "newState [472.20398  471.76077  465.91     471.61142  467.60263   11.344924\n",
      "  14.519432  32.227753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info {'type': array([11.3449239 , 14.51943186, 32.22775095])}\n",
      "\n",
      "iter 121\n",
      "episode 0\n",
      "step 1\n",
      "oldState [472.20398  471.76077  465.91     471.61142  467.60263   11.344924\n",
      "  14.519432  32.227753]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9285040263812026\n",
      "newState [453.09872  452.5845   444.9821   452.41394  442.07758   58.592712\n",
      "  95.66263  123.06715 ]\n",
      "info {'type': array([ 58.59271254,  95.66262732, 123.06714403])}\n",
      "\n",
      "iter 121\n",
      "episode 0\n",
      "step 2\n",
      "oldState [453.09872  452.5845   444.9821   452.41394  442.07758   58.592712\n",
      "  95.66263  123.06715 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8904486076543321\n",
      "newState [443.5      443.5      443.5      443.5      443.5       29.078756\n",
      "  30.836649 125.66759 ]\n",
      "info {'type': array([ 29.07875603,  30.83664873, 125.66758704])}\n",
      "\n",
      "iter 122\n",
      "episode 0\n",
      "step 0\n",
      "oldState [191.72742 190.1939  174.42021 189.663   207.66934 117.20645  80.34187\n",
      " 127.63663]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9073729386889424\n",
      "newState [331.59833  330.33704  317.0615   329.901    342.3615    73.03942\n",
      "  62.509537  89.88461 ]\n",
      "info {'type': array([73.03942062, 62.50953489, 89.88461087])}\n",
      "\n",
      "iter 122\n",
      "episode 0\n",
      "step 1\n",
      "oldState [331.59833  330.33704  317.0615   329.901    342.3615    73.03942\n",
      "  62.509537  89.88461 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9008545352011789\n",
      "newState [252.67085  250.97977  233.74104  250.39345  271.13928   40.296295\n",
      "  53.416073  80.118095]\n",
      "info {'type': array([40.29629657, 53.41607342, 80.11809296])}\n",
      "\n",
      "iter 122\n",
      "episode 0\n",
      "step 2\n",
      "oldState [252.67085  250.97977  233.74104  250.39345  271.13928   40.296295\n",
      "  53.416073  80.118095]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9019183752877575\n",
      "newState [621.6      621.6      621.6      621.6      621.6       48.443268\n",
      "  59.809654  74.45893 ]\n",
      "info {'type': array([48.44326848, 59.80965332, 74.458929  ])}\n",
      "\n",
      "iter 123\n",
      "episode 0\n",
      "step 0\n",
      "oldState [500.87143  502.7793   529.3464   503.41858  530.87      20.759085\n",
      "  48.603493  10.883497]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.7855423098591581\n",
      "newState [585.681    586.84265  604.3123   587.2275   612.9497    23.406046\n",
      "  40.41084   36.318703]\n",
      "info {'type': array([23.406045  , 40.41083812, 36.31870303])}\n",
      "\n",
      "iter 123\n",
      "episode 0\n",
      "step 1\n",
      "oldState [585.681    586.84265  604.3123   587.2275   612.9497    23.406046\n",
      "  40.41084   36.318703]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.86527809227802\n",
      "newState [547.5059   549.20703  574.3171   549.7722   584.1672    25.797628\n",
      "  41.378555  67.28431 ]\n",
      "info {'type': array([25.79762849, 41.3785568 , 67.28430567])}\n",
      "\n",
      "iter 123\n",
      "episode 0\n",
      "step 2\n",
      "oldState [547.5059   549.20703  574.3171   549.7722   584.1672    25.797628\n",
      "  41.378555  67.28431 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9071237607289573\n",
      "newState [445.4      445.4      445.4      445.4      445.4       37.50318\n",
      "  46.522472  72.21837 ]\n",
      "info {'type': array([37.50318239, 46.52247094, 72.21836601])}\n",
      "\n",
      "iter 124\n",
      "episode 0\n",
      "step 0\n",
      "oldState [321.3877   321.01532  314.36206  320.8959   305.5696    35.997913\n",
      "  50.500515  33.465603]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8497782335099353\n",
      "newState [398.22717 398.8498  409.06064 399.05334 418.86472  44.61839  39.17722\n",
      " 124.95083]\n",
      "info {'type': array([ 44.61838835,  39.1772207 , 124.95083168])}\n",
      "\n",
      "iter 124\n",
      "episode 0\n",
      "step 1\n",
      "oldState [398.22717 398.8498  409.06064 399.05334 418.86472  44.61839  39.17722\n",
      " 124.95083]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9495489614056783\n",
      "newState [333.30948  333.00922  327.548    332.91327  319.90924    8.746069\n",
      "   8.905902  18.10315 ]\n",
      "info {'type': array([ 8.74606855,  8.90590184, 18.10315008])}\n",
      "\n",
      "iter 124\n",
      "episode 0\n",
      "step 2\n",
      "oldState [333.30948  333.00922  327.548    332.91327  319.90924    8.746069\n",
      "   8.905902  18.10315 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9221931483317317\n",
      "newState [225.2      225.2      225.2      225.2      225.2       18.012775\n",
      "  18.275724  23.856304]\n",
      "info {'type': array([18.01277573, 18.27572402, 23.85630419])}\n",
      "\n",
      "iter 125\n",
      "episode 0\n",
      "step 0\n",
      "oldState [180.78198   180.662     178.56412   180.62337   185.30295     9.678753\n",
      "   6.1305666  15.506537 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7948672529367267\n",
      "newState [220.92603   220.8539    219.8685    220.82968   220.00392    14.747507\n",
      "  12.7448845  20.188892 ]\n",
      "info {'type': array([14.74750678, 12.74488439, 20.18889246])}\n",
      "\n",
      "iter 125\n",
      "episode 0\n",
      "step 1\n",
      "oldState [220.92603   220.8539    219.8685    220.82968   220.00392    14.747507\n",
      "  12.7448845  20.188892 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.9872402684489582\n",
      "newState [204.4514   204.27675  202.15338  204.21732  213.23538   13.55508\n",
      "  20.255032  35.263794]\n",
      "info {'type': array([13.55508011, 20.25503065, 35.2637953 ])}\n",
      "\n",
      "iter 125\n",
      "episode 0\n",
      "step 2\n",
      "oldState [204.4514   204.27675  202.15338  204.21732  213.23538   13.55508\n",
      "  20.255032  35.263794]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9120141505473744\n",
      "newState [263.3      263.3      263.3      263.3      263.3       41.887405\n",
      "  62.40885  118.15421 ]\n",
      "info {'type': array([ 41.88740526,  62.40885348, 118.15421648])}\n",
      "\n",
      "iter 126\n",
      "episode 0\n",
      "step 0\n",
      "oldState [181.33229   181.86751   186.91121   182.05484   173.03688    11.28861\n",
      "  15.4703665  26.756807 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7728055406483392\n",
      "newState [255.54771   255.55658   255.47028   255.56015   254.33432     7.3725243\n",
      "   8.209448    6.464558 ]\n",
      "info {'type': array([7.37252407, 8.2094474 , 6.46455828])}\n",
      "\n",
      "iter 126\n",
      "episode 0\n",
      "step 1\n",
      "oldState [255.54771   255.55658   255.47028   255.56015   254.33432     7.3725243\n",
      "   8.209448    6.464558 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8635225482123041\n",
      "newState [247.14336  247.2049   248.19905  247.22499  249.20906   31.913866\n",
      "  60.579903  96.16475 ]\n",
      "info {'type': array([31.91386541, 60.57990156, 96.16474914])}\n",
      "\n",
      "iter 126\n",
      "episode 0\n",
      "step 2\n",
      "oldState [247.14336  247.2049   248.19905  247.22499  249.20906   31.913866\n",
      "  60.579903  96.16475 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9051246850560024\n",
      "newState [366.2      366.2      366.2      366.2      366.2       37.437077\n",
      "  72.17125   80.789856]\n",
      "info {'type': array([37.43707813, 72.17125108, 80.78985892])}\n",
      "\n",
      "iter 127\n",
      "episode 0\n",
      "step 0\n",
      "oldState [175.9802   175.53957  169.22142  175.39331  168.29391   33.118614\n",
      "  43.576427  21.261703]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8356352369575234\n",
      "newState [326.57657 327.13773 336.93274 327.3192  349.33047  55.79978  75.79572\n",
      "  97.11128]\n",
      "info {'type': array([55.79978179, 75.79572601, 97.11127865])}\n",
      "\n",
      "iter 127\n",
      "episode 0\n",
      "step 1\n",
      "oldState [326.57657 327.13773 336.93274 327.3192  349.33047  55.79978  75.79572\n",
      "  97.11128]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8911663278478574\n",
      "newState [244.37677  245.36127  260.83328  245.68549  272.38943   56.67799\n",
      "  35.558636 131.43857 ]\n",
      "info {'type': array([ 56.67798899,  35.55863607, 131.43856272])}\n",
      "\n",
      "iter 127\n",
      "episode 0\n",
      "step 2\n",
      "oldState [244.37677  245.36127  260.83328  245.68549  272.38943   56.67799\n",
      "  35.558636 131.43857 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.955061656831874\n",
      "newState [493.5      493.5      493.5      493.5      493.5       19.104223\n",
      "  21.830187  31.898563]\n",
      "info {'type': array([19.10422239, 21.8301859 , 31.89856339])}\n",
      "\n",
      "iter 128\n",
      "episode 0\n",
      "step 0\n",
      "oldState [297.97577  297.52133  294.96344  297.35748  317.86215   75.20923\n",
      "  56.516838  50.81548 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8767979083362328\n",
      "newState [426.1521   425.83517  425.95126  425.7144   453.20758   55.725857\n",
      "  76.91471   86.83417 ]\n",
      "info {'type': array([55.72585857, 76.91471189, 86.83416773])}\n",
      "\n",
      "iter 128\n",
      "episode 0\n",
      "step 1\n",
      "oldState [426.1521   425.83517  425.95126  425.7144   453.20758   55.725857\n",
      "  76.91471   86.83417 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8826362690773197\n",
      "newState [345.7356   345.9874   354.3876   346.05612  384.4016    37.662563\n",
      "  29.25563   84.01254 ]\n",
      "info {'type': array([37.66256323, 29.25563132, 84.01254198])}\n",
      "\n",
      "iter 128\n",
      "episode 0\n",
      "step 2\n",
      "oldState [345.7356   345.9874   354.3876   346.05612  384.4016    37.662563\n",
      "  29.25563   84.01254 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9424073595058412\n",
      "newState [520.5      520.5      520.5      520.5      520.5       37.69594\n",
      "  69.98379   67.860855]\n",
      "info {'type': array([37.69593769, 69.98379096, 67.86085731])}\n",
      "\n",
      "iter 129\n",
      "episode 0\n",
      "step 0\n",
      "oldState [339.74026  341.35217  367.53098  341.8802   391.5098    27.057447\n",
      "  85.857895  73.049286]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8551840670881523\n",
      "newState [447.78912  449.54807  472.2284   450.1432   462.61627   55.360832\n",
      "  46.170242  48.89015 ]\n",
      "info {'type': array([55.36083355, 46.17024234, 48.89014923])}\n",
      "\n",
      "iter 129\n",
      "episode 0\n",
      "step 1\n",
      "oldState [447.78912  449.54807  472.2284   450.1432   462.61627   55.360832\n",
      "  46.170242  48.89015 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8837232262045388\n",
      "newState [393.06573  394.6457   417.4842   395.17236  423.8631    53.271904\n",
      "  48.278934  40.805588]\n",
      "info {'type': array([53.27190316, 48.27893283, 40.80558729])}\n",
      "\n",
      "iter 129\n",
      "episode 0\n",
      "step 2\n",
      "oldState [393.06573  394.6457   417.4842   395.17236  423.8631    53.271904\n",
      "  48.278934  40.805588]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8707235657086497\n",
      "newState [472.       472.       472.       472.       472.         9.663223\n",
      "  12.337429  17.854826]\n",
      "info {'type': array([ 9.66322318, 12.33742861, 17.85482628])}\n",
      "\n",
      "iter 130\n",
      "episode 0\n",
      "step 0\n",
      "oldState [210.6818   212.96735  247.63152  213.72417  266.84564   83.950066\n",
      "  73.77508  129.30031 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9127472954143664\n",
      "newState [374.23157 373.5501  364.87326 373.31964 369.56442  73.37229 110.26625\n",
      "  65.2465 ]\n",
      "info {'type': array([ 73.37229386, 110.2662474 ,  65.24649743])}\n",
      "\n",
      "iter 130\n",
      "episode 0\n",
      "step 1\n",
      "oldState [374.23157 373.5501  364.87326 373.31964 369.56442  73.37229 110.26625\n",
      "  65.2465 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8421443266866195\n",
      "newState [274.75394  275.64166  292.097    275.92612  317.82217   27.074383\n",
      "  73.73301   64.33152 ]\n",
      "info {'type': array([27.07438242, 73.73300987, 64.33151946])}\n",
      "\n",
      "iter 130\n",
      "episode 0\n",
      "step 2\n",
      "oldState [274.75394  275.64166  292.097    275.92612  317.82217   27.074383\n",
      "  73.73301   64.33152 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8584451192842032\n",
      "newState [727.9     727.9     727.9     727.9     727.9      73.24871  82.78508\n",
      " 151.20374]\n",
      "info {'type': array([ 73.24871233,  82.78507983, 151.20374212])}\n",
      "\n",
      "iter 131\n",
      "episode 0\n",
      "step 0\n",
      "oldState [650.7137    651.112     656.2906    651.2468    654.518       5.9131155\n",
      "   4.203285   10.06228  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9310872954771338\n",
      "newState [721.3366    721.24243   719.93756   721.21094   719.92944     6.363274\n",
      "   5.944884    6.7060013]\n",
      "info {'type': array([6.36327426, 5.94488389, 6.70600106])}\n",
      "\n",
      "iter 131\n",
      "episode 0\n",
      "step 1\n",
      "oldState [721.3366    721.24243   719.93756   721.21094   719.92944     6.363274\n",
      "   5.944884    6.7060013]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8860537789762479\n",
      "newState [714.4469   714.3449   713.17     714.31     714.6147    39.332012\n",
      "  60.89371   75.85275 ]\n",
      "info {'type': array([39.33201407, 60.8937093 , 75.85275457])}\n",
      "\n",
      "iter 131\n",
      "episode 0\n",
      "step 2\n",
      "oldState [714.4469   714.3449   713.17     714.31     714.6147    39.332012\n",
      "  60.89371   75.85275 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8884877476587366\n",
      "newState [496.9      496.9      496.9      496.9      496.9       63.87586\n",
      "  88.135025  28.49166 ]\n",
      "info {'type': array([63.8758597 , 88.13502216, 28.49166003])}\n",
      "\n",
      "iter 132\n",
      "episode 0\n",
      "step 0\n",
      "oldState [439.14017   439.99072   454.3536    440.26736   470.22855     3.285375\n",
      "   4.4102817   8.239618 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9169039854882374\n",
      "newState [491.50705   491.50494   491.3172    491.5048    490.3735      3.955265\n",
      "   5.0899377  12.8673525]\n",
      "info {'type': array([ 3.95526495,  5.08993768, 12.8673523 ])}\n",
      "\n",
      "iter 132\n",
      "episode 0\n",
      "step 1\n",
      "oldState [491.50705   491.50494   491.3172    491.5048    490.3735      3.955265\n",
      "   5.0899377  12.8673525]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9371650689772478\n",
      "newState [484.45453  484.41248  483.30783  484.40015  480.18292   38.935055\n",
      "  54.17516   12.515893]\n",
      "info {'type': array([38.93505496, 54.17515907, 12.51589307])}\n",
      "\n",
      "iter 132\n",
      "episode 0\n",
      "step 2\n",
      "oldState [484.45453  484.41248  483.30783  484.40015  480.18292   38.935055\n",
      "  54.17516   12.515893]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8058171038832043\n",
      "newState [340.5      340.5      340.5      340.5      340.5       56.902996\n",
      "  37.050056  75.11639 ]\n",
      "info {'type': array([56.90299437, 37.05005459, 75.11638922])}\n",
      "\n",
      "iter 133\n",
      "episode 0\n",
      "step 0\n",
      "oldState [207.76073  206.95282  192.82275  206.69138  223.43806   57.523327\n",
      "  85.151634 216.79782 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7993861316062063\n",
      "newState [291.7016   291.51233  285.68616  291.45874  267.89246   66.74836\n",
      "  50.117027 102.25382 ]\n",
      "info {'type': array([ 66.74836175,  50.11702584, 102.25382273])}\n",
      "\n",
      "iter 133\n",
      "episode 0\n",
      "step 1\n",
      "oldState [291.7016   291.51233  285.68616  291.45874  267.89246   66.74836\n",
      "  50.117027 102.25382 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.0106804606042956\n",
      "newState [218.76624   217.72546   200.7558    217.3847    233.62193     3.8319468\n",
      "  12.39549    12.854346 ]\n",
      "info {'type': array([ 3.83194692, 12.39548963, 12.85434603])}\n",
      "\n",
      "iter 133\n",
      "episode 0\n",
      "step 2\n",
      "oldState [218.76624   217.72546   200.7558    217.3847    233.62193     3.8319468\n",
      "  12.39549    12.854346 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8704319708870958\n",
      "newState [407.2      407.2      407.2      407.2      407.2       41.882137\n",
      "  39.20108   12.969887]\n",
      "info {'type': array([41.8821373 , 39.20108122, 12.96988705])}\n",
      "\n",
      "iter 134\n",
      "episode 0\n",
      "step 0\n",
      "oldState [129.22113  130.32352  142.55688  130.70386  192.63559   61.706684\n",
      "  85.55704  109.112495]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.890737451691481\n",
      "newState [314.95096 315.4661  322.29163 315.64005 320.75073  72.93623 109.75057\n",
      " 147.65816]\n",
      "info {'type': array([ 72.93623074, 109.75057012, 147.65815401])}\n",
      "\n",
      "iter 134\n",
      "episode 0\n",
      "step 1\n",
      "oldState [314.95096 315.4661  322.29163 315.64005 320.75073  72.93623 109.75057\n",
      " 147.65816]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.9790962980449016\n",
      "newState [196.88467  198.14095  213.75864  198.56848  271.25592   46.134903\n",
      "  54.12429   99.25242 ]\n",
      "info {'type': array([46.13490107, 54.12428908, 99.25241831])}\n",
      "\n",
      "iter 134\n",
      "episode 0\n",
      "step 2\n",
      "oldState [196.88467  198.14095  213.75864  198.56848  271.25592   46.134903\n",
      "  54.12429   99.25242 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9156015008723742\n",
      "newState [794.3     794.3     794.3     794.3     794.3      52.1105  117.81323\n",
      " 102.40379]\n",
      "info {'type': array([ 52.11050091, 117.81322944, 102.40379216])}\n",
      "\n",
      "iter 135\n",
      "episode 0\n",
      "step 0\n",
      "oldState [767.7067   767.6512   767.4732   767.6308   771.0858     3.89895\n",
      "   9.664298  14.835396]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9021566852489757\n",
      "newState [784.3095    784.42017   785.4621    784.4589    782.5492      6.561416\n",
      "   3.1944785  10.936631 ]\n",
      "info {'type': array([ 6.56141629,  3.19447843, 10.93663114])}\n",
      "\n",
      "iter 135\n",
      "episode 0\n",
      "step 1\n",
      "oldState [784.3095    784.42017   785.4621    784.4589    782.5492      6.561416\n",
      "   3.1944785  10.936631 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9482290482307634\n",
      "newState [777.88324   777.83746   776.7274    777.8238    773.88666    12.796289\n",
      "   9.432148    3.5240695]\n",
      "info {'type': array([12.79628912,  9.43214814,  3.5240696 ])}\n",
      "\n",
      "iter 135\n",
      "episode 0\n",
      "step 2\n",
      "oldState [777.88324   777.83746   776.7274    777.8238    773.88666    12.796289\n",
      "   9.432148    3.5240695]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8439704408036067\n",
      "newState [346.1      346.1      346.1      346.1      346.1       70.32473\n",
      "  25.046865  60.1807  ]\n",
      "info {'type': array([70.32472874, 25.04686577, 60.1806993 ])}\n",
      "\n",
      "iter 136\n",
      "episode 0\n",
      "step 0\n",
      "oldState [291.68262  291.47424  288.12466  291.40616  285.42313   15.420512\n",
      "  16.366308  24.298306]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9019637582175207\n",
      "newState [326.47507  326.4483   326.18152  326.4391   326.8491    15.952059\n",
      "  16.984915  35.105927]\n",
      "info {'type': array([15.95205872, 16.98491395, 35.10592716])}\n",
      "\n",
      "iter 136\n",
      "episode 0\n",
      "step 1\n",
      "oldState [326.47507  326.4483   326.18152  326.4391   326.8491    15.952059\n",
      "  16.984915  35.105927]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9233570724631798\n",
      "newState [303.84357  303.69196  301.2188   303.64255  299.04205    9.254173\n",
      "   9.422149  17.19211 ]\n",
      "info {'type': array([ 9.25417327,  9.4221489 , 17.19211076])}\n",
      "\n",
      "iter 136\n",
      "episode 0\n",
      "step 2\n",
      "oldState [303.84357  303.69196  301.2188   303.64255  299.04205    9.254173\n",
      "   9.422149  17.19211 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9152497580389043\n",
      "newState [376.6      376.6      376.6      376.6      376.6       53.86708\n",
      "  96.352806 215.69995 ]\n",
      "info {'type': array([ 53.8670815 ,  96.35280674, 215.69994705])}\n",
      "\n",
      "iter 137\n",
      "episode 0\n",
      "step 0\n",
      "oldState [132.2288   132.70592  135.19846  132.88016  195.54239   54.086872\n",
      "  73.05046   50.31956 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8526626672891661\n",
      "newState [307.2605  308.0913  321.98514 308.36206 336.70245  41.91815  63.30721\n",
      " 184.81572]\n",
      "info {'type': array([ 41.91815216,  63.30720877, 184.81572225])}\n",
      "\n",
      "iter 137\n",
      "episode 0\n",
      "step 1\n",
      "oldState [307.2605  308.0913  321.98514 308.36206 336.70245  41.91815  63.30721\n",
      " 184.81572]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.0686458192017965\n",
      "newState [216.2175  216.48825 215.92206 216.59375 274.8142   61.34222  74.49697\n",
      " 100.05293]\n",
      "info {'type': array([ 61.3422191 ,  74.49697137, 100.05293032])}\n",
      "\n",
      "iter 137\n",
      "episode 0\n",
      "step 2\n",
      "oldState [216.2175  216.48825 215.92206 216.59375 274.8142   61.34222  74.49697\n",
      " 100.05293]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.894900493317063\n",
      "newState [636.2      636.2      636.2      636.2      636.2       58.62291\n",
      "  63.33896   67.319046]\n",
      "info {'type': array([58.62290858, 63.33895951, 67.31904294])}\n",
      "\n",
      "iter 138\n",
      "episode 0\n",
      "step 0\n",
      "oldState [325.00507 326.5653  353.177   327.07272 384.3807   92.62877 123.22062\n",
      " 243.56802]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9207473712778114\n",
      "newState [482.1676  481.95483 473.877   481.901   443.27875 104.73469 146.77966\n",
      "   1.     ]\n",
      "info {'type': array([104.73468605, 146.7796573 ,   1.        ])}\n",
      "\n",
      "iter 138\n",
      "episode 0\n",
      "step 1\n",
      "oldState [482.1676  481.95483 473.877   481.901   443.27875 104.73469 146.77966\n",
      "   1.     ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.773768543801259\n",
      "newState [367.23572  369.78778  410.2681   370.6269   442.36136   41.638336\n",
      "  21.319794  73.203316]\n",
      "info {'type': array([41.63833741, 21.31979373, 73.20331465])}\n",
      "\n",
      "iter 138\n",
      "episode 0\n",
      "step 2\n",
      "oldState [367.23572  369.78778  410.2681   370.6269   442.36136   41.638336\n",
      "  21.319794  73.203316]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9489170231778523\n",
      "newState [467.1      467.1      467.1      467.1      467.1        9.806706\n",
      "   9.496274  14.046153]\n",
      "info {'type': array([ 9.80670671,  9.49627406, 14.04615332])}\n",
      "\n",
      "iter 139\n",
      "episode 0\n",
      "step 0\n",
      "oldState [165.00975  167.20844  182.5303   167.99599  176.5716    41.482876\n",
      "  88.303444 131.87953 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9003731501079775\n",
      "newState [374.73923  375.63922  384.4235   375.95322  362.63663   44.098515\n",
      "  85.35191  157.11702 ]\n",
      "info {'type': array([ 44.09851302,  85.35191169, 157.11701926])}\n",
      "\n",
      "iter 139\n",
      "episode 0\n",
      "step 1\n",
      "oldState [374.73923  375.63922  384.4235   375.95322  362.63663   44.098515\n",
      "  85.35191  157.11702 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9159720995674727\n",
      "newState [277.31107  278.68506  289.1421   279.17432  238.19492   43.414757\n",
      " 101.62746  183.9644  ]\n",
      "info {'type': array([ 43.41475556, 101.62745331, 183.9644004 ])}\n",
      "\n",
      "iter 139\n",
      "episode 0\n",
      "step 2\n",
      "oldState [277.31107  278.68506  289.1421   279.17432  238.19492   43.414757\n",
      " 101.62746  183.9644  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.0212273110935437\n",
      "newState [711.       711.       711.       711.       711.        45.482166\n",
      "  49.808247  77.601776]\n",
      "info {'type': array([45.48216777, 49.80824487, 77.6017757 ])}\n",
      "\n",
      "iter 140\n",
      "episode 0\n",
      "step 0\n",
      "oldState [684.0951    683.9845    681.76904   683.94977   677.69476     4.5880466\n",
      "   6.8367825   6.174641 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8673572008705399\n",
      "newState [704.3281    704.40326   705.5337    704.42816   706.1063      4.289804\n",
      "   4.9536605  18.696096 ]\n",
      "info {'type': array([ 4.28980395,  4.95366054, 18.69609582])}\n",
      "\n",
      "iter 140\n",
      "episode 0\n",
      "step 1\n",
      "oldState [704.3281    704.40326   705.5337    704.42816   706.1063      4.289804\n",
      "   4.9536605  18.696096 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.961570989182715\n",
      "newState [695.89545  695.8592   694.77527  695.849    691.3015     9.119541\n",
      "   8.850144  17.177158]\n",
      "info {'type': array([ 9.11954146,  8.85014428, 17.17715798])}\n",
      "\n",
      "iter 140\n",
      "episode 0\n",
      "step 2\n",
      "oldState [695.89545  695.8592   694.77527  695.849    691.3015     9.119541\n",
      "   8.850144  17.177158]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9191645285541393\n",
      "newState [132.7      132.7      132.7      132.7      132.7       17.124409\n",
      "  23.252542  21.89141 ]\n",
      "info {'type': array([17.12440884, 23.25254204, 21.89141047])}\n",
      "\n",
      "iter 141\n",
      "episode 0\n",
      "step 0\n",
      "oldState [ 33.438698  33.092022  26.325861  32.981594  16.008703  47.94852\n",
      "  36.80733  126.8989  ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.8142355333763969\n",
      "newState [105.16231  104.697815  97.001785 104.546104  90.19978   64.68349\n",
      "  88.64628  108.68382 ]\n",
      "info {'type': array([ 64.68348566,  88.64627564, 108.68382314])}\n",
      "\n",
      "iter 141\n",
      "episode 0\n",
      "step 1\n",
      "oldState [105.16231  104.697815  97.001785 104.546104  90.19978   64.68349\n",
      "  88.64628  108.68382 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.749358377876443\n",
      "newState [ 65.08786   64.85851   60.410683  64.78538   53.759686  51.947823\n",
      "  58.184273 112.666374]\n",
      "info {'type': array([ 51.9478235 ,  58.18427285, 112.66637254])}\n",
      "\n",
      "iter 141\n",
      "episode 0\n",
      "step 2\n",
      "oldState [ 65.08786   64.85851   60.410683  64.78538   53.759686  51.947823\n",
      "  58.184273 112.666374]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7803704769274393\n",
      "newState [673.4      673.4      673.4      673.4      673.4       41.7477\n",
      " 143.98477   16.539148]\n",
      "info {'type': array([ 41.74769818, 143.98477823,  16.53914767])}\n",
      "\n",
      "iter 142\n",
      "episode 0\n",
      "step 0\n",
      "oldState [631.88635   632.1904    636.6412    632.2917    638.24066     5.5809407\n",
      "   8.710138    6.851326 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8580323178348616\n",
      "newState [665.22107  665.33356  667.0389   665.3708   667.96924    5.648735\n",
      "   8.916913   8.445515]\n",
      "info {'type': array([5.6487349 , 8.91691341, 8.44551509])}\n",
      "\n",
      "iter 142\n",
      "episode 0\n",
      "step 1\n",
      "oldState [665.22107  665.33356  667.0389   665.3708   667.96924    5.648735\n",
      "   8.916913   8.445515]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.869767406039475\n",
      "newState [656.53894  656.75397  659.94     656.8254   661.2763    17.561708\n",
      "  22.256811  29.074213]\n",
      "info {'type': array([17.56170836, 22.25681139, 29.07421234])}\n",
      "\n",
      "iter 142\n",
      "episode 0\n",
      "step 2\n",
      "oldState [656.53894  656.75397  659.94     656.8254   661.2763    17.561708\n",
      "  22.256811  29.074213]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8928489405723935\n",
      "newState [262.7      262.7      262.7      262.7      262.7       63.30445\n",
      "  62.452217 127.00237 ]\n",
      "info {'type': array([ 63.30444951,  62.45221584, 127.00236966])}\n",
      "\n",
      "iter 143\n",
      "episode 0\n",
      "step 0\n",
      "oldState [161.92361  162.55563  172.16321  162.76428  178.38994   31.882038\n",
      "  33.803192  55.134113]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7691951867630122\n",
      "newState [245.0811   245.03745  244.37944  245.0229   244.2204    40.91576\n",
      "  62.745888 118.80581 ]\n",
      "info {'type': array([ 40.91575909,  62.74588863, 118.80580926])}\n",
      "\n",
      "iter 143\n",
      "episode 0\n",
      "step 1\n",
      "oldState [245.0811   245.03745  244.37944  245.0229   244.2204    40.91576\n",
      "  62.745888 118.80581 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7791005962405262\n",
      "newState [213.3151   213.31673  211.95163  213.32137  204.41852   42.18849\n",
      "  54.767525  32.818913]\n",
      "info {'type': array([42.18849166, 54.76752368, 32.81891139])}\n",
      "\n",
      "iter 143\n",
      "episode 0\n",
      "step 2\n",
      "oldState [213.3151   213.31673  211.95163  213.32137  204.41852   42.18849\n",
      "  54.767525  32.818913]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8460136995109502\n",
      "newState [516.3      516.3      516.3      516.3      516.3       77.679985\n",
      " 107.5607   154.96458 ]\n",
      "info {'type': array([ 77.67998243, 107.56070056, 154.96459005])}\n",
      "\n",
      "iter 144\n",
      "episode 0\n",
      "step 0\n",
      "oldState [265.8454   265.54218  257.09842  265.45544  232.06201   64.22522\n",
      "  52.925625 116.19393 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9264873496840642\n",
      "newState [439.44077  438.61786  426.79553  438.34378  424.25995   51.544224\n",
      "  63.988945  99.59933 ]\n",
      "info {'type': array([51.54422298, 63.98894638, 99.59932769])}\n",
      "\n",
      "iter 144\n",
      "episode 0\n",
      "step 1\n",
      "oldState [439.44077  438.61786  426.79553  438.34378  424.25995   51.544224\n",
      "  63.988945  99.59933 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.904593534345022\n",
      "newState [364.52377  363.77112  352.1783   363.52325  345.35736   53.98272\n",
      "  87.643585 143.02893 ]\n",
      "info {'type': array([ 53.98271957,  87.64358778, 143.02893078])}\n",
      "\n",
      "iter 144\n",
      "episode 0\n",
      "step 2\n",
      "oldState [364.52377  363.77112  352.1783   363.52325  345.35736   53.98272\n",
      "  87.643585 143.02893 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9073631090978163\n",
      "newState [588.       588.       588.       588.       588.        31.257387\n",
      "  41.715717  66.54332 ]\n",
      "info {'type': array([31.25738641, 41.71571605, 66.54332138])}\n",
      "\n",
      "iter 145\n",
      "episode 0\n",
      "step 0\n",
      "oldState [490.4329   490.0185   480.29147  489.89316  456.40616   21.961329\n",
      "  27.850466  32.40772 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8852877091787277\n",
      "newState [558.073    558.22437  560.5908   558.2743   562.3205    25.696592\n",
      "  17.372793  26.078936]\n",
      "info {'type': array([25.69659315, 17.3727935 , 26.07893532])}\n",
      "\n",
      "iter 145\n",
      "episode 0\n",
      "step 1\n",
      "oldState [558.073    558.22437  560.5908   558.2743   562.3205    25.696592\n",
      "  17.372793  26.078936]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9042905748767667\n",
      "newState [534.11096  533.99585  533.70264  533.9531   541.65436   10.524293\n",
      "  28.115593 107.66389 ]\n",
      "info {'type': array([ 10.52429292,  28.11559266, 107.66388734])}\n",
      "\n",
      "iter 145\n",
      "episode 0\n",
      "step 2\n",
      "oldState [534.11096  533.99585  533.70264  533.9531   541.65436   10.524293\n",
      "  28.115593 107.66389 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9669289644452616\n",
      "newState [343.3      343.3      343.3      343.3      343.3       18.386501\n",
      "  39.33978   50.860443]\n",
      "info {'type': array([18.38650041, 39.33977854, 50.8604438 ])}\n",
      "\n",
      "iter 146\n",
      "episode 0\n",
      "step 0\n",
      "oldState [281.31024  281.128    280.56808  281.0607   292.52234   10.510422\n",
      "   8.959895  20.583656]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9293916399291964\n",
      "newState [330.19675  330.0575   327.9669   330.0114   326.99582    8.499482\n",
      "   5.828298  14.759619]\n",
      "info {'type': array([ 8.49948262,  5.82829792, 14.75961853])}\n",
      "\n",
      "iter 146\n",
      "episode 0\n",
      "step 1\n",
      "oldState [330.19675  330.0575   327.9669   330.0114   326.99582    8.499482\n",
      "   5.828298  14.759619]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9341965435660858\n",
      "newState [320.81094  320.52554  316.3924   320.4306   315.30466   38.588608\n",
      "  36.916855  28.731676]\n",
      "info {'type': array([38.58860776, 36.91685528, 28.73167554])}\n",
      "\n",
      "iter 146\n",
      "episode 0\n",
      "step 2\n",
      "oldState [320.81094  320.52554  316.3924   320.4306   315.30466   38.588608\n",
      "  36.916855  28.731676]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8655874350591984\n",
      "newState [373.1      373.1      373.1      373.1      373.1       47.148235\n",
      "  38.63328   85.47568 ]\n",
      "info {'type': array([47.14823719, 38.63328237, 85.47567392])}\n",
      "\n",
      "iter 147\n",
      "episode 0\n",
      "step 0\n",
      "oldState [214.29054 214.95271 180.0033  215.15071 229.94891 101.98864  95.16695\n",
      "  64.32684]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8592189568145493\n",
      "newState [272.69415 272.99362 283.493   273.0734  322.079    75.12408 107.28938\n",
      " 100.2036 ]\n",
      "info {'type': array([ 75.12408025, 107.28938157, 100.20359625])}\n",
      "\n",
      "iter 147\n",
      "episode 0\n",
      "step 1\n",
      "oldState [272.69415 272.99362 283.493   273.0734  322.079    75.12408 107.28938\n",
      " 100.2036 ]\n",
      "action [[1.3917e-01 1.4981e-01 6.0246e-01 1.5351e-01 5.0000e-04]\n",
      " [2.3113e-01 2.1565e-01 5.0000e-04 2.1047e-01 5.0000e-04]\n",
      " [9.7380e-02 1.0151e-01 4.3707e-01 1.0281e-01 7.9162e-01]]\n",
      "reward -1.4332824104922872\n",
      "newState [227.6835   228.43066  194.38412  228.65796  242.66463   12.218663\n",
      "  10.376433  16.048637]\n",
      "info {'type': array([12.21866351, 10.37643347, 16.04863789])}\n",
      "\n",
      "iter 147\n",
      "episode 0\n",
      "step 2\n",
      "oldState [227.6835   228.43066  194.38412  228.65796  242.66463   12.218663\n",
      "  10.376433  16.048637]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9052192520371237\n",
      "newState [458.1      458.1      458.1      458.1      458.1       32.819954\n",
      "  27.335163  67.16096 ]\n",
      "info {'type': array([32.81995497, 27.33516298, 67.16095494])}\n",
      "\n",
      "iter 148\n",
      "episode 0\n",
      "step 0\n",
      "oldState [332.68832  332.73538  337.38962  332.73843  361.82617   14.186366\n",
      "  10.253393  25.420925]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9332393482319163\n",
      "newState [441.96555  441.7332   438.43744  441.65564  437.96408   11.315774\n",
      "  11.596023  15.859975]\n",
      "info {'type': array([11.31577374, 11.59602283, 15.85997495])}\n",
      "\n",
      "iter 148\n",
      "episode 0\n",
      "step 1\n",
      "oldState [441.96555  441.7332   438.43744  441.65564  437.96408   11.315774\n",
      "  11.596023  15.859975]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8969409807168467\n",
      "newState [428.24548  427.99783  424.68243  427.91458  425.39755   86.641014\n",
      "  88.8275    80.19458 ]\n",
      "info {'type': array([86.64101569, 88.82749827, 80.1945831 ])}\n",
      "\n",
      "iter 148\n",
      "episode 0\n",
      "step 2\n",
      "oldState [428.24548  427.99783  424.68243  427.91458  425.39755   86.641014\n",
      "  88.8275    80.19458 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8723404854667165\n",
      "newState [324.2      324.2      324.2      324.2      324.2        8.222885\n",
      "   9.859234  15.006166]\n",
      "info {'type': array([ 8.22288534,  9.85923381, 15.00616625])}\n",
      "\n",
      "iter 149\n",
      "episode 0\n",
      "step 0\n",
      "oldState [138.07301  139.50635  153.53712  140.0057   180.51093   38.394894\n",
      "  88.88558  139.34015 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.765071233071861\n",
      "newState [284.74353  285.13547  288.59207  285.2727   277.51593   46.15921\n",
      "  86.276245 132.79741 ]\n",
      "info {'type': array([ 46.15921053,  86.2762422 , 132.79741629])}\n",
      "\n",
      "iter 149\n",
      "episode 0\n",
      "step 1\n",
      "oldState [284.74353  285.13547  288.59207  285.2727   277.51593   46.15921\n",
      "  86.276245 132.79741 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.9982375073803559\n",
      "newState [191.7438   192.83386  202.69809  193.21606  233.01836   33.476994\n",
      "  50.054485  66.27632 ]\n",
      "info {'type': array([33.47699185, 50.05448692, 66.27631855])}\n",
      "\n",
      "iter 149\n",
      "episode 0\n",
      "step 2\n",
      "oldState [191.7438   192.83386  202.69809  193.21606  233.01836   33.476994\n",
      "  50.054485  66.27632 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8929002261425006\n",
      "newState [796.3     796.3     796.3     796.3     796.3      96.69082 115.95339\n",
      " 225.6768 ]\n",
      "info {'type': array([ 96.69081507, 115.95339536, 225.67680673])}\n",
      "\n",
      "iter 150\n",
      "episode 0\n",
      "step 0\n",
      "oldState [601.63477  601.68365  608.978    601.67896  649.3417    53.358135\n",
      "  39.631744  37.793907]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8798252178546391\n",
      "newState [748.37146  748.1122   747.6154   748.01526  766.3351    54.07917\n",
      "  59.410973  96.28825 ]\n",
      "info {'type': array([54.07916868, 59.41097294, 96.28825094])}\n",
      "\n",
      "iter 150\n",
      "episode 0\n",
      "step 1\n",
      "oldState [748.37146  748.1122   747.6154   748.01526  766.3351    54.07917\n",
      "  59.410973  96.28825 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9075231336634181\n",
      "newState [675.8901  675.5011  672.9205  675.36194 690.0546   68.82898  72.75336\n",
      "  51.34048]\n",
      "info {'type': array([68.82897876, 72.75335784, 51.34048091])}\n",
      "\n",
      "iter 150\n",
      "episode 0\n",
      "step 2\n",
      "oldState [675.8901  675.5011  672.9205  675.36194 690.0546   68.82898  72.75336\n",
      "  51.34048]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8587220590016444\n",
      "newState [439.6      439.6      439.6      439.6      439.6        8.235048\n",
      "   6.769574  13.642383]\n",
      "info {'type': array([ 8.23504858,  6.76957437, 13.6423825 ])}\n",
      "\n",
      "iter 151\n",
      "episode 0\n",
      "step 0\n",
      "oldState [308.2022   310.1317   336.91116  310.77847  337.9399    24.99323\n",
      "  19.304762  52.84357 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9395154208662543\n",
      "newState [408.637     408.1932    401.43658   408.04663   397.74582     7.6029677\n",
      "  21.218925   16.681393 ]\n",
      "info {'type': array([ 7.60296754, 21.21892611, 16.68139356])}\n",
      "\n",
      "iter 151\n",
      "episode 0\n",
      "step 1\n",
      "oldState [408.637     408.1932    401.43658   408.04663   397.74582     7.6029677\n",
      "  21.218925   16.681393 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8505311696615664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newState [390.68286 390.66434 389.55457 390.6611  384.5261   44.67073  99.16755\n",
      "  58.75831]\n",
      "info {'type': array([44.67073204, 99.16754622, 58.75830875])}\n",
      "\n",
      "iter 151\n",
      "episode 0\n",
      "step 2\n",
      "oldState [390.68286 390.66434 389.55457 390.6611  384.5261   44.67073  99.16755\n",
      "  58.75831]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.834591982534829\n",
      "newState [364.3      364.3      364.3      364.3      364.3       11.45339\n",
      "  22.747179  41.27174 ]\n",
      "info {'type': array([11.45339017, 22.74717898, 41.27174019])}\n",
      "\n",
      "iter 152\n",
      "episode 0\n",
      "step 0\n",
      "oldState [138.36005  139.2631   144.91911  139.58904  170.7311    27.08266\n",
      "  51.075848  47.723213]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8669552895099502\n",
      "newState [316.4516   317.1784   327.09985  317.4226   326.48227   34.824142\n",
      "  54.057438 145.25854 ]\n",
      "info {'type': array([ 34.8241425 ,  54.05743844, 145.25853983])}\n",
      "\n",
      "iter 152\n",
      "episode 0\n",
      "step 1\n",
      "oldState [316.4516   317.1784   327.09985  317.4226   326.48227   34.824142\n",
      "  54.057438 145.25854 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.0601139724057622\n",
      "newState [241.92569  242.32364  242.60452  242.47466  277.83722   63.98186\n",
      "  93.874794 135.20021 ]\n",
      "info {'type': array([ 63.98186299,  93.8747913 , 135.2002072 ])}\n",
      "\n",
      "iter 152\n",
      "episode 0\n",
      "step 2\n",
      "oldState [241.92569  242.32364  242.60452  242.47466  277.83722   63.98186\n",
      "  93.874794 135.20021 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8988047902068845\n",
      "newState [401.4      401.4      401.4      401.4      401.4        6.098319\n",
      "   4.772723   9.258717]\n",
      "info {'type': array([6.09831914, 4.7727232 , 9.25871692])}\n",
      "\n",
      "iter 153\n",
      "episode 0\n",
      "step 0\n",
      "oldState [223.75012  224.68495  236.95424  225.00107  233.4746    29.316319\n",
      "  39.61586   49.1508  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8890468444604188\n",
      "newState [358.75766  358.9911   362.23593  359.0694   362.4568    29.13105\n",
      "  61.092022  81.07897 ]\n",
      "info {'type': array([29.13104989, 61.09202233, 81.07897546])}\n",
      "\n",
      "iter 153\n",
      "episode 0\n",
      "step 1\n",
      "oldState [358.75766  358.9911   362.23593  359.0694   362.4568    29.13105\n",
      "  61.092022  81.07897 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8915799064810733\n",
      "newState [297.0612   298.00748  309.2179   298.33115  298.22794   60.609123\n",
      "  63.15045   81.72035 ]\n",
      "info {'type': array([60.60912134, 63.15045176, 81.72035408])}\n",
      "\n",
      "iter 153\n",
      "episode 0\n",
      "step 2\n",
      "oldState [297.0612   298.00748  309.2179   298.33115  298.22794   60.609123\n",
      "  63.15045   81.72035 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.893406299316554\n",
      "newState [503.3      503.3      503.3      503.3      503.3       34.764263\n",
      "  81.447266  73.64049 ]\n",
      "info {'type': array([34.76426309, 81.44726665, 73.64048976])}\n",
      "\n",
      "iter 154\n",
      "episode 0\n",
      "step 0\n",
      "oldState [365.41696  365.034    359.94702  364.9055   361.51382   39.59024\n",
      "  37.397976  85.21637 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.929263506556284\n",
      "newState [450.1749   449.70853  442.18423  449.55597  435.8025    59.188087\n",
      "  68.41645   83.03026 ]\n",
      "info {'type': array([59.18808752, 68.41645348, 83.03025911])}\n",
      "\n",
      "iter 154\n",
      "episode 0\n",
      "step 1\n",
      "oldState [450.1749   449.70853  442.18423  449.55597  435.8025    59.188087\n",
      "  68.41645   83.03026 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8886797832152794\n",
      "newState [374.14764  373.88696  370.20154  373.80035  370.01025    9.236551\n",
      "   5.890423  10.723495]\n",
      "info {'type': array([ 9.23655122,  5.89042295, 10.72349483])}\n",
      "\n",
      "iter 154\n",
      "episode 0\n",
      "step 2\n",
      "oldState [374.14764  373.88696  370.20154  373.80035  370.01025    9.236551\n",
      "   5.890423  10.723495]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9150486033847129\n",
      "newState [267.6       267.6       267.6       267.6       267.6         9.548276\n",
      "   5.9779587   7.4027944]\n",
      "info {'type': array([9.54827586, 5.97795863, 7.40279457])}\n",
      "\n",
      "iter 155\n",
      "episode 0\n",
      "step 0\n",
      "oldState [213.55782  213.26715  219.96127  213.17238  213.75043   17.689411\n",
      "  11.085096  20.981953]\n",
      "action [[3.2850e-01 3.5372e-01 2.5356e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 1.8536e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.1533641368194225\n",
      "newState [250.88397  250.63812  259.2199   250.55405  260.5655    15.435555\n",
      "  17.394087  31.969809]\n",
      "info {'type': array([15.4355557 , 17.39408612, 31.96980908])}\n",
      "\n",
      "iter 155\n",
      "episode 0\n",
      "step 1\n",
      "oldState [250.88397  250.63812  259.2199   250.55405  260.5655    15.435555\n",
      "  17.394087  31.969809]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9157429546425455\n",
      "newState [228.92188  228.61049  235.93886  228.50568  235.24113    6.824006\n",
      "  12.543059  27.135523]\n",
      "info {'type': array([ 6.82400605, 12.5430596 , 27.13552345])}\n",
      "\n",
      "iter 155\n",
      "episode 0\n",
      "step 2\n",
      "oldState [228.92188  228.61049  235.93886  228.50568  235.24113    6.824006\n",
      "  12.543059  27.135523]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9275568774987207\n",
      "newState [114.5      114.5      114.5      114.5      114.5        7.27624\n",
      "   8.514111  10.751683]\n",
      "info {'type': array([ 7.27624   ,  8.51411103, 10.75168284])}\n",
      "\n",
      "iter 156\n",
      "episode 0\n",
      "step 0\n",
      "oldState [73.50516  73.92013  81.64008  74.05272  92.99153  36.364445 46.98437\n",
      " 10.492073]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.6690738020518237\n",
      "newState [ 97.557945  97.85501  103.31113   97.9502   110.94789   32.431248\n",
      "  35.023155  49.899723]\n",
      "info {'type': array([32.43124728, 35.02315512, 49.89972291])}\n",
      "\n",
      "iter 156\n",
      "episode 0\n",
      "step 1\n",
      "oldState [ 97.557945  97.85501  103.31113   97.9502   110.94789   32.431248\n",
      "  35.023155  49.899723]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7604656936523888\n",
      "newState [80.09035   80.37842   85.82094   80.47017   94.21871   13.806016\n",
      " 18.653427   3.6193054]\n",
      "info {'type': array([13.80601587, 18.65342762,  3.61930539])}\n",
      "\n",
      "iter 156\n",
      "episode 0\n",
      "step 2\n",
      "oldState [80.09035   80.37842   85.82094   80.47017   94.21871   13.806016\n",
      " 18.653427   3.6193054]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.6635514358416834\n",
      "newState [339.2      339.2      339.2      339.2      339.2       39.384003\n",
      "  23.200354  65.963104]\n",
      "info {'type': array([39.38400434, 23.20035436, 65.963106  ])}\n",
      "\n",
      "iter 157\n",
      "episode 0\n",
      "step 0\n",
      "oldState [216.56322  216.86516  220.28648  216.96925  216.05692   12.56045\n",
      "  21.951267  22.231857]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8732597458241578\n",
      "newState [317.93613  318.20816  321.905    318.2996   321.58356   20.333698\n",
      "  23.062817  37.561985]\n",
      "info {'type': array([20.33369898, 23.06281718, 37.56198453])}\n",
      "\n",
      "iter 157\n",
      "episode 0\n",
      "step 1\n",
      "oldState [317.93613  318.20816  321.905    318.2996   321.58356   20.333698\n",
      "  23.062817  37.561985]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9077863792013585\n",
      "newState [289.9737  290.21017 293.226   290.29044 291.82703  51.63069  62.85173\n",
      "  95.64299]\n",
      "info {'type': array([51.63069289, 62.85172903, 95.64299158])}\n",
      "\n",
      "iter 157\n",
      "episode 0\n",
      "step 2\n",
      "oldState [289.9737  290.21017 293.226   290.29044 291.82703  51.63069  62.85173\n",
      "  95.64299]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.903136922723737\n",
      "newState [527.4      527.4      527.4      527.4      527.4       60.14454\n",
      "  99.68646  101.030846]\n",
      "info {'type': array([ 60.14453897,  99.686465  , 101.03084246])}\n",
      "\n",
      "iter 158\n",
      "episode 0\n",
      "step 0\n",
      "oldState [352.14044  351.81363  344.9819   351.71234  331.44348   28.766623\n",
      "  63.268185 124.21661 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9207718945353561\n",
      "newState [454.68005  455.05322  455.74628  455.19324  429.02164   50.649708\n",
      "  52.236057 122.154495]\n",
      "info {'type': array([ 50.64970608,  52.23605805, 122.15449307])}\n",
      "\n",
      "iter 158\n",
      "episode 0\n",
      "step 1\n",
      "oldState [454.68005  455.05322  455.74628  455.19324  429.02164   50.649708\n",
      "  52.236057 122.154495]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9312317579587408\n",
      "newState [381.2824   381.09027  371.81567  381.04816  332.27026   43.792885\n",
      "  26.55208    1.      ]\n",
      "info {'type': array([43.79288554, 26.55208041,  1.        ])}\n",
      "\n",
      "iter 158\n",
      "episode 0\n",
      "step 2\n",
      "oldState [381.2824   381.09027  371.81567  381.04816  332.27026   43.792885\n",
      "  26.55208    1.      ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8260092695415006\n",
      "newState [565.5      565.5      565.5      565.5      565.5       38.850998\n",
      "  36.417805   1.      ]\n",
      "info {'type': array([38.85099972, 36.41780536,  1.        ])}\n",
      "\n",
      "iter 159\n",
      "episode 0\n",
      "step 0\n",
      "oldState [523.0021   523.22375  527.0348   523.2957   531.6483    16.779213\n",
      "  11.785979  21.082573]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9140506299431082\n",
      "newState [548.67633  548.4783   546.1707   548.4106   548.7963    10.199828\n",
      "  19.59361    9.868646]\n",
      "info {'type': array([10.19982837, 19.59361108,  9.86864569])}\n",
      "\n",
      "iter 159\n",
      "episode 0\n",
      "step 1\n",
      "oldState [548.67633  548.4783   546.1707   548.4106   548.7963    10.199828\n",
      "  19.59361    9.868646]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8279455072197297\n",
      "newState [532.3301    532.49963   535.70264   532.5538    540.96924     5.8447986\n",
      "   8.5796175  11.765418 ]\n",
      "info {'type': array([ 5.84479854,  8.57961736, 11.7654178 ])}\n",
      "\n",
      "iter 159\n",
      "episode 0\n",
      "step 2\n",
      "oldState [532.3301    532.49963   535.70264   532.5538    540.96924     5.8447986\n",
      "   8.5796175  11.765418 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8954081134157502\n",
      "newState [108.        108.        108.        108.        108.          7.6562033\n",
      "  10.891478    8.104808 ]\n",
      "info {'type': array([ 7.65620341, 10.8914775 ,  8.10480801])}\n",
      "\n",
      "iter 160\n",
      "episode 0\n",
      "step 0\n",
      "oldState [87.00692  86.86877  85.01082  86.82223  85.531586 10.436405 11.924848\n",
      " 22.002163]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7771994665787803\n",
      "newState [101.6488   101.631485 101.26946  101.626045 100.627335  22.179323\n",
      "  16.982635  25.267923]\n",
      "info {'type': array([22.17932249, 16.98263582, 25.26792282])}\n",
      "\n",
      "iter 160\n",
      "episode 0\n",
      "step 1\n",
      "oldState [101.6488   101.631485 101.26946  101.626045 100.627335  22.179323\n",
      "  16.982635  25.267923]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7645039769350037\n",
      "newState [92.17632  92.08155  90.95352  92.049164 92.15361   8.970692  8.636539\n",
      " 19.765734]\n",
      "info {'type': array([ 8.97069127,  8.63653908, 19.76573438])}\n",
      "\n",
      "iter 160\n",
      "episode 0\n",
      "step 2\n",
      "oldState [92.17632  92.08155  90.95352  92.049164 92.15361   8.970692  8.636539\n",
      " 19.765734]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7908070950991637\n",
      "newState [259.7      259.7      259.7      259.7      259.7       52.912067\n",
      "  20.16191   28.24115 ]\n",
      "info {'type': array([52.91206624, 20.16190991, 28.24115034])}\n",
      "\n",
      "iter 161\n",
      "episode 0\n",
      "step 0\n",
      "oldState [167.30893  167.04161  163.5777   166.9509   165.79953   45.306343\n",
      "  61.14471   88.674446]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7607695822926284\n",
      "newState [230.62723  230.72546  231.74487  230.7593   229.97809   44.86815\n",
      "  59.13619  104.924194]\n",
      "info {'type': array([ 44.86814712,  59.13618943, 104.92419759])}\n",
      "\n",
      "iter 161\n",
      "episode 0\n",
      "step 1\n",
      "oldState [230.62723  230.72546  231.74487  230.7593   229.97809   44.86815\n",
      "  59.13619  104.924194]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7745733624683642\n",
      "newState [200.49727  200.60019  200.88979  200.63794  194.82056   35.344025\n",
      "  23.99819   36.622818]\n",
      "info {'type': array([35.34402393, 23.99819004, 36.62281811])}\n",
      "\n",
      "iter 161\n",
      "episode 0\n",
      "step 2\n",
      "oldState [200.49727  200.60019  200.88979  200.63794  194.82056   35.344025\n",
      "  23.99819   36.622818]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9051776156098061\n",
      "newState [508.6     508.6     508.6     508.6     508.6      46.59111  82.87959\n",
      " 135.54373]\n",
      "info {'type': array([ 46.59110927,  82.8795961 , 135.54373427])}\n",
      "\n",
      "iter 162\n",
      "episode 0\n",
      "step 0\n",
      "oldState [485.29608  485.54324  488.56     485.62744  486.2151     6.205319\n",
      "   9.300648  17.036728]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9155729350303914\n",
      "newState [497.54294   497.56012   497.41064   497.56717   495.10565     2.5169039\n",
      "  10.28949     8.901958 ]\n",
      "info {'type': array([ 2.51690376, 10.28949017,  8.90195849])}\n",
      "\n",
      "iter 162\n",
      "episode 0\n",
      "step 1\n",
      "oldState [497.54294   497.56012   497.41064   497.56717   495.10565     2.5169039\n",
      "  10.28949     8.901958 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8545130412428358\n",
      "newState [489.03342   489.27823   491.99838   489.3625    488.05228     4.0241184\n",
      "   3.438509    2.3160698]\n",
      "info {'type': array([4.02411843, 3.43850895, 2.31606977])}\n",
      "\n",
      "iter 162\n",
      "episode 0\n",
      "step 2\n",
      "oldState [489.03342   489.27823   491.99838   489.3625    488.05228     4.0241184\n",
      "   3.438509    2.3160698]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8609845494842158\n",
      "newState [158.2      158.2      158.2      158.2      158.2       36.381714\n",
      "  50.08759   28.244116]\n",
      "info {'type': array([36.38171356, 50.08759006, 28.24411595])}\n",
      "\n",
      "iter 163\n",
      "episode 0\n",
      "step 0\n",
      "oldState [86.68457  86.84828  89.67528  86.90099  93.311714 26.407448 16.20041\n",
      " 12.233514]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7340033785100426\n",
      "newState [149.58917  149.50845  149.22842  149.47876  154.0856    30.571407\n",
      "  36.41513   18.17623 ]\n",
      "info {'type': array([30.57140812, 36.41512912, 18.17622912])}\n",
      "\n",
      "iter 163\n",
      "episode 0\n",
      "step 1\n",
      "oldState [149.58917  149.50845  149.22842  149.47876  154.0856    30.571407\n",
      "  36.41513   18.17623 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7005355078732385\n",
      "newState [135.14792  135.23056  138.08939  135.25275  147.9707    71.504036\n",
      "  97.90251  163.11281 ]\n",
      "info {'type': array([ 71.50403615,  97.90251283, 163.11280334])}\n",
      "\n",
      "iter 163\n",
      "episode 0\n",
      "step 2\n",
      "oldState [135.14792  135.23056  138.08939  135.25275  147.9707    71.504036\n",
      "  97.90251  163.11281 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7702337840299078\n",
      "newState [632.1      632.1      632.1      632.1      632.1       85.00664\n",
      "  49.54382   42.874012]\n",
      "info {'type': array([85.0066399 , 49.54381778, 42.87401108])}\n",
      "\n",
      "iter 164\n",
      "episode 0\n",
      "step 0\n",
      "oldState [596.9056    597.2456    602.8807    597.3567    608.6048     10.489874\n",
      "  13.050293    1.7849479]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.7987702714765638\n",
      "newState [621.1031   621.3023   624.9936   621.366    630.67523    8.194466\n",
      "  13.246318  16.880304]\n",
      "info {'type': array([ 8.19446558, 13.24631794, 16.88030423])}\n",
      "\n",
      "iter 164\n",
      "episode 0\n",
      "step 1\n",
      "oldState [621.1031   621.3023   624.9936   621.366    630.67523    8.194466\n",
      "  13.246318  16.880304]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8898340702100823\n",
      "newState [607.2702   607.58356  612.67224  607.6862   617.3017     8.282765\n",
      "   9.343883  10.975043]\n",
      "info {'type': array([ 8.28276498,  9.34388216, 10.97504348])}\n",
      "\n",
      "iter 164\n",
      "episode 0\n",
      "step 2\n",
      "oldState [607.2702   607.58356  612.67224  607.6862   617.3017     8.282765\n",
      "   9.343883  10.975043]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8868138149383339\n",
      "newState [88.4      88.4      88.4      88.4      88.4       7.745594  7.176407\n",
      "  6.834895]\n",
      "info {'type': array([7.74559423, 7.17640681, 6.83489516])}\n",
      "\n",
      "iter 165\n",
      "episode 0\n",
      "step 0\n",
      "oldState [70.90401   70.74611   67.78407   70.69558   63.56438    9.646631\n",
      "  4.5748014 13.86835  ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.8026792289841769\n",
      "newState [84.649605 84.56051  83.38107  84.53049  83.752815  7.150502 10.046663\n",
      " 16.76197 ]\n",
      "info {'type': array([ 7.15050214, 10.04666313, 16.76197067])}\n",
      "\n",
      "iter 165\n",
      "episode 0\n",
      "step 1\n",
      "oldState [84.649605 84.56051  83.38107  84.53049  83.752815  7.150502 10.046663\n",
      " 16.76197 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.770299572889159\n",
      "newState [79.7001   79.62122  78.45597  79.59499  78.135994 10.249759 13.550874\n",
      " 43.51639 ]\n",
      "info {'type': array([10.24975879, 13.5508742 , 43.51639217])}\n",
      "\n",
      "iter 165\n",
      "episode 0\n",
      "step 2\n",
      "oldState [79.7001   79.62122  78.45597  79.59499  78.135994 10.249759 13.550874\n",
      " 43.51639 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.8138771955046646\n",
      "newState [220.       220.       220.       220.       220.        30.658995\n",
      "  24.893032  54.17347 ]\n",
      "info {'type': array([30.65899391, 24.89303115, 54.17347121])}\n",
      "\n",
      "iter 166\n",
      "episode 0\n",
      "step 0\n",
      "oldState [121.96239  123.82987  147.68576  124.462494 148.6191    13.196286\n",
      "  17.780426  16.578196]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.731795970562632\n",
      "newState [212.4395    212.50586   213.57213   212.52759   214.43777    11.4358635\n",
      "  18.743681   27.334913 ]\n",
      "info {'type': array([11.43586394, 18.74368035, 27.33491383])}\n",
      "\n",
      "iter 166\n",
      "episode 0\n",
      "step 1\n",
      "oldState [212.4395    212.50586   213.57213   212.52759   214.43777    11.4358635\n",
      "  18.743681   27.334913 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.9898308685109035\n",
      "newState [192.12238  192.31998  194.72583  192.38733  205.27696   26.137577\n",
      "  82.39925   71.503494]\n",
      "info {'type': array([26.13757613, 82.39924559, 71.50349326])}\n",
      "\n",
      "iter 166\n",
      "episode 0\n",
      "step 2\n",
      "oldState [192.12238  192.31998  194.72583  192.38733  205.27696   26.137577\n",
      "  82.39925   71.503494]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.856745841024015\n",
      "newState [456.2      456.2      456.2      456.2      456.2       40.274456\n",
      "  47.60826   56.760155]\n",
      "info {'type': array([40.27445482, 47.60825924, 56.76015315])}\n",
      "\n",
      "iter 167\n",
      "episode 0\n",
      "step 0\n",
      "oldState [182.3443   181.42448  163.4229   181.13463  234.19832   59.82241\n",
      "  85.882     55.813496]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8482411697610165\n",
      "newState [376.6893   377.79428  395.72205  378.15616  411.9441    78.22735\n",
      "  61.886433 130.034   ]\n",
      "info {'type': array([ 78.227345  ,  61.88643078, 130.03400283])}\n",
      "\n",
      "iter 167\n",
      "episode 0\n",
      "step 1\n",
      "oldState [376.6893   377.79428  395.72205  378.15616  411.9441    78.22735\n",
      "  61.886433 130.034   ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9237008242388057\n",
      "newState [287.1352   287.25705  291.72827  287.28934  308.93652   50.985306\n",
      "  66.80337  223.20316 ]\n",
      "info {'type': array([ 50.98530476,  66.80336884, 223.20315009])}\n",
      "\n",
      "iter 167\n",
      "episode 0\n",
      "step 2\n",
      "oldState [287.1352   287.25705  291.72827  287.28934  308.93652   50.985306\n",
      "  66.80337  223.20316 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.079730563376177\n",
      "newState [516.4       516.4       516.4       516.4       516.4         8.163467\n",
      "   5.8351316  11.795287 ]\n",
      "info {'type': array([ 8.16346768,  5.83513184, 11.79528735])}\n",
      "\n",
      "iter 168\n",
      "episode 0\n",
      "step 0\n",
      "oldState [413.21106  413.6102   420.3353   413.74036  427.878     29.825026\n",
      "  32.781982  49.62298 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9030938069248329\n",
      "newState [477.2201   477.18384  476.72653  477.17166  477.08618   41.308857\n",
      "  54.615284  52.681507]\n",
      "info {'type': array([41.30885557, 54.61528476, 52.68150588])}\n",
      "\n",
      "iter 168\n",
      "episode 0\n",
      "step 1\n",
      "oldState [477.2201   477.18384  476.72653  477.17166  477.08618   41.308857\n",
      "  54.615284  52.681507]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8729475751005714\n",
      "newState [421.61816  422.03122  428.78677  422.16653  435.33447    7.195511\n",
      "   7.078414   9.410249]\n",
      "info {'type': array([7.19551084, 7.07841391, 9.4102492 ])}\n",
      "\n",
      "iter 168\n",
      "episode 0\n",
      "step 2\n",
      "oldState [421.61816  422.03122  428.78677  422.16653  435.33447    7.195511\n",
      "   7.078414   9.410249]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8954147297569606\n",
      "newState [412.2      412.2      412.2      412.2      412.2       85.74529\n",
      "  60.292377 135.72963 ]\n",
      "info {'type': array([ 85.74528911,  60.29237706, 135.72963689])}\n",
      "\n",
      "iter 169\n",
      "episode 0\n",
      "step 0\n",
      "oldState [192.01451  193.96274  214.70581  194.63678  178.00844   36.132717\n",
      "  43.70706  126.582054]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.945664188757322\n",
      "newState [347.21545  346.65747  335.0844   346.48343  311.9552    31.277657\n",
      "  61.211998  37.902855]\n",
      "info {'type': array([31.2776561 , 61.21199757, 37.90285355])}\n",
      "\n",
      "iter 169\n",
      "episode 0\n",
      "step 1\n",
      "oldState [347.21545  346.65747  335.0844   346.48343  311.9552    31.277657\n",
      "  61.211998  37.902855]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8395568226754555\n",
      "newState [294.70978  295.24457  299.64407  295.43408  281.9043    45.752937\n",
      " 104.93855  131.14943 ]\n",
      "info {'type': array([ 45.75293817, 104.93855403, 131.14942196])}\n",
      "\n",
      "iter 169\n",
      "episode 0\n",
      "step 2\n",
      "oldState [294.70978  295.24457  299.64407  295.43408  281.9043    45.752937\n",
      " 104.93855  131.14943 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8866858638707033\n",
      "newState [566.1     566.1     566.1     566.1     566.1      42.18442  34.97069\n",
      "  90.92688]\n",
      "info {'type': array([42.18442233, 34.97069136, 90.92688082])}\n",
      "\n",
      "iter 170\n",
      "episode 0\n",
      "step 0\n",
      "oldState [472.24078   470.93375   448.9604    470.50885   425.60175     7.4680643\n",
      "   3.575111   19.022127 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9708737272188568\n",
      "newState [557.3022   557.05646  553.285    556.9754   551.03613   10.686058\n",
      "   7.467669  18.518513]\n",
      "info {'type': array([10.68605781,  7.46766912, 18.51851359])}\n",
      "\n",
      "iter 170\n",
      "episode 0\n",
      "step 1\n",
      "oldState [557.3022   557.05646  553.285    556.9754   551.03613   10.686058\n",
      "   7.467669  18.518513]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9330734014215745\n",
      "newState [545.434    545.01013  538.74945  544.86945  536.36743   47.531406\n",
      "  46.26605  139.86356 ]\n",
      "info {'type': array([ 47.53140641,  46.26604832, 139.86356267])}\n",
      "\n",
      "iter 170\n",
      "episode 0\n",
      "step 2\n",
      "oldState [545.434    545.01013  538.74945  544.86945  536.36743   47.531406\n",
      "  46.26605  139.86356 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9470355786629647\n",
      "newState [454.6      454.6      454.6      454.6      454.6       82.09983\n",
      "  64.70097   89.103966]\n",
      "info {'type': array([82.09982821, 64.70097563, 89.10396808])}\n",
      "\n",
      "iter 171\n",
      "episode 0\n",
      "step 0\n",
      "oldState [233.34036  234.88458  259.22232  235.39305  277.83908   52.061653\n",
      "  52.75246   43.59242 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8677066845014892\n",
      "newState [398.58188  398.7817   404.15564  398.84027  420.03897   55.48459\n",
      " 101.083145  79.136215]\n",
      "info {'type': array([ 55.48458975, 101.08314275,  79.13621741])}\n",
      "\n",
      "iter 171\n",
      "episode 0\n",
      "step 1\n",
      "oldState [398.58188  398.7817   404.15564  398.84027  420.03897   55.48459\n",
      " 101.083145  79.136215]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8554964909307465\n",
      "newState [306.79935  308.54242  336.08978  309.11572  357.31488   54.757347\n",
      "  59.088448 100.32448 ]\n",
      "info {'type': array([ 54.75734553,  59.08844588, 100.32448155])}\n",
      "\n",
      "iter 171\n",
      "episode 0\n",
      "step 2\n",
      "oldState [306.79935  308.54242  336.08978  309.11572  357.31488   54.757347\n",
      "  59.088448 100.32448 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9105720506197426\n",
      "newState [587.9      587.9      587.9      587.9      587.9       37.253998\n",
      "  34.592457  80.636795]\n",
      "info {'type': array([37.25399689, 34.59245639, 80.63679536])}\n",
      "\n",
      "iter 172\n",
      "episode 0\n",
      "step 0\n",
      "oldState [379.01096  379.6409   386.38672  379.8592   375.08957   38.19759\n",
      "  60.128147 100.3493  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9089939734235227\n",
      "newState [519.3064  519.56335 520.9978  519.6566  508.41235  64.81151  90.60811\n",
      " 127.76511]\n",
      "info {'type': array([ 64.81151149,  90.60810756, 127.76510975])}\n",
      "\n",
      "iter 172\n",
      "episode 0\n",
      "step 1\n",
      "oldState [519.3064  519.56335 520.9978  519.6566  508.41235  64.81151  90.60811\n",
      " 127.76511]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8975259894858144\n",
      "newState [418.9707   419.66528  426.06384  419.90912  407.19324   36.44139\n",
      "  34.07788   40.509834]\n",
      "info {'type': array([36.44138954, 34.07788032, 40.50983292])}\n",
      "\n",
      "iter 172\n",
      "episode 0\n",
      "step 2\n",
      "oldState [418.9707   419.66528  426.06384  419.90912  407.19324   36.44139\n",
      "  34.07788   40.509834]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8890855283342283\n",
      "newState [504.6      504.6      504.6      504.6      504.6       34.460728\n",
      "  77.61331   64.535904]\n",
      "info {'type': array([34.4607283 , 77.61331344, 64.5359054 ])}\n",
      "\n",
      "iter 173\n",
      "episode 0\n",
      "step 0\n",
      "oldState [290.9813   290.5466   276.3042   290.4288   227.17563   64.09125\n",
      "  34.462917 114.78362 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9477647421748561\n",
      "newState [438.2102   436.72342  415.80188  436.22656  413.68573   18.004229\n",
      "  60.72966   99.35022 ]\n",
      "info {'type': array([18.00422848, 60.72965945, 99.35022011])}\n",
      "\n",
      "iter 173\n",
      "episode 0\n",
      "step 1\n",
      "oldState [438.2102   436.72342  415.80188  436.22656  413.68573   18.004229\n",
      "  60.72966   99.35022 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9067583638856902\n",
      "newState [376.15158  375.4631   361.50168  375.24744  334.99875   42.594604\n",
      "  72.69792  136.13284 ]\n",
      "info {'type': array([ 42.59460274,  72.69792145, 136.13284305])}\n",
      "\n",
      "iter 173\n",
      "episode 0\n",
      "step 2\n",
      "oldState [376.15158  375.4631   361.50168  375.24744  334.99875   42.594604\n",
      "  72.69792  136.13284 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9171704812971566\n",
      "newState [661.4      661.4      661.4      661.4      661.4       37.498142\n",
      "  39.021225  32.164284]\n",
      "info {'type': array([37.49814064, 39.02122375, 32.16428335])}\n",
      "\n",
      "iter 174\n",
      "episode 0\n",
      "step 0\n",
      "oldState [596.9736    597.4719    602.7728    597.6444    593.3797      6.2124577\n",
      "  12.030902   17.200745 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8973776816452266\n",
      "newState [648.80914   648.9253    650.1333    648.9656    647.7745      8.822592\n",
      "   7.6110125   2.9511516]\n",
      "info {'type': array([8.82259218, 7.61101266, 2.95115171])}\n",
      "\n",
      "iter 174\n",
      "episode 0\n",
      "step 1\n",
      "oldState [648.80914   648.9253    650.1333    648.9656    647.7745      8.822592\n",
      "   7.6110125   2.9511516]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.839625164628816\n",
      "newState [641.0664   641.21155  643.52435  641.2593   645.43005   19.934557\n",
      "  40.915787  65.71326 ]\n",
      "info {'type': array([19.93455724, 40.91578827, 65.71325423])}\n",
      "\n",
      "iter 174\n",
      "episode 0\n",
      "step 2\n",
      "oldState [641.0664   641.21155  643.52435  641.2593   645.43005   19.934557\n",
      "  40.915787  65.71326 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9058713600848793\n",
      "newState [215.3      215.3      215.3      215.3      215.3       14.84476\n",
      "  14.389273  48.144257]\n",
      "info {'type': array([14.84475973, 14.3892724 , 48.14425741])}\n",
      "\n",
      "iter 175\n",
      "episode 0\n",
      "step 0\n",
      "oldState [174.97137  174.91675  175.2444   174.8949   181.83112   30.050158\n",
      "  33.209988  58.845104]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.77453741006581\n",
      "newState [197.71176  197.66309  196.75635  197.64743  195.57999   39.65833\n",
      "  31.506659  29.179987]\n",
      "info {'type': array([39.65832726, 31.50665847, 29.17998682])}\n",
      "\n",
      "iter 175\n",
      "episode 0\n",
      "step 1\n",
      "oldState [197.71176  197.66309  196.75635  197.64743  195.57999   39.65833\n",
      "  31.506659  29.179987]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.738595751695283\n",
      "newState [182.06883   181.9654    181.27603   181.92828   185.78136     6.3918304\n",
      "   7.0348005   4.9815793]\n",
      "info {'type': array([6.39183032, 7.03480037, 4.98157922])}\n",
      "\n",
      "iter 175\n",
      "episode 0\n",
      "step 2\n",
      "oldState [182.06883   181.9654    181.27603   181.92828   185.78136     6.3918304\n",
      "   7.0348005   4.9815793]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8580996022356715\n",
      "newState [333.7     333.7     333.7     333.7     333.7      50.06396  44.31238\n",
      " 122.26987]\n",
      "info {'type': array([ 50.06396013,  44.31238224, 122.2698686 ])}\n",
      "\n",
      "iter 176\n",
      "episode 0\n",
      "step 0\n",
      "oldState [311.27054   311.52548   315.8633    311.60828   320.8342      6.5959435\n",
      "   7.389706    9.841022 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.894782891976198\n",
      "newState [325.22018   325.2286    325.42133   325.2312    325.90268     4.304062\n",
      "   6.521314    5.3385315]\n",
      "info {'type': array([4.30406204, 6.52131415, 5.33853173])}\n",
      "\n",
      "iter 176\n",
      "episode 0\n",
      "step 1\n",
      "oldState [325.22018   325.2286    325.42133   325.2312    325.90268     4.304062\n",
      "   6.521314    5.3385315]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8609436881554099\n",
      "newState [319.0071    319.0945    320.49173   319.1232    321.67117     6.915069\n",
      "   9.548352    1.0468866]\n",
      "info {'type': array([6.91506917, 9.54835213, 1.04688655])}\n",
      "\n",
      "iter 176\n",
      "episode 0\n",
      "step 2\n",
      "oldState [319.0071    319.0945    320.49173   319.1232    321.67117     6.915069\n",
      "   9.548352    1.0468866]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.7900336034489578\n",
      "newState [216.7      216.7      216.7      216.7      216.7       39.737335\n",
      "  32.925243  77.16384 ]\n",
      "info {'type': array([39.73733663, 32.92524487, 77.16383988])}\n",
      "\n",
      "iter 177\n",
      "episode 0\n",
      "step 0\n",
      "oldState [144.4714   143.73683  135.21114  143.48546  151.95096    8.625412\n",
      "  14.075221  25.115183]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.774920174903543\n",
      "newState [209.80067   209.82306   209.85056   209.8314    208.28561     9.918766\n",
      "  12.4025755  14.314523 ]\n",
      "info {'type': array([ 9.91876617, 12.40257536, 14.31452237])}\n",
      "\n",
      "iter 177\n",
      "episode 0\n",
      "step 1\n",
      "oldState [209.80067   209.82306   209.85056   209.8314    208.28561     9.918766\n",
      "  12.4025755  14.314523 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.9592798361036833\n",
      "newState [196.45488  196.54234  197.61224  196.57208  203.4851   133.57787\n",
      "  79.718735 153.70766 ]\n",
      "info {'type': array([133.57786589,  79.71873554, 153.70766146])}\n",
      "\n",
      "iter 177\n",
      "episode 0\n",
      "step 2\n",
      "oldState [196.45488  196.54234  197.61224  196.57208  203.4851   133.57787\n",
      "  79.718735 153.70766 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.779373124720645\n",
      "newState [476.7      476.7      476.7      476.7      476.7       31.17636\n",
      "  54.586113  40.58431 ]\n",
      "info {'type': array([31.17635877, 54.58611398, 40.58430769])}\n",
      "\n",
      "iter 178\n",
      "episode 0\n",
      "step 0\n",
      "oldState [410.1401   409.11963  391.70422  408.78876  371.8847     5.629762\n",
      "   7.84565   17.00879 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.927124394144164\n",
      "newState [466.6344    466.6127    465.87036   466.6069    463.2288      7.9253364\n",
      "   7.194479    1.       ]\n",
      "info {'type': array([7.92533653, 7.19447895, 1.        ])}\n",
      "\n",
      "iter 178\n",
      "episode 0\n",
      "step 1\n",
      "oldState [466.6344    466.6127    465.87036   466.6069    463.2288      7.9253364\n",
      "   7.194479    1.       ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8144250289165897\n",
      "newState [459.86447  459.8984   460.655    459.9089   462.4296    31.474958\n",
      "  23.769869 114.34436 ]\n",
      "info {'type': array([ 31.47495905,  23.7698681 , 114.34436214])}\n",
      "\n",
      "iter 178\n",
      "episode 0\n",
      "step 2\n",
      "oldState [459.86447  459.8984   460.655    459.9089   462.4296    31.474958\n",
      "  23.769869 114.34436 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9712922478508228\n",
      "newState [387.2      387.2      387.2      387.2      387.2       57.397236\n",
      "  63.437225  61.13236 ]\n",
      "info {'type': array([57.39723443, 63.43722491, 61.13235772])}\n",
      "\n",
      "iter 179\n",
      "episode 0\n",
      "step 0\n",
      "oldState [211.33916  210.31998  192.73024  209.99055  227.1239    53.94307\n",
      "  13.269053  91.94805 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9721256705010812\n",
      "newState [341.00662  339.22092  314.50708  338.62274  314.37848   20.853426\n",
      "  67.95867  120.57998 ]\n",
      "info {'type': array([ 20.85342644,  67.95867244, 120.57998197])}\n",
      "\n",
      "iter 179\n",
      "episode 0\n",
      "step 1\n",
      "oldState [341.00662  339.22092  314.50708  338.62274  314.37848   20.853426\n",
      "  67.95867  120.57998 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.0228451911880154\n",
      "newState [269.15927  268.15555  249.20786  267.8363   273.99042   50.799114\n",
      "  50.24758   59.139477]\n",
      "info {'type': array([50.79911266, 50.24758086, 59.13947747])}\n",
      "\n",
      "iter 179\n",
      "episode 0\n",
      "step 2\n",
      "oldState [269.15927  268.15555  249.20786  267.8363   273.99042   50.799114\n",
      "  50.24758   59.139477]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8880247898213735\n",
      "newState [343.4       343.4       343.4       343.4       343.4         6.9706616\n",
      "   5.670271    1.       ]\n",
      "info {'type': array([6.97066142, 5.67027089, 1.        ])}\n",
      "\n",
      "iter 180\n",
      "episode 0\n",
      "step 0\n",
      "oldState [195.4145   194.28355  175.70605  193.91472  199.39061   29.085903\n",
      "  47.19737   89.94591 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.0214345676364887\n",
      "newState [287.27362  287.38672  286.54065  287.43274  313.26776   44.505474\n",
      "  41.59888   91.696526]\n",
      "info {'type': array([44.50547474, 41.59887996, 91.69652405])}\n",
      "\n",
      "iter 180\n",
      "episode 0\n",
      "step 1\n",
      "oldState [287.27362  287.38672  286.54065  287.43274  313.26776   44.505474\n",
      "  41.59888   91.696526]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9271388944724429\n",
      "newState [228.74069  228.35397  219.62927  228.23589  240.6359    35.116917\n",
      "  17.87208   52.06892 ]\n",
      "info {'type': array([35.11691598, 17.87207963, 52.06891982])}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 180\n",
      "episode 0\n",
      "step 2\n",
      "oldState [228.74069  228.35397  219.62927  228.23589  240.6359    35.116917\n",
      "  17.87208   52.06892 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9399715713804938\n",
      "newState [469.5      469.5      469.5      469.5      469.5       33.133133\n",
      "  48.93146   74.913124]\n",
      "info {'type': array([33.13313439, 48.93146102, 74.91312507])}\n",
      "\n",
      "iter 181\n",
      "episode 0\n",
      "step 0\n",
      "oldState [310.72058  311.82     329.34534  312.1814   343.79437   25.460798\n",
      "  44.391293  15.7513  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8132498648373071\n",
      "newState [433.21774  434.05692  447.25427  434.33304  456.99603   33.008034\n",
      "  49.12839   50.76525 ]\n",
      "info {'type': array([33.00803419, 49.12839024, 50.76525088])}\n",
      "\n",
      "iter 181\n",
      "episode 0\n",
      "step 1\n",
      "oldState [433.21774  434.05692  447.25427  434.33304  456.99603   33.008034\n",
      "  49.12839   50.76525 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8761222320824131\n",
      "newState [383.78635  385.1008   405.1557   385.53543  416.7682    58.96327\n",
      "  59.309258  92.1082  ]\n",
      "info {'type': array([58.96326711, 59.30925646, 92.10819919])}\n",
      "\n",
      "iter 181\n",
      "episode 0\n",
      "step 2\n",
      "oldState [383.78635  385.1008   405.1557   385.53543  416.7682    58.96327\n",
      "  59.309258  92.1082  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9049882648285952\n",
      "newState [663.1     663.1     663.1     663.1     663.1      85.51604 104.47578\n",
      " 153.50558]\n",
      "info {'type': array([ 85.5160371 , 104.47577361, 153.50557846])}\n",
      "\n",
      "iter 182\n",
      "episode 0\n",
      "step 0\n",
      "oldState [550.4044   550.5045   555.76337  550.52563  579.40295   55.929287\n",
      "  36.781372  63.06222 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9116947660588421\n",
      "newState [610.0562   609.3755   601.8238   609.14136  613.1323    37.405754\n",
      "  57.180626  36.73604 ]\n",
      "info {'type': array([37.40575486, 57.18062519, 36.73603885])}\n",
      "\n",
      "iter 182\n",
      "episode 0\n",
      "step 1\n",
      "oldState [610.0562   609.3755   601.8238   609.14136  613.1323    37.405754\n",
      "  57.180626  36.73604 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8463641916457297\n",
      "newState [558.012     558.1324    563.2035    558.1618    584.004       8.134197\n",
      "   6.5746107   5.8029385]\n",
      "info {'type': array([8.13419756, 6.57461051, 5.80293862])}\n",
      "\n",
      "iter 182\n",
      "episode 0\n",
      "step 2\n",
      "oldState [558.012     558.1324    563.2035    558.1618    584.004       8.134197\n",
      "   6.5746107   5.8029385]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8747504439489835\n",
      "newState [258.       258.       258.       258.       258.        15.861988\n",
      "  19.140491  12.048944]\n",
      "info {'type': array([15.86198836, 19.14049084, 12.04894493])}\n",
      "\n",
      "iter 183\n",
      "episode 0\n",
      "step 0\n",
      "oldState [207.15184  207.39233  209.73433  207.47623  223.89322   11.518289\n",
      "  21.274712  28.710829]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7545124756672164\n",
      "newState [248.68391  248.77213  249.74695  248.80238  248.37753   20.099638\n",
      "  27.451147  43.479935]\n",
      "info {'type': array([20.09963852, 27.45114714, 43.47993493])}\n",
      "\n",
      "iter 183\n",
      "episode 0\n",
      "step 1\n",
      "oldState [248.68391  248.77213  249.74695  248.80238  248.37753   20.099638\n",
      "  27.451147  43.479935]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.99652338647783\n",
      "newState [217.03235  217.19397  218.62022  217.2508   233.80624    5.663736\n",
      "   9.383028  12.512944]\n",
      "info {'type': array([ 5.66373576,  9.38302833, 12.51294419])}\n",
      "\n",
      "iter 183\n",
      "episode 0\n",
      "step 2\n",
      "oldState [217.03235  217.19397  218.62022  217.2508   233.80624    5.663736\n",
      "   9.383028  12.512944]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.892921536045622\n",
      "newState [298.7      298.7      298.7      298.7      298.7       38.285866\n",
      "  71.02421  125.677246]\n",
      "info {'type': array([ 38.28586746,  71.02421158, 125.67724629])}\n",
      "\n",
      "iter 184\n",
      "episode 0\n",
      "step 0\n",
      "oldState [141.38643 140.62003 175.71408 140.35957 178.76685  52.69368  76.86482\n",
      " 120.95825]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.766180024073823\n",
      "newState [261.82196 261.9516  262.87976 261.99756 258.16504  64.40043  48.75971\n",
      "  87.80043]\n",
      "info {'type': array([64.40043163, 48.75970896, 87.80043305])}\n",
      "\n",
      "iter 184\n",
      "episode 0\n",
      "step 1\n",
      "oldState [261.82196 261.9516  262.87976 261.99756 258.16504  64.40043  48.75971\n",
      "  87.80043]\n",
      "action [[3.2850e-01 3.5372e-01 2.5356e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 1.8536e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.1487089167145585\n",
      "newState [193.7351   193.16618  230.25131  192.97418  228.7322    44.73864\n",
      "  42.23047   63.062866]\n",
      "info {'type': array([44.73863819, 42.23046852, 63.06286502])}\n",
      "\n",
      "iter 184\n",
      "episode 0\n",
      "step 2\n",
      "oldState [193.7351   193.16618  230.25131  192.97418  228.7322    44.73864\n",
      "  42.23047   63.062866]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9027420274320974\n",
      "newState [421.9      421.9      421.9      421.9      421.9       20.367168\n",
      "  14.929051  28.97692 ]\n",
      "info {'type': array([20.36716785, 14.92905175, 28.97691864])}\n",
      "\n",
      "iter 185\n",
      "episode 0\n",
      "step 0\n",
      "oldState [250.89981  250.27034  238.95018  250.06862  223.55609   42.704178\n",
      "  53.84729   65.30015 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8880075955028713\n",
      "newState [363.34845  363.6087   367.60477  363.6948   370.1588    48.31242\n",
      "  51.394344  89.22318 ]\n",
      "info {'type': array([48.31241815, 51.39434401, 89.22318065])}\n",
      "\n",
      "iter 185\n",
      "episode 0\n",
      "step 1\n",
      "oldState [363.34845  363.6087   367.60477  363.6948   370.1588    48.31242\n",
      "  51.394344  89.22318 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9120271109175915\n",
      "newState [298.77698  298.82745  299.47598  298.84497  299.4781    30.889675\n",
      "  28.536442  95.86964 ]\n",
      "info {'type': array([30.88967461, 28.5364413 , 95.86963694])}\n",
      "\n",
      "iter 185\n",
      "episode 0\n",
      "step 2\n",
      "oldState [298.77698  298.82745  299.47598  298.84497  299.4781    30.889675\n",
      "  28.536442  95.86964 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.953027383572906\n",
      "newState [532.7      532.7      532.7      532.7      532.7       29.215311\n",
      "  29.297398  90.52053 ]\n",
      "info {'type': array([29.21531171, 29.29739753, 90.52053158])}\n",
      "\n",
      "iter 186\n",
      "episode 0\n",
      "step 0\n",
      "oldState [432.37216  432.31342  431.44778  432.29428  431.36407   15.893612\n",
      "  22.797962  31.012772]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.89495551416555\n",
      "newState [507.85208  507.9839   509.5586   508.029    508.13034   10.531451\n",
      "  20.25539   27.191671]\n",
      "info {'type': array([10.53145081, 20.25538998, 27.19167051])}\n",
      "\n",
      "iter 186\n",
      "episode 0\n",
      "step 1\n",
      "oldState [507.85208  507.9839   509.5586   508.029    508.13034   10.531451\n",
      "  20.25539   27.191671]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8927693228400359\n",
      "newState [487.03812  487.3812   491.31903  487.49902  486.58948   48.773994\n",
      "  41.24159   69.70564 ]\n",
      "info {'type': array([48.77399386, 41.24158935, 69.70564225])}\n",
      "\n",
      "iter 186\n",
      "episode 0\n",
      "step 2\n",
      "oldState [487.03812  487.3812   491.31903  487.49902  486.58948   48.773994\n",
      "  41.24159   69.70564 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9105690088024604\n",
      "newState [385.8      385.8      385.8      385.8      385.8       53.84964\n",
      "  53.398853  45.083656]\n",
      "info {'type': array([53.84964114, 53.39885311, 45.08365742])}\n",
      "\n",
      "iter 187\n",
      "episode 0\n",
      "step 0\n",
      "oldState [193.79672   191.22903   207.99814   190.37247   218.02953    88.03877\n",
      "   3.5990686 150.67554  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.1131492380817034\n",
      "newState [320.1465   316.55975  266.9026   315.3582   335.34116   61.643486\n",
      " 101.91466  126.1111  ]\n",
      "info {'type': array([ 61.64348661, 101.91465488, 126.11109992])}\n",
      "\n",
      "iter 187\n",
      "episode 0\n",
      "step 1\n",
      "oldState [320.1465   316.55975  266.9026   315.3582   335.34116   61.643486\n",
      " 101.91466  126.1111  ]\n",
      "action [[3.2850e-01 3.5372e-01 2.5356e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 1.8536e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.999856575598038\n",
      "newState [215.04785  212.4123   227.84535  211.5342   235.4273    17.000122\n",
      "  19.378986  21.95446 ]\n",
      "info {'type': array([17.00012192, 19.3789859 , 21.95446021])}\n",
      "\n",
      "iter 187\n",
      "episode 0\n",
      "step 2\n",
      "oldState [215.04785  212.4123   227.84535  211.5342   235.4273    17.000122\n",
      "  19.378986  21.95446 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8844804183770909\n",
      "newState [369.3       369.3       369.3       369.3       369.3         9.954162\n",
      "   6.2021093  11.368587 ]\n",
      "info {'type': array([ 9.95416132,  6.20210947, 11.36858663])}\n",
      "\n",
      "iter 188\n",
      "episode 0\n",
      "step 0\n",
      "oldState [221.58765  222.1635   234.41843  222.34285  299.2536    68.656334\n",
      "  57.28457   84.397415]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.9788072159692502\n",
      "newState [295.9367   295.47922  291.02106  295.32     340.99933   51.262974\n",
      "  73.26143   38.579063]\n",
      "info {'type': array([51.26297382, 73.26142531, 38.57906465])}\n",
      "\n",
      "iter 188\n",
      "episode 0\n",
      "step 1\n",
      "oldState [295.9367   295.47922  291.02106  295.32     340.99933   51.262974\n",
      "  73.26143   38.579063]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8372051517575029\n",
      "newState [230.1182    230.68735   243.23878   230.86314   310.3971      4.4276123\n",
      "   7.0010343  14.069587 ]\n",
      "info {'type': array([ 4.42761231,  7.00103439, 14.06958665])}\n",
      "\n",
      "iter 188\n",
      "episode 0\n",
      "step 2\n",
      "oldState [230.1182    230.68735   243.23878   230.86314   310.3971      4.4276123\n",
      "   7.0010343  14.069587 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9221084978169882\n",
      "newState [405.9      405.9      405.9      405.9      405.9       35.008423\n",
      "  64.534256  63.143757]\n",
      "info {'type': array([35.00842191, 64.53425388, 63.14375803])}\n",
      "\n",
      "iter 189\n",
      "episode 0\n",
      "step 0\n",
      "oldState [210.23167  210.64781  214.98535  210.79263  282.64243   53.765198\n",
      "  93.29372   57.67846 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8417017944063266\n",
      "newState [323.89423  325.4069   348.25244  325.90778  360.16705   58.072224\n",
      "  58.741592 165.6324  ]\n",
      "info {'type': array([ 58.07222357,  58.74159275, 165.63239456])}\n",
      "\n",
      "iter 189\n",
      "episode 0\n",
      "step 1\n",
      "oldState [323.89423  325.4069   348.25244  325.90778  360.16705   58.072224\n",
      "  58.741592 165.6324  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -1.0546479772544828\n",
      "newState [234.4682   235.03581  240.84393  235.23337  304.69135   22.718405\n",
      "  18.92584   27.826614]\n",
      "info {'type': array([22.71840552, 18.92584058, 27.82661353])}\n",
      "\n",
      "iter 189\n",
      "episode 0\n",
      "step 2\n",
      "oldState [234.4682   235.03581  240.84393  235.23337  304.69135   22.718405\n",
      "  18.92584   27.826614]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9022830997645095\n",
      "newState [483.8      483.8      483.8      483.8      483.8       32.634827\n",
      "  52.41685   70.07109 ]\n",
      "info {'type': array([32.63482679, 52.41685003, 70.07109138])}\n",
      "\n",
      "iter 190\n",
      "episode 0\n",
      "step 0\n",
      "oldState [267.09686 269.4696  306.42197 270.2519  332.0582   67.67647 102.43869\n",
      "  71.08226]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8509847228057704\n",
      "newState [389.1291   390.495    411.90848  390.94476  427.4448    67.41368\n",
      "  95.658356  70.84475 ]\n",
      "info {'type': array([67.41367724, 95.65835372, 70.84474689])}\n",
      "\n",
      "iter 190\n",
      "episode 0\n",
      "step 1\n",
      "oldState [389.1291   390.495    411.90848  390.94476  427.4448    67.41368\n",
      "  95.658356  70.84475 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8559192199420735\n",
      "newState [298.3085   300.79913  340.28247  301.61783  371.28113   20.258537\n",
      "  24.00422   49.519707]\n",
      "info {'type': array([20.25853796, 24.0042181 , 49.51970658])}\n",
      "\n",
      "iter 190\n",
      "episode 0\n",
      "step 2\n",
      "oldState [298.3085   300.79913  340.28247  301.61783  371.28113   20.258537\n",
      "  24.00422   49.519707]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9234416594760434\n",
      "newState [504.2      504.2      504.2      504.2      504.2       25.789259\n",
      "  24.07652   70.3113  ]\n",
      "info {'type': array([25.7892586 , 24.0765205 , 70.31130032])}\n",
      "\n",
      "iter 191\n",
      "episode 0\n",
      "step 0\n",
      "oldState [201.26787 201.37126 203.71475 201.40396 209.95772  69.09545  87.1684\n",
      " 117.49688]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8949465840395786\n",
      "newState [406.7078   407.01263  411.1748   407.1153   411.109     75.718445\n",
      "  76.953064  42.86057 ]\n",
      "info {'type': array([75.71844225, 76.95306163, 42.86056877])}\n",
      "\n",
      "iter 191\n",
      "episode 0\n",
      "step 1\n",
      "oldState [406.7078   407.01263  411.1748   407.1153   411.109     75.718445\n",
      "  76.953064  42.86057 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8484075256640932\n",
      "newState [329.84833 330.65665 346.78592 330.91183 377.1034   84.30181  95.41798\n",
      " 211.03032]\n",
      "info {'type': array([ 84.30180978,  95.41797434, 211.03032634])}\n",
      "\n",
      "iter 191\n",
      "episode 0\n",
      "step 2\n",
      "oldState [329.84833 330.65665 346.78592 330.91183 377.1034   84.30181  95.41798\n",
      " 211.03032]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9279240420707758\n",
      "newState [625.8      625.8      625.8      625.8      625.8        6.914862\n",
      "   7.725626   8.847546]\n",
      "info {'type': array([6.91486208, 7.72562602, 8.84754516])}\n",
      "\n",
      "iter 192\n",
      "episode 0\n",
      "step 0\n",
      "oldState [395.53952 396.27658 406.28293 396.52502 405.76456  91.13546 113.52861\n",
      " 206.13072]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9149449841069092\n",
      "newState [486.1977   486.03745  480.7442   485.9944   462.52045   66.19723\n",
      "  89.615776  66.893295]\n",
      "info {'type': array([66.19722747, 89.61577329, 66.89329309])}\n",
      "\n",
      "iter 192\n",
      "episode 0\n",
      "step 1\n",
      "oldState [486.1977   486.03745  480.7442   485.9944   462.52045   66.19723\n",
      "  89.615776  66.893295]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8571765392094859\n",
      "newState [399.99396   400.80548   411.58118   401.0797    409.48846     5.382935\n",
      "   2.9284296   4.6989017]\n",
      "info {'type': array([5.38293488, 2.9284297 , 4.69890177])}\n",
      "\n",
      "iter 192\n",
      "episode 0\n",
      "step 2\n",
      "oldState [399.99396   400.80548   411.58118   401.0797    409.48846     5.382935\n",
      "   2.9284296   4.6989017]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9085058190415924\n",
      "newState [361.2      361.2      361.2      361.2      361.2       15.225042\n",
      "  30.047523  30.504225]\n",
      "info {'type': array([15.2250419 , 30.04752272, 30.50422506])}\n",
      "\n",
      "iter 193\n",
      "episode 0\n",
      "step 0\n",
      "oldState [216.21686  216.145    211.42627  216.13322  245.14764   53.08944\n",
      "  87.212166 119.767044]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.9827385613667079\n",
      "newState [268.41806  269.1056   276.82556  269.34222  321.0582    72.977165\n",
      "  61.269924 181.84932 ]\n",
      "info {'type': array([ 72.97716486,  61.26992551, 181.8493255 ])}\n",
      "\n",
      "iter 193\n",
      "episode 0\n",
      "step 1\n",
      "oldState [268.41806  269.1056   276.82556  269.34222  321.0582    72.977165\n",
      "  61.269924 181.84932 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.80612071900549\n",
      "newState [226.39203   226.50049   224.58325   226.5481    260.14792     8.093409\n",
      "   5.7520013  18.94009  ]\n",
      "info {'type': array([ 8.09340883,  5.75200113, 18.94009038])}\n",
      "\n",
      "iter 193\n",
      "episode 0\n",
      "step 2\n",
      "oldState [226.39203   226.50049   224.58325   226.5481    260.14792     8.093409\n",
      "   5.7520013  18.94009  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9497173528219441\n",
      "newState [273.2      273.2      273.2      273.2      273.2        6.601778\n",
      "  11.453204  16.405418]\n",
      "info {'type': array([ 6.60177781, 11.45320386, 16.40541778])}\n",
      "\n",
      "iter 194\n",
      "episode 0\n",
      "step 0\n",
      "oldState [186.16885  186.04834  185.06937  186.00569  203.17389   34.82256\n",
      "  53.696167  75.69512 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.7583284929447496\n",
      "newState [248.57178  248.71985  250.31271  248.77075  247.82968   39.66742\n",
      "  27.729004  29.691042]\n",
      "info {'type': array([39.66741925, 27.72900331, 29.691042  ])}\n",
      "\n",
      "iter 194\n",
      "episode 0\n",
      "step 1\n",
      "oldState [248.57178  248.71985  250.31271  248.77075  247.82968   39.66742\n",
      "  27.729004  29.691042]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.9445682896254431\n",
      "newState [213.52156  213.39699  213.42375  213.3494   237.86195   15.273366\n",
      "  22.358013  43.79532 ]\n",
      "info {'type': array([15.27336566, 22.35801393, 43.79531806])}\n",
      "\n",
      "iter 194\n",
      "episode 0\n",
      "step 2\n",
      "oldState [213.52156  213.39699  213.42375  213.3494   237.86195   15.273366\n",
      "  22.358013  43.79532 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9202313052644221\n",
      "newState [351.8      351.8      351.8      351.8      351.8       37.66859\n",
      "  53.746574  35.644295]\n",
      "info {'type': array([37.6685923 , 53.74657482, 35.64429382])}\n",
      "\n",
      "iter 195\n",
      "episode 0\n",
      "step 0\n",
      "oldState [312.77167  312.2895   304.70657  312.13104  299.2538    10.779009\n",
      "  11.067336  23.435661]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9248420864655307\n",
      "newState [336.7976    336.701     335.0575    336.66965   333.23694     7.3338127\n",
      "   9.361227   20.569546 ]\n",
      "info {'type': array([ 7.33381287,  9.36122721, 20.56954543])}\n",
      "\n",
      "iter 195\n",
      "episode 0\n",
      "step 1\n",
      "oldState [336.7976    336.701     335.0575    336.66965   333.23694     7.3338127\n",
      "   9.361227   20.569546 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9278200629041428\n",
      "newState [324.52158   324.38077   321.64417   324.33624   316.9453     11.904407\n",
      "   4.9091125  22.337868 ]\n",
      "info {'type': array([11.90440627,  4.90911269, 22.33786831])}\n",
      "\n",
      "iter 195\n",
      "episode 0\n",
      "step 2\n",
      "oldState [324.52158   324.38077   321.64417   324.33624   316.9453     11.904407\n",
      "   4.9091125  22.337868 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9609373068316432\n",
      "newState [236.1      236.1      236.1      236.1      236.1       33.18761\n",
      "  65.25444   52.266026]\n",
      "info {'type': array([33.18760946, 65.2544376 , 52.26602736])}\n",
      "\n",
      "iter 196\n",
      "episode 0\n",
      "step 0\n",
      "oldState [123.83489  124.40518  133.73372  124.59178  161.8681    12.941438\n",
      "  14.481087  45.23311 ]\n",
      "action [[0.13917 0.14981 0.25356 0.15351 0.0005 ]\n",
      " [0.23113 0.21565 0.0005  0.21047 0.0005 ]\n",
      " [0.09738 0.10151 0.18536 0.10281 0.33458]]\n",
      "reward -1.8111487531418515\n",
      "newState [226.54713  226.4468   224.42693  226.41512  220.95221   15.168373\n",
      "  27.646135  41.162754]\n",
      "info {'type': array([15.16837335, 27.64613529, 41.1627525 ])}\n",
      "\n",
      "iter 196\n",
      "episode 0\n",
      "step 1\n",
      "oldState [226.54713  226.4468   224.42693  226.41512  220.95221   15.168373\n",
      "  27.646135  41.162754]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 3.3458e-01]]\n",
      "reward -0.9938646457919367\n",
      "newState [196.94344 197.07112 197.28375 197.11899 207.15857  63.98094  71.12779\n",
      "  57.12702]\n",
      "info {'type': array([63.98094216, 71.12779577, 57.127021  ])}\n",
      "\n",
      "iter 196\n",
      "episode 0\n",
      "step 2\n",
      "oldState [196.94344 197.07112 197.28375 197.11899 207.15857  63.98094  71.12779\n",
      "  57.12702]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8646295846296232\n",
      "newState [543.5      543.5      543.5      543.5      543.5      106.001465\n",
      "  92.573204 112.9911  ]\n",
      "info {'type': array([106.00146476,  92.57320351, 112.99109289])}\n",
      "\n",
      "iter 197\n",
      "episode 0\n",
      "step 0\n",
      "oldState [319.36526  317.4469   284.81995  316.82486  248.47429   48.984474\n",
      "  57.27402   80.303246]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.8978912594115115\n",
      "newState [477.5493   477.6283   478.86203  477.65454  479.8772    48.26404\n",
      "  63.238087 157.48856 ]\n",
      "info {'type': array([ 48.2640423 ,  63.23808766, 157.48855519])}\n",
      "\n",
      "iter 197\n",
      "episode 0\n",
      "step 1\n",
      "oldState [477.5493   477.6283   478.86203  477.65454  479.8772    48.26404\n",
      "  63.238087 157.48856 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9362479605458074\n",
      "newState [390.7644   390.39264  380.91974  390.2829   355.15036   61.764336\n",
      "  36.61974  134.69456 ]\n",
      "info {'type': array([ 61.7643359 ,  36.61973929, 134.69455809])}\n",
      "\n",
      "iter 197\n",
      "episode 0\n",
      "step 2\n",
      "oldState [390.7644   390.39264  380.91974  390.2829   355.15036   61.764336\n",
      "  36.61974  134.69456 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.954204482821824\n",
      "newState [373.6       373.6       373.6       373.6       373.6         7.4688554\n",
      "   6.943538   17.029524 ]\n",
      "info {'type': array([ 7.46885519,  6.94353825, 17.02952425])}\n",
      "\n",
      "iter 198\n",
      "episode 0\n",
      "step 0\n",
      "oldState [259.65588  260.25266  264.58865  260.46594  241.2975    13.486623\n",
      "  11.047715  27.249176]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9335675258748992\n",
      "newState [356.83908  356.63547  353.55954  356.56815  352.01675   13.740166\n",
      "  18.264805  28.609154]\n",
      "info {'type': array([13.74016611, 18.26480571, 28.60915302])}\n",
      "\n",
      "iter 198\n",
      "episode 0\n",
      "step 1\n",
      "oldState [356.83908  356.63547  353.55954  356.56815  352.01675   13.740166\n",
      "  18.264805  28.609154]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9048606681705091\n",
      "newState [335.73297  335.57214  332.7683   335.5203   329.35318   32.45851\n",
      "  72.69114  111.168365]\n",
      "info {'type': array([ 32.458512  ,  72.69113803, 111.16836586])}\n",
      "\n",
      "iter 198\n",
      "episode 0\n",
      "step 2\n",
      "oldState [335.73297  335.57214  332.7683   335.5203   329.35318   32.45851\n",
      "  72.69114  111.168365]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.902054100729266\n",
      "newState [417.8     417.8     417.8     417.8     417.8      28.0652   58.87434\n",
      "  65.21824]\n",
      "info {'type': array([28.06520017, 58.87434041, 65.21824083])}\n",
      "\n",
      "iter 199\n",
      "episode 0\n",
      "step 0\n",
      "oldState [242.50084  241.37318  225.6594   240.99626  225.2848    37.554443\n",
      "  29.651537  87.394646]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9440694833816652\n",
      "newState [369.0788   368.35623  356.96252  368.11887  348.58304   51.693523\n",
      "  53.992424  77.7959  ]\n",
      "info {'type': array([51.69352197, 53.99242291, 77.79589665])}\n",
      "\n",
      "iter 199\n",
      "episode 0\n",
      "step 1\n",
      "oldState [369.0788   368.35623  356.96252  368.11887  348.58304   51.693523\n",
      "  53.992424  77.7959  ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9001232412462973\n",
      "newState [304.61185  303.80383  291.78998  303.5362   286.9454    53.265434\n",
      "  48.72865   77.82725 ]\n",
      "info {'type': array([53.26543398, 48.72864788, 77.82724691])}\n",
      "\n",
      "iter 199\n",
      "episode 0\n",
      "step 2\n",
      "oldState [304.61185  303.80383  291.78998  303.5362   286.9454    53.265434\n",
      "  48.72865   77.82725 ]\n",
      "action [[3.2850e-01 3.5372e-01 6.0246e-01 3.6250e-01 5.0000e-04]\n",
      " [5.4705e-01 5.1015e-01 5.0000e-04 4.9778e-01 5.0000e-04]\n",
      " [2.3072e-01 2.4067e-01 4.3707e-01 2.4381e-01 7.9162e-01]]\n",
      "reward -0.9069737602983101\n",
      "newState [539.6      539.6      539.6      539.6      539.6       49.757053\n",
      "  35.54494  107.010925]\n",
      "info {'type': array([ 49.75705264,  35.54494175, 107.01092572])}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Parameter value must be nonnegative.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#                       'Prop': lambda traj : or_suite.utils.delta_PROP(traj, CONFIG), \\\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#                       'Exante Envy': lambda traj : or_suite.utils.delta_EXANTE_ENVY(traj, CONFIG)}\u001b[39;00m\n\u001b[1;32m     31\u001b[0m fig_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresource\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_radar_plot\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 32\u001b[0m \u001b[43mor_suite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplots\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_radar_plots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_list_radar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgo_list_radar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43mfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43madditional_metric\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/GitHub/ORSuite/or_suite/plots.py:164\u001b[0m, in \u001b[0;36mplot_radar_plots\u001b[0;34m(path_list, algo_list, fig_path, fig_name, additional_metric)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m additional_metric \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m additional_metric:\n\u001b[0;32m--> 164\u001b[0m             algo_dict[metric] \u001b[38;5;241m=\u001b[39m \u001b[43madditional_metric\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m values\u001b[38;5;241m.\u001b[39mappend(algo_dict)\n\u001b[1;32m    168\u001b[0m index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(traj)\u001b[0m\n\u001b[1;32m     22\u001b[0m fig_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresource\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_line_plot\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     23\u001b[0m or_suite\u001b[38;5;241m.\u001b[39mplots\u001b[38;5;241m.\u001b[39mplot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, \u001b[38;5;28mint\u001b[39m(nEps \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m40\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)        \n\u001b[1;32m     25\u001b[0m additional_metric \u001b[38;5;241m=\u001b[39m { \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEfficiency\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m traj : or_suite\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdelta_EFFICIENCY(traj, CONFIG),\n\u001b[1;32m     26\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHindsight Envy\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m traj : or_suite\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdelta_HINDSIGHT_ENVY(traj, CONFIG),\n\u001b[0;32m---> 27\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCounterfactual Envy\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m traj : \u001b[43mor_suite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelta_COUNTERFACTUAL_ENVY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     28\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBudget\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m traj : or_suite\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mtimes_out_of_budget(traj, CONFIG)}\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#                       'Prop': lambda traj : or_suite.utils.delta_PROP(traj, CONFIG), \\\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#                       'Exante Envy': lambda traj : or_suite.utils.delta_EXANTE_ENVY(traj, CONFIG)}\u001b[39;00m\n\u001b[1;32m     31\u001b[0m fig_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresource\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_radar_plot\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/GitHub/ORSuite/or_suite/utils.py:377\u001b[0m, in \u001b[0;36mdelta_COUNTERFACTUAL_ENVY\u001b[0;34m(traj, env_config)\u001b[0m\n\u001b[1;32m    374\u001b[0m     sizes[step] \u001b[38;5;241m=\u001b[39m cur_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moldState\u001b[39m\u001b[38;5;124m'\u001b[39m][num_commodities:]\n\u001b[1;32m    375\u001b[0m     traj_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 377\u001b[0m X_opt \u001b[38;5;241m=\u001b[39m \u001b[43moffline_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m max_envy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m theta \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_types):\n",
      "File \u001b[0;32m~/Desktop/GitHub/ORSuite/or_suite/utils.py:156\u001b[0m, in \u001b[0;36moffline_opt\u001b[0;34m(budget, size, weights, solver)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03mUses solver from generate_cvxpy_solve and applies it to values.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m    weights: 2D numpy array containing the demands of each type.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    155\u001b[0m tot_size \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(size, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 156\u001b[0m _, x \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtot_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m allocation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((size\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], weights\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], weights\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(size\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m~/Desktop/GitHub/ORSuite/or_suite/utils.py:190\u001b[0m, in \u001b[0;36mgenerate_cvxpy_solve.<locals>.solver\u001b[0;34m(true_sizes, true_weights, true_budget)\u001b[0m\n\u001b[1;32m    188\u001b[0m sizes\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m true_sizes\n\u001b[1;32m    189\u001b[0m weights\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m true_weights\n\u001b[0;32m--> 190\u001b[0m budget\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m true_budget\n\u001b[1;32m    191\u001b[0m prob\u001b[38;5;241m.\u001b[39msolve()\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prob\u001b[38;5;241m.\u001b[39mvalue, np\u001b[38;5;241m.\u001b[39maround(x\u001b[38;5;241m.\u001b[39mvalue, \u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ORSuite/lib/python3.8/site-packages/cvxpy/expressions/constants/parameter.py:82\u001b[0m, in \u001b[0;36mParameter.value\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;129m@value\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalue\u001b[39m(\u001b[38;5;28mself\u001b[39m, val):\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ORSuite/lib/python3.8/site-packages/cvxpy/expressions/leaf.py:430\u001b[0m, in \u001b[0;36mLeaf._validate_value\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m             attr_str \u001b[38;5;241m=\u001b[39m ([k \u001b[38;5;28;01mfor\u001b[39;00m (k, v) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreal\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 430\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    431\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m value must be \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, attr_str)\n\u001b[1;32m    432\u001b[0m         )\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val\n",
      "\u001b[0;31mValueError\u001b[0m: Parameter value must be nonnegative."
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/resource_'+str(agent)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'AdaQL' or agent == 'Unif QL' or agent == 'AdaMB' or agent == 'Unif MB':\n",
    "        or_suite.utils.run_single_algo_tune(resource_env, agents[agent], scaling_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(resource_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/resource_'+str(agent))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/resource_'+str(agent)+'/')\n",
    "        algo_list_radar.append(str(agent))     \n",
    "        \n",
    "fig_path = '../figures/'\n",
    "fig_name = 'resource'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)        \n",
    "        \n",
    "additional_metric = { 'Efficiency': lambda traj : or_suite.utils.delta_EFFICIENCY(traj, CONFIG),\n",
    "                    'Hindsight Envy': lambda traj : or_suite.utils.delta_HINDSIGHT_ENVY(traj, CONFIG),\n",
    "                      'Counterfactual Envy': lambda traj : or_suite.utils.delta_COUNTERFACTUAL_ENVY(traj, CONFIG),\n",
    "                    'Budget': lambda traj : or_suite.utils.times_out_of_budget(traj, CONFIG)}\n",
    "#                       'Prop': lambda traj : or_suite.utils.delta_PROP(traj, CONFIG), \\\n",
    "#                       'Exante Envy': lambda traj : or_suite.utils.delta_EXANTE_ENVY(traj, CONFIG)}\n",
    "fig_name = 'resource'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96273425",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"../figures/resource_line_plot.pdf\", width=600, height=280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c08c369",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "IFrame(\"../figures/resource_radar_plot.pdf\", width=600, height=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
