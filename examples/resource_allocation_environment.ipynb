{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "experienced-income",
   "metadata": {},
   "source": [
    "# Resource Allocation Code Demo\n",
    "\n",
    "The Food Bank of the Southern Tier (FBST) is a member of Feeding America, focused on providing food security for people with limited financial resources, and serves six counties and nearly 4,000 square miles in the New York.  Under normal operations (non COVID times), the Mobile Food Pantry program is among the main activities of the FBST.  The goal of the service is to make nutritious and healthy food more accessible to people in underserved communities.  Even in areas where other agencies provide assistance, clients may not always have access to food due to limited public transportation options, or because those agencies are only open hours or days per work.\n",
    "\n",
    "Here we do a sample experiment testing out some of the existing and developed algorithms against a randomized heuristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54262089",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import or_suite\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exclusive-roots",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting out configuration parameter for the environment\n",
    "CONFIG = or_suite.envs.env_configs.resource_allocation_foodbank_config(5)\n",
    "# CONFIG = or_suite.envs.env_configs.resource_allocation_default_config\n",
    "\n",
    "\n",
    "# Specifying training iteration, epLen, number of episodes, and number of iterations\n",
    "epLen = CONFIG['num_rounds']\n",
    "nEps = 1\n",
    "numIters = 100\n",
    "\n",
    "# Configuration parameters for running the experiment\n",
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/resource/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, # save trajectory for calculating additional metrics\n",
    "                    'epLen' : epLen,\n",
    "                    'render': False,\n",
    "                    'pickle': False # indicator for pickling final information\n",
    "                    }\n",
    "\n",
    "resource_env = gym.make('Resource-v0', config=CONFIG)\n",
    "mon_env = Monitor(resource_env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "comprehensive-amplifier",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and variance endomwnets:\n",
      "[[35.32146354 34.82342926 35.60643908 35.60462872 33.86564477]\n",
      " [43.1625433  42.27228204 42.09735355 43.13484842 41.40156445]\n",
      " [64.59694454 64.13501184 64.72398915 65.17613151 62.66874067]] [[ 619.84840311  589.11307591  561.98606976  583.14221513  527.47570332]\n",
      " [1014.03791607  922.29527899  881.63801835  900.8344631   933.14029223]\n",
      " [2743.60976587 2739.21570403 2871.28815007 2686.77163026 2761.33654738]]\n",
      "Mean and variance endomwnets:\n",
      "[[36.79063473 36.62856159 36.21216004 34.74872621 35.62584123]\n",
      " [43.25381407 44.17079193 43.27272857 41.82326674 42.76529222]\n",
      " [66.11117137 65.66326239 62.25431907 61.9071235  65.49413413]] [[ 651.75786011  626.92255854  623.73817886  576.42293999  614.57833337]\n",
      " [ 920.00431182  968.24246067  961.61214291  977.32266414  981.76924734]\n",
      " [2741.67804652 2563.82622333 2631.13082255 2531.1700942  2815.38005979]]\n",
      "Mean and variance endomwnets:\n",
      "[[36.66104844 34.47848764 33.4236911  37.64544109 34.14830365]\n",
      " [43.61125171 41.77030456 40.02066533 43.71747883 40.56988458]\n",
      " [65.7659129  61.55180602 61.39823971 67.91657512 63.43237906]] [[ 595.14264811  576.33503176  542.52815626  636.95094116  525.29741708]\n",
      " [ 925.06275208  926.02182626  832.11774613  892.61344496  816.02165171]\n",
      " [2769.82617284 2763.75314422 2552.79471064 2897.72005192 2518.09350311]]\n"
     ]
    }
   ],
   "source": [
    "agents = { # 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "#  'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "#  'Equal': or_suite.agents.resource_allocation.equal_allocation.equalAllocationAgent(epLen, CONFIG),\n",
    "#  'FixedThreshold': or_suite.agents.resource_allocation.fixed_threshold.fixedThresholdAgent(epLen, CONFIG),\n",
    " 'Guardrail-0.5': or_suite.agents.resource_allocation.hope_guardrail.hopeguardrailAgent(epLen, CONFIG, 0.5),\n",
    " 'Guardrail-0.3': or_suite.agents.resource_allocation.hope_guardrail.hopeguardrailAgent(epLen, CONFIG, 0.3),\n",
    " 'Guardrail-0.25': or_suite.agents.resource_allocation.hope_guardrail.hopeguardrailAgent(epLen, CONFIG, 0.25)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-dublin",
   "metadata": {},
   "source": [
    "# Step 5: Run Simulations\n",
    "\n",
    "Run the different heuristics in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e2e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1a07ba9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardrail-0.5\n",
      "Lower and Upper Solutions:\n",
      "[[0.05469 0.05887 0.09567 0.06035 0.     ]\n",
      " [0.08916 0.08383 0.      0.08204 0.     ]\n",
      " [0.03893 0.03996 0.07222 0.04026 0.12533]]\n",
      "[[0.09893 0.1065  0.17308 0.10917 0.     ]\n",
      " [0.1613  0.15164 0.      0.14841 0.     ]\n",
      " [0.07042 0.07229 0.13063 0.07283 0.22673]]\n",
      "Writing to file data.csv\n",
      "Guardrail-0.3\n",
      "Lower and Upper Solutions:\n",
      "[[0.05447 0.05859 0.09631 0.06004 0.     ]\n",
      " [0.08919 0.08371 0.      0.08187 0.     ]\n",
      " [0.03861 0.03978 0.07194 0.04013 0.12649]]\n",
      "[[0.14211 0.1529  0.25186 0.15669 0.     ]\n",
      " [0.23288 0.21858 0.      0.21379 0.     ]\n",
      " [0.10088 0.10392 0.18764 0.10484 0.33028]]\n",
      "Writing to file data.csv\n",
      "Guardrail-0.25\n",
      "Lower and Upper Solutions:\n",
      "[[0.0547  0.05879 0.09537 0.06022 0.     ]\n",
      " [0.08894 0.08371 0.      0.08197 0.     ]\n",
      " [0.03897 0.03995 0.07184 0.04024 0.12509]]\n",
      "[[0.1648  0.17721 0.28884 0.18158 0.     ]\n",
      " [0.26845 0.25274 0.      0.24748 0.     ]\n",
      " [0.11785 0.12074 0.21636 0.12159 0.37762]]\n",
      "Writing to file data.csv\n",
      "        Algorithm     Reward      Time     Space     Efficiency  \\\n",
      "0   Guardrail-0.5 -10.578513  3.673069 -11493.46 -250762.803174   \n",
      "1   Guardrail-0.3  -8.747808  3.677672  -9286.74 -232382.247434   \n",
      "2  Guardrail-0.25  -8.026695  3.680483  -9242.97 -223164.746350   \n",
      "\n",
      "   Hindsight Envy  Counterfactual Envy  Budget  \n",
      "0       -4.768472           -97.618069     0.0  \n",
      "1       -6.876736           -90.919008     0.0  \n",
      "2       -7.942899           -87.529559     0.0  \n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/resource_'+str(agent)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'AdaQL' or agent == 'Unif QL' or agent == 'AdaMB' or agent == 'Unif MB':\n",
    "        or_suite.utils.run_single_algo_tune(resource_env, agents[agent], scaling_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(resource_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/resource_'+str(agent))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/resource_'+str(agent)+'/')\n",
    "        algo_list_radar.append(str(agent))     \n",
    "        \n",
    "fig_path = '../figures/'\n",
    "fig_name = 'resource'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)        \n",
    "        \n",
    "additional_metric = {'Efficiency': lambda traj : or_suite.utils.delta_EFFICIENCY(traj, CONFIG), \\\n",
    "                      'Hindsight Envy': lambda traj : or_suite.utils.delta_HINDSIGHT_ENVY(traj, CONFIG), \\\n",
    "                      'Counterfactual Envy': lambda traj : or_suite.utils.delta_COUNTERFACTUAL_ENVY(traj, CONFIG), \\\n",
    "                      'Budget' : lambda traj : or_suite.utils.times_out_of_budget(traj, CONFIG)}\n",
    "#                       'Prop': lambda traj : or_suite.utils.delta_PROP(traj, CONFIG), \\\n",
    "#                       'Exante Envy': lambda traj : or_suite.utils.delta_EXANTE_ENVY(traj, CONFIG)}\n",
    "fig_name = 'resource'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96273425",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"280\"\n",
       "            src=\"../figures/resource_line_plot.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd415a44e80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"../figures/resource_line_plot.pdf\", width=600, height=280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c08c369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"500\"\n",
       "            src=\"../figures/resource_radar_plot.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd415a2c970>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"../figures/resource_radar_plot.pdf\", width=600, height=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
