{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "experienced-income",
   "metadata": {},
   "source": [
    "# Resource Allocation Code Demo\n",
    "\n",
    "The Food Bank of the Southern Tier (FBST) is a member of Feeding America, focused on providing food security for people with limited financial resources, and serves six counties and nearly 4,000 square miles in the New York.  Under normal operations (non COVID times), the Mobile Food Pantry program is among the main activities of the FBST.  The goal of the service is to make nutritious and healthy food more accessible to people in underserved communities.  Even in areas where other agencies provide assistance, clients may not always have access to food due to limited public transportation options, or because those agencies are only open hours or days per work.\n",
    "\n",
    "Here we do a sample experiment testing out some of the existing and developed algorithms against a randomized heuristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54262089",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import or_suite\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8006de58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting out configuration parameter for the environment\n",
    "CONFIG = or_suite.envs.env_configs.resource_allocation_foodbank_config(6)\n",
    "# CONFIG = or_suite.envs.env_configs.resource_allocation_default_config\n",
    "\n",
    "\n",
    "# Specifying training iteration, epLen, number of episodes, and number of iterations\n",
    "epLen = CONFIG['num_rounds']\n",
    "nEps = 1\n",
    "numIters = 50\n",
    "\n",
    "# Configuration parameters for running the experiment\n",
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/resource/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, # save trajectory for calculating additional metrics\n",
    "                    'epLen' : epLen,\n",
    "                    'render': False,\n",
    "                    'pickle': False # indicator for pickling final information\n",
    "                    }\n",
    "\n",
    "resource_env = gym.make('Resource-v0', config=CONFIG)\n",
    "mon_env = Monitor(resource_env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "comprehensive-amplifier",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and variance endomwnets:\n",
      "[[ 78.26375893   6.0727015    6.44300652  45.77261221  44.09344226\n",
      "   65.08365485]\n",
      " [ 95.46955096   7.22226892   7.79065549  54.01600952  52.40468424\n",
      "   78.47564501]\n",
      " [143.91159334  10.74500626  11.99429086  82.83258243  78.44525594\n",
      "  122.24599817]] [[3.64072981e+02 2.33741060e+00 2.57228850e+00 1.15437516e+02\n",
      "  1.18667423e+02 2.38134618e+02]\n",
      " [7.94745501e+02 5.05359566e+00 5.24406535e+00 2.59898915e+02\n",
      "  2.39934924e+02 5.14491414e+02]\n",
      " [4.02164318e+03 2.28563550e+01 2.64385547e+01 1.36285195e+03\n",
      "  1.23836885e+03 2.72751318e+03]]\n",
      "Mean and variance endomwnets:\n",
      "[[ 78.41886444   6.08126054   6.39750545  45.47523737  43.64117171\n",
      "   65.20269258]\n",
      " [ 92.97936165   7.36984864   7.76322388  53.98400493  53.45615034\n",
      "   78.02872186]\n",
      " [144.72413253  11.09143577  11.94231468  80.29985241  80.27982003\n",
      "  116.85010458]] [[3.75543122e+02 2.24332816e+00 2.63604673e+00 1.25118369e+02\n",
      "  1.21187605e+02 2.72275097e+02]\n",
      " [7.87113421e+02 4.65884021e+00 5.12908280e+00 2.60890199e+02\n",
      "  2.61219114e+02 5.53556571e+02]\n",
      " [3.82696593e+03 2.51293231e+01 2.53053382e+01 1.24074783e+03\n",
      "  1.24404673e+03 2.58560824e+03]]\n"
     ]
    }
   ],
   "source": [
    "agents = { # 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "#  'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "#  'Equal': or_suite.agents.resource_allocation.equal_allocation.equalAllocationAgent(epLen, CONFIG),\n",
    "  'FixedThreshold': or_suite.agents.resource_allocation.fixed_threshold.fixedThresholdAgent(epLen, CONFIG),\n",
    " 'Guardrail-0.5': or_suite.agents.resource_allocation.hope_guardrail.hopeguardrailAgent(epLen, CONFIG, 0.5),\n",
    "  'Guardrail-0.3': or_suite.agents.resource_allocation.hope_guardrail.hopeguardrailAgent(epLen, CONFIG, 0.3),\n",
    "#  'Guardrail-0.25': or_suite.agents.resource_allocation.hope_guardrail.hopeguardrailAgent(epLen, CONFIG, 0.25)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-dublin",
   "metadata": {},
   "source": [
    "# Step 5: Run Simulations\n",
    "\n",
    "Run the different heuristics in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e2e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1a07ba9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FixedThreshold\n",
      "Lower Solutions:\n",
      "[[0.32854 0.34986 0.55642 0.35732 0.     ]\n",
      " [0.52429 0.49707 0.      0.48804 0.     ]\n",
      " [0.23534 0.23951 0.41909 0.24067 0.73371]]\n",
      "Writing to file data.csv\n",
      "Guardrail-0.5\n",
      "Lower and Upper Solutions:\n",
      "[[0.32854 0.34986 0.55642 0.35732 0.     ]\n",
      " [0.52429 0.49707 0.      0.48804 0.     ]\n",
      " [0.23534 0.23951 0.41909 0.24067 0.73371]]\n",
      "[[0.55367 0.58995 0.94496 0.60261 0.     ]\n",
      " [0.88643 0.83982 0.      0.82429 0.     ]\n",
      " [0.39829 0.40557 0.70558 0.40766 1.23989]]\n",
      "Writing to file data.csv\n",
      "Guardrail-0.3\n",
      "Lower and Upper Solutions:\n",
      "[[0.32854 0.34986 0.55642 0.35732 0.     ]\n",
      " [0.52429 0.49707 0.      0.48804 0.     ]\n",
      " [0.23534 0.23951 0.41909 0.24067 0.73371]]\n",
      "[[0.78633 0.83699 1.35296 0.85437 0.     ]\n",
      " [1.26498 1.19346 0.      1.16997 0.     ]\n",
      " [0.56566 0.57966 0.99953 0.58384 1.76452]]\n",
      "Writing to file data.csv\n",
      "        Algorithm     Reward      Time     Space     Efficiency  \\\n",
      "0  FixedThreshold -44.802121  1.021070 -35583.46 -211437.667358   \n",
      "1   Guardrail-0.5 -44.802121  1.014202 -31454.66 -209072.167603   \n",
      "2   Guardrail-0.3 -44.802121  1.014641 -31102.96 -209072.167603   \n",
      "\n",
      "   Hindsight Envy  Counterfactual Envy  \n",
      "0       -0.155863           -80.575882  \n",
      "1       -0.155863           -79.823583  \n",
      "2       -0.155863           -79.823583  \n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/resource_'+str(agent)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'AdaQL' or agent == 'Unif QL' or agent == 'AdaMB' or agent == 'Unif MB':\n",
    "        or_suite.utils.run_single_algo_tune(resource_env, agents[agent], scaling_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(resource_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/resource_'+str(agent))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/resource_'+str(agent)+'/')\n",
    "        algo_list_radar.append(str(agent))     \n",
    "        \n",
    "fig_path = '../figures/'\n",
    "fig_name = 'resource'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)        \n",
    "        \n",
    "additional_metric = { 'Efficiency': lambda traj : or_suite.utils.delta_EFFICIENCY(traj, CONFIG),\n",
    "                    'Hindsight Envy': lambda traj : or_suite.utils.delta_HINDSIGHT_ENVY(traj, CONFIG),\n",
    "                      'Counterfactual Envy': lambda traj : or_suite.utils.delta_COUNTERFACTUAL_ENVY(traj, CONFIG),\n",
    "#                     'Budget': lambda traj : or_suite.utils.times_out_of_budget(traj, CONFIG)\n",
    "#                       'Prop': lambda traj : or_suite.utils.delta_PROP(traj, CONFIG), \\\n",
    "#                       'Exante Envy': lambda traj : or_suite.utils.delta_EXANTE_ENVY(traj, CONFIG)\n",
    "                    }\n",
    "fig_name = 'resource'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96273425",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"280\"\n",
       "            src=\"../figures/resource_line_plot.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8bb78e2160>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"../figures/resource_line_plot.pdf\", width=600, height=280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c08c369",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"500\"\n",
       "            src=\"../figures/resource_radar_plot.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8bb7a60a60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"../figures/resource_radar_plot.pdf\", width=600, height=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
