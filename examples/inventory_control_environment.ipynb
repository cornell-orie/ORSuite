{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3649ba78",
   "metadata": {},
   "source": [
    "# Inventory Management Code Demo\n",
    "\n",
    "One potential application of reinforcement learning involves ordering supplies with mutliple suppliers having various lead times and costs in order to meet a changing demand. Lead time in inventory management is the lapse in time between when an order is placed to replenish inventory and when the order is received. This affects the amount of stock a supplier needs to hold at any point in time. Moreover, due to having multiple suppliers, at every stage the supplier is faced with a decision on how much to order from each supplier, noting that more costly suppliers might have to be used to replenish the inventory from a shorter lead time.\n",
    "\n",
    "The inventory control model addresses this by modeling an environment where there are multiplie suppliers with different costs and lead times. Orders must be placed with these suppliers to have an on-hand inventory to meet a changing demand. However, both having supplies on backorder and holding unused inventory have associated costs. The goal of the agent is to choose the amount to order from each supplier to maximize the revenue earned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4af43d",
   "metadata": {},
   "source": [
    "# Step 1: Package Installation\n",
    "First we import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85555dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import or_suite\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93486d4f",
   "metadata": {},
   "source": [
    "# Run Simulation with One Supplier\n",
    "\n",
    "# Step 2: Pick problem parameters for the environment\n",
    "\n",
    "Here we use the inventory control environment as outlined in `or_suite/envs/inventory_control_multiple_suppliers/multiple_suppliers_env.py`.\n",
    "Here we use some simple values for an environment with only 1 supplier.\n",
    "\n",
    "In addition, we need to specify the number of episodes for learning, and the number of iterations (in order to plot average results with confidence intervals).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "266b167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {'lead_times': [5],\n",
    "           'demand_dist': lambda x: np.random.poisson(5),\n",
    "           'supplier_costs': [10],\n",
    "           'hold_cost': 1,\n",
    "           'backorder_cost': 100,\n",
    "           'max_inventory': 1000,\n",
    "           'max_order': 50,\n",
    "           'epLen': 500,\n",
    "           'starting_state': None,\n",
    "           'neg_inventory': False\n",
    "         }\n",
    "CONFIG['epLen'] = 100\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 2\n",
    "numIters = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ee6560",
   "metadata": {},
   "source": [
    "# Step 3: Pick simulation parameters\n",
    "\n",
    "Next we need to specify parameters for the simulation. This includes setting a seed, the frequency to record the metrics, directory path for saving the data files, a deBug mode which prints the trajectory, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea98c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/ambulance/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : CONFIG['epLen'],\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "env = gym.make('MultipleSuppliers-v0', config=CONFIG)\n",
    "mon_env = Monitor(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab765965",
   "metadata": {},
   "source": [
    "# Step 4: Pick list of algorithms\n",
    "\n",
    "We have several heuristics implemented for each of the environments defined, in addition to a `Random` policy, and some `RL discretization based` algorithms. \n",
    "\n",
    "The `Random` agent chooses random amounts to order from each supplier between 0 and the $maxorder$ value.\n",
    "\n",
    "The `TBS` agent uses an order-up-to-amount, $S$, and for the supplier with the largest lead time, orders $S$ minus the current inventory. For the other suppliers, different values are used, which are stored in an array, $r$, which has the length of the number of suppliers minus 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "879c2789",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = { # 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'TBS': or_suite.agents.inventory_control_multiple_suppliers.base_surge.base_surgeAgent([],0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692b8d30",
   "metadata": {},
   "source": [
    "# Step 5: Run Simulations\n",
    "\n",
    "Run the different heuristics in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2941cf99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random\n",
      "Writing to file data.csv\n",
      "TBS\n",
      "Chosen parameters: [[], 26]\n",
      "Writing to file data.csv\n",
      "[[], 26]\n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "\n",
    "#each index of param_list is another list, param, where param[0] is r and param[1] is S\n",
    "max_order = CONFIG['max_order']\n",
    "param_list = []\n",
    "for S in range(max_order + 1):\n",
    "        param_list.append([[],S])\n",
    "        \n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/inventory_control_'+str(agent)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'TBS':\n",
    "        or_suite.utils.run_single_algo_tune(env, agents[agent], param_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/inventory_control_'+str(agent))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/inventory_control_'+str(agent))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d832b264",
   "metadata": {},
   "source": [
    "# Step 6: Generate Figures\n",
    "\n",
    "Create a chart to compare the different heuristic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01214ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Algorithm   Reward      Time    Space\n",
      "0    Random -99816.5  4.996653 -94775.9\n",
      "1       TBS -14378.4  5.096435 -94820.8\n"
     ]
    }
   ],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'inventory'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {}\n",
    "fig_name = 'inventory'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f52750d",
   "metadata": {},
   "source": [
    "Here we see that the `TBS` agent performs better than the `Random` agent for an environment that involves only a single supplier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5582f0ab",
   "metadata": {},
   "source": [
    "# Run Simulation with 2 Suppliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff38f208",
   "metadata": {},
   "source": [
    "The package has default specifications for all of the environments in the file `or_suite/envs/env_configs.py`, and so we use a default for the inventory control problem for 2 suppliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d75e2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "CONFIG =  or_suite.envs.env_configs.inventory_control_multiple_suppliers_modified_config\n",
    "CONFIG['epLen'] = 500\n",
    "CONFIG['neg_inventory']= False\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 2\n",
    "numIters = 10\n",
    "print(epLen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31d81c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/ambulance/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : CONFIG['epLen'],\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "env = gym.make('MultipleSuppliers-v0', config=CONFIG)\n",
    "mon_env = Monitor(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53964e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = { # 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'TBS': or_suite.agents.inventory_control_multiple_suppliers.base_surge.base_surgeAgent([14],0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f81c8f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random\n",
      "Writing to file data.csv\n",
      "TBS\n",
      "Chosen parameters: [[9], 12]\n",
      "Writing to file data.csv\n",
      "[[9], 12]\n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "\n",
    "#each index of param_list is another list, param, where param[0] is r and param[1] is S\n",
    "max_order = CONFIG['max_order']\n",
    "param_list = []\n",
    "for r in range(max_order+1):\n",
    "    for S in range(max_order + 1):\n",
    "        param_list.append([[r],S])\n",
    "        \n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/inventory_control_'+str(agent)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'TBS':\n",
    "        or_suite.utils.run_single_algo_tune(env, agents[agent], param_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/inventory_control_'+str(agent))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/inventory_control_'+str(agent))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "091bec4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Algorithm    Reward      Time     Space\n",
      "0    Random -550306.4  3.253349 -513325.2\n",
      "1       TBS  -91386.2  3.135725 -513337.6\n"
     ]
    }
   ],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'inventory'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {}\n",
    "fig_name = 'inventory'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n",
    "\n",
    "# TODO: Import figures and display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950319f3",
   "metadata": {},
   "source": [
    "## Results\n",
    "Here we see that the `TBS` agent also performs better than the `Random` agent for an environment that involves two suppliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea87872",
   "metadata": {},
   "source": [
    "# Run with 3 Suppliers\n",
    "\n",
    "We now use an example environment that uses 3 suppliers, each with different lead times and costs. This results in a non-trivial best action when using the `TBS` agent that still performs better than the `Random` agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6f335b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {'lead_times': [5, 7, 11],\n",
    "           'demand_dist': lambda x: np.random.poisson(17),\n",
    "           'supplier_costs': [100 ,85, 73],\n",
    "           'hold_cost': 1,\n",
    "           'backorder_cost': 200,\n",
    "           'max_inventory': 1000,\n",
    "           'max_order': 20,\n",
    "           'epLen': 500,\n",
    "           'starting_state': None,\n",
    "           'neg_inventory': False\n",
    "         }\n",
    "CONFIG['epLen'] = 100\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 2\n",
    "numIters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09797c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/ambulance/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : CONFIG['epLen'],\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "env = gym.make('MultipleSuppliers-v0', config=CONFIG)\n",
    "mon_env = Monitor(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc9573b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = { # 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'TBS': or_suite.agents.inventory_control_multiple_suppliers.base_surge.base_surgeAgent([14,14],0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5dd2ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random\n",
      "Writing to file data.csv\n",
      "TBS\n",
      "Chosen parameters: [[0, 17], 0]\n",
      "Writing to file data.csv\n",
      "[[0, 17], 0]\n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "\n",
    "#each index of param_list is another list, param, where param[0] is r and param[1] is S\n",
    "max_order = CONFIG['max_order']\n",
    "param_list = []\n",
    "for S in range(max_order + 1):\n",
    "    for r1 in range(max_order + 1):\n",
    "        for r2 in range(max_order +1):\n",
    "            param_list.append([[r1, r2],S])\n",
    "        \n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/inventory_control_'+str(agent)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'TBS':\n",
    "        or_suite.utils.run_single_algo_tune(env, agents[agent], param_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/inventory_control_'+str(agent))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/inventory_control_'+str(agent))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18cb0038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Algorithm    Reward      Time     Space\n",
      "0    Random -332754.8  4.802525 -110972.8\n",
      "1       TBS -174007.7  4.783570 -110972.8\n"
     ]
    }
   ],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'inventory'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {}\n",
    "fig_name = 'inventory'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8b0895",
   "metadata": {},
   "source": [
    "## Results\n",
    "Here we see that the `TBS` agent also performs better than the `Random` agent for an environment that involves three suppliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f970b89",
   "metadata": {},
   "source": [
    "# Nontrivial Two Suppliers Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35da2f69",
   "metadata": {},
   "source": [
    "We now use an example environment that uses 2 suppliers, each with different lead times and costs, but where the resulting optimal action for the TBS agent does not have `r=0` or `S=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a6020b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {'lead_times': [5, 7],\n",
    "           'demand_dist': lambda x: np.random.poisson(17),\n",
    "           'supplier_costs': [100 ,85],\n",
    "           'hold_cost': 1,\n",
    "           'backorder_cost': 200,\n",
    "           'max_inventory': 1000,\n",
    "           'max_order': 20,\n",
    "           'epLen': 500,\n",
    "           'starting_state': None,\n",
    "           'neg_inventory': False\n",
    "         }\n",
    "CONFIG['epLen'] = 100\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 2\n",
    "numIters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "140cf206",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/ambulance/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : CONFIG['epLen'],\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "env = gym.make('MultipleSuppliers-v0', config=CONFIG)\n",
    "mon_env = Monitor(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bc3bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = { # 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'TBS': or_suite.agents.inventory_control_multiple_suppliers.base_surge.base_surgeAgent([14,14],0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bb657c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random\n",
      "Writing to file data.csv\n",
      "TBS\n",
      "Chosen parameters: [[0], 17]\n",
      "Writing to file data.csv\n",
      "[[0], 17]\n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "\n",
    "#each index of param_list is another list, param, where param[0] is r and param[1] is S\n",
    "max_order = CONFIG['max_order']\n",
    "param_list = []\n",
    "for r in range(max_order+1):\n",
    "    for S in range(max_order + 1):\n",
    "        param_list.append([[r],S])\n",
    "        \n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/inventory_control_'+str(agent)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'TBS':\n",
    "        or_suite.utils.run_single_algo_tune(env, agents[agent], param_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/inventory_control_'+str(agent))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/inventory_control_'+str(agent))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcfa94c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Algorithm    Reward      Time     Space\n",
      "0    Random -221322.2  4.446902 -101284.8\n",
      "1       TBS -198592.4  4.872351 -101284.8\n"
     ]
    }
   ],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'inventory'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {}\n",
    "fig_name = 'inventory'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d10371",
   "metadata": {},
   "source": [
    "## Results\n",
    "Here, the `TBS` agent still performs better than the `Random` agent. However, the `r` and `S` values for the `TBS` agent are both non-zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd4c705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7256ee09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2488fc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
