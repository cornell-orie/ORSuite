{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3649ba78",
   "metadata": {},
   "source": [
    "# Inventory Management Code Demo\n",
    "\n",
    "One potential application of reinforcement learning involves ordering supplies with mutliple suppliers having various lead times and costs in order to meet a changing demand. Lead time in inventory management is the lapse in time between when an order is placed to replenish inventory and when the order is received. This affects the amount of stock a supplier needs to hold at any point in time. Moreover, due to having multiple suppliers, at every stage the supplier is faced with a decision on how much to order from each supplier, noting that more costly suppliers might have to be used to replenish the inventory from a shorter lead time.\n",
    "\n",
    "The inventory control model addresses this by modeling an environment where there are multiplie suppliers with different costs and lead times. Orders must be placed with these suppliers to have an on-hand inventory to meet a changing demand. However, both having supplies on backorder and holding unused inventory have associated costs. The goal of the agent is to choose the amount to order from each supplier to maximize the revenue earned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4af43d",
   "metadata": {},
   "source": [
    "### Package Installation\n",
    "First we import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a85555dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import or_suite\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93486d4f",
   "metadata": {},
   "source": [
    "## Run Simulation with One Supplier\n",
    "\n",
    "### Environment Parameters\n",
    "\n",
    "The inventory management problem has several parameters. Here we use some simple values for an environment with only 1 supplier:\n",
    "* `lead_times`: array of ints representing the lead times of each supplier\n",
    "* `demand_dist`: the random number sampled from the given distribution to be used to calculate the demand\n",
    "* `supplier_costs`: array of ints representing the costs of each supplier\n",
    "* `hold_cost`: The int holding cost.\n",
    "* `backorder_cost`: The backorder holding cost.\n",
    "* `max_inventory`: The maximum value (int) that can be held in inventory\n",
    "* `max_order`: The maximum value (int) that can be ordered from each supplier\n",
    "* `epLen`: The int number of time steps to run the experiment for.\n",
    "* `starting_state`: An int list containing enough indices for the sum of all the lead times, plus an additional index for the initial on-hand inventory.\n",
    "* `neg_inventory`: A bool that says whether the on-hand inventory can be negative or not.\n",
    "* `nEps`: an int representing the number of episodes\n",
    "* `numIters`: an int representing the number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "266b167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {'lead_times': [5],\n",
    "           'demand_dist': lambda x: np.random.poisson(5),\n",
    "           'supplier_costs': [10],\n",
    "           'hold_cost': 1,\n",
    "           'backorder_cost': 100,\n",
    "           'max_inventory': 1000,\n",
    "           'max_order': 50,\n",
    "           'epLen': 500,\n",
    "           'starting_state': None,\n",
    "           'neg_inventory': False\n",
    "         }\n",
    "CONFIG['epLen'] = 100\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 2\n",
    "numIters = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ee6560",
   "metadata": {},
   "source": [
    "### Experimental parameters\n",
    "\n",
    "Next we need to specify parameters for the inventory control experiment.\n",
    "* `seed` allows random numbers to be generated. \n",
    "* `dirPath`, a string, is the location where the data files are stored.\n",
    "* `deBug`, a bool, prints information to the command line when set true. \n",
    "* `save_trajectory`, a bool, saves the trajectory information of the simulation when set to true. \n",
    "* `render` renders the algorithm when set to true.\n",
    "* `pickle` is a bool that saves the information to a pickle file when set to true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea98c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/ambulance/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : CONFIG['epLen'],\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "env = gym.make('MultipleSuppliers-v0', config=CONFIG)\n",
    "mon_env = Monitor(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab765965",
   "metadata": {},
   "source": [
    "### Specifying Agent\n",
    "We specify 6 different agents to compare the effectiveness of each.\n",
    "* `SB PPO` is Proximal Policy Optimization. When policy is updated, there is a parameter that “clips” each policy update so that action update does not go too far\n",
    "* `Random` implements the randomized RL algorithm, which chooses random amounts to order from each supplier between 0 and the $maxorder$ value.\n",
    "* `TBS` is an agent that uses an order-up-to-amount, $S$, and for the supplier with the largest lead time, orders $S$ minus the current inventory. For the other suppliers, different values are used, which are stored in an array, $r$, which has the length of the number of suppliers minus 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "879c2789",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = { # 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'TBS': or_suite.agents.inventory_control_multiple_suppliers.base_surge.base_surgeAgent([],0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692b8d30",
   "metadata": {},
   "source": [
    "### Running Algorithm\n",
    "\n",
    "Run the different heuristics in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2941cf99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random\n",
      "Writing to file data.csv\n",
      "TBS\n",
      "Chosen parameters: [[], 26]\n",
      "Writing to file data.csv\n",
      "[[], 26]\n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "\n",
    "#each index of param_list is another list, param, where param[0] is r and param[1] is S\n",
    "max_order = CONFIG['max_order']\n",
    "param_list = []\n",
    "for S in range(max_order + 1):\n",
    "        param_list.append([[],S])\n",
    "        \n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/inventory_control_'+str(agent)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'TBS':\n",
    "        or_suite.utils.run_single_algo_tune(env, agents[agent], param_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/inventory_control_'+str(agent))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/inventory_control_'+str(agent))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d832b264",
   "metadata": {},
   "source": [
    "### Generate Figures\n",
    "\n",
    "Create a chart to compare the different heuristic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01214ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Algorithm   Reward      Time    Space\n",
      "0    Random -98526.2  4.396521 -93336.3\n",
      "1       TBS -14378.4  4.545949 -93252.8\n"
     ]
    }
   ],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'inventory'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {}\n",
    "fig_name = 'inventory'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0815e146",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"280\"\n",
       "            src=\"../figures/inventory_line_plot.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fb7e22e44f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"../figures/inventory_line_plot.pdf\", width=600, height=280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5eb49ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"450\"\n",
       "            src=\"../figures/inventory_radar_plot.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fb7e22e4d90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"../figures/inventory_radar_plot.pdf\", width=600, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f52750d",
   "metadata": {},
   "source": [
    "### Results\n",
    "Here we see that the `TBS` agent performs better than the `Random` agent for an environment that involves only a single supplier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5582f0ab",
   "metadata": {},
   "source": [
    "## Run Simulation with 2 Suppliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd5d023",
   "metadata": {},
   "source": [
    "### Experimental Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff38f208",
   "metadata": {},
   "source": [
    "The package has default specifications for all of the environments in the file `or_suite/envs/env_configs.py`, and so we use a default for the inventory control problem for 2 suppliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d75e2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "CONFIG =  or_suite.envs.env_configs.inventory_control_multiple_suppliers_modified_config\n",
    "CONFIG['epLen'] = 500\n",
    "CONFIG['neg_inventory']= False\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 2\n",
    "numIters = 10\n",
    "print(epLen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31d81c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/ambulance/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : CONFIG['epLen'],\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "env = gym.make('MultipleSuppliers-v0', config=CONFIG)\n",
    "mon_env = Monitor(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28ee670",
   "metadata": {},
   "source": [
    "### Specifying Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53964e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = { # 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'TBS': or_suite.agents.inventory_control_multiple_suppliers.base_surge.base_surgeAgent([14],0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71253400",
   "metadata": {},
   "source": [
    "### Running Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f81c8f1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random\n",
      "Writing to file data.csv\n",
      "TBS\n",
      "Chosen parameters: [[9], 12]\n",
      "Writing to file data.csv\n",
      "[[9], 12]\n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "\n",
    "#each index of param_list is another list, param, where param[0] is r and param[1] is S\n",
    "max_order = CONFIG['max_order']\n",
    "param_list = []\n",
    "for r in range(max_order+1):\n",
    "    for S in range(max_order + 1):\n",
    "        param_list.append([[r],S])\n",
    "        \n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/inventory_control_'+str(agent)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'TBS':\n",
    "        or_suite.utils.run_single_algo_tune(env, agents[agent], param_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/inventory_control_'+str(agent))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/inventory_control_'+str(agent))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b24ecc",
   "metadata": {},
   "source": [
    "### Generate Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "091bec4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Algorithm    Reward      Time     Space\n",
      "0    Random -550071.1  2.192443 -505358.0\n",
      "1       TBS  -91386.2  2.474930 -505353.6\n"
     ]
    }
   ],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'inventory'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {}\n",
    "fig_name = 'inventory'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a288414c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"280\"\n",
       "            src=\"../figures/inventory_line_plot.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fb77d1d87f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"../figures/inventory_line_plot.pdf\", width=600, height=280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d017065f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"450\"\n",
       "            src=\"../figures/inventory_radar_plot.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fb77d653910>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"../figures/inventory_radar_plot.pdf\", width=600, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950319f3",
   "metadata": {},
   "source": [
    "### Results\n",
    "Here we see that the `TBS` agent also performs better than the `Random` agent for an environment that involves two suppliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea87872",
   "metadata": {},
   "source": [
    "## Run with 3 Suppliers\n",
    "\n",
    "We now use an example environment that uses 3 suppliers, each with different lead times and costs. This results in a non-trivial best action when using the `TBS` agent that still performs better than the `Random` agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a1f5e0",
   "metadata": {},
   "source": [
    "### Experimental Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6f335b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {'lead_times': [5, 7, 11],\n",
    "           'demand_dist': lambda x: np.random.poisson(17),\n",
    "           'supplier_costs': [100 ,85, 73],\n",
    "           'hold_cost': 1,\n",
    "           'backorder_cost': 200,\n",
    "           'max_inventory': 1000,\n",
    "           'max_order': 20,\n",
    "           'epLen': 500,\n",
    "           'starting_state': None,\n",
    "           'neg_inventory': False\n",
    "         }\n",
    "CONFIG['epLen'] = 100\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 2\n",
    "numIters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09797c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/ambulance/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : CONFIG['epLen'],\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "env = gym.make('MultipleSuppliers-v0', config=CONFIG)\n",
    "mon_env = Monitor(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ff6b61",
   "metadata": {},
   "source": [
    "### Specifying Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc9573b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = { # 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'TBS': or_suite.agents.inventory_control_multiple_suppliers.base_surge.base_surgeAgent([14,14],0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c2c53",
   "metadata": {},
   "source": [
    "### Running Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5dd2ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random\n",
      "Writing to file data.csv\n",
      "TBS\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Action, [0 0 0],  not part of action space",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4972/437293872.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mor_suite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single_sb_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmon_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_SETTINGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'TBS'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mor_suite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single_algo_tune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_SETTINGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mor_suite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_SETTINGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/ORSuite/or_suite/utils.py\u001b[0m in \u001b[0;36mrun_single_algo_tune\u001b[0;34m(env, agent, param_list, settings)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mor_suite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         dt = pd.DataFrame(exp.data, columns=[\n\u001b[1;32m     37\u001b[0m                           'episode', 'iteration', 'epReward', 'memory', 'time'])\n",
      "\u001b[0;32m~/github/ORSuite/or_suite/experiment/experiment.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0;31m# steps based on the action chosen by the algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                     \u001b[0mnewState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                     \u001b[0mepReward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/ORSuite/or_suite/envs/inventory_control_multiple_suppliers/multiple_suppliers_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    110\u001b[0m             info: A dictionary containing extra information about the step. This dictionary contains the int value of the demand during the previous step\"\"\"\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         assert self.action_space.contains(\n\u001b[0m\u001b[1;32m    113\u001b[0m             action), \"Action, {},  not part of action space\".format(action)\n\u001b[1;32m    114\u001b[0m         \u001b[0mdemand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdemand_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Action, [0 0 0],  not part of action space"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "\n",
    "#each index of param_list is another list, param, where param[0] is r and param[1] is S\n",
    "max_order = CONFIG['max_order']\n",
    "param_list = []\n",
    "for S in range(max_order + 1):\n",
    "    for r1 in range(max_order + 1):\n",
    "        for r2 in range(max_order +1):\n",
    "            param_list.append([[r1, r2],S])\n",
    "        \n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/inventory_control_'+str(agent)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'TBS':\n",
    "        or_suite.utils.run_single_algo_tune(env, agents[agent], param_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/inventory_control_'+str(agent))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/inventory_control_'+str(agent))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee123ff",
   "metadata": {},
   "source": [
    "### Generate Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cb0038",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'inventory'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {}\n",
    "fig_name = 'inventory'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dfe78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(\"../figures/inventory_line_plot.pdf\", width=600, height=280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb7a03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(\"../figures/inventory_radar_plot.pdf\", width=600, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8b0895",
   "metadata": {},
   "source": [
    "### Results\n",
    "Here we see that the `TBS` agent also performs better than the `Random` agent for an environment that involves three suppliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f970b89",
   "metadata": {},
   "source": [
    "## Nontrivial Two Suppliers Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35da2f69",
   "metadata": {},
   "source": [
    "We now use an example environment that uses 2 suppliers, each with different lead times and costs, but where the resulting optimal action for the TBS agent does not have `r=0` or `S=0`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9443f4",
   "metadata": {},
   "source": [
    "### Experimental Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6020b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {'lead_times': [5, 7],\n",
    "           'demand_dist': lambda x: np.random.poisson(17),\n",
    "           'supplier_costs': [100 ,85],\n",
    "           'hold_cost': 1,\n",
    "           'backorder_cost': 200,\n",
    "           'max_inventory': 1000,\n",
    "           'max_order': 20,\n",
    "           'epLen': 500,\n",
    "           'starting_state': None,\n",
    "           'neg_inventory': False\n",
    "         }\n",
    "CONFIG['epLen'] = 100\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 2\n",
    "numIters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140cf206",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/ambulance/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : CONFIG['epLen'],\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "env = gym.make('MultipleSuppliers-v0', config=CONFIG)\n",
    "mon_env = Monitor(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9018752e",
   "metadata": {},
   "source": [
    "### Specifying Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc3bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = { # 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'TBS': or_suite.agents.inventory_control_multiple_suppliers.base_surge.base_surgeAgent([14,14],0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190538ed",
   "metadata": {},
   "source": [
    "### Running Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb657c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "\n",
    "#each index of param_list is another list, param, where param[0] is r and param[1] is S\n",
    "max_order = CONFIG['max_order']\n",
    "param_list = []\n",
    "for r in range(max_order+1):\n",
    "    for S in range(max_order + 1):\n",
    "        param_list.append([[r],S])\n",
    "        \n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/inventory_control_'+str(agent)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'TBS':\n",
    "        or_suite.utils.run_single_algo_tune(env, agents[agent], param_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/inventory_control_'+str(agent))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/inventory_control_'+str(agent))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa973f2",
   "metadata": {},
   "source": [
    "### Generate Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa94c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'inventory'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {}\n",
    "fig_name = 'inventory'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dbbbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(\"../figures/inventory_line_plot.pdf\", width=600, height=280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abed98c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(\"../figures/inventory_radar_plot.pdf\", width=600, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d10371",
   "metadata": {},
   "source": [
    "### Results\n",
    "Here, the `TBS` agent still performs better than the `Random` agent. However, the `r` and `S` values for the `TBS` agent are both non-zero."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
