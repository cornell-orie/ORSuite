{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54262089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import or_suite\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exclusive-roots",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidwolfers/opt/anaconda3/envs/ORSuite/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py:131: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 5`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 5\n",
      "We recommend using a `batch_size` that is a multiple of `n_steps * n_envs`.\n",
      "Info: (n_steps=5 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SB PPO\n",
      "New Experiment Run\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 8\n",
      "Iteration: 9\n",
      "10000 10000 10000 10000 10000\n",
      "Writing to file ../data/ambulance_metric_SB PPO_1_0.25_beta/data.csv\n",
      "Random\n",
      "Chosen parameters: 0.05\n",
      "Writing to file data.csv\n",
      "0.05\n",
      "Stable\n",
      "Chosen parameters: 0.5\n",
      "Writing to file data.csv\n",
      "0.5\n",
      "  Algorithm    Reward      Time      Space       MRT       RTV\n",
      "0    SB PPO -1.422057  3.226302 -6445721.6 -0.260197 -0.030403\n",
      "1    Random -1.564413  7.149539    -4622.0 -0.321921 -0.051603\n",
      "2    Stable -1.104076  7.636336    -3852.0 -0.286562 -0.065896\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Getting out configuration parameter for the environment\n",
    "CONFIG =  or_suite.envs.env_configs.ambulance_metric_default_config\n",
    "\n",
    "\n",
    "# Specifying training iteration, epLen, number of episodes, and number of iterations\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 1000\n",
    "numIters = 10\n",
    "\n",
    "# Parameters needed for the heuristic algorithms\n",
    "epsilon = (nEps * epLen)**(-1 / 4)\n",
    "action_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "state_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "\n",
    "scaling_list = [0.00005,.00025, 0.0005, 0.0025, 0.005, 0.025, 0.05, 0.25, 0.5]\n",
    "\n",
    "\n",
    "# Specifying the arrival distribution\n",
    "def beta(step):\n",
    "    return np.random.beta(5,2)\n",
    "\n",
    "\n",
    "# Configuration parameters for running the experiment\n",
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/ambulance/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, # save trajectory for calculating additional metrics\n",
    "                    'epLen' : 5,\n",
    "                    'render': False,\n",
    "                    'pickle': False # indicator for pickling final information\n",
    "                    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "alpha = CONFIG['alpha']\n",
    "arrival_dist = beta\n",
    "num_ambulance = CONFIG['num_ambulance']\n",
    "\n",
    "ambulance_env = gym.make('Ambulance-v0', config=CONFIG)\n",
    "mon_env = Monitor(ambulance_env)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# callback = or_suite.experiment.trajectory_callback.TrajectoryCallback(verbose = 1)\n",
    "\n",
    "model = PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen)\n",
    "# model.learn(total_timesteps=10, callback=callback)\n",
    "#start running experiments with the sb_experiment file from now on (make sure to edit it to facilitate this)\n",
    "\n",
    "\n",
    "agents = { 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'Stable': or_suite.agents.ambulance.stable.stableAgent(CONFIG['epLen'])\n",
    "# 'Median': or_suite.agents.ambulance.median.medianAgent(CONFIG['epLen']),\n",
    "# 'AdaQL': or_suite.agents.rl.ada_ql.AdaptiveDiscretizationQL(epLen, scaling_list[0], True, num_ambulance*2),\n",
    "# 'AdaMB': or_suite.agents.rl.ada_mb.AdaptiveDiscretizationMB(epLen, scaling_list[0], 0, 2, True, True, num_ambulance, num_ambulance),\n",
    "# 'Unif QL': or_suite.agents.rl.enet_ql.eNetQL(action_net, state_net, epLen, scaling_list[0], (num_ambulance,num_ambulance)),\n",
    "# 'Unif MB': or_suite.agents.rl.enet_mb.eNetMB(action_net, state_net, epLen, scaling_list[0], (num_ambulance,num_ambulance), 0, False),\n",
    "}\n",
    "\n",
    "\n",
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo_tune(ambulance_env, agents[agent],scaling_list,DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__))\n",
    "    algo_list_line.append(str(agent))\n",
    "    \n",
    "    path_list_radar.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__))\n",
    "    algo_list_radar.append(str(agent))\n",
    "fig_path = '../figures/'\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {'MRT': lambda traj : or_suite.utils.mean_response_time(traj, lambda x, y : np.abs(x-y)), 'RTV': lambda traj : or_suite.utils.response_time_variance(traj, lambda x, y : np.abs(x-y))}\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c60c161",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"280\"\n",
       "            src=\"../figures/ambulance_metric_1_0.25_beta_line_plot.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa345f62a30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "figureLinePlot = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_line_plot'+'.pdf'\n",
    "IFrame(\"../figures/\" + figureLinePlot, width=600, height=280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c67803d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"450\"\n",
       "            src=\"../figures/ambulance_metric_1_0.25_beta_radar_plot.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa345eeec40>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figureRadarPlot = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_radar_plot'+'.pdf'\n",
    "IFrame(\"../figures/\" + figureRadarPlot, width=600, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d11dfcb",
   "metadata": {},
   "source": [
    "Here we see with a quick set-up that the best-performing algorithm in this limited data regime is the Median algorithm, essentially putting the ambulances at the estimated median from the observed data thus far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7829c708",
   "metadata": {},
   "source": [
    "## Test 2: Uniform Arrivals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ab6cd3",
   "metadata": {},
   "source": [
    "### Experimental Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91e22b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Getting out configuration parameter for the environment\n",
    "CONFIG =  or_suite.envs.env_configs.ambulance_metric_default_config\n",
    "\n",
    "\n",
    "# Specifying training iteration, epLen, number of episodes, and number of iterations\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 100\n",
    "numIters = 2\n",
    "\n",
    "# Parameters needed for the heuristic algorithms\n",
    "epsilon = (nEps * epLen)**(-1 / 4)\n",
    "action_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "state_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "\n",
    "scaling_list = [0.1, 0.3, 1, 5]\n",
    "\n",
    "\n",
    "# Specifying the arrival distribution\n",
    "def uniform(step):\n",
    "    return np.random.uniform(0,1)\n",
    "\n",
    "\n",
    "# Configuration parameters for running the experiment\n",
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/ambulance/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, # save trajectory for calculating additional metrics\n",
    "                    'epLen' : 5,\n",
    "                    'render': False,\n",
    "                    'pickle': False # indicator for pickling final information\n",
    "                    }\n",
    "\n",
    "\n",
    "alpha = CONFIG['alpha']\n",
    "arrival_dist = uniform\n",
    "num_ambulance = CONFIG['num_ambulance']\n",
    "\n",
    "ambulance_env = gym.make('Ambulance-v0', config=CONFIG)\n",
    "mon_env = Monitor(ambulance_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11338f03",
   "metadata": {},
   "source": [
    "### Specifying Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728feb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = { 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'Stable': or_suite.agents.ambulance.stable.stableAgent(CONFIG['epLen']),\n",
    "'Median': or_suite.agents.ambulance.median.medianAgent(CONFIG['epLen']),\n",
    "'AdaQL': or_suite.agents.rl.ada_ql.AdaptiveDiscretizationQL(epLen, scaling_list[0], True, num_ambulance*2),\n",
    "'AdaMB': or_suite.agents.rl.ada_mb.AdaptiveDiscretizationMB(epLen, scaling_list[0], 0, 2, True, True, num_ambulance, num_ambulance),\n",
    "'Unif QL': or_suite.agents.rl.enet_ql.eNetQL(action_net, state_net, epLen, scaling_list[0], (num_ambulance,num_ambulance)),\n",
    "'Unif MB': or_suite.agents.rl.enet_mb.eNetMB(action_net, state_net, epLen, scaling_list[0], (num_ambulance,num_ambulance), 0, False),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcc7f2c",
   "metadata": {},
   "source": [
    "### Running Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9564fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'AdaQL' or agent == 'Unif QL' or agent == 'AdaMB' or agent == 'Unif MB':\n",
    "        or_suite.utils.run_single_algo_tune(ambulance_env, agents[agent], scaling_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(ambulance_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__))\n",
    "        algo_list_radar.append(str(agent))\n",
    "fig_path = '../figures/'\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {'MRT': lambda traj : or_suite.utils.mean_response_time(traj, lambda x, y : np.abs(x-y)), 'RTV': lambda traj : or_suite.utils.response_time_variance(traj, lambda x, y : np.abs(x-y))}\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1659e615",
   "metadata": {},
   "outputs": [],
   "source": [
    "figureLinePlot = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_line_plot'+'.pdf'\n",
    "IFrame(\"../figures/\" + figureLinePlot, width=600, height=280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a9566",
   "metadata": {},
   "outputs": [],
   "source": [
    "figureRadarPlot = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_radar_plot'+'.pdf'\n",
    "IFrame(\"../figures/\" + figureRadarPlot, width=600, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d71d0e",
   "metadata": {},
   "source": [
    "Here we again see that the median heuristic performs the best in this limited data regime by again placing ambulances close to the median of the arrival distribution (which in this setting will be at $0.5$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed69b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import or_suite\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import gym\n",
    "\n",
    "### Specifying Agent\n",
    "We specify 8 different agents to compare the effectiveness of each.\n",
    "\n",
    "* `SB PPO` is Proximal Policy Optimization. When policy is updated, there is a parameter that “clips” each policy update so that action update does not go too far\n",
    "* `Random` implements the randomized RL algorithm, which selects an action uniformly at random from the action space. In particular, the algorithm stores an internal copy of the environment’s action space and samples uniformly at random from it.\n",
    "* `AdaQL` is an Adaptive Discretization Model-Free Agent, implemented for enviroments with continuous states and actions using the metric induced by the l_inf norm.\n",
    "* `AdaMB` is an Adaptive Discretizaiton Model-Based Agent, implemented for enviroments with continuous states and actions using the metric induced by the l_inf norm.\n",
    "* `Unif QL` is an eNet Model-Based Agent, implemented for enviroments with continuous states and actions using the metric induces by the l_inf norm.\n",
    "* `Unif MB` is a eNet Model-Free Agent, implemented for enviroments with continuous states and actions using the metric induces by the l_inf norm.\n",
    "* `Stable` is an agent that only moves ambulances when responding to an incoming call and not in between calls. This means the policy $\\pi$ chosen by the agent for any given state $X$ will be $\\pi_h(X) = X$\n",
    "* `Median` is an agent that takes a list of all past call arrivals sorted by arrival location, and partitions it into $k$ quantiles where $k$ is the number of ambulances. The algorithm then selects the middle data point in each quantile as the locations to station the ambulances. \n",
    "\n",
    "\n",
    "\n",
    "# Getting out configuration parameter for the environment\n",
    "CONFIG =  or_suite.envs.env_configs.ambulance_metric_default_config\n",
    "\n",
    "\n",
    "# Specifying training iteration, epLen, number of episodes, and number of iterations\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 2\n",
    "numIters = 50\n",
    "\n",
    "# Parameters needed for the heuristic algorithms\n",
    "epsilon = (nEps * epLen)**(-1 / 4)\n",
    "action_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "state_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "\n",
    "scaling_list = [0.1, 0.3, 1, 5]\n",
    "\n",
    "\n",
    "# Specifying the arrival distribution\n",
    "def beta(step):\n",
    "    return np.random.beta(5,2)\n",
    "\n",
    "\n",
    "# Configuration parameters for running the experiment\n",
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/ambulance/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, # save trajectory for calculating additional metrics\n",
    "                    'epLen' : 5,\n",
    "                    'render': False,\n",
    "                    'pickle': False # indicator for pickling final information\n",
    "                    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "alpha = CONFIG['alpha']\n",
    "arrival_dist = beta\n",
    "num_ambulance = CONFIG['num_ambulance']\n",
    "\n",
    "ambulance_env = gym.make('Ambulance-v0', config=CONFIG)\n",
    "mon_env = Monitor(ambulance_env)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# callback = or_suite.experiment.trajectory_callback.TrajectoryCallback(verbose = 1)\n",
    "\n",
    "model = PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen)\n",
    "# model.learn(total_timesteps=10, callback=callback)\n",
    "#start running experiments with the sb_experiment file from now on (make sure to edit it to facilitate this)\n",
    "\n",
    "\n",
    "\n",
    "agents = { 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'Stable': or_suite.agents.ambulance.stable.stableAgent(CONFIG['epLen']),\n",
    "'Median': or_suite.agents.ambulance.median.medianAgent(CONFIG['epLen']),\n",
    "'AdaQL': or_suite.agents.rl.ada_ql.AdaptiveDiscretizationQL(epLen, scaling_list[0], True, num_ambulance*2),\n",
    "'AdaMB': or_suite.agents.rl.ada_mb.AdaptiveDiscretizationMB(epLen, scaling_list[0], 0, 2, True, True, num_ambulance, num_ambulance),\n",
    "'Unif QL': or_suite.agents.rl.enet_ql.eNetQL(action_net, state_net, epLen, scaling_list[0], (num_ambulance,num_ambulance)),\n",
    "'Unif MB': or_suite.agents.rl.enet_mb.eNetMB(action_net, state_net, epLen, scaling_list[0], (num_ambulance,num_ambulance), 0, False),\n",
    "}\n",
    "\n",
    "\n",
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'AdaQL' or agent == 'Unif QL' or agent == 'AdaMB' or agent == 'Unif MB':\n",
    "        or_suite.utils.run_single_algo_tune(ambulance_env, agents[agent], scaling_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(ambulance_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__))\n",
    "    algo_list_line.append(str(agent))\n",
    "    \n",
    "    path_list_radar.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__))\n",
    "    algo_list_radar.append(str(agent))\n",
    "fig_path = '../figures/'\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {'MRT': lambda traj : or_suite.utils.mean_response_time(traj, lambda x, y : np.abs(x-y)), 'RTV': lambda traj : or_suite.utils.response_time_variance(traj, lambda x, y : np.abs(x-y))}\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import IFrame\n",
    "figureLinePlot = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_line_plot'+'.pdf'\n",
    "IFrame(\"../figures/\" + figureLinePlot, width=600, height=280)\n",
    "\n",
    "figureRadarPlot = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_radar_plot'+'.pdf'\n",
    "IFrame(\"../figures/\" + figureRadarPlot, width=600, height=450)\n",
    "\n",
    "Here we see with a quick set-up that the best-performing algorithm in this limited data regime is the Median algorithm, essentially putting the ambulances at the estimated median from the observed data thus far.\n",
    "\n",
    "## Test 2: Uniform Arrivals\n",
    "\n",
    "### Experimental Parameters\n",
    "\n",
    "\n",
    "# Getting out configuration parameter for the environment\n",
    "CONFIG =  or_suite.envs.env_configs.ambulance_metric_default_config\n",
    "\n",
    "\n",
    "# Specifying training iteration, epLen, number of episodes, and number of iterations\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 100\n",
    "numIters = 2\n",
    "\n",
    "# Parameters needed for the heuristic algorithms\n",
    "epsilon = (nEps * epLen)**(-1 / 4)\n",
    "action_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "state_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "\n",
    "scaling_list = [0.1, 0.3, 1, 5]\n",
    "\n",
    "\n",
    "# Specifying the arrival distribution\n",
    "def uniform(step):\n",
    "    return np.random.uniform(0,1)\n",
    "\n",
    "\n",
    "# Configuration parameters for running the experiment\n",
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/ambulance/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, # save trajectory for calculating additional metrics\n",
    "                    'epLen' : 5,\n",
    "                    'render': False,\n",
    "                    'pickle': False # indicator for pickling final information\n",
    "                    }\n",
    "\n",
    "\n",
    "alpha = CONFIG['alpha']\n",
    "arrival_dist = uniform\n",
    "num_ambulance = CONFIG['num_ambulance']\n",
    "\n",
    "ambulance_env = gym.make('Ambulance-v0', config=CONFIG)\n",
    "mon_env = Monitor(ambulance_env)\n",
    "\n",
    "### Specifying Agents\n",
    "\n",
    "agents = { 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'Stable': or_suite.agents.ambulance.stable.stableAgent(CONFIG['epLen']),\n",
    "'Median': or_suite.agents.ambulance.median.medianAgent(CONFIG['epLen']),\n",
    "'AdaQL': or_suite.agents.rl.ada_ql.AdaptiveDiscretizationQL(epLen, scaling_list[0], True, num_ambulance*2),\n",
    "'AdaMB': or_suite.agents.rl.ada_mb.AdaptiveDiscretizationMB(epLen, scaling_list[0], 0, 2, True, True, num_ambulance, num_ambulance),\n",
    "'Unif QL': or_suite.agents.rl.enet_ql.eNetQL(action_net, state_net, epLen, scaling_list[0], (num_ambulance,num_ambulance)),\n",
    "'Unif MB': or_suite.agents.rl.enet_mb.eNetMB(action_net, state_net, epLen, scaling_list[0], (num_ambulance,num_ambulance), 0, False),\n",
    "}\n",
    "\n",
    "### Running Algorithm\n",
    "\n",
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'AdaQL' or agent == 'Unif QL' or agent == 'AdaMB' or agent == 'Unif MB':\n",
    "        or_suite.utils.run_single_algo_tune(ambulance_env, agents[agent], scaling_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(ambulance_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__))\n",
    "        algo_list_radar.append(str(agent))\n",
    "fig_path = '../figures/'\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {'MRT': lambda traj : or_suite.utils.mean_response_time(traj, lambda x, y : np.abs(x-y)), 'RTV': lambda traj : or_suite.utils.response_time_variance(traj, lambda x, y : np.abs(x-y))}\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n",
    "\n",
    "figureLinePlot = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_line_plot'+'.pdf'\n",
    "IFrame(\"../figures/\" + figureLinePlot, width=600, height=280)\n",
    "\n",
    "figureRadarPlot = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_radar_plot'+'.pdf'\n",
    "IFrame(\"../figures/\" + figureRadarPlot, width=600, height=450)\n",
    "\n",
    "Here we again see that the median heuristic performs the best in this limited data regime by again placing ambulances close to the median of the arrival distribution (which in this setting will be at $0.5$)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
