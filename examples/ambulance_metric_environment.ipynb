{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "divided-unknown",
   "metadata": {},
   "source": [
    "# Ambulance Routing on Metric Space\n",
    "\n",
    "One potential application of reinforcement learning involves positioning a server or servers (in this case an ambulance) in an optimal way geographically to respond to incoming calls while minimizing the distance traveled by the servers. This is closely related to the [k-server problem](https://en.wikipedia.org/wiki/K-server_problem), where there are $k$ servers stationed in a space that must respond to requests arriving in that space in such a way as to minimize the total distance traveled. \n",
    "\n",
    "The ambulance routing problem addresses the problem by modeling an environment where there are ambulances stationed at locations, and calls come in that one of the ambulances must be sent to respond to. The goal of the agent is to minimize both the distance traveled by the ambulances between calls and the distance traveled to respond to a call by optimally choosing the locations to station the ambulances. The ambulance environment has been implemented in two different ways; as a 1-dimensional number line $[0,1]$ along which ambulances will be stationed and calls will arrive, and a graph with nodes where ambulances can be stationed and calls can arrive, and edges between the nodes that ambulances travel along."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-income",
   "metadata": {},
   "source": [
    "In this notebook, we walk through the Ambulance Routing problem with a 1-dimensional reinforcement learning environment in the space $X = [0, 1]$. Each ambulance in the problem can be located anywhere in $X$, so the state space is $S = X^k$, where $k$ is the number of ambulances. For this example there will be only one ambulance, so $k = 1$.\n",
    "\n",
    "The default distribution for call arrivals is $Beta(5, 2)$ over $[0,1]$, however any probability distribution defined over the interval $[0,1]$ is valid. The probability distribution can also change with each timestep.\n",
    "\n",
    "For example, in a problem with two ambulances, imagine the ambulances are initially located at $0.4$ and $0.6$, and the distance function being used is the $\\ell_1$ norm. The agent could choose to move the ambulances to $0.342$ and $0.887$. If a call arrived at $0.115$, ambulance 1, which was at $0.342$, would respond to that call, and the state at the end of the iteration would be ambulance 1 at $0.115$ and ambulance 2 at $0.887$. The agent could then choose new locations to move the ambulances to, and the cycle would repeat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-universe",
   "metadata": {},
   "source": [
    "### Package Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54262089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import or_suite\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-burst",
   "metadata": {},
   "source": [
    "\n",
    "Here we use the ambulance metric environment as outlined in `or_suite/envs/ambulance/ambulance_metric.py`.  The package has default specifications for all of the environments in the file `or_suite/envs/env_configs.py`, and so we use one the default for the ambulance problem in a metric space.\n",
    "\n",
    "In addition, we need to specify the number of episodes for learning, and the number of iterations (in order to plot average results with confidence intervals)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313d5366",
   "metadata": {},
   "source": [
    "### Test One: Beta Arrivals\n",
    "\n",
    "In this first test we set the arrival distribution to be Beta(5,2)"
   ]
  },
      {
   "cell_type": "markdown",
   "id": "revolutionary-universe",
   "metadata": {},
   "source": [
    "### Experimental Parameters\n",
    "\n",
       "\n",
    "The ambulance routing problem has several experiment parameters\n",
    "* The parameter `epLen`, an int, number of time steps to run the experiment for \n",
    "* `arrival_dist`,a lambda, is the arrival distribution for calls over the space [0,1]. This takes an integer (step) and returns a float between 0 and 1. \n",
    "* `nEps` is an int representing the number of episodes. The default is set to 2. \n",
    "* `numIters`, an int, is the number of iterations. Here it is set to 50. \n",
    "* `seed` allows random numbers to be generated. \n",
    "* `dirPath`, a string, is the location where the data files are stored.\n",
    "* `deBug`, a bool, prints information to the command line when set true. \n",
    "* `save_trajectory`, a bool, saves the trajectory information of the ambulance when set to true. \n",
    "* `render` renders the algorithm when set to true.\n",
    "* `pickle` is a bool that saves the information to a pickle file when set to true.\n",
    "* `alpha`, a float controlling the proportional difference between the cost to move ambulances in between calls and the cost to move the ambulance to respond to a call. If `alpha` is 0, there is no cost to move between calls. If `alpha` is one, there is no cost to respond to calls.\n",
    "* `num_ambulance`, an int which represents the number of ambulances in the system. \n",
    "* `starting_state` is a float list containing the starting locations for each ambulance \n",
    "* `state`, an int list, representing the current state of the environment \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exclusive-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Getting out configuration parameter for the environment\n",
    "CONFIG =  or_suite.envs.env_configs.ambulance_metric_default_config\n",
    "\n",
    "\n",
    "# Specifying training iteration, epLen, number of episodes, and number of iterations\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 2\n",
    "numIters = 50\n",
    "\n",
    "# Parameters needed for the heuristic algorithms\n",
    "epsilon = (nEps * epLen)**(-1 / 4)\n",
    "action_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "state_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "\n",
    "scaling_list = [0.1, 0.3, 1, 5]\n",
    "\n",
    "\n",
    "# Specifying the arrival distribution\n",
    "def beta(step):\n",
    "    return np.random.beta(5,2)\n",
    "\n",
    "\n",
    "# Configuration parameters for running the experiment\n",
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/ambulance/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, # save trajectory for calculating additional metrics\n",
    "                    'epLen' : 5,\n",
    "                    'render': False,\n",
    "                    'pickle': False # indicator for pickling final information\n",
    "                    }\n",
    "\n",
    "\n",
    "alpha = CONFIG['alpha']\n",
    "arrival_dist = beta\n",
    "num_ambulance = CONFIG['num_ambulance']\n",
    "\n",
    "ambulance_env = gym.make('Ambulance-v0', config=CONFIG)\n",
    "mon_env = Monitor(ambulance_env)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-shooting",
   "metadata": {},
   "source": [
    "### Specifying Agent\n",
    "We have several heuristics implemented for each of the environments defined, in addition to a `Random` policy, and some `RL discretization based` algorithms. \n",
    "\n",
    "The `Stable` agent only moves ambulances when responding to an incoming call and not in between calls. This means the policy $\\pi$ chosen by the agent for any given state $X$ will be $\\pi_h(X) = X$\n",
    "\n",
    "The `Median` agent takes a list of all past call arrivals sorted by arrival location, and partitions it into $k$ quantiles where $k$ is the number of ambulances. The algorithm then selects the middle data point in each quantile as the locations to station the ambulances. \n",
    "\n",
    "The `Mode` agent chooses to stattion the ambulances at the nodes where the most calls have come in the past. This uses the policy $\\pi$ chosen by a state $X$ will be $\\pi_h(X) = $`mode` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "comprehensive-amplifier",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/anaconda3/envs/ORSuite/lib/python3.7/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 5`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 5\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=5 and n_envs=1)\n",
      "  f\"You have specified a mini-batch size of {batch_size},\"\n"
     ]
    }
   ],
   "source": [
    "agents = { 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'Stable': or_suite.agents.ambulance.stable.stableAgent(CONFIG['epLen']),\n",
    "'Median': or_suite.agents.ambulance.median.medianAgent(CONFIG['epLen']),\n",
    "'AdaQL': or_suite.agents.rl.ada_ql.AdaptiveDiscretizationQL(epLen, scaling_list[0], True, num_ambulance*2),\n",
    "'AdaMB': or_suite.agents.rl.ada_mb.AdaptiveDiscretizationMB(epLen, scaling_list[0], 0, 2, True, True, num_ambulance, num_ambulance),\n",
    "'Unif QL': or_suite.agents.rl.enet_ql.eNetQL(action_net, state_net, epLen, scaling_list[0], (num_ambulance,num_ambulance)),\n",
    "'Unif MB': or_suite.agents.rl.enet_mb.eNetMB(action_net, state_net, epLen, scaling_list[0], (num_ambulance,num_ambulance), 0, False),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-dublin",
   "metadata": {},
   "source": [
    "### Specifying Agent\n",
    "Run the different heuristics in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "honest-equipment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SB PPO\n",
      "Writing to file ../data/ambulance_metric_SB PPO_1_0.25_beta/data.csv\n",
      "Random\n",
      "Writing to file data.csv\n",
      "Stable\n",
      "Writing to file data.csv\n",
      "Median\n",
      "Writing to file data.csv\n",
      "AdaQL\n",
      "Writing to file data.csv\n",
      "0.1\n",
      "AdaMB\n",
      "Writing to file data.csv\n",
      "0.1\n",
      "Unif QL\n",
      "Writing to file data.csv\n",
      "1\n",
      "Unif MB\n",
      "Writing to file data.csv\n",
      "0.1\n",
      "  Algorithm    Reward      Time   Space       MRT       RTV\n",
      "0    Random -1.883535  7.312215 -5022.0 -0.321546 -0.051930\n",
      "1    Stable -1.001835  7.830615 -4012.0 -0.291050 -0.065029\n",
      "2    Median -0.658575  6.767415 -4776.0 -0.135620 -0.011065\n",
      "3     AdaQL -0.837780  6.393955 -5716.0 -0.222062 -0.031312\n",
      "4     AdaMB -1.027855  6.608590 -4700.0 -0.208191 -0.025374\n",
      "5   Unif QL -1.295775  7.018440 -4596.0 -0.283919 -0.051300\n",
      "6   Unif MB -0.514845  6.284035 -4604.0 -0.229288 -0.037576\n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'AdaQL' or agent == 'Unif QL' or agent == 'AdaMB' or agent == 'Unif MB':\n",
    "        or_suite.utils.run_single_algo_tune(ambulance_env, agents[agent], scaling_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(ambulance_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__))\n",
    "        algo_list_radar.append(str(agent))\n",
    "fig_path = '../figures/'\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {'MRT': lambda traj : or_suite.utils.mean_response_time(traj, lambda x, y : np.abs(x-y)), 'RTV': lambda traj : or_suite.utils.response_time_variance(traj, lambda x, y : np.abs(x-y))}\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d11dfcb",
   "metadata": {},
   "source": [
    "Here we see with a quick set-up that the best-performing algorithm in this limited data regime is the Median algorithm, essentially putting the ambulances at the estimated median from the observed data thus far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7829c708",
   "metadata": {},
   "source": [
    "### Test 2: Uniform Arrivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91e22b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/anaconda3/envs/ORSuite/lib/python3.7/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 5`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 5\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=5 and n_envs=1)\n",
      "  f\"You have specified a mini-batch size of {batch_size},\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SB PPO\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Getting out configuration parameter for the environment\n",
    "CONFIG =  or_suite.envs.env_configs.ambulance_metric_default_config\n",
    "\n",
    "\n",
    "# Specifying training iteration, epLen, number of episodes, and number of iterations\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 100\n",
    "numIters = 2\n",
    "\n",
    "# Parameters needed for the heuristic algorithms\n",
    "epsilon = (nEps * epLen)**(-1 / 4)\n",
    "action_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "state_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "\n",
    "scaling_list = [0.1, 0.3, 1, 5]\n",
    "\n",
    "\n",
    "# Specifying the arrival distribution\n",
    "def uniform(step):\n",
    "    return np.random.uniform(0,1)\n",
    "\n",
    "\n",
    "# Configuration parameters for running the experiment\n",
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/ambulance/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, # save trajectory for calculating additional metrics\n",
    "                    'epLen' : 5,\n",
    "                    'render': False,\n",
    "                    'pickle': False # indicator for pickling final information\n",
    "                    }\n",
    "\n",
    "\n",
    "alpha = CONFIG['alpha']\n",
    "arrival_dist = uniform\n",
    "num_ambulance = CONFIG['num_ambulance']\n",
    "\n",
    "ambulance_env = gym.make('Ambulance-v0', config=CONFIG)\n",
    "mon_env = Monitor(ambulance_env)\n",
    "\n",
    "agents = { 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'Stable': or_suite.agents.ambulance.stable.stableAgent(CONFIG['epLen']),\n",
    "'Median': or_suite.agents.ambulance.median.medianAgent(CONFIG['epLen']),\n",
    "'AdaQL': or_suite.agents.rl.ada_ql.AdaptiveDiscretizationQL(epLen, scaling_list[0], True, num_ambulance*2),\n",
    "'AdaMB': or_suite.agents.rl.ada_mb.AdaptiveDiscretizationMB(epLen, scaling_list[0], 0, 2, True, True, num_ambulance, num_ambulance),\n",
    "'Unif QL': or_suite.agents.rl.enet_ql.eNetQL(action_net, state_net, epLen, scaling_list[0], (num_ambulance,num_ambulance)),\n",
    "'Unif MB': or_suite.agents.rl.enet_mb.eNetMB(action_net, state_net, epLen, scaling_list[0], (num_ambulance,num_ambulance), 0, False),\n",
    "}\n",
    "\n",
    "\n",
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'AdaQL' or agent == 'Unif QL' or agent == 'AdaMB' or agent == 'Unif MB':\n",
    "        or_suite.utils.run_single_algo_tune(ambulance_env, agents[agent], scaling_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(ambulance_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__))\n",
    "        algo_list_radar.append(str(agent))\n",
    "fig_path = '../figures/'\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {'MRT': lambda traj : or_suite.utils.mean_response_time(traj, lambda x, y : np.abs(x-y)), 'RTV': lambda traj : or_suite.utils.response_time_variance(traj, lambda x, y : np.abs(x-y))}\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d71d0e",
   "metadata": {},
   "source": [
    "Here we again see that the median heuristic performs the best in this limited data regime by again placing ambulances close to the median of the arrival distribution (which in this setting will be at $0.5$)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
